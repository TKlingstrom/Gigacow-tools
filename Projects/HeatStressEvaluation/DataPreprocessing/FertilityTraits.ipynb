{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT TO GENERATE FERTILITY TRAITS AND ADD THI DATA\n",
    "\n",
    "Script assuming that either of the following programs have been run in order to generate \"updateDF.csv\":\n",
    "1. \"HeatStressCleanWorkFlow.ipynb\" (old process code) or \n",
    "2. \"BuildingDataset.ipynb\" (advised)\n",
    "\n",
    "\"updateDF.csv\" has the following sturcture:\n",
    "- SE_Number, LactationNumber, Breed, FarmName_Pseudo, AnimalNumber, Del_Cow_Id, BirthDate, Father_SE_Number, Mother_SE_Number,\n",
    "- CalvingDate, upper_limit, InseminationDate, PregnancyCheckDate, PregnancyStatus, DryOffDate, CullingDate,\n",
    "- ExitReason_PrimaryReasonKok, ExitReason_SecondaryReason1Kok, ExitReason_SecondaryReason2Kok, CullingReason1, CullingReason2,\n",
    "- next_calving, next_ins, prev_ins, prev_calf\n",
    "\n",
    "This script creates the following fertility traits\n",
    "- NINS: Number of inseminations\n",
    "- CFI: Interval from calving to first service\n",
    "- CLI: Interval from calving to last service\n",
    "- FLI: Interval from first to last service\n",
    "- CI: Calving interval\n",
    "- GL: Gestation length\n",
    "- CR: Conception rate\n",
    "\n",
    "Adding THI data from \"MY_weather.csv\"\n",
    "- Including an indicator of whether or not the cow has been put through heat stress conditions (i.e. temperatures above THI_adj 61 or 67) 7 days prior to and 7 days after insemination in order to cover estrus, insemination and early embryonic development (called HeatStress)\n",
    "- Also a counting indicator within each insemination (called HS_sum)\n",
    "\n",
    "This script generates \"fertilityDF_W.csv\" which contains the following columns: NOTE! without MY306d\n",
    "- SE_Number,LactationNumber,InseminationDate,NINS_bw,Breed,FarmName_Pseudo,AnimalNumber,Del_Cow_Id,\n",
    "- BirthDate,Father_SE_Number,Mother_SE_Number,CalvingDate,PregnancyCheckDate,PregnancyStatus,DryOffDate,\n",
    "- CullingDate,ExitReason_PrimaryReasonKok,ExitReason_SecondaryReason1Kok,ExitReason_SecondaryReason2Kok,CullingReason1,CullingReason2,\n",
    "- next_calving,next_ins,prev_ins,shift_calf,upper_limit,NINS,CFI,CLI,FLI,InseminationDate_last,CI,GL,ins_within_cycle,CR0,CR1,CR4,\n",
    "- preg_period,CR5,CR6,CR7,prev_lact,non_consec_calving,ins_int,CR8a,CR8b,CR8aa,CR8bb,CR8cc,\n",
    "- SalesDate1,SalesDate2,first_ins_before_sold,service_period1_end,first_ins_after_sold,service_period2_end,CR9a,CR9b,\n",
    "- last_ins,last_preg_check,CR10,date_extraction,extraction_limit,lact_length,extraction_to_last_ins,CR11,HS_sum,HeatStress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "df_ins2d = pd.read_csv(\"../Data/MergedData/updateDF.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NINS - NUMBER OF INSEMINATIONS\n",
    "ins_count = df_ins2d.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"InseminationDate\"])\n",
    "ins_count = (ins_count.groupby([\"SE_Number\", 'LactationNumber']).size().reset_index(name='NINS'))\n",
    "df_ins2d = df_ins2d.merge(ins_count, on=[\"SE_Number\", \"LactationNumber\"], how=\"left\")\n",
    "df_ins2d.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFI - INTERVAL FROM CALVING TO FIRST SERVICE\n",
    "# CLI - INTERVAL FROM CALVING TO LAST SERVICE\n",
    "# FLI - INTERVAL FROM FIRST TO LAST SERVICE\n",
    "# Group by cow and lactation, and get the first and last inseminations\n",
    "first_observations = (df_ins2d.groupby([\"SE_Number\", \"LactationNumber\"]).first().reset_index())\n",
    "last_observations = (df_ins2d.groupby([\"SE_Number\", \"LactationNumber\"]).last().reset_index())\n",
    "\n",
    "print(last_observations.columns)\n",
    "print(len(last_observations.columns))\n",
    "\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"InseminationDate\"]\n",
    "first_observations = first_observations[col_keep]\n",
    "\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"InseminationDate\"]\n",
    "last_observations = last_observations[col_keep]\n",
    "\n",
    "# Rename the columns of the last observations df to distinguish them\n",
    "last_observations.rename(columns={\n",
    "    \"CalvingDate\": \"CalvingDate_last\",\n",
    "    \"InseminationDate\": \"InseminationDate_last\",\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Concatenate first and last observations df side by side\n",
    "df_ins2e = pd.concat([first_observations, last_observations.iloc[:, 2:]], axis=1)\n",
    "\n",
    "# Convert columns to datetime objects\n",
    "df_ins2e[\"InseminationDate\"] = pd.to_datetime(df_ins2e[\"InseminationDate\"])\n",
    "df_ins2e[\"InseminationDate_last\"] = pd.to_datetime(df_ins2e[\"InseminationDate_last\"])\n",
    "df_ins2e[\"CalvingDate\"] = pd.to_datetime(df_ins2e[\"CalvingDate\"])\n",
    "df_ins2e[\"CalvingDate_last\"] = pd.to_datetime(df_ins2e[\"CalvingDate_last\"])\n",
    "\n",
    "# Calculate fertility traits\n",
    "df_ins2e[\"CFI\"] = (df_ins2e[\"InseminationDate\"] - df_ins2e[\"CalvingDate\"]).dt.days\n",
    "df_ins2e[\"CLI\"] = (df_ins2e[\"InseminationDate_last\"] - df_ins2e[\"CalvingDate_last\"]).dt.days\n",
    "df_ins2e[\"FLI\"] = (df_ins2e[\"InseminationDate_last\"] - df_ins2e[\"InseminationDate\"]).dt.days\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"CFI\", \"CLI\", \"FLI\", \"InseminationDate_last\"]\n",
    "df_ins2e = df_ins2e[col_keep]\n",
    "\n",
    "df_ins2f = df_ins2d.merge(df_ins2e, on=[\"SE_Number\", \"LactationNumber\"], how=\"left\")\n",
    "df_ins2f.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI - CALVING INTERVAL\n",
    "df_ins2g = df_ins2f.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"next_calving\"])\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"next_calving\"]\n",
    "df_ins2g = df_ins2g[col_keep]\n",
    "df_ins2g[\"CalvingDate\"] = pd.to_datetime(df_ins2g[\"CalvingDate\"])\n",
    "df_ins2g[\"next_calving\"] = pd.to_datetime(df_ins2g[\"next_calving\"])\n",
    "df_ins2g[\"CI\"] = (df_ins2g[\"next_calving\"] - df_ins2g[\"CalvingDate\"]).dt.days\n",
    "df_ins2g.drop(columns=[\"CalvingDate\", \"next_calving\"], inplace=True)\n",
    "\n",
    "df_ins2h = df_ins2f.merge(df_ins2g, on=[\"SE_Number\", \"LactationNumber\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GL - GESTATION LENGTH\n",
    "# i.e. length from last insemination to next calving\n",
    "df_ins2h[\"InseminationDate_last\"] = pd.to_datetime(df_ins2h[\"InseminationDate_last\"])\n",
    "df_ins2h[\"next_calving\"] = pd.to_datetime(df_ins2h[\"next_calving\"])\n",
    "df_ins2h[\"GL\"] = (df_ins2h[\"next_calving\"] - df_ins2h[\"InseminationDate_last\"]).dt.days\n",
    "df_ins2h.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCEPTION RATE - script not finished\n",
    "- see Appendix 2 in \"NAV official genetic evaluation of Dairy Cattle - data and genetic models\" for full description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATIONS\n",
    "# Make insemination interval to later sort insemination in the same cycle (<= 6 days)\n",
    "df[\"next_ins\"] = pd.to_datetime(df[\"next_ins\"])\n",
    "df[\"InseminationDate\"] = pd.to_datetime(df[\"InseminationDate\"])\n",
    "df[\"ins_within_cycle\"] = (df[\"next_ins\"] - df[\"InseminationDate\"]).dt.days\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df['PregnancyStatus'].value_counts()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REORDER PregnancyStatus\n",
    "df[\"PregnancyStatus\"] = df[\"PregnancyStatus\"].replace(\n",
    "    {2: \"Positive\",\n",
    "     22: \"Positive\",\n",
    "     42: \"Positive\",\n",
    "     52: \"Positive\",\n",
    "     \n",
    "     1: \"Negative\",\n",
    "     21: \"Negative\",\n",
    "     51: \"Negative\",\n",
    "     \n",
    "     3: \"Uncertain\",\n",
    "     53: \"Uncertain\"\n",
    "     })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary value\n",
    "Each new insemination is preliminarily set to successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining phenotypes for conception rate\n",
    "df[\"CR0\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New ins, same cycle, pregnancy checks\n",
    "CR0 is updated based on new data for each insemination record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cr1(row):\n",
    "    # If followed by a new insemination the former CR is set to CR=0\n",
    "    if pd.notna(row[\"next_ins\"]):\n",
    "        return 0\n",
    "    # Set former CR to missing if the cow was inseminated in the same cycle (<= 6 days).\n",
    "    if row[\"ins_within_cycle\"] <= 6:\n",
    "        return np.nan\n",
    "    # Pregnancy checks: the last insemination is updated accordingly.\n",
    "    if pd.notna(row[\"PregnancyCheckDate\"]):\n",
    "        if row[\"PregnancyStatus\"] == \"Negative\":\n",
    "            return 0\n",
    "        elif row[\"PregnancyStatus\"] == \"Positive\":\n",
    "            return 1\n",
    "\n",
    "\n",
    "# Apply the function to df\n",
    "df['CR1'] = df.apply(cr1, axis=1)\n",
    "\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values including NaNs for several columns\n",
    "columns_to_count = ['CR0', 'CR1']  # List of columns you want to count unique values for\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "# Print the result\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check occurrence\n",
    "df5 = df[pd.isna(df[\"CR1\"])]\n",
    "df5.to_csv(\"../Data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ERRONEOUS UPDATE\n",
    "# Update CR0 with CR1 wherever CR1 has data (including NaN, 0, 1)\n",
    "df['CR0'] = df['CR1'].combine_first(df['CR0'])\n",
    "# df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CR0'] = df['CR1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values including NaNs for several columns\n",
    "columns_to_count = ['CR0', 'CR1']  # List of columns you want to count unique values for\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "# Print the result\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early abortion\n",
    "If a cow faced an early abortion, i.e., insemination started again after successful pregnancy check, the last insemination before pregnancy check is left as successful. \n",
    "- E.g. SE-5b581702-1851, LactationNumber 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cr4(row):\n",
    "    if pd.notna(row[\"PregnancyCheckDate\"]):\n",
    "        if row[\"PregnancyStatus\"] == \"Positive\":\n",
    "            if pd.notna(row[\"next_ins\"]):\n",
    "                return 1\n",
    "#            if pd.isna(row[\"next_ins\"]):\n",
    "#                return np.nan\n",
    "#    else:\n",
    "#        return 2\n",
    "\n",
    "\n",
    "# Apply the function to df\n",
    "df['CR4'] = df.apply(cr4, axis=1)\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CR0 with CR4 only where CR4 is not missing\n",
    "df.loc[df['CR4'].notna(), 'CR0'] = df['CR4']\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CR0'] = np.where(df['CR4'] == 1, 1, df['CR0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values\n",
    "columns_to_count = ['CR0', 'CR1', 'CR4']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "# Print the result\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregnancy period\n",
    "After calving, it is checked whether the last insemination is within the limits of acceptable pregnancy period (260-302 days).\n",
    "\n",
    "If the pregnancy period is shorter, it is checked iteratively whether some of\n",
    "the former/previous inseminations are within acceptable limits, in which case insemination\n",
    "for this day is set to 1. All inseminations that are newer than/ie after this successful\n",
    "insemination are set to missing values. E.g. SE-5b581702-1756, LactationNumber 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pregnancy period\n",
    "df[\"next_calving\"] = pd.to_datetime(df[\"next_calving\"])\n",
    "df[\"preg_period\"] = (df['next_calving'] - df['InseminationDate']).dt.days\n",
    "df[\"CR5\"] = np.nan\n",
    "\n",
    "# If the pregnancy period is longer, the last insemination is set to zero (possible that a farm bull was used).\n",
    "def cr5(row):\n",
    "    if pd.notna(row[\"preg_period\"]):  # Ensure preg_period is valid\n",
    "        if 260 <= row[\"preg_period\"] <= 302:\n",
    "            return 1  # Valid insemination\n",
    "        elif row[\"preg_period\"] > 302:\n",
    "            return 0  # Too long pregnancy period\n",
    "\n",
    "# Apply the cr5 function\n",
    "df['CR5'] = df.apply(cr5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CR0'] = np.where(df['CR5'].notna(), df['CR5'], df['CR0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values \n",
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5'] \n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "# Print the result\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate with 2 because have to overwrite with 1s and NaNs\n",
    "df[\"CR6\"] = 2\n",
    "\n",
    "\n",
    "# Iterate through rows and handle pregnancy period less than 260 days\n",
    "for i in df.index:\n",
    "    if df.loc[i, \"preg_period\"] < 260:\n",
    "        # Filter for valid previous inseminations (preg_period between 260 and 302 days) up to the current row\n",
    "        valid_prev = df.loc[:i]\n",
    "        valid_prev = valid_prev[(valid_prev['preg_period'] >= 260) & (valid_prev['preg_period'] <= 302)]\n",
    "        \n",
    "        if not valid_prev.empty:\n",
    "            # If valid previous insemination exists, get the last valid index\n",
    "            last_valid_index = valid_prev.index[-1]\n",
    "            df.at[last_valid_index, \"CR6\"] = 1  # Update CR6 to 1 for the last valid insemination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values \n",
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6'] \n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process each group\n",
    "def cr6(group):\n",
    "    # Ensure the condition is applied to the Series and `.any()` works correctly\n",
    "    if group['CR6'].eq(1).any():  # Check if any insemination in the group has CR6 == 1\n",
    "        # Set rows to NaN or retain 1 based on conditions\n",
    "        group.loc[group['CR6'] != 1, 'CR6'] = np.nan  # Set rows where CR6 != 1 to NaN\n",
    "        group.loc[group['CR6'] == 1, 'CR6'] = 1      # Ensure rows with CR6 == 1 retain their value\n",
    "    return group\n",
    "\n",
    "# Apply the function group by group\n",
    "df = df.groupby(['SE_Number', 'LactationNumber']).apply(cr6)\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Define a function to process each group, ==========================================================>>> does same as above, only run one of these cells!\n",
    "def cr6(group):\n",
    "    if (group['CR6'] == 1).any():  # Check if any insemination in the group has CR6 == 1\n",
    "        # Set rows to NaN or retain 1 based on conditions\n",
    "        group.loc[group['CR6'] != 1, 'CR6'] = np.nan  # Set to NaN based on condition\n",
    "        group.loc[group['CR6'] == 1, 'CR6'] = 1      # Retain 1 for specific condition\n",
    "    return group\n",
    "\n",
    "# Apply the function group by group\n",
    "df = df.groupby(['SE_Number', 'LactationNumber']).apply(cr6)\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload dataset cuz index\n",
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values \n",
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6']  \n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CR0'] = df['CR6'].where((df['CR6'] == 1) | (df['CR6'].isna()), df['CR0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values \n",
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index.names)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For checking example cow\n",
    "SE_Number = [\"SE-5b581702-1756\"]\n",
    "df5 = df[df[\"SE_Number\"].isin(SE_Number)]\n",
    "\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"InseminationDate\", \"PregnancyCheckDate\", \"prev_ins\", \"next_ins\", \"preg_period\", \"CR0\", \"CR5\", \"CR6\"]\n",
    "df5 = df5[col_keep]\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NINS = 1\n",
    "Special case for defining phenotypes: if there is only one insemination record (i.e. NINS = 1) and\n",
    "positive pregnancy check result after this, the last insemination is accepted as\n",
    "successful, even if the pregnancy period is too short (<260d), i.e., too early calving occurred.\n",
    "- E.g. SE-5b581702-1756, SE-4b8091ac-1472, LactationNumber 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate with 2 and overwrite with 1s\n",
    "df[\"CR7\"] = 2\n",
    "\n",
    "\n",
    "def cr7(row):\n",
    "    if (row[\"NINS\"] == 1) and (row[\"PregnancyStatus\"] == \"Positive\") and (row[\"preg_period\"] < 260):\n",
    "        return 1\n",
    "\n",
    "\n",
    "# Apply the function to df\n",
    "df[\"CR7\"] = df.apply(cr7, axis=1)\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CR0'] = df['CR7'].where((df['CR7'] == 1), df['CR0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values\n",
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7'] \n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-consecutive calvings or (re-?)started inseminations\n",
    "If a non-consecutive calving was noticed or a cow started with insemination records (again? after long period of pregnancy??),\n",
    "inseminations that were done within 365 days from the new calving are considered.\n",
    "This means that with an average pregnancy period of 281 days and an average cycle\n",
    "of 21 days, as a maximum 5 inseminations are included for the new calving.\n",
    "All earlier inseminations are set to missing values.\n",
    "e.g. SE-5b581702-1742, lact 1 and lact 3, i.e. lact 2 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make variable for non-consecutive calving, ie where != 1 means have non_concec_calving\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\"]\n",
    "df2 = df[col_keep]\n",
    "df2 = df2.drop_duplicates(subset=['SE_Number', 'LactationNumber'])\n",
    "\n",
    "df2['prev_lact'] = df2.groupby('SE_Number')['LactationNumber'].shift(-1)\n",
    "df2[\"non_consec_calving\"] = (df2[\"prev_lact\"] - df2[\"LactationNumber\"])\n",
    "df2.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)\n",
    "\n",
    "# Merge onto other df\n",
    "print(df2.shape) \n",
    "print(df.shape)  \n",
    "df = pd.merge(df, df2, on=[\"SE_Number\", \"LactationNumber\"], how=\"left\")\n",
    "print(df.shape)  \n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)\n",
    "\n",
    "# Occurence of non-consecutive calvings\n",
    "subset_df = df.drop_duplicates(subset=['SE_Number', 'LactationNumber'])\n",
    "print(subset_df.shape)  \n",
    "subset_df2 = subset_df[subset_df[\"non_consec_calving\"] > 1]\n",
    "print(subset_df2.shape)  # 2 lact where missing lactations? if 0 don't have non-consecutive calvings in current dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To handle non-consecutive calving or ins within longer service period\n",
    "df.loc[df[\"non_consec_calving\"] > 1, \"next_calving\"] = df[\"upper_limit\"]\n",
    "df[\"upper_limit\"] = pd.to_datetime(df[\"upper_limit\"])\n",
    "df[\"InseminationDate\"] = pd.to_datetime(df[\"InseminationDate\"])\n",
    "\n",
    "df[\"ins_int\"] = df[\"upper_limit\"] - pd.Timedelta(days=365)\n",
    "df[\"ins_int\"] = pd.to_datetime(df[\"ins_int\"])\n",
    "\n",
    "#Make NINS that is counted backwards from calving i.e. last ins record is first NINS\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"InseminationDate\"]\n",
    "df3 = df[col_keep]\n",
    "df3 = df3.sort_values(by=['SE_Number', 'LactationNumber', 'InseminationDate'])\n",
    "df3 = df3.drop_duplicates(subset=['SE_Number', 'LactationNumber', 'InseminationDate'])\n",
    "df3['NINS_bw'] = df3.groupby(['SE_Number', 'LactationNumber']).cumcount(ascending=False) + 1\n",
    "print(df3.shape)  \n",
    "print(df.shape)  \n",
    "df = pd.merge(df3, df, on=[\"SE_Number\", \"LactationNumber\", \"InseminationDate\"])\n",
    "print(df.shape)  \n",
    "\n",
    "# Initiate variable to indicate where have conditions\n",
    "df[\"CR8a\"] = 2\n",
    "df[\"CR8b\"] = 2\n",
    "\n",
    "\n",
    "def cr8a(row):\n",
    "    if row[\"ins_int\"] <= row[\"InseminationDate\"] <= row[\"upper_limit\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def cr8b(row):\n",
    "    if row[\"NINS_bw\"] <=5:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "df['CR8a'] = df.apply(cr8a, axis=1)\n",
    "df['CR8b'] = df.apply(cr8b, axis=1)\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts1 = df[\"CR8a\"].value_counts()\n",
    "print(value_counts1)\n",
    "value_counts2 = df[\"CR8b\"].value_counts()\n",
    "print(value_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run previous functions for these data points to define their CR scoring\n",
    "def create_CR8a(row):\n",
    "    # Check if either CR8a or CR8b is equal to 1\n",
    "    if row['CR8a'] == 1 or row['CR8b'] == 1:\n",
    "        # Apply cr1 to cr5 functions as needed\n",
    "        cr1_value = cr1(row)\n",
    "        cr4_value = cr4(row)\n",
    "        cr5_value = cr5(row)\n",
    "        \n",
    "        # Check the values of cr1, cr4, cr5 in order\n",
    "        if pd.notna(cr1_value) or pd.isna(cr1_value):\n",
    "            return cr1_value  # CR8 is set based on cr1_value\n",
    "        \n",
    "        if pd.notna(cr4_value):\n",
    "            return cr4_value  # CR8 is set based on cr4_value\n",
    "        \n",
    "        if pd.notna(cr5_value) or pd.isna(cr5_value):\n",
    "            return cr5_value  # CR8 is set based on cr5_value\n",
    "\n",
    "        # If none of cr1, cr4, or cr5 are valid, return NaN for CR8aa\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        # If neither CR8a nor CR8b is equal to 1, return NaN for CR8aa\n",
    "        return np.nan\n",
    "\n",
    "# Apply the create_CR8a function to the dataframe\n",
    "df['CR8aa'] = df.apply(create_CR8a, axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values\n",
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7', 'CR8aa']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun code for CR6 separately here due to issue with .any() and eq() from function, returning AttributeErrors for bool and float handling in python => called CR8bb\n",
    "\n",
    "# If the pregnancy period is shorter, it is checked iteratively whether some of\n",
    "# the former/previous inseminations are within acceptable limits, in which case insemination\n",
    "# for this day is set to 1. All inseminations that are newer than/ie after this successful\n",
    "# insemination are set to missing values. E.g. SE-5b581702-1756, LactationNumber 2.0\n",
    "df[\"CR8bb\"] = 2\n",
    "\n",
    "\n",
    "# Iterate through rows and handle pregnancy period less than 260 days\n",
    "for i in df.index:\n",
    "    if df.loc[i, \"preg_period\"] < 260:\n",
    "        # Filter for valid previous inseminations (preg_period between 260 and 302 days) up to the current row\n",
    "        valid_prev = df.loc[:i]\n",
    "        valid_prev = valid_prev[(valid_prev['preg_period'] >= 260) & (valid_prev['preg_period'] <= 302)]\n",
    "        \n",
    "        if not valid_prev.empty:\n",
    "            # If valid previous insemination exists, get the last valid index\n",
    "            last_valid_index = valid_prev.index[-1]\n",
    "            df.at[last_valid_index, \"CR8bb\"] = 1  # Update CR8bb to 1 for the last valid insemination\n",
    "\n",
    "\n",
    "# Define a function to process each group\n",
    "def cr8c(group):\n",
    "    # Ensure the condition is applied to the Series and `.any()` works correctly\n",
    "    if group['CR8bb'].eq(1).any():  # Check if any insemination in the group has CR8bb == 1\n",
    "        # Set rows to NaN or retain 1 based on conditions\n",
    "        group.loc[group['CR8bb'] != 1, 'CR8bb'] = np.nan  # Set rows where CR8bb != 1 to NaN\n",
    "        group.loc[group['CR8bb'] == 1, 'CR8bb'] = 1      # Ensure rows with CR8bb == 1 retain their value\n",
    "    return group\n",
    "\n",
    "# Apply the function group by group\n",
    "df = df.groupby(['SE_Number', 'LactationNumber']).apply(cr8c)\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload cuz index\n",
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run function for cr7 creating CR8cc\n",
    "def create_CR8b(row):\n",
    "    # Check if either CR8a or CR8b is equal to 1\n",
    "    if row['CR8a'] == 1 or row['CR8b'] == 1:\n",
    "        # Apply cr7 function as needed\n",
    "        cr7_value = cr7(row)\n",
    "        \n",
    "        # Check the values of cr7\n",
    "        if pd.notna(cr7_value):\n",
    "            return cr7_value  # CR8cc is set based on cr7_value\n",
    "\n",
    "        # If cr7 is not valid, return NaN for CR8cc\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        # If neither CR8a nor CR8b is equal to 1, return NaN for CR8cc\n",
    "        return np.nan\n",
    "\n",
    "# Apply the create_CR7 function to the dataframe\n",
    "df['CR8cc'] = df.apply(create_CR8b, axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values\n",
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7', 'CR8aa', 'CR8bb', 'CR8cc']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CR0 with CR8aa wherever CR8aa has data (including NaN, 0, 1)\n",
    "df['CR0'] = df['CR8aa'].combine_first(df['CR8aa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CR0 with CR8bb where CR8bb has 1s or NaNs\n",
    "df['CR0'] = df['CR8bb'].where((df['CR8bb'] == 1) | (df['CR8bb'].isna()), df['CR0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CR0 with CR8cc where CR8cc has 1s\n",
    "df['CR0'] = df['CR8cc'].where((df['CR8cc'] == 1), df['CR0'])\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values\n",
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7', 'CR8aa', 'CR8bb', 'CR8cc']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales data\n",
    "If a cow was sold during a service period, all subsequent inseminations are set to\n",
    "missing and those before accepted. If the service period occurred before or after\n",
    "the cow was sold, inseminations are accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DelPro data - assume cow database is superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect sales date from raw data\n",
    "sold_delpro = pd.read_csv(\"C:/Users/pagd0001/Desktop/Gigacow/Data/20241009/Gigacow-tools/Projects/HeatStressEvaluation/Data/CowData/Del_Cow240823.csv\", low_memory=False, delimiter=\";\")\n",
    "col_keep = [\"SE_Number\", \"ArrivalDate\", \"CullDecisionDate\",\"CullReason1\",\"CullReason2\"]\n",
    "sold_delpro = sold_delpro[col_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_delpro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and remove cows with missing IDs\n",
    "missing_ids_count = sold_delpro['SE_Number'].isna().sum()\n",
    "print(f\"No. of cows with missing IDs: {missing_ids_count}\")\n",
    "print(f\"No. of observations in dataframe: {sold_delpro.shape}\")\n",
    "\n",
    "sold_delpro = sold_delpro[sold_delpro[\"SE_Number\"].notna()]\n",
    "print(f\"No. of observations in dataframe after removing missing cow IDs: {sold_delpro.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = sold_delpro['CullReason1'].unique()\n",
    "print(unique_values)\n",
    "unique_values = sold_delpro['CullReason2'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only data from sales\n",
    "sold_delpro = sold_delpro[(sold_delpro[\"CullReason1\"] == \"01 Såld till liv\") | (sold_delpro[\"CullReason2\"] == \"01 Såld till liv\")]\n",
    "print(f\"No. of observations with sales data: {sold_delpro.shape}\")\n",
    "\n",
    "# Remove cows where missing CullDecisionDate\n",
    "sold_delpro = sold_delpro[sold_delpro[\"CullDecisionDate\"].notna()]\n",
    "print(f\"No. of observations with exit date: {sold_delpro.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check no. of observations with arrival date\n",
    "test = sold_delpro[sold_delpro[\"ArrivalDate\"].isna()]\n",
    "print(f\"No. of observaitons with missing arrival i.e. entry date in DelPro: {sold_delpro.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_delpro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename & keep only SE_Number and SalesDate for each cow\n",
    "sold_delpro.rename(columns={\"CullDecisionDate\": \"SalesDate_delpro\"}, inplace=True)\n",
    "\n",
    "col_keep = [\"SE_Number\", \"SalesDate_delpro\"]\n",
    "sold_delpro = sold_delpro[col_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times each cow has been sold\n",
    "sales_count = sold_delpro.groupby('SE_Number').size().reset_index(name='times_sold')\n",
    "\n",
    "# Count the number of cows for each \"times_sold\" value\n",
    "summary = sales_count['times_sold'].value_counts().reset_index()\n",
    "summary.columns = ['number_of_times_sold', 'number_of_cows']\n",
    "\n",
    "# Sort by the number of times sold\n",
    "summary = summary.sort_values(by='number_of_times_sold')\n",
    "\n",
    "# Display the result\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually look at cows with multiple sales date\n",
    "sold_delpro = pd.merge(sold_delpro, sales_count, on=[\"SE_Number\"], how=\"left\")\n",
    "multiple_sold = sold_delpro[sold_delpro[\"times_sold\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sold_delpro.index.names)\n",
    "print(sold_delpro.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose CullDecisionDate into two columns, one for each date within cow\n",
    "# Create a new column for the sequential index within each group\n",
    "multiple_sold = multiple_sold.copy()\n",
    "multiple_sold['sequence'] = multiple_sold.groupby('SE_Number').cumcount() + 1\n",
    "\n",
    "# Pivot the table to transpose `column2` into multiple columns\n",
    "result = multiple_sold.pivot(index='SE_Number', columns='sequence', values='SalesDate_delpro')\n",
    "\n",
    "# Rename the columns for clarity (optional)\n",
    "result.columns = [f'SalesDate_delpro_{i}' for i in result.columns]\n",
    "\n",
    "# Reset the index to return a clean DataFrame (optional)\n",
    "result = result.reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename SalesDate_delpro to SalesDate_delpro_1, \n",
    "sold_delpro.rename(columns={\"SalesDate_delpro\": \"SalesDate_delpro_1\"}, inplace=True)\n",
    "\n",
    "# Remove the cows with multiple obs from original dataset\n",
    "sold_delpro = sold_delpro[~sold_delpro['SE_Number'].isin(multiple_sold['SE_Number'])]\n",
    "\n",
    "# Initiate SalesDate_delpro_2 in original dataframe so can fill it with data from multiple_sold\n",
    "sold_delpro = sold_delpro.copy()\n",
    "sold_delpro[\"SalesDate_delpro_2\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_delpro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat multiple_sold back to original df\n",
    "# Sort both datasets by cowID and date before concatenating\n",
    "sold_delpro = sold_delpro.sort_values(by=['SE_Number', 'SalesDate_delpro_1', 'SalesDate_delpro_2'])\n",
    "result = result.sort_values(by=['SE_Number', 'SalesDate_delpro_1', 'SalesDate_delpro_2'])\n",
    "\n",
    "# Concatenate along rows\n",
    "sold_delpro = pd.concat([sold_delpro, result], axis=0, ignore_index=True)\n",
    "\n",
    "# Change times_sold to 2 for cows with multiple records\n",
    "sold_delpro['times_sold'] = sold_delpro['times_sold'].fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_delpro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_delpro.to_csv(\"../Data/CowData/sales_delpro.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cow database sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect sales date from raw data\n",
    "sold_kok = pd.read_csv(\"C:/Users/pagd0001/Desktop/Gigacow/Data/20241009/Gigacow-tools/Projects/HeatStressEvaluation/Data/CowData/Kok_HerdEntryExit240820.csv\", low_memory=False, delimiter=\";\")\n",
    "col_keep = [\"BirthID\", \"EntryDate\", \"ExitDate\", \"ExitReason_PrimaryReason\", \"ExitReason_SecondaryReason1\", \"ExitReason_SecondaryReason2\"]\n",
    "sold_kok = sold_kok[col_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the recording look? Entry-Exit pairing possible?\n",
    "test2 = sold_kok[sold_kok[\"EntryDate\"].isna()]\n",
    "print(f\"No. of cows with missing EntryDate: {test2.shape}\")\n",
    "\n",
    "test2 = sold_kok[sold_kok[\"ExitDate\"].isna()]\n",
    "print(f\"No. of cows with missing ExitDate, i.e. still alive: {test2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To examine example cow\n",
    "SE_Number = [\"SE-a756bc39-1200\"]\n",
    "test = sold_kok[sold_kok[\"BirthID\"].isin(SE_Number)]\n",
    "test = test.sort_values(by=['BirthID', 'EntryDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_kok = sold_kok.drop_duplicates(subset=[\"BirthID\", \"ExitDate\"])\n",
    "sold_kok.rename(columns={\"BirthID\": \"SE_Number\"}, inplace=True)\n",
    "col_keep = [\"SE_Number\", \"ExitDate\"]\n",
    "sold_kok = sold_kok[col_keep]\n",
    "\n",
    "sold_kok = sold_kok.sort_values(by=[\"SE_Number\", \"ExitDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove those missing exit date, i.e. still alive\n",
    "df2 = sold_kok[sold_kok[\"ExitDate\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pair sales data within each lactation within cow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"upper_limit\"]\n",
    "df1 = df1[col_keep]\n",
    "\n",
    "df1 = df1.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add date of extraction as last possible upper_limit for cows with open records ============================================>>> change this date according to date of data extraction from Samo\n",
    "df1[\"upper_limit\"] = df1[\"upper_limit\"].where(pd.notna(df1[\"upper_limit\"]), \"2024-08-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "for col in ['CalvingDate', 'upper_limit']:\n",
    "    df1[col] = pd.to_datetime(df1[col])\n",
    "for col in ['ExitDate']:\n",
    "    df2[col] = pd.to_datetime(df2[col])\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate over each row in df1\n",
    "for _, row1 in df1.iterrows():\n",
    "    # Filter df2 for matching SE_Number and date intervals\n",
    "    matches = df2[\n",
    "        (df2['SE_Number'] == row1['SE_Number']) &\n",
    "        (df2['ExitDate'].between(row1['CalvingDate'], row1['upper_limit']))\n",
    "    ]\n",
    "    \n",
    "    # If matches are found, add all matches to results\n",
    "    if not matches.empty:\n",
    "        for _, match in matches.iterrows():\n",
    "            results.append({\n",
    "                'SE_Number': row1['SE_Number'],\n",
    "                'LactationNumber': row1['LactationNumber'],  # From df1\n",
    "                'CalvingDate': row1['CalvingDate'],\n",
    "                'upper_limit': row1['upper_limit'],\n",
    "                'matching_ExitDate': match['ExitDate']  # From df2\n",
    "            })\n",
    "    else:\n",
    "        # If no matches, add the row with NaN for matching_ExitDate\n",
    "        results.append({\n",
    "            'SE_Number': row1['SE_Number'],\n",
    "            'LactationNumber': row1['LactationNumber'],  # From df1\n",
    "            'CalvingDate': row1['CalvingDate'],\n",
    "            'upper_limit': row1['upper_limit'],\n",
    "            'matching_ExitDate': None  # No match\n",
    "        })\n",
    "\n",
    "# Create a DataFrame with results\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv(\"../Data/CowData/sales_matched.csv\", index=False)\n",
    "\n",
    "# Display the resulting table\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for sales between herds\n",
    "test = pd.read_csv(\"../Data/CowData/sales_matched.csv\", low_memory=False)\n",
    "test2 = test[test[\"upper_limit\"] == test[\"matching_ExitDate\"]]\n",
    "print(f\"No. of observations where ExitDate is equal to upper_limit for given lactation: {test2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of sales within cow and lactation\n",
    "sales_count = test.groupby(['SE_Number', \"LactationNumber\"]).size().reset_index(name='times_sold')\n",
    "\n",
    "# Count the number \"times_sold\"\n",
    "summary = sales_count['times_sold'].value_counts().reset_index()\n",
    "summary.columns = ['number_of_times_sold', 'number_of_cows']\n",
    "\n",
    "# Sort by the number of times sold\n",
    "summary = summary.sort_values(by='number_of_times_sold')\n",
    "\n",
    "# Display the result\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose CullDecisionDate into two columns, one for each date within cow\n",
    "# Create a new column for the sequential index within each group\n",
    "test = test.copy()\n",
    "test['sequence'] = test.groupby(['SE_Number', 'LactationNumber']).cumcount() + 1\n",
    "\n",
    "# Pivot the table to transpose `column2` into multiple columns\n",
    "result = test.pivot(index=['SE_Number', 'LactationNumber'], columns='sequence', values='matching_ExitDate')\n",
    "\n",
    "# Rename the columns for clarity (optional)\n",
    "result.columns = [f'SalesDate{i}' for i in result.columns]\n",
    "\n",
    "# Reset the index to return a clean DataFrame (optional)\n",
    "result = result.reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result[pd.notna(result[\"SalesDate2\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer sales data to fertilityDF.csv\n",
    "df1 = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)\n",
    "\n",
    "df1 = pd.merge(df1, result, on=[\"SE_Number\", \"LactationNumber\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processkod - skip these cells unless want to create sales.csv\n",
    "- if want to match sales_delpro.csv with sales_kok.csv to create sales.csv (however, not matched with fertilityDF.csv)\n",
    "- otherwise skip to \"Continue with CR program based on cow database data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = sold_kok['ExitReason_PrimaryReason'].unique()\n",
    "print(unique_values)\n",
    "unique_values = sold_kok['ExitReason_SecondaryReason1'].unique()\n",
    "print(unique_values)\n",
    "unique_values = sold_kok['ExitReason_SecondaryReason2'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename BirthID for concatenating\n",
    "sold_kok.rename(columns=\n",
    "                {\"BirthID\": \"SE_Number\",\n",
    "                 \"ExitDate\": \"SalesDate_kok\",\n",
    "                 \"ExitReason_PrimaryReason\": \"ExitReason_PrimaryReason_kok\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and remove cows with missing IDs\n",
    "missing_ids_count = sold_kok['SE_Number'].isna().sum()\n",
    "print(f\"Number of cows with missing IDs: {missing_ids_count}\")\n",
    "print(f\"Number of observations in dataframe: {sold_kok.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only data from sales\n",
    "sold_kok = sold_kok[(sold_kok[\"ExitReason_PrimaryReason_kok\"] == \"Såld till liv\")]\n",
    "\n",
    "# Remove cows where missing ExitDate\n",
    "sold_kok = sold_kok[sold_kok[\"SalesDate_kok\"].notna()]\n",
    "print(f\"Number of cows with sales date: {sold_kok.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_kok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times each cow has been sold\n",
    "sales_count = sold_kok.groupby('SE_Number').size().reset_index(name='times_sold')\n",
    "\n",
    "# Count the number of cows for each \"times_sold\" value\n",
    "summary = sales_count['times_sold'].value_counts().reset_index()\n",
    "summary.columns = ['number_of_times_sold', 'number_of_cows']\n",
    "\n",
    "# Sort by the number of times sold\n",
    "summary = summary.sort_values(by='number_of_times_sold')\n",
    "\n",
    "# Display the result\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"times_sold\" to original df and sort for cows with multiple records\n",
    "sold_kok = pd.merge(sold_kok, sales_count, on=[\"SE_Number\"], how=\"left\")\n",
    "multiple_sold = sold_kok[sold_kok[\"times_sold\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose SalesDate into columns, one for each date within cow\n",
    "#First sort to ensure getting sales into chronological order\n",
    "multiple_sold = multiple_sold.sort_values(by=['SE_Number', 'SalesDate_kok'])\n",
    "\n",
    "# Create a new column for the sequential index within each group\n",
    "multiple_sold = multiple_sold.copy()\n",
    "multiple_sold['sequence'] = multiple_sold.groupby('SE_Number').cumcount() + 1\n",
    "\n",
    "# Pivot the table to transpose `column2` into multiple columns\n",
    "result = multiple_sold.pivot(index='SE_Number', columns='sequence', values='SalesDate_kok')\n",
    "\n",
    "# Rename the columns for clarity (optional)\n",
    "result.columns = [f'SalesDate_kok_{i}' for i in result.columns]\n",
    "\n",
    "# Reset the index to return a clean DataFrame\n",
    "result = result.reset_index()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_kok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename SalesDate_delpro to SalesDate_delpro_1, \n",
    "sold_kok.rename(columns={\"SalesDate_kok\": \"SalesDate_kok_1\"}, inplace=True)\n",
    "\n",
    "# Remove the cows with multiple obs from original dataset\n",
    "sold_kok = sold_kok[~sold_kok['SE_Number'].isin(multiple_sold['SE_Number'])]\n",
    "\n",
    "# Initiate SalesDate_delpro_n in original dataframe so can fill it with data from multiple_sold\n",
    "sold_kok = sold_kok.copy()\n",
    "sold_kok[\"SalesDate_kok_2\"] = np.nan\n",
    "sold_kok[\"SalesDate_kok_3\"] = np.nan\n",
    "sold_kok[\"SalesDate_kok_4\"] = np.nan\n",
    "sold_kok[\"SalesDate_kok_5\"] = np.nan\n",
    "sold_kok[\"SalesDate_kok_6\"] = np.nan\n",
    "sold_kok[\"SalesDate_kok_7\"] = np.nan\n",
    "sold_kok[\"SalesDate_kok_8\"] = np.nan\n",
    "sold_kok[\"SalesDate_kok_9\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_kok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat multiple_sold back to original df\n",
    "# Sort both datasets by cowID and date before concatenating\n",
    "sold_kok = sold_kok.sort_values(by=['SE_Number', 'EntryDate', 'SalesDate_kok_1', 'SalesDate_kok_2', 'SalesDate_kok_3', 'SalesDate_kok_4', 'SalesDate_kok_5', 'SalesDate_kok_6', \n",
    "                                    'SalesDate_kok_7', 'SalesDate_kok_8', 'SalesDate_kok_9'])\n",
    "result = result.sort_values(by=['SE_Number', 'SalesDate_kok_1', 'SalesDate_kok_2', 'SalesDate_kok_3', 'SalesDate_kok_4', 'SalesDate_kok_5', 'SalesDate_kok_6', \n",
    "                                'SalesDate_kok_7', 'SalesDate_kok_8', 'SalesDate_kok_9'])\n",
    "\n",
    "# Concatenate along rows\n",
    "sold_kok = pd.concat([sold_kok, result], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_kok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update EntryDate and times_sold for cows with multiple records\n",
    "col_keep = [\"SE_Number\", \"EntryDate\", \"times_sold\"]\n",
    "multi_sold = multiple_sold[col_keep]\n",
    "multi_sold.drop_duplicates(subset=\"SE_Number\")\n",
    "\n",
    "sold_kok = pd.merge(sold_kok, multi_sold, on=[\"SE_Number\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_kok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_kok[\"times_sold\"] = sold_kok[\"times_sold_x\"].fillna(sold_kok[\"times_sold_y\"])\n",
    "sold_kok[\"EntryDate\"] = sold_kok[\"EntryDate_x\"].fillna(sold_kok[\"EntryDate_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_kok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_keep = [\"SE_Number\", \"EntryDate\", \"times_sold\", 'SalesDate_kok_1', 'SalesDate_kok_2', 'SalesDate_kok_3', 'SalesDate_kok_4', 'SalesDate_kok_5', 'SalesDate_kok_6', \n",
    "            'SalesDate_kok_7', 'SalesDate_kok_8', 'SalesDate_kok_9']\n",
    "sold_kok = sold_kok[col_keep]\n",
    "\n",
    "sold_kok.to_csv(\"../Data/CowData/sales_kok.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAIRING COW DATABASE AND DELPRO FOR SALES\n",
    "ckok = pd.read_csv(\"../Data/CowData/sales_kok.csv\", low_memory=False)\n",
    "cDel = pd.read_csv(\"../Data/CowData/sales_delpro.csv\", low_memory=False)\n",
    "\n",
    "ckok2 = pd.merge(ckok, cDel, on=[\"SE_Number\"], how=\"left\")\n",
    "ckok2.drop_duplicates(subset=[\"SE_Number\"], inplace=True)\n",
    "# ckok2['CullingDate'] = ckok2['ExitDateKok'].fillna(cDel['CullDecisionDateDelPro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of these cows are in our dataframe?\n",
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"upper_limit\"]\n",
    "df_fert = df[col_keep]\n",
    "df_fert = df_fert.copy()\n",
    "df_fert.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"], inplace=True)\n",
    "print(df_fert.shape)\n",
    "\n",
    "df_fert = pd.merge(df_fert, ckok2, on=(\"SE_Number\"), how=\"left\")\n",
    "print(df_fert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fert.to_csv(\"../Data/CowData/sales.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does this data look like?\n",
    "non_null_counts = df_fert.groupby(\"FarmName_Pseudo\").count()\n",
    "print(f\"Non-null counts in each column: {non_null_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue with CR program based on cow database data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check culling reasons\n",
    "col_keep = [\"SE_Number\", \"CullingDate\", \"CullingReason1\", \"CullingReason2\"]\n",
    "df4 = df[col_keep]\n",
    "\n",
    "unique_values = df4['CullingReason1'].unique()\n",
    "print(unique_values)\n",
    "unique_values = df4['CullingReason2'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "print(df4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find example cows\n",
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)\n",
    "\n",
    "# df2 = df[pd.notna(df[\"SalesDate1\"])]\n",
    "# df2 = df[df[\"InseminationDate\"] > df[\"SalesDate1\"]]\n",
    "\n",
    "SE_Number = [\"SE-a756bc39-1249\"]\n",
    "df2 = df[df[\"SE_Number\"].isin(SE_Number)]\n",
    "\n",
    "df2.to_csv(\"../Data/CowData/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)\n",
    "\n",
    "# Define service periods, find first ins date, allow for 7ins i.e. 147d\n",
    "df[\"InseminationDate\"] = pd.to_datetime(df[\"InseminationDate\"])\n",
    "first_ins1 = df.groupby(['SE_Number', 'LactationNumber'])['InseminationDate'].min().reset_index()\n",
    "first_ins1.rename(columns={'InseminationDate': 'first_ins_before_sold'}, inplace=True)\n",
    "df = df.merge(first_ins1, on=['SE_Number', 'LactationNumber'], how='left')\n",
    "\n",
    "df[\"first_ins_before_sold\"] = pd.to_datetime(df[\"first_ins_before_sold\"])\n",
    "df[\"service_period1_end\"] = df[\"first_ins_before_sold\"] + pd.Timedelta(days=147)\n",
    "# df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)\n",
    "\n",
    "df = df.sort_values(by=['SE_Number', 'LactationNumber', 'InseminationDate', 'PregnancyCheckDate'])\n",
    "\n",
    "\n",
    "def ins_after_sold(df):\n",
    "    # Filter rows where InseminationDate is after SalesDate\n",
    "    filtered = df[df[\"InseminationDate\"] > df[\"SalesDate1\"]]\n",
    "\n",
    "    # Group by SE_Number and LactationNumber and find the minimum ie first InseminationDate after SalesDate\n",
    "    first_ins2 = filtered.groupby(['SE_Number', 'LactationNumber'])['InseminationDate'].min().reset_index()\n",
    "    first_ins2.rename(columns={'InseminationDate': 'first_ins_after_sold'}, inplace=True)\n",
    "\n",
    "    # Merge the result back to the original test DataFrame\n",
    "    df = pd.merge(df, first_ins2, on=['SE_Number', 'LactationNumber'], how='left')\n",
    "\n",
    "    # Convert the merged column to datetime\n",
    "    df[\"first_ins_after_sold\"] = pd.to_datetime(df[\"first_ins_after_sold\"])\n",
    "\n",
    "    # Calculate service_period2 by adding 147 days to first_ins_after_sold\n",
    "    df[\"service_period2_end\"] = df[\"first_ins_after_sold\"] + pd.Timedelta(days=147)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Call the function and save the result\n",
    "df = ins_after_sold(df)\n",
    "# df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)\n",
    "# df.to_csv(\"../Data/CowData/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)\n",
    "\n",
    "# Define service periods, find first ins date\n",
    "df[\"InseminationDate\"] = pd.to_datetime(df[\"InseminationDate\"])\n",
    "first_ins1 = df.groupby(['SE_Number', 'LactationNumber'])['InseminationDate'].min().reset_index()\n",
    "first_ins1.rename(columns={'InseminationDate': 'first_ins_before_sold'}, inplace=True)\n",
    "df = df.merge(first_ins1, on=['SE_Number', 'LactationNumber'], how='left')\n",
    "\n",
    "# Convert date columns to datetime\n",
    "df[\"InseminationDate\"] = pd.to_datetime(df[\"InseminationDate\"])\n",
    "df[\"SalesDate1\"] = pd.to_datetime(df[\"SalesDate1\"])\n",
    "df[\"first_ins_before_sold\"] = pd.to_datetime(df[\"first_ins_before_sold\"])\n",
    "\n",
    "# Define end of service period (147 days after the first insemination)\n",
    "df[\"service_period_end\"] = df[\"first_ins_before_sold\"] + pd.Timedelta(days=147)\n",
    "\n",
    "# Initialize CR9 with a default value of 2\n",
    "df[\"CR9\"] = 2\n",
    "\n",
    "# Sort dataframe to ensure it's ordered by SE_Number, LactationNumber, and InseminationDate\n",
    "df = df.sort_values(by=['SE_Number', 'LactationNumber', 'InseminationDate'])\n",
    "\n",
    "def handle_inseminations(df):\n",
    "    # List to store the updated rows\n",
    "    updated_rows = []\n",
    "\n",
    "    # Iterate over each group (cow and lactation)\n",
    "    for _, group in df.groupby(['SE_Number', 'LactationNumber']):\n",
    "        cow_sales_date = group['SalesDate1'].iloc[0]\n",
    "        service_period_start = group['first_ins_before_sold'].iloc[0]\n",
    "        service_period_end = group['service_period_end'].iloc[0]\n",
    "\n",
    "        # Insemination logic based on cow sales\n",
    "        for index, row in group.iterrows():\n",
    "\n",
    "            # If cow was sold during service period, all subsequent inseminations are set to NaT (missing)\n",
    "            if pd.notna(cow_sales_date) and service_period_start <= cow_sales_date <= service_period_end:\n",
    "                # If insemination date is after the sales date within the service period, set to NaT and CR9 to None\n",
    "                if row['InseminationDate'] > cow_sales_date:\n",
    "                    row['CR9'] = np.nan  # Set CR9 to missing for post-sale inseminations\n",
    "            else:\n",
    "                # If the sale happened before or after the service period, accept insemination date and CR9=1\n",
    "                row['CR9'] = 1\n",
    "\n",
    "            updated_rows.append(row)\n",
    "\n",
    "    # Convert the list of updated rows into a new dataframe\n",
    "    updated_df = pd.DataFrame(updated_rows)\n",
    "    return updated_df\n",
    "\n",
    "# Call the function to process inseminations\n",
    "df_updated = handle_inseminations(df)\n",
    "\n",
    "# Display the result\n",
    "print(df_updated)\n",
    "\n",
    "\n",
    "first_ins_before_sold\tservice_period1_end\tfirst_ins_after_sold\tservice_period2_end\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "df[\"InseminationDate\"] = pd.to_datetime(df[\"InseminationDate\"])\n",
    "df[\"SalesDate1\"] = pd.to_datetime(df[\"SalesDate1\"])\n",
    "df[\"first_ins_before_sold\"] = pd.to_datetime(df[\"first_ins_before_sold\"])\n",
    "\n",
    "# Initiate CR9 with 2 to be overwritten with 1s and NaNs\n",
    "df[\"CR9a\"] = 2\n",
    "\n",
    "\n",
    "def cr9a(row):\n",
    "    if pd.notna(row[\"SalesDate1\"]):\n",
    "        \n",
    "        # If a cow was sold during a service period, all inseminations before are accepted\n",
    "        if row[\"first_ins_before_sold\"] <= row[\"InseminationDate\"] < row[\"SalesDate1\"]:\n",
    "            return 1\n",
    "        \n",
    "        # If a cow was sold during a service period, all subsequent inseminations are set to missing ============================================================>>> done below instead\n",
    "        #if row[\"first_ins_before_sold\"] < row[\"SalesDate1\"] < row[\"service_period1_end\"]:\n",
    "        #   return np.nan\n",
    "                \n",
    "        # If the service period occurred before sold ie date of service period ends sooner than sold date, accept ins\n",
    "        if row[\"service_period1_end\"] < row[\"SalesDate1\"]:\n",
    "            if row[\"first_ins_before_sold\"] <= row[\"InseminationDate\"] < row[\"service_period1_end\"]:\n",
    "                return 1\n",
    "            \n",
    "        # If the service period occurred after sold ie date of first ins after sold is past sold date, accept ins\n",
    "        if row[\"service_period1_end\"] < row[\"SalesDate1\"]:\n",
    "            if row[\"first_ins_after_sold\"] <= row[\"InseminationDate\"] < row[\"service_period1_end\"]:\n",
    "                return 1\n",
    "\n",
    "\n",
    "# Apply the function to df\n",
    "df['CR9a'] = df.apply(cr9a, axis=1)\n",
    "# df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)\n",
    "# df.to_csv(\"../data/CowData/test.csv\", index=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a cow was sold during a service period, all subsequent inseminations are set to missing\n",
    "# Step 1: Sort by cow (SE_Number), lactation, and insemination date\n",
    "df = df.sort_values(by=['SE_Number', 'LactationNumber', 'InseminationDate'])\n",
    "\n",
    "# Step 2: Define the function to handle inseminations based on sale date\n",
    "def handle_inseminations_after_sale(df):\n",
    "    # Initialize CR9 with 2 (or any initial value)\n",
    "    df['CR9b'] = 2\n",
    "    \n",
    "    # Step 3: Loop through each cow and lactation group\n",
    "    for _, group in df.groupby(['SE_Number', 'LactationNumber']):\n",
    "        # Get the sale date for the group (assuming only one sale date per cow per lactation)\n",
    "        sale_date = group['SalesDate1'].iloc[0]\n",
    "        \n",
    "        # Step 4: Identify inseminations after the sale date\n",
    "        # Inseminations before or on the sale date are kept, after the sale date are set to NaN\n",
    "        is_after_sale = group['InseminationDate'] > sale_date\n",
    "        \n",
    "        # Step 5: Set CR9 to 1 for valid inseminations and NaN for subsequent inseminations\n",
    "        group.loc[~is_after_sale, 'CR9b'] = 1  # Set CR9=1 for valid inseminations\n",
    "        group.loc[is_after_sale, 'CR9b'] = np.nan  # Set subsequent inseminations to NaN\n",
    "        \n",
    "        # Replace the original group in the dataframe\n",
    "        df.loc[group.index, ['InseminationDate', 'CR9b']] = group[['InseminationDate', 'CR9b']]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Step 6: Apply the function to the dataset\n",
    "df = handle_inseminations_after_sale(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7', 'CR8aa', 'CR8bb', 'CR8cc', 'CR9a', 'CR9b']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CR0 with CR9a where CR9a has 1s\n",
    "df[\"CR0\"] = df[\"CR9a\"].where((df[\"CR9a\"] == 1), df[\"CR0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7', 'CR8aa', 'CR8bb', 'CR8cc', 'CR9a', 'CR9b']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CR0\"] = df[\"CR9b\"].where((df[\"CR9b\"].isna()), df[\"CR0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7', 'CR8aa', 'CR8bb', 'CR8cc', 'CR9a', 'CR9b']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slaughter data\n",
    "When a cow is slaughtered (i.e. all other exit codes but sold or moved), the last phenotype is left successful only in the case\n",
    "of a positive pregnancy check; otherwise, it is set to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df['CullingReason1'].unique()\n",
    "print(unique_values)\n",
    "unique_values = df['CullingReason2'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find last ins within cow and lactation\n",
    "df = df.sort_values(by=['SE_Number', 'LactationNumber', 'InseminationDate', 'PregnancyCheckDate'])\n",
    "df[\"InseminationDate\"] = pd.to_datetime(df[\"InseminationDate\"])\n",
    "df['last_ins'] = (df.groupby(['SE_Number', 'LactationNumber'])['InseminationDate'].transform('max') == df['InseminationDate'])\n",
    "\n",
    "# Find last pregnancy check date within cow in case of multiple preg checks for last ins\n",
    "df[\"PregnancyCheckDate\"] = pd.to_datetime(df[\"PregnancyCheckDate\"])\n",
    "df['last_preg_check'] = (df.groupby(['SE_Number', 'LactationNumber'])['PregnancyCheckDate'].transform('max') == df['PregnancyCheckDate'])\n",
    "df[\"CR10\"] = np.nan\n",
    "\n",
    "\n",
    "def cr10(row):\n",
    "    if pd.isna(row[\"next_calving\"]) and pd.notna(row[\"CullingReason1\"]) and row[\"CullingReason1\"] != \"Såld till liv\" and row[\"CullingReason2\"] != \"Såld till liv\":\n",
    "        if row[\"last_ins\"] and row[\"last_preg_check\"] and row[\"PregnancyStatus\"] == \"Positive\":\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "# Apply the function to df\n",
    "df['CR10'] = df.apply(cr10, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7', 'CR8aa', 'CR8bb', 'CR8cc', 'CR9a', 'CR9b', 'CR10']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CR0 with CR10 only where have data\n",
    "df['CR0'] = np.where(df['CR10'].notna(), df['CR10'], df['CR0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7', 'CR8aa', 'CR8bb', 'CR8cc', 'CR9a', 'CR9b', 'CR10']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open records\n",
    "Open records due to the data extraction: All data is used to define phenotypes\n",
    "before removing data that is too new (150-d gap).\n",
    "\n",
    "OPEN REC signified by no next_ins, next_calving or CullingDate i.e. all pd.isna\n",
    "\n",
    "In this class of open records, the last CR is set to 0 if the lactation length\n",
    "is > 260 days and days from the data extraction to the last insemination is > 340 days. For the remaining open records, CR is set to 0.7, i.e., average NRR\n",
    "in heifers. The rationale behind this is that if there are no events during 150\n",
    "days before the extraction of data, it is very probable that a cow is pregnant\n",
    "and has not calved yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When is the maximum of pregnancy checks happening?\n",
    "df[\"PregnancyCheckDate\"] = pd.to_datetime(df[\"PregnancyCheckDate\"])\n",
    "max_value = df['PregnancyCheckDate'].max()\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date for extraction from Samo\n",
    "df[\"date_extraction\"] = \"2024-08-18\" # ==========================================================================>>> Change this date to correspond with raw data extraction date from Samo\n",
    "df[\"date_extraction\"] = pd.to_datetime(df[\"date_extraction\"])\n",
    "\n",
    "# Set interval for open records, i.e. 150d from data extraction\n",
    "df[\"extraction_limit\"] = df[\"date_extraction\"] - pd.Timedelta(days=150)\n",
    "df[\"extraction_limit\"] = pd.to_datetime(df[\"extraction_limit\"])\n",
    "\n",
    "# Define lactation length, between calving date and dry off date\n",
    "df[\"CalvingDate\"] = pd.to_datetime(df[\"CalvingDate\"])\n",
    "df[\"DryOffDate\"] = pd.to_datetime(df[\"DryOffDate\"])\n",
    "df[\"lact_length\"] = (df[\"DryOffDate\"] - df[\"CalvingDate\"]).dt.days\n",
    "\n",
    "# Define interval from data extraction to last ins\n",
    "df[\"InseminationDate_last\"] = pd.to_datetime(df[\"InseminationDate_last\"])\n",
    "df[\"extraction_to_last_ins\"] = (df[\"date_extraction\"] - df[\"InseminationDate_last\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cr11(row):\n",
    "    if pd.isna(row[\"next_ins\"]) and pd.isna(row[\"next_calving\"]) and pd.isna(row[\"CullingDate\"]):\n",
    "        if row[\"last_ins\"] == True:\n",
    "            if row[\"lact_length\"] > 260 and row[\"extraction_to_last_ins\"] > 340:\n",
    "                return 0\n",
    "        else:\n",
    "            return 0.7\n",
    "\n",
    "\n",
    "# Apply the function to df\n",
    "df['CR11'] = df.apply(cr11, axis=1)\n",
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7', 'CR8aa', 'CR8bb', 'CR8cc', 'CR9a', 'CR9b', 'CR10', 'CR11']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CR0 with CR9a where CR9a has 1s or 0.7s\n",
    "df[\"CR0\"] = df[\"CR11\"].where((df[\"CR11\"] == 1) | (df[\"CR11\"] == 0.7), df[\"CR0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_count = ['CR0', 'CR1', 'CR4', 'CR5', 'CR6', 'CR7', 'CR8aa', 'CR8bb', 'CR8cc', 'CR9a', 'CR9b', 'CR10', 'CR11']\n",
    "value_counts = df[columns_to_count].apply(lambda x: x.value_counts(dropna=False))\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/CowData/fertilityDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add THI data\n",
    "Include an indicator of whether or not the cow has been put through heat stress conditions (i.e. temperatures above 15 degrees, or THI 61) 7 days prior to and 7 days after insemination in order to cover estrus, insemination and early embryonic development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_THI = pd.read_csv(\"../Data/MergedData/MY_weather.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fert = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill THI_adj where missing data due to not milked or missing time stamp in milking records\n",
    "df_THI['THI_adj'] = df_THI['THI_adj'].fillna(df_THI['MeanTHI_adj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate THI data to mean value per day\n",
    "df_THI = df_THI.groupby(['SE_Number', 'LactationNumber', 'StartDate']).agg({\n",
    "    'THI_adj': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "df_THI.rename(columns={'THI_adj': 'MeanTHI_adj'}, inplace=True)\n",
    "df_THI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weather data 7d prior to and 7d after insemination date\n",
    "# Convert the dates to datetime\n",
    "df_fert['InseminationDate'] = pd.to_datetime(df_fert['InseminationDate'])\n",
    "df_THI['StartDate'] = pd.to_datetime(df_THI['StartDate'])\n",
    "\n",
    "# Function to filter weather data within the 7-day window of insemination\n",
    "def filter_THI(insemination_row, df_THI):\n",
    "    start_date = insemination_row['InseminationDate'] - pd.Timedelta(days=7)\n",
    "    end_date = insemination_row['InseminationDate'] + pd.Timedelta(days=7)\n",
    "\n",
    "    # Filter THI data within the 7-day window\n",
    "    filtered_THI = df_THI[(df_THI['StartDate'] >= start_date) & \n",
    "                          (df_THI['StartDate'] <= end_date) &\n",
    "                          (df_THI['SE_Number'] == insemination_row['SE_Number']) & \n",
    "                          (df_THI['LactationNumber'] == insemination_row['LactationNumber'])]\n",
    "    \n",
    "    # Add InseminationDate to the filtered dataframe\n",
    "    filtered_THI['InseminationDate'] = insemination_row['InseminationDate']\n",
    "    \n",
    "    return filtered_THI\n",
    "\n",
    "# List to hold the resulting filtered weather data\n",
    "resulting_THI = []\n",
    "\n",
    "# Loop through each insemination row and filter weather data\n",
    "for _, insemination_row in df_fert.iterrows():\n",
    "    filtered_THI = filter_THI(insemination_row, df_THI)\n",
    "    resulting_THI.append(filtered_THI)\n",
    "\n",
    "# Concatenate the filtered weather data back into a single dataframe\n",
    "df_result = pd.concat(resulting_THI)\n",
    "\n",
    "# Reset the index\n",
    "df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# View the resulting dataframe with weather data within the 7-day window\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume a cow is heat stressed if THI is above 68 at any one time during the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set HeatStress to 1 if MeanTHI_adj is above 68 (i.e. heat stress during estrus, insemination and early embryonic development) ====================>>> Change THI threshold in this cell\n",
    "df_result = df_result.copy()\n",
    "df_result[\"HS\"] = np.nan\n",
    "\n",
    "\n",
    "def heat_stress(row):\n",
    "    if row[\"MeanTHI_adj\"] >= 68:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "df_result[\"HS\"] = df_result.apply(heat_stress, axis=1)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"InseminationDate\"] = pd.to_datetime(df_result[\"InseminationDate\"])\n",
    "\n",
    "# Summarize HS into HeatStress indicator \n",
    "# (i.e. if experiencing heat stress conditions on any day within -7 to +7 interval of insemination, HeatStress = 1)\n",
    "hs_summary = (\n",
    "    df_result.groupby([\"SE_Number\", \"LactationNumber\", \"InseminationDate\"])[\"HS\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"HS\": \"HS_sum\"})\n",
    ")\n",
    "\n",
    "hs_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_summary = pd.merge(df_result, hs_summary, on=[\"SE_Number\", \"LactationNumber\", \"InseminationDate\"], how=\"left\")\n",
    "hs_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/CowData/fertilityDF.csv\", low_memory=False)\n",
    "print(df.shape)\n",
    "\"\"\"\n",
    "SE_Number = [\"SE-5c06d92d-3114\"]\n",
    "df = df[df[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Define the thermalstress function for use in modelling\n",
    "def thermalstress(row):\n",
    "    if row[\"HS_sum\"] >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Apply the thermalstress function\n",
    "hs_summary[\"HeatStress\"] = hs_summary.apply(thermalstress, axis=1)\n",
    "\"\"\"\n",
    "df[\"InseminationDate\"] = pd.to_datetime(df[\"InseminationDate\"])\n",
    "hs_summary[\"InseminationDate\"] = pd.to_datetime(hs_summary[\"InseminationDate\"])\n",
    "\n",
    "# Merge the summarized data with the original DataFrame\n",
    "fert_THI = pd.merge(df, hs_summary, on=[\"SE_Number\", \"LactationNumber\", \"InseminationDate\"], how=\"left\")\n",
    "fert_THI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fert_THI.to_csv(\"../Data/MergedData/fertilityDF_W61.csv\", index=False)\n",
    "fert_THI.to_csv(\"../Data/MergedData/fertilityDF_W68.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below assumes cow is heat stressed if THI is above 68 for at least 3 consecutive days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.read_csv(\"../Data/MergedData/fertilityDF_W68.csv\", low_memory=False)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the Date column is a datetime type\n",
    "df_result['StartDate'] = pd.to_datetime(df_result['StartDate'])\n",
    "\n",
    "# Set StartDate as the index for time-based operations\n",
    "df_result = df_result.set_index('StartDate')\n",
    "\n",
    "# Create a rolling window of 3 days and check if all THI values within the window are >= 68\n",
    "df_result['THI_3D_Above_68'] = (\n",
    "    df_result['MeanTHI_adj']\n",
    "    .rolling(window=3, min_periods=3)  # 3-day rolling window\n",
    "    .apply(lambda x: 1 if (x >= 68).all() else 0, raw=True)\n",
    ")\n",
    "\n",
    "# Reset the index if needed\n",
    "df_result = df_result.reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "df_result.to_csv(\"../Data/MergedData/fertilityDF_W68.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of data\n",
    "df = pd.read_csv(\"../Data/MergedData/fertilityDF_W68.csv\", low_memory=False)\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"InseminationDate\", \"PregnancyCheckDate\"]) \n",
    "print(f\"No. pregnancy checks: {df2.shape}\")\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"InseminationDate\"]) \n",
    "print(f\"No. ins: {df2.shape}\")\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"]) \n",
    "print(f\"No. lact: {df2.shape}\")\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\"]) \n",
    "print(f\"No. cows: {df2.shape}\")\n",
    "df2 = df.drop_duplicates(subset=[\"FarmName_Pseudo\"])\n",
    "print(f\"No. herds: {df2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at thresholds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = df_result['THI_3D_Above_61'].describe()\n",
    "print(\"Descriptive statistics: \\n\", summary_stats)\n",
    "\n",
    "percentiles = np.percentile(df_result['THI_3D_Above_61'].dropna(), [1, 5, 10, 90, 95, 99])\n",
    "print(\"\\nPercentiles (1%, 5%, 10%, 90%, 95%, 99%):\", percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df_result[\"THI_3D_Above_61\"], bins=10)\n",
    "plt.title('Histogram of No. obs Above THI 61')\n",
    "plt.xlabel('THI Above 61')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# To make a dataframe with only the selected data do the following\n",
    "Ensure the Date column is a datetime type\n",
    "df_result['StartDate'] = pd.to_datetime(df_result['StartDate'])\n",
    "\n",
    "# Define the time interval (here rolling window of 3 consecutive days, full period 7+7days is probably too much?)\n",
    "time_interval = '3D'\n",
    "\n",
    "# Group by rolling time intervals\n",
    "df_result = df_result.set_index('StartDate')  # Set Date as the index for time-based operations\n",
    "\n",
    "# Create a new DataFrame where all THI values in each group are equal to or exceed 61\n",
    "filtered_df = df_result.groupby(pd.Grouper(freq=time_interval)).filter(lambda x: (x['MeanTHI_adj'] >= 61).all())\n",
    "\n",
    "# Reset the index\n",
    "filtered_df = filtered_df.reset_index()\n",
    "\n",
    "# Display the filtered data\n",
    "print(filtered_df)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
