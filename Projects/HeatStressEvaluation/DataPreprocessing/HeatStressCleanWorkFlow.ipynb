{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA FROM COW DATABASE\n",
    "\n",
    "Requires the following data to create dfKok.csv:\n",
    "- Kok_Calving\n",
    "- Kok_HerdEntryExit\n",
    "- Kok_CowMilkSampling\n",
    "- Kok_Lineage\n",
    "- Kok_Reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# LOAD COW DATABASE CALVING DATA\n",
    "calving = pd.read_csv(\"Kok_Calving240820.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"ActiveHerdNumber\", \"BirthID\", \"CalvingDate\", \"CalvingNumber\"]\n",
    "calving = calving[col_keep]\n",
    "calving.rename(columns={'BirthID': 'SE_Number', \"ActiveHerdNumber\": \"FarmName_Pseudo\", \"CalvingDate\": \"CalvingDateKok\",\n",
    "                        \"CalvingNumber\": \"LactationNumberKok\"}, inplace=True)\n",
    "calving = calving.sort_values(by=[\"SE_Number\", \"CalvingDateKok\"])\n",
    "calving = calving.drop_duplicates(subset=[\"SE_Number\", \"CalvingDateKok\"])\n",
    "# calving[\"upper_limit\"] = calving.groupby([\"SE_Number\"])[\"CalvingDateKok\"].shift(-1)\n",
    "calving.to_csv(\"calving_kok.csv\", index=False)\n",
    "\n",
    "calving2 = calving.groupby([\"FarmName_Pseudo\"])[\"LactationNumberKok\"].count().reset_index()\n",
    "calving2.rename(columns={'LactationNumberKok': 'CountLact'}, inplace=True)\n",
    "print(f\"No. of lactation records in cow database in different herds: \\n\", calving2.to_string(index=False))\n",
    "calving2 = calving.drop_duplicates(subset=[\"SE_Number\", \"CalvingDateKok\"])\n",
    "print(f\"No. of lactation records in cow database: {calving2.shape}\")  # 23,688\n",
    "\n",
    "calving2 = calving.groupby([\"FarmName_Pseudo\"])[\"SE_Number\"].count().reset_index()\n",
    "calving2.rename(columns={'SE_Number': 'CountCows'}, inplace=True)\n",
    "print(f\"No. of cows with calving data in cow database in different herds: \\n\", calving2.to_string(index=False))\n",
    "calving2 = calving.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows with calving data in cow database: {calving2.shape}\")  # 9,168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ADD ENRTY AND CULLING DATA FROM COW DATABASE\n",
    "cull = pd.read_csv(\"Kok_HerdEntryExit240820.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"BirthID\", \"ActiveHerdNumber\", \"EntryDate\", \"ExitDate\", \"ExitReason_PrimaryReason\",\n",
    "            \"ExitReason_SecondaryReason1\",\"ExitReason_SecondaryReason2\"]\n",
    "cull = cull[col_keep]\n",
    "cull.rename(columns={'BirthID': 'SE_Number', \"ActiveHerdNumber\": \"FarmName_Pseudo\", \"EntryDate\": \"EntryDateKok\",\n",
    "                     \"ExitDate\": \"ExitDateKok\", \"ExitReason_PrimaryReason\": \"ExitReason_PrimaryReasonKok\",\n",
    "                     \"ExitReason_SecondaryReason1\": \"ExitReason_SecondaryReason1Kok\",\n",
    "                     \"ExitReason_SecondaryReason2\": \"ExitReason_SecondaryReason2Kok\"}, inplace=True)\n",
    "cull = cull.sort_values(by=[\"SE_Number\", \"ExitDateKok\"])\n",
    "print(f\"Number of records in raw entry/culling file: {cull.shape}\")  # 33,679\n",
    "cull2 = cull.drop_duplicates(subset=[\"SE_Number\", \"ExitDateKok\"])\n",
    "print(f\"NUmber of unique records in entry/culling file: {cull2.shape}\")  # 33,668\n",
    "# => 11 records with multiple culling reasons\n",
    "\n",
    "# check how many cows enter/exit herds multiple times\n",
    "cull3 = cull2.groupby([\"SE_Number\"])[\"ExitDateKok\"].count().reset_index()\n",
    "cull3.rename(columns={'ExitDateKok': 'CountExits'}, inplace=True)\n",
    "\n",
    "frequency_table = cull3['CountExits'].value_counts()\n",
    "print(f\"No. of cows with multiple exit records in cow database:\")\n",
    "print(frequency_table)\n",
    "\n",
    "# Assume last record within cow as culling date\n",
    "cull2 = cull2.groupby('SE_Number').tail(1)\n",
    "cull2.to_csv(\"cullingKok.csv\", index=False)\n",
    "\n",
    "# Merge\n",
    "dfKok = calving.merge(cull2, on=[\"FarmName_Pseudo\", \"SE_Number\"], how=\"left\")\n",
    "\n",
    "# Make upper_limit to sort dry off date later\n",
    "dfKok = dfKok.sort_values(by=[\"SE_Number\", \"CalvingDateKok\"]).reset_index(drop=True)\n",
    "dfKok[\"upper_limit\"] = dfKok.groupby([\"SE_Number\"])[\"CalvingDateKok\"].shift(-1)\n",
    "\n",
    "dfKok.to_csv(\"dfKok.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ADD DRY OFF DATA FROM COW DATABASE\n",
    "dry_offKok = pd.read_csv(\"Kok_Kok_CowMilkSampling240829.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"BirthID\", \"ActiveHerdNumber\", \"SamplingDate\", \"VariousSystemInfo\"]\n",
    "dry_offKok = dry_offKok[col_keep]\n",
    "dry_offKok.rename(columns={'BirthID': 'SE_Number', \"ActiveHerdNumber\": \"FarmName_Pseudo\",\n",
    "                           \"SamplingDate\": \"DryOffDateKok\"}, inplace=True)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"DryOffDateKok\", \"VariousSystemInfo\"]\n",
    "dry_offKok = dry_offKok[col_keep]\n",
    "\n",
    "# Find dry off data and output last record for each cow (ie last time she's sampled for test day sampling)\n",
    "# and by \"kod: 02\"\n",
    "dry_offKok = dry_offKok.sort_values(by=[\"SE_Number\", \"DryOffDateKok\"])\n",
    "# Create a new column to track when the \"VariousSystemInfo\" changes, want the last one ie -1\n",
    "dry_offKok['InfoChange'] = (dry_offKok.groupby('SE_Number')['VariousSystemInfo'].shift(-1) !=\n",
    "                            dry_offKok['VariousSystemInfo'])\n",
    "dry_offKok.to_csv(\"DryOffKok1.csv\", index=False)\n",
    "# Keep only the rows where there is a change in \"VariousSystemInfo\" AND \"VariousSystemInfo\" is 2 ie dry off\n",
    "dry_offKok = dry_offKok[(dry_offKok[\"VariousSystemInfo\"] == \"kod: 02\") & (dry_offKok[\"InfoChange\"] == True)]\n",
    "# Drop columns\n",
    "dry_offKok = dry_offKok.drop(columns=['InfoChange', \"VariousSystemInfo\"])\n",
    "dry_offKok.to_csv(\"DryOffKok.csv\", index=False)\n",
    "\n",
    "print(f\"No. dry off records in cow database: {dry_offKok.shape}\")  # 12,513\n",
    "dry_offKok2 = dry_offKok.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. cows with dry off records in cow database: {dry_offKok2.shape}\")  # 6,447\n",
    "\n",
    "# Merge\n",
    "dfKok = dfKok.merge(dry_offKok, on=[\"FarmName_Pseudo\", \"SE_Number\"], how=\"left\")\n",
    "dfKok[\"CalvingDateKok\"] = pd.to_datetime(dfKok[\"CalvingDateKok\"])\n",
    "dfKok[\"DryOffDateKok\"] = pd.to_datetime(dfKok[\"DryOffDateKok\"])\n",
    "dfKok[\"upper_limit\"] = pd.to_datetime(dfKok[\"upper_limit\"])\n",
    "\n",
    "\n",
    "def data(row):\n",
    "    if row[\"CalvingDateKok\"] < row[\"DryOffDateKok\"] <= row[\"upper_limit\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "dfKok[\"dryoff\"] = dfKok.apply(data, axis=1)\n",
    "\n",
    "# Keep all records with dry off dates fitted within lactation\n",
    "df_ones = dfKok[dfKok['dryoff'] == 1]\n",
    "# Keep last record where open and lacking dry off date\n",
    "df_last_zero = dfKok[dfKok['dryoff'] == 0].groupby(\"SE_Number\").tail(1)\n",
    "# Concatenate dataframe and sort to maintain original order\n",
    "df_combined = pd.concat([df_ones, df_last_zero])\n",
    "df_combined = df_combined.sort_values(by=[\"SE_Number\", \"CalvingDateKok\"]).reset_index(drop=True)\n",
    "df_combined.to_csv(\"dfKok.csv\", index=False)\n",
    "\n",
    "# Put ExitDateKok as upper_limit if upper_limit is missing from calving date (mostly last lactation)\n",
    "df_combined.loc[df_combined[\"upper_limit\"].isna() & df_combined[\"ExitDateKok\"].notna(), \"upper_limit\"] = (\n",
    "    df_combined)[\"ExitDateKok\"]\n",
    "\n",
    "# Get today's date for current lactation when missing upper_limit after adjusting using ExitDateKok\n",
    "df_combined['TodayDate'] = pd.to_datetime('today').normalize()\n",
    "df_combined.loc[df_combined[\"upper_limit\"].isna() & df_combined[\"ExitDateKok\"].isna(), \"upper_limit\"] = (\n",
    "    df_combined)[\"TodayDate\"]\n",
    "\n",
    "df_combined.loc[df_combined[\"upper_limit\"].isna()\n",
    "                & (df_combined[\"DryOffDateKok\"] < df_combined[\"CalvingDateKok\"]), \"upper_limit\"] = (df_combined)[\"DryOffDateKok\"]\n",
    "df_combined.loc[df_combined[\"dryoff\"] == 0, \"DryOffDateKok\"] = np.nan\n",
    "df_combined.to_csv(\"dfKok.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ADD BREED INFORMATION FROM COW DATABASE\n",
    "df = pd.read_csv(\"Kok_Lineage240821.csv\", delimiter=';', low_memory=False)\n",
    "df.rename(columns={\"BirthID\": \"SE_Number\", \"ActiveHerdNumber\": \"FarmName_Pseudo\", \"Father_Breed\": \"SireBreedKok\",\n",
    "                   \"Mother_Breed\": \"DamBreedKok\", \"MothersFather_Breed\": \"MGSBreedKok\"}, inplace=True)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"SireBreedKok\", \"DamBreedKok\", \"MGSBreedKok\"]\n",
    "df = df[col_keep]\n",
    "\n",
    "# Check for duplicates and sort\n",
    "print(df.shape)  # 24,067\n",
    "df = df.sort_values(by=[\"FarmName_Pseudo\", \"SE_Number\"])\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\", \"SireBreedKok\", \"DamBreedKok\", \"MGSBreedKok\"])\n",
    "print(f\"No. cows with breed data: {df2.shape}\")  # 22,653 => 1414 duplicates, all okay\n",
    "df3 = df.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. cows with different breed data recorded: {df3.shape}\")  # 22,607 => 46 cows with conflicting breed\n",
    "\n",
    "# The 46 cows with conflicting breed are a mess, e.g. LIM and SJB for the same sire, remove!\n",
    "duplicate_records = df2[df2['SE_Number'].duplicated(keep=False)]\n",
    "duplicate_records = duplicate_records.copy()\n",
    "duplicate_records[\"DupBreed\"] = 1\n",
    "col_keep = [\"SE_Number\", \"DupBreed\"]\n",
    "duplicate_records = duplicate_records[col_keep]\n",
    "df_ras = df2.merge(duplicate_records, on=[\"SE_Number\"], how=\"left\")\n",
    "df_ras = df_ras[df_ras['DupBreed'] != 1]\n",
    "df_ras.to_csv(\"kok_ras.csv\", index=False)\n",
    "\n",
    "dfKok = pd.read_csv(\"dfKok.csv\", low_memory=False)\n",
    "dfKok = dfKok.merge(df_ras, on=[\"FarmName_Pseudo\", \"SE_Number\"], how=\"left\")\n",
    "dfKok.to_csv(\"dfKok.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ADD INSEMINATION FROM COW DATABASE\n",
    "df13 = pd.read_csv(\"Kok_Reproduction240820.csv\", delimiter=';', low_memory=False)\n",
    "\n",
    "# Create a boolean mask where SireBull_SE_Number is NE 0\n",
    "mask = df13[\"SireBull_SE_Number\"] != 0\n",
    "# Sum the mask to count the number of True values (i.e., the number of not 0s)\n",
    "count_non_zeros = mask.sum()\n",
    "print(f\"Number of events with sire ID in cow database: {count_non_zeros}\")  # 95,369\n",
    "\n",
    "# Count occurrences of each unique value in the EventType column\n",
    "value_counts = df13[\"EventType\"].value_counts()\n",
    "print(value_counts)\n",
    "\"\"\"\n",
    "EventType\n",
    "Inseminering               47926\n",
    "Dräktighetsundersökning    41625\n",
    "Behandling                  2120\n",
    "Embryoinlägg                2092\n",
    "Betäckning                  1433\n",
    "Fri bet                      173\n",
    "\"\"\"\n",
    "# Keep only data from insemination\n",
    "df14 = df13[df13[\"EventType\"] == \"Inseminering\"]\n",
    "\n",
    "# Check for duplicates and sort\n",
    "print(f\"No. insemination records in raw file in cow database: {df14.shape}\")  # 47,926, 27col\n",
    "df14 = df14.sort_values(by=[\"BirthID\", \"EventDate\"])\n",
    "df15 = df14.drop_duplicates(subset=[\"BirthID\", \"EventDate\"])\n",
    "print(f\"No. unique inseminations in cow database: {df15.shape}\")  # 43,951, 27col\n",
    "\n",
    "df15 = df15.copy()\n",
    "df15.rename(columns={\"ActiveHerdNumber\": \"FarmName_Pseudo\", \"BirthID\": \"SE_Number\", \"EventDate\": \"InseminationDateKok\",\n",
    "                     \"SireBull_SE_Number\": \"SireBull_SE_NumberKok\"}, inplace=True)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"InseminationDateKok\", \"SireBull_SE_NumberKok\"]\n",
    "df15 = df15[col_keep]\n",
    "\n",
    "\"\"\"\n",
    "# Subset chosen cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "df15 = df15[df15[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Subset chosen cows\n",
    "SE_Number = [\"SE-064c0cec-1189\", \"SE-5c06d92d-3145\", \"SE-5c06d92d-3177\", \"SE-5b581702-1742\",\n",
    "             \"SE-5b581702-1851\", \"SE-5c06d92d-2915\", \"SE-5b581702-2002\", \"SE-5c06d92d-2515\"]\n",
    "df15 = df15[df15[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "# Merge with calving data\n",
    "dfkok2 = pd.read_csv(\"dfKok.csv\", low_memory=False)\n",
    "dfins6 = pd.merge(dfkok2, df15, on=[\"FarmName_Pseudo\", \"SE_Number\"])\n",
    "\n",
    "# Filter df for relevant inseminations sorted to correct lactation\n",
    "dfins6 = dfins6[(dfins6[\"InseminationDateKok\"] >= dfins6[\"CalvingDateKok\"]) & (dfins6[\"InseminationDateKok\"] <= dfins6[\"upper_limit\"])]\n",
    "dfins6.to_csv(\"dfKok.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ADD PREGNANCY CHECKS FROM COW DATABASE\n",
    "# Make next_ins to sort pregnancy checks\n",
    "df20 = pd.read_csv(\"dfKok.csv\", low_memory=False)\n",
    "# df20 = pd.DataFrame(df20, columns=[\"SE_Number\", \"LactationNumberKok\", \"InseminationDateKok\", \"upper_limit\"])\n",
    "\n",
    "df20['next_ins'] = df20.groupby(['SE_Number', 'LactationNumberKok'])['InseminationDateKok'].shift(-1)\n",
    "\n",
    "# only keep next_ins where falls within range\n",
    "dfins7 = df20[(df20[\"next_ins\"] >= df20[\"InseminationDateKok\"]) & (df20[\"next_ins\"] <= df20[\"upper_limit\"])]\n",
    "col_keep = [\"SE_Number\", \"LactationNumberKok\", \"InseminationDateKok\", \"next_ins\", \"upper_limit\"]\n",
    "dfins7 = dfins7[col_keep]\n",
    "dfins7.to_csv(\"dfKok2.csv\", index=False)\n",
    "\n",
    "\"\"\"\n",
    "#Subset chosen cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "dfins8 = dfins8[dfins8[\"SE_Number\"].isin(SE_Number)]\n",
    "#dfins8.to_csv(\"dataframe3.csv\", index=False)\n",
    "\"\"\"\n",
    "\n",
    "# Load pregnancy check data, check for duplicates, sort\n",
    "preg = pd.read_csv(\"Kok_Reproduction240820.csv\", delimiter=';', low_memory=False)\n",
    "# Keep only data from pregnancy checks\n",
    "preg = preg[preg[\"EventType\"] == \"Dräktighetsundersökning\"]\n",
    "\n",
    "col_keep = [\"BirthID\", \"EventDate\", \"PregnancyStatus\"]\n",
    "preg = preg[col_keep]\n",
    "preg.rename(columns={\"BirthID\": \"SE_Number\", \"EventDate\": \"PregnancyCheckDateKok\",\n",
    "                     \"PregnancyStatus\": \"PregnancyStatusKok\"}, inplace=True)\n",
    "\n",
    "print(f\"No. pregnancy checks in cow database: {preg.shape}\")  # 41,625 events, 3col\n",
    "preg = preg.drop_duplicates(subset=[\"SE_Number\", \"PregnancyCheckDateKok\"])\n",
    "print(f\"No. unique pregnancy checks in cow database: {preg.shape}\")    # 38,320 unique events, 3col\n",
    "preg = preg.sort_values(by=[\"SE_Number\", \"PregnancyCheckDateKok\"])\n",
    "\n",
    "# Add to subset df\n",
    "col_keep = [\"SE_Number\", \"LactationNumberKok\", \"InseminationDateKok\", \"next_ins\", \"upper_limit\"]\n",
    "df20 = df20[col_keep]\n",
    "df21 = df20.join(preg.set_index([\"SE_Number\"]), on=[\"SE_Number\"])\n",
    "\n",
    "# Ensure datetime conversion\n",
    "df21['InseminationDateKok'] = pd.to_datetime(df21['InseminationDateKok'])\n",
    "df21['PregnancyCheckDateKok'] = pd.to_datetime(df21['PregnancyCheckDateKok'])\n",
    "df21['next_ins'] = pd.to_datetime(df21['next_ins'])\n",
    "df21['upper_limit'] = pd.to_datetime(df21['upper_limit'])\n",
    "\n",
    "# Initialize 'C' column with NaN\n",
    "df21['C'] = np.nan\n",
    "\n",
    "\n",
    "# Define the filtering function\n",
    "def filter_pregcheck(row):\n",
    "    if pd.isna(row[\"next_ins\"]):\n",
    "        if (row[\"PregnancyCheckDateKok\"] >= row[\"InseminationDateKok\"]) and (row[\"PregnancyCheckDateKok\"]\n",
    "                                                                             <= row[\"upper_limit\"]):\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "    if pd.notna(row[\"next_ins\"]):\n",
    "        if (row[\"PregnancyCheckDateKok\"] >= row[\"InseminationDateKok\"]) and (row[\"PregnancyCheckDateKok\"]\n",
    "                                                                             <= row[\"next_ins\"]):\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "\n",
    "\n",
    "# Apply the filter function to each row\n",
    "df21['C'] = df21.apply(filter_pregcheck, axis=1)\n",
    "dfins10 = df21[df21[\"C\"] == \"Yes\"]\n",
    "dfins10.to_csv(\"dfKok2.csv\", index=False)\n",
    "\n",
    "col_keep = [\"SE_Number\", \"LactationNumberKok\", \"InseminationDateKok\", \"PregnancyCheckDateKok\", \"PregnancyStatusKok\"]\n",
    "dfins11 = dfins10[col_keep]\n",
    "\n",
    "# Convert the 'InseminationDate' column from datetime64[ns] to object for merging\n",
    "print(dfins11.dtypes)\n",
    "dfins11 = dfins11.copy()\n",
    "dfins11['InseminationDateKok'] = dfins11['InseminationDateKok'].astype(str)\n",
    "\n",
    "# Add to master df\n",
    "dfins12 = pd.read_csv(\"dfKok.csv\")\n",
    "print(dfins12.dtypes)\n",
    "dfins13 = dfins12.merge(dfins11, on=[\"SE_Number\", \"LactationNumberKok\", \"InseminationDateKok\"], how=\"left\")\n",
    "\n",
    "\"\"\"\n",
    "#Subset chosen cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "dfins13 = dfins13[dfins13[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "dfins13.to_csv(\"dfKok.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DELPRO DATA\n",
    "\n",
    "Requires the following data to create dfDelPro.csv:\n",
    "- Del_Calving\n",
    "- Del_DryOff\n",
    "- Del_Lactation\n",
    "- Del_Cow\n",
    "- Del_Insemination\n",
    "- Del_PregnancyCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# LOAD DELPRO CALVING DATA\n",
    "calving = pd.read_csv(\"Del_Calving240823.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"CalvingDate\"]\n",
    "calving = calving[col_keep]\n",
    "calving.rename(columns={\"CalvingDate\": \"CalvingDateDelPro\"}, inplace=True)\n",
    "calving = calving.sort_values(by=[\"SE_Number\", \"CalvingDateDelPro\"])\n",
    "calving = calving.drop_duplicates(subset=[\"SE_Number\", \"CalvingDateDelPro\"])\n",
    "calving[\"upper_limit\"] = calving.groupby([\"SE_Number\"])[\"CalvingDateDelPro\"].shift(-1)\n",
    "calving.to_csv(\"calving_delpro.csv\", index=False)\n",
    "\n",
    "calving2 = calving.groupby([\"FarmName_Pseudo\"])[\"CalvingDateDelPro\"].count().reset_index()\n",
    "calving2.rename(columns={'CalvingDateDelPro': 'CountLact'}, inplace=True)\n",
    "print(f\"No. of lactation records in DelPro in different herds: \\n\", calving2.to_string(index=False))\n",
    "calving2 = calving.drop_duplicates(subset=[\"SE_Number\", \"CalvingDateDelPro\"])\n",
    "print(f\"No. of lactation records in DelPro: {calving2.shape}\")  # 10,163\n",
    "\n",
    "calving2 = calving.groupby([\"FarmName_Pseudo\"])[\"SE_Number\"].count().reset_index()\n",
    "calving2.rename(columns={'SE_Number': 'CountCows'}, inplace=True)\n",
    "print(f\"No. of cows with calving data in DelPro in different herds: \\n\", calving2.to_string(index=False))\n",
    "calving2 = calving.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows with calving data in DelPro: {calving2.shape}\")  # 5,401\n",
    "\n",
    "# LOAD DELPRO CULLING DATA\n",
    "culling = pd.read_csv(\"Del_Cow240823.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"SE_Number\", \"BirthDate\", \"CullDecisionDate\", \"CullReason1\", \"CullReason2\"]\n",
    "culling = culling[col_keep]\n",
    "culling = culling.sort_values(by=[\"SE_Number\", \"CullDecisionDate\"])\n",
    "print(f\"No. records in raw culling file: {culling.shape}\")  # 25,105\n",
    "culling2 = culling.drop_duplicates(subset=[\"SE_Number\", \"CullDecisionDate\"])\n",
    "print(f\"No. records in culling file: {culling.shape}\")  # 25,105\n",
    "culling2.to_csv(\"cull_delpro.csv\", index=False)\n",
    "\n",
    "# Merge\n",
    "for_my_rec = calving.merge(culling2, on=[\"SE_Number\"], how=\"left\")\n",
    "for_my_rec.loc[pd.isna(for_my_rec[\"upper_limit\"]), \"upper_limit\"] = for_my_rec[\"CullDecisionDate\"]\n",
    "for_my_rec.to_csv(\"dfDelPro.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# LOAD DELPRO CULLING DATA\n",
    "culling = pd.read_csv(\"Del_Cow240823.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"SE_Number\", \"BirthDate\", \"CullDecisionDate\", \"CullReason1\", \"CullReason2\"]\n",
    "culling = culling[col_keep]\n",
    "culling = culling.sort_values(by=[\"SE_Number\", \"CullDecisionDate\"])\n",
    "print(f\"No. records in raw culling file: {culling.shape}\")  # 25,105\n",
    "culling2 = culling.drop_duplicates(subset=[\"SE_Number\", \"CullDecisionDate\"])\n",
    "print(f\"No. records in culling file: {culling.shape}\")  # 25,105\n",
    "culling2.to_csv(\"cull_delpro.csv\", index=False)\n",
    "\n",
    "# Merge\n",
    "for_my_rec = calving.merge(culling2, on=[\"SE_Number\"], how=\"left\")\n",
    "for_my_rec.loc[pd.isna(for_my_rec[\"upper_limit\"]), \"upper_limit\"] = for_my_rec[\"CullDecisionDate\"]\n",
    "for_my_rec.to_csv(\"dfDelPro.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# LOAD DELPRO DRY OFF DATA\n",
    "dry_off = pd.read_csv(\"Del_DryOff240823.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"SE_Number\", \"DryOffDate\"]\n",
    "dry_off = dry_off[col_keep]\n",
    "dry_off = dry_off.sort_values(by=[\"SE_Number\", \"DryOffDate\"])\n",
    "dry_off = dry_off.drop_duplicates(subset=[\"SE_Number\", \"DryOffDate\"])\n",
    "print(f\"No. records in dry off file: {dry_off.shape}\")  # 5,305\n",
    "dry_off.to_csv(\"dry_off_delpro.csv\", index=False)\n",
    "\n",
    "for_my_rec = for_my_rec.merge(dry_off, on=[\"SE_Number\"], how=\"left\")\n",
    "for_my_rec[\"CalvingDateDelPro\"] = pd.to_datetime(for_my_rec[\"CalvingDateDelPro\"])\n",
    "for_my_rec[\"DryOffDate\"] = pd.to_datetime(for_my_rec[\"DryOffDate\"])\n",
    "for_my_rec[\"upper_limit\"] = pd.to_datetime(for_my_rec[\"upper_limit\"])\n",
    "\n",
    "\n",
    "def data(row):\n",
    "    if row[\"CalvingDateDelPro\"] < row[\"DryOffDate\"] <= row[\"upper_limit\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "for_my_rec[\"dryoff\"] = for_my_rec.apply(data, axis=1)\n",
    "\n",
    "# Keep all records with dry off dates fitted within lactation\n",
    "df_ones = for_my_rec[for_my_rec['dryoff'] == 1]\n",
    "# Keep last record where open and lacking dry off date\n",
    "df_last_zero = for_my_rec[for_my_rec['dryoff'] == 0].groupby(\"SE_Number\").tail(1)\n",
    "# Concatenate dataframe and sort to maintain original order\n",
    "df_combined = pd.concat([df_ones, df_last_zero])\n",
    "df_combined = df_combined.sort_values(by=[\"SE_Number\", \"CalvingDateDelPro\"]).reset_index(drop=True)\n",
    "df_combined.to_csv(\"dfDelPro.csv\", index=False)\n",
    "\n",
    "# Get today's date for current lactation missing upper_limit\n",
    "df_combined['TodayDate'] = pd.to_datetime('today').normalize()\n",
    "df_combined.loc[df_combined[\"upper_limit\"].isna() & df_combined[\"CullDecisionDate\"].isna(), \"upper_limit\"] = (\n",
    "    df_combined)[\"TodayDate\"]\n",
    "\n",
    "df_combined.loc[df_combined[\"upper_limit\"].isna()\n",
    "                & (df_combined[\"DryOffDate\"] < df_combined[\"CalvingDateDelPro\"]), \"upper_limit\"] = df_combined[\n",
    "    \"DryOffDate\"]\n",
    "df_combined.loc[df_combined[\"dryoff\"] == 0, \"DryOffDate\"] = np.nan\n",
    "df_combined.to_csv(\"dfDelPro.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# LOAD DELPRO LACTATION NUMBER\n",
    "lact = pd.read_csv(\"Del_Lactation240823.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"SE_Number\", \"LactationInfoDate\", \"LactationNumber\"]\n",
    "lact = lact[col_keep]\n",
    "lact = lact.sort_values(by=[\"SE_Number\", \"LactationInfoDate\", \"LactationNumber\"])\n",
    "lact = lact.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "lact.to_csv(\"lact.csv\", index=False)\n",
    "\n",
    "for_my_rec2 = lact.merge(df_combined, on=[\"SE_Number\"], how=\"left\")\n",
    "for_my_rec2 = for_my_rec2[for_my_rec2[\"LactationInfoDate\"] != \"2022-05\"]\n",
    "for_my_rec2[\"LactationInfoDate\"] = pd.to_datetime(for_my_rec2[\"LactationInfoDate\"])\n",
    "\n",
    "\n",
    "def data1(row):\n",
    "    if row[\"CalvingDateDelPro\"] <= row[\"LactationInfoDate\"] <= row[\"upper_limit\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "for_my_rec2[\"lact\"] = for_my_rec2.apply(data1, axis=1)\n",
    "for_my_rec2 = for_my_rec2[for_my_rec2['lact'] == 1]\n",
    "for_my_rec2.to_csv(\"dfDelPro.csv\", index=False)\n",
    "print(f\"No. of lactations in dataframe: {for_my_rec2.shape}\")  # 10,361 lact - when DelPro data is used\n",
    "for_my_rec3 = for_my_rec2.drop_duplicates(\"SE_Number\")\n",
    "print(f\"No. of cows in dataframe: {for_my_rec3.shape}\")  # 5,397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ADD DELPRO BREED INFORMATION\n",
    "breed = pd.read_csv(\"Del_Cow240823.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"SE_Number\", \"BreedName\"]\n",
    "breed = breed[col_keep]\n",
    "breed = breed.sort_values(by=[\"SE_Number\", \"BreedName\"])\n",
    "breed = breed.drop_duplicates(subset=[\"SE_Number\", \"BreedName\"])\n",
    "breed.to_csv(\"breed.csv\", index=False)\n",
    "\n",
    "for_my_rec2 = for_my_rec2.merge(breed, on=[\"SE_Number\"], how=\"left\")  # - when Del_Calving is used\n",
    "# for_my_rec2 = df_combined.merge(breed, on=[\"SE_Number\"], how=\"left\") - when cow database is used\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"BreedName\", \"LactationNumber\", \"CalvingDateDelPro\", \"upper_limit\",\n",
    "            \"CullDecisionDate\", \"CullReason1\", \"CullReason2\", \"DryOffDate\"]\n",
    "for_my_rec2 = for_my_rec2[col_keep]\n",
    "for_my_rec2.rename(columns={\"BreedName\": \"BreedNameDelPro\", \"LactationNumber\": \"LactationNumberDelPro\",\n",
    "                            \"BirthDate\": \"BirthDateDelPro\",\n",
    "                            \"upper_limit\": \"UpperLimitDelPro\", \"CullDecisionDate\": \"CullDecisionDateDelPro\",\n",
    "                            \"CullReason1\": \"CullReason1DelPro\", \"CullReason2\": \"CullReason2DelPro\",\n",
    "                            \"DryOffDate\": \"DryOffDateDelPro\"}, inplace=True)\n",
    "for_my_rec2.to_csv(\"dfDelPro.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ADD INSEMINATION DATA FROM DELPRO\n",
    "# Load data, keep cowid, insdate, check for duplicates, sort\n",
    "dfins = pd.read_csv(\"Del_Insemination240823.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"InseminationDate\", \"Breeder\"]\n",
    "dfins2 = dfins[col_keep]\n",
    "print(dfins2.shape)  # 18,775 insemination events, 6col\n",
    "dfins2 = dfins2.drop_duplicates(subset=[\"SE_Number\", \"InseminationDate\"])\n",
    "print(dfins2.shape)  # 18,689 unique insemination events, 6col\n",
    "dfins2 = dfins2.sort_values(by=[\"SE_Number\", \"InseminationDate\"])\n",
    "\n",
    "dfins2.rename(columns={\"InseminationDate\": \"InseminationDateDelPro\", \"Breeder\": \"BreederDelPro\"}, inplace=True)\n",
    "\n",
    "# Merge with dataframe\n",
    "delpro = pd.read_csv(\"dfDelPro.csv\", low_memory=False)\n",
    "dfins4 = pd.merge(delpro, dfins2, on=[\"FarmName_Pseudo\", \"SE_Number\"])\n",
    "\"\"\"\n",
    "# Subset chosen cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "dfins4 = dfins4[dfins4[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "# Filter df for relevant insemination sorted to correct lactation\n",
    "dfins5 = dfins4[(dfins4[\"InseminationDateDelPro\"] >= dfins4[\"CalvingDateDelPro\"]) & (dfins4[\"InseminationDateDelPro\"] <= dfins4[\"UpperLimitDelPro\"])]\n",
    "dfins5.to_csv(\"dfDelPro.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ADD PREGNANCY CHECKS FROM DELPRO\n",
    "# Make next_ins to sort pregnancy checks\n",
    "df20 = pd.read_csv(\"dfDelPro.csv\", low_memory=False)\n",
    "df20['next_ins'] = df20.groupby(['SE_Number', 'LactationNumberDelPro'])['InseminationDateDelPro'].shift(-1)\n",
    "\n",
    "# only keep next_ins where falls within range\n",
    "dfins7 = df20[(df20[\"next_ins\"] >= df20[\"InseminationDateDelPro\"]) & (df20[\"next_ins\"] <= df20[\"UpperLimitDelPro\"])]\n",
    "col_keep = [\"SE_Number\", \"LactationNumberDelPro\", \"InseminationDateDelPro\", \"next_ins\", \"UpperLimitDelPro\"]\n",
    "dfins7 = dfins7[col_keep]\n",
    "dfins7.to_csv(\"dfDelPro2.csv\", index=False)\n",
    "\n",
    "\"\"\"\n",
    "#Subset chosen cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "dfins8 = dfins8[dfins8[\"SE_Number\"].isin(SE_Number)]\n",
    "#dfins8.to_csv(\"dataframe3.csv\", index=False)\n",
    "\"\"\"\n",
    "\n",
    "# Load pregnancy check data, check for duplicates, sort\n",
    "preg = pd.read_csv(\"Del_PregnancyCheck240823.csv\", delimiter=';', low_memory=False)\n",
    "\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"PregnancyCheckDate\", \"PregnancyCheckResult\"]\n",
    "preg = preg[col_keep]\n",
    "preg.rename(columns={\"PregnancyCheckDate\": \"PregnancyCheckDateDelPro\",\n",
    "                     \"PregnancyCheckResult\": \"PregnancyCheckResultDelPro\"}, inplace=True)\n",
    "\n",
    "print(f\"No. pregnancy checks in cow database: {preg.shape}\")  # 14,169 events, 4col\n",
    "preg = preg.drop_duplicates(subset=[\"SE_Number\", \"PregnancyCheckDateDelPro\"])\n",
    "print(f\"No. unique pregnancy checks in cow database: {preg.shape}\")    # 14,146 unique events, 4col\n",
    "preg = preg.sort_values(by=[\"SE_Number\", \"PregnancyCheckDateDelPro\"])\n",
    "\n",
    "# Add to subset df\n",
    "col_keep = [\"SE_Number\", \"LactationNumberDelPro\", \"InseminationDateDelPro\", \"next_ins\", \"UpperLimitDelPro\"]\n",
    "df20 = df20[col_keep]\n",
    "df21 = df20.join(preg.set_index([\"SE_Number\"]), on=[\"SE_Number\"])\n",
    "df21.to_csv(\"dfDelPro2.csv\", index=False)\n",
    "\n",
    "# Ensure datetime conversion\n",
    "df21['InseminationDateDelPro'] = pd.to_datetime(df21['InseminationDateDelPro'])\n",
    "df21['PregnancyCheckDateDelPro'] = pd.to_datetime(df21['PregnancyCheckDateDelPro'])\n",
    "df21['next_ins'] = pd.to_datetime(df21['next_ins'])\n",
    "df21['UpperLimitDelPro'] = pd.to_datetime(df21['UpperLimitDelPro'])\n",
    "\n",
    "# Initialize 'C' column with NaN\n",
    "df21['C'] = np.nan\n",
    "\n",
    "\n",
    "# Define the filtering function\n",
    "def filter_pregcheck(row):\n",
    "    if pd.isna(row[\"next_ins\"]):\n",
    "        if (row[\"PregnancyCheckDateDelPro\"] >= row[\"InseminationDateDelPro\"]) and (row[\"PregnancyCheckDateDelPro\"] <= row[\"UpperLimitDelPro\"]):\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "    if pd.notna(row[\"next_ins\"]):\n",
    "        if (row[\"PregnancyCheckDateDelPro\"] >= row[\"InseminationDateDelPro\"]) and (row[\"PregnancyCheckDateDelPro\"] <= row[\"next_ins\"]):\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "\n",
    "\n",
    "# Apply the filter function to each row\n",
    "df21['C'] = df21.apply(filter_pregcheck, axis=1)\n",
    "dfins10 = df21[df21[\"C\"] == \"Yes\"]\n",
    "dfins10.to_csv(\"dfDelPro2.csv\", index=False)\n",
    "\n",
    "col_keep = [\"SE_Number\", \"LactationNumberDelPro\", \"InseminationDateDelPro\", \"PregnancyCheckDateDelPro\",\n",
    "            \"PregnancyCheckResultDelPro\"]\n",
    "dfins11 = dfins10[col_keep]\n",
    "\n",
    "# Convert the 'InseminationDate' column from datetime64[ns] to object for merging\n",
    "print(dfins11.dtypes)\n",
    "dfins11 = dfins11.copy()\n",
    "dfins11['InseminationDateDelPro'] = dfins11['InseminationDateDelPro'].astype(str)\n",
    "\n",
    "# Add to master df\n",
    "dfins12 = pd.read_csv(\"dfDelPro.csv\")\n",
    "print(dfins12.dtypes)\n",
    "dfins13 = dfins12.merge(dfins11, on=[\"SE_Number\", \"LactationNumberDelPro\", \"InseminationDateDelPro\"], how=\"left\")\n",
    "\"\"\"\n",
    "#Subset chosen cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "dfins13 = dfins13[dfins13[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "dfins13.to_csv(\"dfDelPro.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAIRING COW DATABASE AND DELPRO DATA\n",
    "- Use primarily cow database data, fill from DelPro where have missing data.\n",
    "\n",
    "Creates the following datasets:\n",
    "- calving.csv\n",
    "- culling.csv\n",
    "- dry_off.csv\n",
    "- breed.csv\n",
    "- insemination.csv\n",
    "- pregnancy_checks.csv\n",
    "- updateDF.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# PAIRING COW DATABASE AND DELPRO DATA FOR CALVING\n",
    "cKok = pd.read_csv(\"dfKok.csv\", low_memory=False)\n",
    "cKok[\"CalvingDate\"] = cKok[\"CalvingDateKok\"]\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"CalvingDate\", \"CalvingDateKok\", \"LactationNumberKok\"]\n",
    "cKok = cKok[col_keep]\n",
    "cKok = cKok.drop_duplicates(subset=[\"SE_Number\", \"CalvingDateKok\"])\n",
    "\n",
    "cDel = pd.read_csv(\"dfDelPro.csv\", low_memory=False)\n",
    "cDel[\"CalvingDate\"] = cDel[\"CalvingDateDelPro\"]\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"CalvingDate\", \"CalvingDateDelPro\", \"LactationNumberDelPro\"]\n",
    "cDel = cDel[col_keep]\n",
    "cDel = cDel.drop_duplicates(subset=[\"SE_Number\", \"CalvingDateDelPro\"])\n",
    "\n",
    "df_sum = pd.merge(cKok, cDel, on=[\"FarmName_Pseudo\", \"SE_Number\", \"CalvingDate\"], how='outer')\n",
    "df_sum = df_sum.sort_values(by=[\"FarmName_Pseudo\", \"SE_Number\", \"CalvingDate\"])\n",
    "\n",
    "\"\"\"\n",
    "# Subset chosen cow - stämmer!\n",
    "# SE-169e580a-3418 has 5 lactations, 4 in cow database (missing lact 3), last three in DelPro\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "df_sum = df_sum[df_sum[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "df_sum['LactationNumber'] = df_sum['LactationNumberKok'].fillna(df_sum['LactationNumberDelPro'])\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"CalvingDate\", \"LactationNumber\"]\n",
    "df_sum = df_sum[col_keep]\n",
    "df_sum.to_csv(\"calving.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# PAIRING COW DATABASE AND DELPRO FOR CULLING\n",
    "cKok2 = pd.read_csv(\"dfKok.csv\", low_memory=False)\n",
    "cKok2 = cKok2.drop_duplicates(subset=[\"SE_Number\", \"ExitDateKok\"])\n",
    "cKok2[\"CullingDate\"] = cKok2[\"ExitDateKok\"]\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"CullingDate\", \"ExitDateKok\", \"ExitReason_PrimaryReasonKok\",\n",
    "            \"ExitReason_SecondaryReason1Kok\", \"ExitReason_SecondaryReason2Kok\"]\n",
    "cKok2 = cKok2[col_keep]\n",
    "cKok2 = cKok2.drop_duplicates(subset=[\"SE_Number\", \"CullingDate\"])\n",
    "\n",
    "cDel2 = pd.read_csv(\"for_my_rec2.csv\", low_memory=False)\n",
    "cDel2 = cDel2.drop_duplicates(subset=[\"SE_Number\", \"CullDecisionDateDelPro\"])\n",
    "cDel2[\"CullingDate\"] = cDel2[\"CullDecisionDateDelPro\"]\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"CullingDate\", \"CullDecisionDateDelPro\", \"CullReason1DelPro\",\n",
    "            \"CullReason2DelPro\"]\n",
    "cDel2 = cDel2[col_keep]\n",
    "cDel2 = cDel2.drop_duplicates(subset=[\"SE_Number\", \"CullingDate\"])\n",
    "\n",
    "cKok2['CullingDate'] = cKok2['ExitDateKok'].fillna(cDel2['CullDecisionDateDelPro'])\n",
    "cKok2['CullingReason1'] = cKok2['ExitReason_PrimaryReasonKok'].fillna(cDel2['CullReason1DelPro'])\n",
    "cKok2['CullingReason2'] = cKok2['ExitReason_SecondaryReason1Kok'].fillna(cDel2['CullReason2DelPro'])\n",
    "\n",
    "\"\"\"\n",
    "# Subset chosen cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "df_sum = df_sum[df_sum[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "# filt = cKok[cKok[\"ExitDateKok\"].isna()]\n",
    "# filt = cKok[cKok[\"ExitReason_SecondaryReason2Kok\"].notna()]\n",
    "\n",
    "cKok2.drop(columns=[\"ExitDateKok\"], inplace=True)\n",
    "cKok2.to_csv(\"culling.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# PAIRING COW DATABASE AND DELPRO FOR DRY OFF\n",
    "cKok3 = pd.read_csv(\"dfKok.csv\", low_memory=False)\n",
    "cKok3 = cKok3.drop_duplicates(subset=[\"SE_Number\", \"DryOffDateKok\"])\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumberKok\", \"DryOffDateKok\"]\n",
    "cKok3 = cKok3[col_keep]\n",
    "cKok3.rename(columns={\"LactationNumberKok\": \"LactationNumber\"}, inplace=True)\n",
    "cKok3 = cKok3.drop_duplicates(subset=[\"SE_Number\", \"DryOffDateKok\"])\n",
    "\n",
    "cDel3 = pd.read_csv(\"for_my_rec2.csv\", low_memory=False)\n",
    "cDel3 = cDel3.drop_duplicates(subset=[\"SE_Number\", \"DryOffDateDelPro\"])\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumberDelPro\", \"DryOffDateDelPro\"]\n",
    "cDel3 = cDel3[col_keep]\n",
    "cDel3.rename(columns={\"LactationNumberDelPro\": \"LactationNumber\"}, inplace=True)\n",
    "cDel3 = cDel3.drop_duplicates(subset=[\"SE_Number\", \"DryOffDateDelPro\"])\n",
    "\n",
    "merged_df = pd.merge(cKok3, cDel3, on=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\"], how='outer')\n",
    "merged_df['DryOffDate'] = merged_df['DryOffDateKok'].combine_first(merged_df['DryOffDateDelPro'])\n",
    "merged_df = merged_df.sort_values(by=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\"])\n",
    "\n",
    "\"\"\"\n",
    "# Subset chosen cow\n",
    "# obs 867, SE-169e580a-2843, good example cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "merged_df = merged_df[merged_df[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "merged_df.to_csv(\"dry_off.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# PAIRING COW DATABASE AND DELPRO FOR BREED\n",
    "cKok4 = pd.read_csv(\"dfKok.csv\", low_memory=False)\n",
    "cKok4 = cKok4.drop_duplicates(subset=[\"SE_Number\"])\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"SireBreedKok\", \"DamBreedKok\", \"MGSBreedKok\"]\n",
    "cKok4 = cKok4[col_keep]\n",
    "cKok4 = cKok4.drop_duplicates(subset=[\"SE_Number\"])\n",
    "\n",
    "cDel4 = pd.read_csv(\"for_my_rec2.csv\", low_memory=False)\n",
    "cDel4 = cDel4.drop_duplicates(subset=[\"SE_Number\"])\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"BreedNameDelPro\"]\n",
    "cDel4 = cDel4[col_keep]\n",
    "cDel4 = cDel4.drop_duplicates(subset=[\"SE_Number\"])\n",
    "\n",
    "merged_df = pd.merge(cKok4, cDel4, on=[\"FarmName_Pseudo\", \"SE_Number\"], how='outer')\n",
    "\n",
    "# Setting options to display more rows and columns\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "\n",
    "frequency_table = pd.crosstab(merged_df['SireBreedKok'], merged_df['DamBreedKok'])\n",
    "print(frequency_table)\n",
    "\n",
    "\n",
    "# Define breeds in cow database\n",
    "def categorize1(value):\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SRB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"RB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB-SRB\") and (value[\"DamBreedKok\"] == \"RB-SRB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"RB-SRB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"RB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB-SRB\") and (value[\"DamBreedKok\"] == \"RB-SRB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"RB-SRB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"SRB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB-SRB\") and (value[\"DamBreedKok\"] == \"SRB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB-RB\") and (value[\"DamBreedKok\"] == \"SRB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"SRB-RB\"):\n",
    "        return \"NRDC\"\n",
    "    if (value[\"SireBreedKok\"] == \"SAB\") and (value[\"DamBreedKok\"] == \"SAB\"):\n",
    "        return \"NRDC\"\n",
    "\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SLB\"):\n",
    "        return \"SLB\"\n",
    "    if (value[\"SireBreedKok\"] == \"SJB\") and (value[\"DamBreedKok\"] == \"SJB\") and (value[\"MGSBreedKok\"] == \"SJB\"):\n",
    "        return \"SJB\"\n",
    "\n",
    "    if (value[\"SireBreedKok\"] == \"FJÄ\") and (value[\"DamBreedKok\"] == \"FJÄ\"):\n",
    "        return \"Other\"\n",
    "    if (value[\"SireBreedKok\"] == \"SIM\") and (value[\"DamBreedKok\"] == \"SIM\"):\n",
    "        return \"Other\"\n",
    "\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SLB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"RB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"RB-SLB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"RB-SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SJB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SJB-SLB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SJB-SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SKB-SJB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SKB-SLB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SLB-RB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SLB-SJB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SLB-SKB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SLB-SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SRB-RB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SRB-SJB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SRB-SLB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"RB-SJB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SJB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SJB-SLB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SJB-SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SLB-SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SRB-SKB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SRB-SLB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"SJB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"SJB-SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"SLB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"SRB-SJB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"SRB-SLB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SKB\") and (value[\"DamBreedKok\"] == \"FJÄ\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SAB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SAB\") and (value[\"DamBreedKok\"] == \"SAB-SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SAB-SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SAB-SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SAB-SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SLB-BSW\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SLB-SAB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"SRB-SAB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SAB\") and (value[\"DamBreedKok\"] == \"SRB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SRB-SAB\"):\n",
    "        return \"DairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"SRB-SAB\"):\n",
    "        return \"DairyCross\"\n",
    "\n",
    "    if (value[\"SireBreedKok\"] == \"RB\") and (value[\"DamBreedKok\"] == \"MON-SLB\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"CHA-RB\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"HER-SLB\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"MON-RB\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"MON-SLB\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"MON-SRB\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SLB-HER\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SRB-MON\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SLB\") and (value[\"DamBreedKok\"] == \"SLB-MON\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"MON-SLB\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SRB\") and (value[\"DamBreedKok\"] == \"MON-SRB\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SJB\") and (value[\"DamBreedKok\"] == \"SIM-SJB\"):\n",
    "        return \"DairyBeefCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SJB\") and (value[\"DamBreedKok\"] == \"SJB-SIM\"):\n",
    "        return \"DairyBeefCross\"\n",
    "\n",
    "    if (value[\"SireBreedKok\"] == \"CHA\") and (value[\"DamBreedKok\"] == \"RB-SRB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"CHA\") and (value[\"DamBreedKok\"] == \"SLB-SRB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"MON\") and (value[\"DamBreedKok\"] == \"SLB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"MON\") and (value[\"DamBreedKok\"] == \"SRB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"MON\") and (value[\"DamBreedKok\"] == \"RB-SLB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"MON\") and (value[\"DamBreedKok\"] == \"RB-SRB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"MON\") and (value[\"DamBreedKok\"] == \"SRB-SLB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"MON\") and (value[\"DamBreedKok\"] == \"SLB-SRB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SIM\") and (value[\"DamBreedKok\"] == \"SJB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SIM\") and (value[\"DamBreedKok\"] == \"SRB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SIM\") and (value[\"DamBreedKok\"] == \"SRB-SJB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"SIM\") and (value[\"DamBreedKok\"] == \"SRB-SAB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "    if (value[\"SireBreedKok\"] == \"HER\") and (value[\"DamBreedKok\"] == \"SLB-SRB\"):\n",
    "        return \"BeefDairyCross\"\n",
    "\n",
    "    if pd.isna(value[\"SireBreedKok\"]) and pd.isna(value[\"DamBreedKok\"]) and pd.isna(value[\"MGSBreedKok\"]):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "\n",
    "merged_df['BreedKok'] = merged_df.apply(categorize1, axis=1)\n",
    "merged_df.to_csv(\"breed.csv\", index=False)\n",
    "\n",
    "# Count the occurrences of each unique value in the breed column\n",
    "value_counts = merged_df['BreedKok'].value_counts()\n",
    "plt.figure(figsize=(10, 10))  # Optional: Set the figure size\n",
    "plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=140, pctdistance=0.85)\n",
    "plt.axis('equal')\n",
    "plt.title('Distribution of Breeds of Individuals According to Cow Database')\n",
    "plt.show()\n",
    "\n",
    "# Fix missing breed info from DelPro\n",
    "frequency_table = merged_df['BreedNameDelPro'].value_counts()\n",
    "print(frequency_table)\n",
    "\n",
    "\n",
    "# Define breeds in delpro\n",
    "def categorize2(value):\n",
    "    if value[\"BreedNameDelPro\"] == \"01 SRB\":\n",
    "        return \"NRDC\"\n",
    "    if value[\"BreedNameDelPro\"] == \"06 RB\":\n",
    "        return \"NRDC\"\n",
    "    if value[\"BreedNameDelPro\"] == \"02 SLB\":\n",
    "        return \"SLB\"\n",
    "    if value[\"BreedNameDelPro\"] == \"04 SJB\":\n",
    "        return \"SJB\"\n",
    "    if value[\"BreedNameDelPro\"] == \"03 SKB\":\n",
    "        return \"Other\"\n",
    "    if value[\"BreedNameDelPro\"] == \"Unknown Breed\":\n",
    "        return \"Unknown\"\n",
    "    if value[\"BreedNameDelPro\"] == \"186\":\n",
    "        return \"Unknown\"\n",
    "    if value[\"BreedNameDelPro\"] == \"187\":\n",
    "        return \"Unknown\"\n",
    "    if value[\"BreedNameDelPro\"] == \"99 Korsning/Obest Ras\":\n",
    "        return \"Unknown\"\n",
    "    if value[\"BreedNameDelPro\"] == \"99 Korsning/övriga raser\":\n",
    "        return \"Unknown\"\n",
    "    if value[\"BreedNameDelPro\"] == \"41 Fjällko\":\n",
    "        return \"Other\"\n",
    "    if value[\"BreedNameDelPro\"] == \"08 Hereford\":\n",
    "        return \"Other\"\n",
    "    if value[\"BreedNameDelPro\"] == \"11 Aberdeen Angus\":\n",
    "        return \"Other\"\n",
    "    if value[\"BreedNameDelPro\"] == \"28 Fleckvieh\":\n",
    "        return \"Other\"\n",
    "    if value[\"BreedNameDelPro\"] == \"27 Montbéliard\":\n",
    "        return \"Other\"\n",
    "    if (value[\"BreedKok\"] == \"Missing\") & pd.isna(value[\"BreedNameDelPro\"]):\n",
    "        return np.nan\n",
    "    if pd.isna(value[\"BreedNameDelPro\"]):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "\n",
    "merged_df['BreedDelPro'] = merged_df.apply(categorize2, axis=1)\n",
    "\n",
    "merged_df['Breed'] = merged_df['BreedKok'].fillna(merged_df['BreedDelPro'])\n",
    "merged_df.to_csv(\"breed.csv\", index=False)\n",
    "\n",
    "# Count the occurrences of each unique value in the 'Fruit' column\n",
    "value_counts = merged_df['Breed'].value_counts()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=140, pctdistance=0.85)\n",
    "plt.axis('equal')\n",
    "plt.title('Distribution of Breeds in Full Material')\n",
    "plt.show()\n",
    "\n",
    "# Fix missing breed info from DelPro\n",
    "frequency_table = merged_df['Breed'].value_counts()\n",
    "print(frequency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# PAIRING COW DATABASE AND DELPRO FOR INSEMINATION DATA\n",
    "cKok4 = pd.read_csv(\"dfKok.csv\", low_memory=False)\n",
    "cKok4 = cKok4.drop_duplicates(subset=[\"SE_Number\", \"InseminationDateKok\"])\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumberKok\", \"InseminationDateKok\"]\n",
    "cKok4 = cKok4[col_keep]\n",
    "cKok4.rename(columns={\"LactationNumberKok\": \"LactationNumber\"}, inplace=True)\n",
    "cKok4 = cKok4.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"InseminationDateKok\"])\n",
    "\n",
    "cDel4 = pd.read_csv(\"dfDelPro.csv\", low_memory=False)\n",
    "cDel4 = cDel4.drop_duplicates(subset=[\"SE_Number\", \"InseminationDateDelPro\"])\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumberDelPro\", \"InseminationDateDelPro\"]\n",
    "cDel4 = cDel4[col_keep]\n",
    "cDel4.rename(columns={\"LactationNumberDelPro\": \"LactationNumber\"}, inplace=True)\n",
    "cDel4 = cDel4.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"InseminationDateDelPro\"])\n",
    "\n",
    "merged_df = pd.merge(cKok4, cDel4, on=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\"], how='outer')\n",
    "merged_df['InseminationDate'] = merged_df['InseminationDateKok'].fillna(merged_df['InseminationDateDelPro'])\n",
    "merged_df = merged_df.drop_duplicates(subset=[\"SE_Number\", \"InseminationDate\"])\n",
    "\n",
    "\"\"\"\n",
    "# Subset chosen cow\n",
    "# obs 867, SE-169e580a-2843, good example cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "merged_df = merged_df[merged_df[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "merged_df = merged_df.sort_values(by=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"InseminationDate\"])\n",
    "merged_df.to_csv(\"insemination.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# PAIRING PREGNANCY CHECK FROM COW DATABASE AND DELPRO\n",
    "cKok5 = pd.read_csv(\"dfKok.csv\", low_memory=False)\n",
    "cKok5 = cKok5.drop_duplicates(subset=[\"SE_Number\", \"PregnancyCheckDateKok\"])\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumberKok\", \"PregnancyCheckDateKok\", \"PregnancyStatusKok\"]\n",
    "cKok5 = cKok5[col_keep]\n",
    "cKok5.rename(columns={\"LactationNumberKok\": \"LactationNumber\"}, inplace=True)\n",
    "cKok5 = cKok5.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"PregnancyCheckDateKok\"])\n",
    "\n",
    "cDel5 = pd.read_csv(\"dfDelPro.csv\", low_memory=False)\n",
    "cDel5 = cDel5.drop_duplicates(subset=[\"SE_Number\", \"InseminationDateDelPro\"])\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumberDelPro\", \"PregnancyCheckDateDelPro\",\n",
    "            \"PregnancyCheckResultDelPro\"]\n",
    "cDel5 = cDel5[col_keep]\n",
    "cDel5.rename(columns={\"LactationNumberDelPro\": \"LactationNumber\"}, inplace=True)\n",
    "cDel5 = cDel5.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"PregnancyCheckDateDelPro\"])\n",
    "\n",
    "merged_df = pd.merge(cKok5, cDel5, on=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\"], how='outer')\n",
    "merged_df['PregnancyCheckDate'] = merged_df['PregnancyCheckDateKok'].fillna(merged_df['PregnancyCheckDateDelPro'])\n",
    "merged_df['PregnancyStatus'] = merged_df['PregnancyStatusKok'].fillna(merged_df['PregnancyCheckResultDelPro'])\n",
    "merged_df = merged_df.drop_duplicates(subset=[\"SE_Number\", \"PregnancyCheckDate\"])\n",
    "\n",
    "\"\"\"\n",
    "# Subset chosen cow\n",
    "# obs 867, SE-169e580a-2843, good example cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "merged_df = merged_df[merged_df[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "merged_df.to_csv(\"pregnancy_checks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# BUILD MASTER DATAFRAME\n",
    "test2a = pd.read_csv(\"calving.csv\", low_memory=False)\n",
    "test2b = pd.read_csv(\"breed.csv\", low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"Breed\"]\n",
    "test2b = test2b[col_keep]\n",
    "test2c = pd.merge(test2a, test2b, on=[\"FarmName_Pseudo\", \"SE_Number\"], how='outer')\n",
    "test2c.to_csv(\"updateDF.csv\", index=False)\n",
    "\n",
    "test2d = pd.read_csv(\"insemination.csv\", low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"InseminationDate\"]\n",
    "test2d = test2d[col_keep]\n",
    "test2d = test2d.drop_duplicates(subset=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"InseminationDate\"])\n",
    "test2e = pd.merge(test2c, test2d, on=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\"], how='outer')\n",
    "test2e.to_csv(\"updateDF.csv\", index=False)\n",
    "\n",
    "test2f = pd.read_csv(\"pregnancy_checks.csv\", low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"PregnancyCheckDate\", \"PregnancyStatus\"]\n",
    "test2f = test2f[col_keep]\n",
    "test2f = test2f.drop_duplicates(subset=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"PregnancyCheckDate\"])\n",
    "test2g = pd.merge(test2e, test2f, on=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\"], how='outer')\n",
    "# test2g = test2g.drop_duplicates(subset=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"PregnancyCheckDate\"])\n",
    "test2g = test2g.sort_values(by=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"InseminationDate\", \"PregnancyCheckDate\"])\n",
    "test2g.to_csv(\"updateDF.csv\", index=False)\n",
    "\n",
    "test2h = pd.read_csv(\"dry_off.csv\", low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"DryOffDate\"]\n",
    "test2h = test2h[col_keep]\n",
    "test2h = test2h.drop_duplicates(subset=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"DryOffDate\"])\n",
    "test2i = pd.merge(test2g, test2h, on=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\"], how='outer')\n",
    "\n",
    "\"\"\"\n",
    "# Subset chosen cow\n",
    "# obs 867, SE-169e580a-2843, good example cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "test2i = test2i[test2i[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "test2i.to_csv(\"updateDF.csv\", index=False)\n",
    "\n",
    "test2j = pd.read_csv(\"culling.csv\", low_memory=False)\n",
    "test2j = test2j.drop_duplicates(subset=[\"FarmName_Pseudo\", \"SE_Number\", \"CullingDate\"])\n",
    "test2k = pd.merge(test2i, test2j, on=[\"FarmName_Pseudo\", \"SE_Number\"], how='outer')\n",
    "test2k.to_csv(\"updateDF.csv\", index=False)\n",
    "\n",
    "\"\"\"\n",
    "# Subset chosen cow\n",
    "# obs 867, SE-169e580a-2843, good example cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "test2k = test2k[test2k[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"InseminationDate\", \"PregnancyCheckDate\", \"PregnancyStatus\"]\n",
    "test2k2 = test2k[col_keep]\n",
    "\n",
    "# Sort pregnancy checks and keep only for relevant insemination\n",
    "test2l = test2k2.drop_duplicates(subset=[\"SE_Number\", \"CalvingDate\", \"InseminationDate\"])\n",
    "test2l = test2l.copy()\n",
    "test2l[\"next_ins\"] = test2l.groupby([\"SE_Number\", \"LactationNumber\"])[\"InseminationDate\"].shift(-1)\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"InseminationDate\", \"next_ins\"]\n",
    "test2l = test2l[col_keep]\n",
    "test2m = pd.merge(test2k2, test2l, on=[\"SE_Number\", \"LactationNumber\", \"InseminationDate\"], how='outer')\n",
    "# test2m.to_csv(\"updateDF2.csv\", index=False)\n",
    "\n",
    "test2m.loc[test2m['PregnancyCheckDate'] > test2m['next_ins'], 'PregnancyCheckDate'] = np.nan\n",
    "test2m.loc[test2m['PregnancyCheckDate'] < test2m['InseminationDate'], 'PregnancyCheckDate'] = np.nan\n",
    "# test2m.to_csv(\"updateDF3.csv\", index=False)\n",
    "\n",
    "test2n = test2m.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"InseminationDate\", \"PregnancyCheckDate\"])\n",
    "test2n = test2n.sort_values(by=[\"SE_Number\", \"LactationNumber\", \"InseminationDate\", \"PregnancyCheckDate\"])\n",
    "# test2n.to_csv(\"updateDF.csv\", index=False)\n",
    "\n",
    "df_not_missing = test2n[test2n['PregnancyCheckDate'].notna()]\n",
    "# df_not_missing.to_csv(\"updateDF4.csv\", index=False)\n",
    "\n",
    "test2o = test2n[test2n['PregnancyCheckDate'].isnull()]\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"InseminationDate\"]\n",
    "test2o = test2o[col_keep]\n",
    "# test2o.to_csv(\"updateDF5.csv\", index=False)\n",
    "\n",
    "test2p = pd.merge(df_not_missing, test2o, on=[\"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"InseminationDate\"], how='outer')\n",
    "# test2p.to_csv(\"updateDF2.csv\", index=False)\n",
    "\n",
    "test2q = pd.read_csv(\"updateDF.csv\", low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"Breed\", \"DryOffDate\", \"CullingDate\",\n",
    "            \"ExitReason_PrimaryReasonKok\", \"ExitReason_SecondaryReason1Kok\", \"ExitReason_SecondaryReason2Kok\",\n",
    "            \"CullingReason1\", \"CullingReason2\"]\n",
    "test2q = test2q[col_keep]\n",
    "test2r = pd.merge(test2q, test2p, on=[\"SE_Number\", \"LactationNumber\", \"CalvingDate\"], how='left')\n",
    "test2r.to_csv(\"updateDF3.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"updateDF3.csv\", low_memory=False)\n",
    "print(f\"No. of pregnancy checks in database: {df.shape}\")  # 327,839 pregnancy checks\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"InseminationDate\"])\n",
    "print(f\"No. of inseminations in dataset: {df2.shape}\")  # 36,506 inseminations\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "print(f\"No. of lactations in dataset: {df2.shape}\")  # 20,683 lactations\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows in dataset: {df2.shape}\")  # 9,535 cows\n",
    "df2 = df.drop_duplicates(subset=[\"FarmName_Pseudo\"])\n",
    "print(f\"No. of herds in dataset: {df2.shape}\")  # 57 herds\n",
    "\n",
    "#\n",
    "#\n",
    "# ADD LINEAGE INFORMATION\n",
    "lin = pd.read_csv(\"Kok_Lineage240821.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"BirthID\", \"BirthDate\", \"Father_SE_Number\", \"Mother_SE_Number\"]\n",
    "lin = lin[col_keep]\n",
    "lin.rename(columns={'BirthID': 'SE_Number'}, inplace=True)\n",
    "\n",
    "print(f\"No. of unique cows in database: {lin.shape}\")  # 24,067\n",
    "lin = lin.drop_duplicates(subset=[\"SE_Number\", \"BirthDate\", \"Father_SE_Number\", \"Mother_SE_Number\"])\n",
    "print(f\"No. of unique cows in database: {lin.shape}\")  # 22,666\n",
    "\n",
    "df = pd.read_csv(\"updateDF3.csv\", low_memory=False)\n",
    "lin2 = df.merge(lin, on=[\"SE_Number\"], how=\"left\")\n",
    "\n",
    "# Change order of columns\n",
    "new_column_order = [\"FarmName_Pseudo\", \"SE_Number\", \"Breed\", \"BirthDate\", \"Father_SE_Number\", \"Mother_SE_Number\",\n",
    "                    \"CalvingDate\", \"LactationNumber\", \"InseminationDate\",\n",
    "                    \"PregnancyCheckDate\", \"PregnancyStatus\", \"DryOffDate\", \"CullingDate\", \"ExitReason_PrimaryReasonKok\",\n",
    "                    \"ExitReason_SecondaryReason1Kok\", \"ExitReason_SecondaryReason2Kok\", \"CullingReason1\",\n",
    "                    \"CullingReason2\"]\n",
    "lin2 = lin2[new_column_order]\n",
    "lin2 = lin2.drop_duplicates(subset=[\"SE_Number\", \"CalvingDate\", \"LactationNumber\", \"InseminationDate\",\n",
    "                                    \"PregnancyCheckDate\"])\n",
    "\"\"\"\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "lin2 = lin2[lin2[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "# REORDER PregnancyStatus\n",
    "unique_values = lin2['PregnancyStatus'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "lin2[\"PregnancyStatus\"] = lin2[\"PregnancyStatus\"].replace(\n",
    "    {\"Dräktig (undersökt) Dr\": 2,\n",
    "     \"Dräktig Analys Dr A\": 52,\n",
    "     \"Dräktig (ej undersökt) Dr\": 22,\n",
    "     \"Dräktig (tjurbetäckt) Dr\": 32,\n",
    "     \"Ej dräktig (tjurbetäckt) eDr\": 31,\n",
    "     \"Dräktig ? Analys Dr? A\": 53,\n",
    "     \"Ej Dräktig (ej undersökt) eDr\": 21,\n",
    "     \"Negative\": 51,\n",
    "     \"Positive\": 52,\n",
    "     \"Uncertain\": 53,\n",
    "     \"Dräktig ? (undersökt) Dr?\": 3,\n",
    "     \"Dräktig, (sem/bet annan bes) Dr\": 42,\n",
    "     \"Dräktig ? (tjurbetäckt) Dr?\": 33,\n",
    "     \"Ej dräktig Analys eDr A\": 51,\n",
    "     \"Ej Dräktig (undersökt) eDr\": 1})\n",
    "\n",
    "lin2.to_csv(\"updateDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILKING DATA FROM DELPRO\n",
    "- using Del_CowMilkYield_Common\n",
    "- creates MY.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# MILKING DATA\n",
    "# Del_CowMilkYield_Common240823\n",
    "dfmy = pd.read_csv(\"Del_CowMilkYield_Common240823.csv\", delimiter=';', low_memory=False)\n",
    "print(f\"No. of milking events in raw data: {dfmy.shape}\")  # 5,628,715 x 15\n",
    "print(dfmy.dtypes)\n",
    "\n",
    "# No. lactation and cows in raw data\n",
    "test = dfmy.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "print(f\"No. of lactation in raw milking file: {test.shape}\")  # 8,352\n",
    "test = dfmy.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows in raw milking file: {test.shape}\")  # 3,916\n",
    "\n",
    "# Remove pure duplicates\n",
    "dfmy = dfmy.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"StartDate\", \"StartTime\", \"SessionNumber\", \"TotalYield\"])\n",
    "print(f\"No. of milking events in raw data: {dfmy.shape}\")  # 5,624,788\n",
    "\n",
    "# No. lactation and cows in data\n",
    "test = dfmy.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "print(f\"No. of lactation after removed pure duplicates: {test.shape}\")  # 8,352\n",
    "test = test.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows after removed pure duplicates {test.shape}\")  # 3,916\n",
    "\n",
    "# Keep relevant col\n",
    "# LactationNumber removed because of missing values, e.g. SE-064c0cec-1188\n",
    "# DaysInMilk removed due to counting day 1 as day 0, reinitialize later\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"DaysInMilk\", \"StartDate\", \"StartTime\", \"SessionNumber\", \"TotalYield\"]\n",
    "dfmy = dfmy[col_keep]\n",
    "\n",
    "# Which herds are in this file?\n",
    "dfmy_unique2 = dfmy.drop_duplicates(subset=[\"FarmName_Pseudo\"])\n",
    "dfmy_unique2 = dfmy_unique2.drop(columns=[\"SE_Number\", \"StartDate\", \"StartTime\", \"LactationNumber\", \"DaysInMilk\", \"SessionNumber\", \"TotalYield\"])\n",
    "print(dfmy_unique2.to_string(index=False))\n",
    "\n",
    "# Change TotalYield comma to dot\n",
    "dfmy[\"TotalYield\"] = dfmy[\"TotalYield\"].str.replace(',', '.')\n",
    "# Change to datetime\n",
    "dfmy[\"StartDate\"] = pd.to_datetime(dfmy[\"StartDate\"])\n",
    "\n",
    "dfmy = dfmy.sort_values(by=[\"SE_Number\", \"LactationNumber\", \"StartDate\", \"StartTime\", \"SessionNumber\", \"TotalYield\"])\n",
    "\n",
    "# Remove missing yield\n",
    "dfmy2 = dfmy[pd.notna(dfmy[\"TotalYield\"])]\n",
    "print(f\"No. of milking records with recorded yield in milking file: {dfmy2.shape}\")  # 4,948,464\n",
    "\n",
    "# No. lactation and cows in data\n",
    "test = dfmy2.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "print(f\"No. of lactations after removed missing yield: {test.shape}\")  # 7920\n",
    "test = dfmy2.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows after removed missing yield: {test.shape}\")  # 3,657\n",
    "\n",
    "# Remove duplicated sessions\n",
    "dfmy2 = dfmy2.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "dfmy2 = dfmy2.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"StartDate\", \"SessionNumber\", \"TotalYield\"])\n",
    "print(f\"No. of unique milking records in milking file: {dfmy2.shape}\")  # 4,947,223\n",
    "dfmy2.to_csv(\"MY.csv\", index=False)\n",
    "\n",
    "# No. lactation and cows in data\n",
    "test = dfmy2.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "print(f\"No. of lactations after removed duplicated sessions: {test.shape}\")  # 7,920\n",
    "test = dfmy2.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows after removed duplicated sessions: {test.shape}\")  # 3,657\n",
    "\n",
    "# Check raw data for each herd\n",
    "FarmName_Pseudo = [\"a624fb9a\"]\n",
    "lactation_yield = dfmy2[dfmy2[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3a.csv\", index=False)\n",
    "print(f\"No. of unique milking records in a624fb9a milking file: {lactation_yield.shape}\")  # 441,149\n",
    "\n",
    "FarmName_Pseudo = [\"5f7f33d6\"]\n",
    "lactation_yield = dfmy2[dfmy2[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3b.csv\", index=False)\n",
    "print(f\"No. of unique milking records in 5f7f33d6 milking file: {lactation_yield.shape}\")  # 485,361\n",
    "\n",
    "FarmName_Pseudo = [\"ab18b151\"]\n",
    "lactation_yield = dfmy2[dfmy2[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3c.csv\", index=False)\n",
    "print(f\"No. of unique milking records in ab18b151 milking file: {lactation_yield.shape}\")  # 231,172\n",
    "\n",
    "FarmName_Pseudo = [\"f454e660\"]\n",
    "lactation_yield = dfmy2[dfmy2[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3d.csv\", index=False)\n",
    "print(f\"No. of unique milking records in f454e660 milking file: {lactation_yield.shape}\")  # 449,080\n",
    "\n",
    "FarmName_Pseudo = [\"540275a1\"]\n",
    "lactation_yield = dfmy2[dfmy2[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3e.csv\", index=False)\n",
    "print(f\"No. of unique milking records in 540275a1 milking file: {lactation_yield.shape}\")  # 312,961\n",
    "\n",
    "FarmName_Pseudo = [\"afdd9a78\"]\n",
    "lactation_yield = dfmy2[dfmy2[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3f.csv\", index=False)\n",
    "print(f\"No. of unique milking records in afdd9a78 milking file: {lactation_yield.shape}\")  # 45,618\n",
    "\n",
    "FarmName_Pseudo = [\"5b581702\"]\n",
    "lactation_yield = dfmy2[dfmy2[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3g.csv\", index=False)\n",
    "print(f\"No. of unique milking records in 5b581702 milking file: {lactation_yield.shape}\")  # 111,634\n",
    "\n",
    "FarmName_Pseudo = [\"5c06d92d\"]\n",
    "lactation_yield = dfmy2[dfmy2[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3h.csv\", index=False)\n",
    "print(f\"No. of unique milking records in 5c06d92d milking file: {lactation_yield.shape}\")  # 971,965\n",
    "\n",
    "FarmName_Pseudo = [\"752efd72\"]\n",
    "lactation_yield = dfmy2[dfmy2[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3i.csv\", index=False)\n",
    "print(f\"No. of unique milking records in 752efd72 milking file: {lactation_yield.shape}\")  # 863,077\n",
    "\n",
    "# Have 300,000 records but almost all missing MY!\n",
    "FarmName_Pseudo = [\"a756bc39\"]\n",
    "lactation_yield = dfmy[dfmy[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3j.csv\", index=False)\n",
    "print(f\"No. of unique milking records in a756bc39 milking file: {lactation_yield.shape}\")  # 314,841! MY miss\n",
    "\n",
    "FarmName_Pseudo = [\"ad0a39f5\"]\n",
    "lactation_yield = dfmy2[dfmy2[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3k.csv\", index=False)\n",
    "print(f\"No. of unique milking records in ad0a39f5 milking file: {lactation_yield.shape}\")  # 517,188\n",
    "\n",
    "# Have 138,922 sessions recorded, but almost all are missing yield!\n",
    "FarmName_Pseudo = [\"6d38bc90\"]\n",
    "lactation_yield = dfmy[dfmy[\"FarmName_Pseudo\"].isin(FarmName_Pseudo)]\n",
    "lactation_yield = lactation_yield.sort_values(by=['SE_Number', 'StartDate', 'SessionNumber'])\n",
    "lactation_yield.to_csv(\"lact3l.csv\", index=False)\n",
    "print(f\"No. of unique milking records in 6d38bc90 milking file: {lactation_yield.shape}\")  # 153,211 MY miss!\n",
    "\n",
    "# Find start of recording within respective herd\n",
    "first_observations = dfmy2.groupby(\"FarmName_Pseudo\")[\"StartDate\"].first().reset_index()\n",
    "print(f\"Start of recording in Gigacow in different herds: \\n\", first_observations.to_string(index=False))\n",
    "\n",
    "# No. MY records per herd\n",
    "count_my_rec = dfmy2.groupby([\"FarmName_Pseudo\"])[\"StartDate\"].count().reset_index()\n",
    "print(f\"No. milking events per herd: \\n\", count_my_rec.to_string(index=False))\n",
    "\n",
    "# Add lactation number and upper_limit to MY file to sort MY data to correct lactation\n",
    "# Because LactationNumber is not always used in the MY file\n",
    "test2l = pd.read_csv(\"updateDF.csv\", low_memory=False)\n",
    "print(f\"Calving, insemination, pregnancy checks, culling and dry off data with milking data: {test2l.shape}\")\n",
    "# 22,972,867\n",
    "\n",
    "test2m = pd.read_csv(\"dfKok.csv\", low_memory=False)\n",
    "test2m = test2m.drop_duplicates(subset=[\"SE_Number\", \"LactationNumberKok\", \"upper_limit\"])\n",
    "test2m.rename(columns={\"LactationNumberKok\": \"LactationNumber\"}, inplace=True)\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"upper_limit\"]\n",
    "test2m = test2m[col_keep]\n",
    "\n",
    "print(test2l.columns)\n",
    "print(test2m.columns)\n",
    "\n",
    "test2n = pd.merge(test2l, test2m, on=[\"SE_Number\", \"LactationNumber\"], how='left')\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"CalvingDate\", \"LactationNumber\", \"upper_limit\"]\n",
    "test2n = test2n[col_keep]\n",
    "test2n = test2n.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "\n",
    "\"\"\"\n",
    "# Subset chosen cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "test2n = test2n[test2n[\"SE_Number\"].isin(SE_Number)]\n",
    "test2n.to_csv(\"MY2.csv\", index=False)\n",
    "\"\"\"\n",
    "\n",
    "# Load MY data\n",
    "dfmy3 = pd.read_csv(\"MY.csv\", low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"StartDate\", \"StartTime\", \"SessionNumber\", \"TotalYield\"]\n",
    "dfmy3 = dfmy3[col_keep]\n",
    "\n",
    "\"\"\"\n",
    "# Subset chosen cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "dfmy3 = dfmy3[dfmy3[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "# Merge\n",
    "dfmy3 = test2n.merge(dfmy3, on=[\"FarmName_Pseudo\", \"SE_Number\"], how=\"left\")\n",
    "dfmy3 = dfmy3.sort_values(by=[\"SE_Number\", \"LactationNumber\", \"StartDate\", \"StartTime\"])\n",
    "\n",
    "# only keep MY data where falls within lactation, ie between CalvingDate and upper_limit\n",
    "# where upper_limit is either next lactation, slaughter date or today's date for open records (ie ongoing lactation)\n",
    "dfmy4 = dfmy3[(dfmy3[\"StartDate\"] >= dfmy3[\"CalvingDate\"]) & (dfmy3[\"StartDate\"] <= dfmy3[\"upper_limit\"])]\n",
    "\n",
    "\"\"\"\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "dfmy4 = dfmy4[dfmy4[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "# Make DIM\n",
    "dfmy4 = dfmy4.copy()\n",
    "dfmy4[\"StartDate\"] = pd.to_datetime(dfmy4[\"StartDate\"])\n",
    "dfmy4[\"CalvingDate\"] = pd.to_datetime(dfmy4[\"CalvingDate\"])\n",
    "dfmy4[\"DaysInMilk\"] = (dfmy4[\"StartDate\"] - dfmy4[\"CalvingDate\"]).dt.days + 1\n",
    "dfmy4.to_csv(\"MY.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD WEATHER DATA TO MY.CSV FILE\n",
    "- uses weather data from AllPreProcessedWeatherData for each herd and MY.csv\n",
    "- creates weather3.csv, and several MYn.csv to look at data with final dataset MY7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# PREPARATIONS FOR COMBINING MY AND WEATHER DATA\n",
    "# Make next_calving\n",
    "dfins6 = pd.read_csv(\"MY.csv\", low_memory=False)\n",
    "dfins7 = dfins6.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"CalvingDate\"])\n",
    "\n",
    "col_keep = [\"SE_Number\", \"CalvingDate\", \"LactationNumber\"]\n",
    "dfins7 = dfins7[col_keep]\n",
    "dfins7[\"next_calving\"] = dfins7.groupby([\"SE_Number\"])[\"CalvingDate\"].shift(-1)\n",
    "dfins7 = dfins6.merge(dfins7, on=[\"SE_Number\", \"LactationNumber\", \"CalvingDate\"], how=\"left\")\n",
    "\n",
    "\"\"\"\n",
    "Subset chosen cow\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "dfins7 = dfins7[dfins7[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "# Add CullingDate to MY file\n",
    "dfins8 = pd.read_csv(\"updateDF.csv\", low_memory=False)\n",
    "dfins8 = dfins8.drop_duplicates(subset=[\"SE_Number\", \"CullingDate\"])\n",
    "col_keep = [\"SE_Number\", \"CullingDate\"]\n",
    "dfins8 = dfins8[col_keep]\n",
    "dfins8 = dfins7.merge(dfins8, on=[\"SE_Number\"], how=\"left\")\n",
    "dfins8.to_csv(\"MY3.csv\", index=False)\n",
    "\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"CalvingDate\", \"next_calving\", \"upper_limit\",\n",
    "            \"StartDate\"]\n",
    "df = dfins8[col_keep]\n",
    "\n",
    "\"\"\"\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "df = df[df[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "# keep only one obs per date\n",
    "df2 = df.sort_values(by=[\"SE_Number\", \"LactationNumber\", \"StartDate\"])\n",
    "df2 = df2.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"StartDate\"])\n",
    "\n",
    "df2 = df2.copy()\n",
    "df2[\"CalvingDate\"] = pd.to_datetime(df2[\"CalvingDate\"])\n",
    "df2[\"upper_limit\"] = pd.to_datetime(df2[\"upper_limit\"])\n",
    "\n",
    "# Make a date variable for weather data - DateMeterological\n",
    "# Create a list to hold new data\n",
    "new_data = []\n",
    "\n",
    "# Loop through each row in the original DataFrame\n",
    "for _, row in df2.iterrows():\n",
    "    herd = row[\"FarmName_Pseudo\"]\n",
    "    cow = row['SE_Number']\n",
    "    lactation = row['LactationNumber']\n",
    "    next_calving = row[\"next_calving\"]\n",
    "    start_date = row['CalvingDate']\n",
    "    end_date = row['upper_limit']\n",
    "\n",
    "    # Generate a date range\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "    # Create a new DataFrame for Cow, Lactation, and date range\n",
    "    temp_df = pd.DataFrame({\n",
    "        \"FarmName_Pseudo\": herd,\n",
    "        'SE_Number': cow,\n",
    "        'LactationNumber': lactation,\n",
    "        \"next_calving\": next_calving,\n",
    "        'DateMeterological': date_range\n",
    "    })\n",
    "\n",
    "    # Append the new DataFrame to the list\n",
    "    new_data.append(temp_df)\n",
    "\n",
    "# Concatenate all the new DataFrames into one\n",
    "df_exp = pd.concat(new_data, ignore_index=True)\n",
    "df_exp.to_csv(\"MY4.csv\", index=False)\n",
    "\n",
    "# Remove duplicates\n",
    "df_exp = df_exp.sort_values(by=[\"SE_Number\", \"LactationNumber\", \"DateMeterological\"])\n",
    "df_exp = df_exp.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"next_calving\", \"DateMeterological\"])\n",
    "\n",
    "# only keep relevant data within calving interval\n",
    "# Ensure both columns are in datetime format\n",
    "df_exp[\"DateMeterological\"] = pd.to_datetime(df_exp[\"DateMeterological\"])\n",
    "df_exp[\"next_calving\"] = pd.to_datetime(df_exp[\"next_calving\"])\n",
    "\n",
    "# Set values in DateMeterological to NaN if they exceed the values in next_calving\n",
    "df_exp.loc[df_exp[\"DateMeterological\"] >= df_exp[\"next_calving\"], \"DateMeterological\"] = np.nan\n",
    "df_exp = df_exp.dropna(subset=['DateMeterological'])\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"DateMeterological\"]\n",
    "df_exp = df_exp[col_keep]\n",
    "df_exp.to_csv(\"MY5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# COMBINE WEATHER DATA FROM HERDS\n",
    "# Load Global irradiance, THI_adj etc.\n",
    "# set as comment after first time you run program, otherwise multiple columns in dataframe\n",
    "# weather1-15a were \"AllWeatherData\", creating weather.csv and weather2.csv\n",
    "# however, \"AllPreProcessedWeatherData\" contains full data needed, creating only weather3.csv\n",
    "weather1b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_4eab8365.csv\", delimiter=',', low_memory=False)\n",
    "weather1b['FarmName_Pseudo'] = '4eab8365'\n",
    "weather1b.to_csv(\"AllPreProcessedWeatherData/processed_data_4eab8365.csv\", index=False)\n",
    "\n",
    "weather2b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_5b581702.csv\", delimiter=',', low_memory=False)\n",
    "weather2b['FarmName_Pseudo'] = '5b581702'\n",
    "weather2b.to_csv(\"AllPreProcessedWeatherData/processed_data_5b581702.csv\", index=False)\n",
    "\n",
    "weather3b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_5c06d92d.csv\", delimiter=',', low_memory=False)\n",
    "weather3b['FarmName_Pseudo'] = '5c06d92d'\n",
    "weather3b.to_csv(\"AllPreProcessedWeatherData/processed_data_5c06d92d.csv\", index=False)\n",
    "\n",
    "weather4b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_5f7f33d6.csv\", delimiter=',', low_memory=False)\n",
    "weather4b['FarmName_Pseudo'] = '5f7f33d6'\n",
    "weather4b.to_csv(\"AllPreProcessedWeatherData/processed_data_5f7f33d6.csv\", index=False)\n",
    "\n",
    "weather5b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_80b99061.csv\", delimiter=',', low_memory=False)\n",
    "weather5b['FarmName_Pseudo'] = '80b99061'\n",
    "weather5b.to_csv(\"AllPreProcessedWeatherData/processed_data_80b99061.csv\", index=False)\n",
    "\n",
    "weather6b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_169e580a.csv\", delimiter=',', low_memory=False)\n",
    "weather6b['FarmName_Pseudo'] = '169e580a'\n",
    "weather6b.to_csv(\"AllPreProcessedWeatherData/processed_data_169e580a.csv\", index=False)\n",
    "\n",
    "weather7b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_752efd72.csv\", delimiter=',', low_memory=False)\n",
    "weather7b['FarmName_Pseudo'] = '752efd72'\n",
    "weather7b.to_csv(\"AllPreProcessedWeatherData/processed_data_752efd72.csv\", index=False)\n",
    "\n",
    "weather8b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_540275a1.csv\", delimiter=',', low_memory=False)\n",
    "weather8b['FarmName_Pseudo'] = '540275a1'\n",
    "weather8b.to_csv(\"AllPreProcessedWeatherData/processed_data_540275a1.csv\", index=False)\n",
    "\n",
    "weather9b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_a624fb9a.csv\", delimiter=',', low_memory=False)\n",
    "weather9b['FarmName_Pseudo'] = 'a624fb9a'\n",
    "weather9b.to_csv(\"AllPreProcessedWeatherData/processed_data_a624fb9a.csv\", index=False)\n",
    "\n",
    "weather10b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_a756bc39.csv\", delimiter=',', low_memory=False)\n",
    "weather10b['FarmName_Pseudo'] = 'a756bc39'\n",
    "weather10b.to_csv(\"AllPreProcessedWeatherData/processed_data_a756bc39.csv\", index=False)\n",
    "\n",
    "weather11b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_ab18b151.csv\", delimiter=',', low_memory=False)\n",
    "weather11b['FarmName_Pseudo'] = 'ab18b151'\n",
    "weather11b.to_csv(\"AllPreProcessedWeatherData/processed_data_ab18b151.csv\", index=False)\n",
    "\n",
    "weather12b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_ad0a39f5.csv\", delimiter=',', low_memory=False)\n",
    "weather12b['FarmName_Pseudo'] = 'ad0a39f5'\n",
    "weather12b.to_csv(\"AllPreProcessedWeatherData/processed_data_ad0a39f5.csv\", index=False)\n",
    "\n",
    "weather13b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_afdd9a78.csv\", delimiter=',', low_memory=False)\n",
    "weather13b['FarmName_Pseudo'] = 'afdd9a78'\n",
    "weather13b.to_csv(\"AllPreProcessedWeatherData/processed_data_afdd9a78.csv\", index=False)\n",
    "\n",
    "weather14b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_f454e660.csv\", delimiter=',', low_memory=False)\n",
    "weather14b['FarmName_Pseudo'] = 'f454e660'\n",
    "weather14b.to_csv(\"AllPreProcessedWeatherData/processed_data_f454e660.csv\", index=False)\n",
    "\n",
    "weather15b = pd.read_csv(\"AllPreProcessedWeatherData/processed_data_fced84e9.csv\", delimiter=',', low_memory=False)\n",
    "weather15b['FarmName_Pseudo'] = 'fced84e9'\n",
    "weather15b.to_csv(\"AllPreProcessedWeatherData/processed_data_fced84e9.csv\", index=False)\n",
    "\n",
    "# Get a list of all CSV files in the directory (adjust path as needed)\n",
    "all_files = glob.glob(\"C:/Users/pagd0001/Desktop/Gigacow/Data/20240531/Gigacow_240531/AllPreProcessedWeatherData/*.csv\")\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the list of files and read them into DataFrames\n",
    "for file in all_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "mdf2 = pd.concat(dfs, ignore_index=True)\n",
    "mdf2.to_csv(\"weather3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# COMBINE MY.csv and weather3.csv\n",
    "# Add time stamps\n",
    "# Weather file\n",
    "daily = pd.read_csv(\"weather3.csv\", low_memory=False)\n",
    "daily.drop_duplicates(subset=[\"FarmName_Pseudo\", \"Tid\"])\n",
    "\n",
    "# Add time to MY file\n",
    "MY = pd.read_csv(\"MY5.csv\", low_memory=False)\n",
    "MY.drop_duplicates(subset=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"DateMeterological\"])\n",
    "print(MY.shape)  # 1,127,307\n",
    "\n",
    "daily['Tid'] = pd.to_datetime(daily['Tid'])\n",
    "MY['DateMeterological'] = pd.to_datetime(MY['DateMeterological'])\n",
    "MY.rename(columns={\"DateMeterological\": \"StartDate\"}, inplace=True)\n",
    "\n",
    "MY3 = pd.read_csv(\"MY3.csv\", low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"StartDate\", \"StartTime\"]\n",
    "MY3 = MY3[col_keep]\n",
    "MY3['StartDate'] = pd.to_datetime(MY3['StartDate'])\n",
    "dfm = MY.merge(MY3, on=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"StartDate\"], how=\"left\")\n",
    "\n",
    "# Step 1: Convert 'StartTime' column to pandas datetime, allowing NaT for missing values\n",
    "dfm['StartTime'] = pd.to_datetime(dfm['StartTime'], format='%H:%M:%S', errors='coerce')\n",
    "\n",
    "# Step 2: Round time to the nearest hour\n",
    "dfm['RoundedTime'] = dfm['StartTime'].dt.round('h')\n",
    "\n",
    "# Step 3: Fill missing values (NaT) with '00:00:00'\n",
    "# Since 'RoundedTime' is a datetime column, use '00:00:00' as a time\n",
    "dfm['RoundedTime'] = dfm['RoundedTime'].fillna(pd.Timestamp('00:00:00'))\n",
    "\n",
    "# Step 4: Extract the hour from the RoundedTime column\n",
    "dfm['Hour'] = dfm['RoundedTime'].dt.hour\n",
    "# Extract the time part from the 'DateTime' column\n",
    "dfm['StartTime'] = dfm['StartTime'].fillna('00:00:00')\n",
    "dfm['TimeOnly'] = dfm['StartTime'].dt.time\n",
    "\n",
    "# Save\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"StartDate\", \"TimeOnly\", \"Hour\"]\n",
    "dfm = dfm[col_keep]\n",
    "dfm.rename(columns={\"TimeOnly\": \"StartTime\"}, inplace=True)\n",
    "dfm.to_csv(\"MY5a.csv\", index=False)\n",
    "\n",
    "# Make Hour in weather dataset\n",
    "daily['Hour'] = daily['Tid'].dt.hour\n",
    "daily.to_csv(\"MY5b.csv\", index=False)\n",
    "\n",
    "daily['StartDate'] = pd.to_datetime(daily['StartDate'])\n",
    "dfm['StartDate'] = pd.to_datetime(dfm['StartDate'])\n",
    "\n",
    "# Merge MY with weather data FarmName, Date, and Hour\n",
    "dfm = dfm.merge(daily, on=['FarmName_Pseudo', 'StartDate', 'Hour'], how='inner')\n",
    "dfm = dfm.sort_values(by=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"StartDate\", \"StartTime\"])\n",
    "dfm = dfm.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\", \"StartDate\", \"StartTime\"])\n",
    "\n",
    "\"\"\"\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "dfm = dfm[dfm[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"StartDate\", \"StartTime\", \"Hour\",\n",
    "            \"Temperatur\", \"Relativ fuktighet\", \"Vindhastighet\", \"Vindriktning\", \"Byvind\", \"Nederbörd\", \"Snö\",\n",
    "            \"Nederbördstyp\", \"Molnighet\", \"Sikt\", \"Lufttryck\", \"Global irradiance\", \"THI_adj\", \"HW\", \"cum_HW\",\n",
    "            \"Temp15Threshold\"]\n",
    "dfm = dfm[col_keep]\n",
    "\n",
    "dfm.rename(columns={\"Temperatur\": \"Temperature\", \"Relativ fuktighet\": \"RelativeHumidity\",\n",
    "                    \"Vindhastighet\": \"WindSpeed\", \"Vindriktning\": \"WindDirection\",\n",
    "                    \"Byvind\": \"Crosswind\", \"Nederbörd\": \"Precipitation\", \"Snö\": \"Snow\",\n",
    "                    \"Nederbördstyp\": \"PrecipitationType\", \"Molnighet\": \"Cloudiness\",\n",
    "                    \"Sikt\": \"Visibility\", \"Lufttryck\": \"AirPressure\",\n",
    "                    \"Global irradiance\": \"GlobalIrradiance\"}, inplace=True)\n",
    "\n",
    "dfm.to_csv(\"MY5c.csv\", index=False)\n",
    "\n",
    "missing_count = dfm['THI_adj'].isna().sum()\n",
    "print(f\"Number of missing observations in 'THI_adj': {missing_count}\")  # 0\n",
    "print(dfm.shape)  # 1,213,041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Add the rest of the MY data\n",
    "MY2 = pd.read_csv(\"MY5c.csv\", low_memory=False)\n",
    "\n",
    "MY3 = pd.read_csv(\"MY3.csv\", low_memory=False)\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"CalvingDate\", \"LactationNumber\", \"StartDate\", \"StartTime\", \"SessionNumber\",\n",
    "            \"TotalYield\", \"DaysInMilk\"]\n",
    "MY3 = MY3[col_keep]\n",
    "\n",
    "dfm2 = MY3.merge(MY2, on=[\"FarmName_Pseudo\", \"SE_Number\", \"LactationNumber\", \"StartDate\", \"StartTime\"], how=\"left\")\n",
    "dfm2.to_csv(\"MY7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD MILKING PARAMETERS FROM VMS HERDS\n",
    "- adding Del_Milk_Robot to MY7.csv thus creating MY_weather.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ADD MILKING PARAMETERS FROM VMS\n",
    "SCC = pd.read_csv(\"Del_Milk_Robot240918.csv\", delimiter=';', low_memory=False)\n",
    "print(f\"No. of milking events in database: {SCC.shape}\")  # 2,253,923obs\n",
    "SCC = SCC.drop_duplicates(subset=[\"SE_Number\", \"MilkingStartDateTime\"])\n",
    "print(f\"No. of unique milking events in database: {SCC.shape}\")  # 2,244,467obs\n",
    "\n",
    "\"\"\" \n",
    "# Check how many observations are missing timestamp\n",
    "invalid_rows = SCC[pd.to_datetime(SCC['MilkingStartDateTime'], errors='coerce').isna()]\n",
    "print(invalid_rows)\n",
    "invalid_rows.to_csv(\"updateDF2.csv\", index=False)  # 1574 obs\n",
    "\"\"\"\n",
    "\n",
    "SCC['MilkingStartDateTime'] = pd.to_datetime(SCC['MilkingStartDateTime'], errors='coerce')\n",
    "# Identify rows where the time is missing or set to '00:00:00'\n",
    "missing_time_rows = SCC[SCC['MilkingStartDateTime'].dt.time == pd.to_datetime('00:00:00').time()]\n",
    "\n",
    "# Add a time of '00:00:00' to these rows (since they're already '00:00:00', no changes needed)\n",
    "# Just for clarity, we reset the time to '00:00:00'\n",
    "missing_time_rows['MilkingStartDateTime'] = missing_time_rows['MilkingStartDateTime'].apply(\n",
    "    lambda x: x.replace(hour=0, minute=0, second=0)\n",
    ")\n",
    "\n",
    "# Merge the updated rows back onto the original DataFrame\n",
    "# First, remove these rows from the original DataFrame\n",
    "SCC_no_missing = SCC[SCC['MilkingStartDateTime'].dt.time != pd.to_datetime('00:00:00').time()]\n",
    "\n",
    "# Concatenate the original DataFrame (without missing times) and the updated rows\n",
    "SCC_updated = pd.concat([SCC_no_missing, missing_time_rows], ignore_index=True)\n",
    "SCC_updated.to_csv(\"Updated_VMS.csv\", index=False)\n",
    "\n",
    "# Split into separate date and time columns\n",
    "SCC_updated['MilkingStartDateTime'] = pd.to_datetime(SCC_updated['MilkingStartDateTime'])\n",
    "SCC_updated['StartDate'] = SCC_updated['MilkingStartDateTime'].dt.date    # Extract the date part\n",
    "SCC_updated['StartTime'] = SCC_updated['MilkingStartDateTime'].dt.time    # Extract the time part\n",
    "SCC_updated['StartDate'] = pd.to_datetime(SCC_updated['StartDate'])\n",
    "SCC_updated['StartTime'] = pd.to_datetime(SCC_updated['StartTime'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Keep only MY data until 2024-08-18\n",
    "cutoff_date = '2024-08-18'\n",
    "SCC_updated = SCC_updated[SCC_updated['StartDate'] <= cutoff_date]\n",
    "print(f\"No. of unique milking events in database: {SCC_updated.shape}\")  # 2,218,022\n",
    "\n",
    "col_keep = [\"FarmName_Pseudo\", \"SE_Number\", \"StartDate\", \"StartTime\",\n",
    "            \"TotalYieldLF\", \"TotalYieldRF\", \"TotalYieldLR\", \"TotalYieldRR\",\n",
    "            \"KickOffLF\", \"KickOffLR\", \"KickOffRF\", \"KickOffRR\",\n",
    "            \"IncompleteLF\", \"IncompleteLR\", \"IncompleteRF\", \"IncompleteRR\",\n",
    "            \"NotMilkedTeatLF\", \"NotMilkedTeatLR\", \"NotMilkedTeatRF\", \"NotMilkedTeatRR\",\n",
    "            \"AverageFlowLF\", \"AverageFlowLR\", \"AverageFlowRF\", \"AverageFlowRR\",\n",
    "            \"PeakFlowLF\", \"PeakFlowLR\", \"PeakFlowRF\", \"PeakFlowRR\",\n",
    "            \"BloodLF\", \"BloodLR\", \"BloodRF\", \"BloodRR\",\n",
    "            \"ConductivityLF\", \"ConductivityLR\", \"ConductivityRF\", \"ConductivityRR\",\n",
    "            \"Occ\"]\n",
    "SCC_updated = SCC_updated[col_keep]\n",
    "\n",
    "df2 = pd.read_csv(\"MY7.csv\", low_memory=False)\n",
    "print(f\"No. of unique milking events in MY7: {df2.shape}\")  # 2,299,007\n",
    "\n",
    "df2['StartDate'] = pd.to_datetime(df2['StartDate'])\n",
    "df2['StartTime'] = pd.to_datetime(df2['StartTime'], format='%H:%M:%S').dt.time\n",
    "SCC2 = df2.merge(SCC_updated, on=[\"FarmName_Pseudo\", \"SE_Number\", \"StartDate\", \"StartTime\"], how=\"left\")  # changed from outer\n",
    "\n",
    "\"\"\"\n",
    "# How dos this data look?\n",
    "frequency_table = SCC2['KickOffLF'].value_counts()\n",
    "print(frequency_table)\n",
    "frequency_table = SCC2['IncompleteLF'].value_counts()\n",
    "print(frequency_table)\n",
    "frequency_table = SCC2['NotMilkedTeatLF'].value_counts()\n",
    "print(frequency_table)\n",
    "\"\"\"\n",
    "\n",
    "# List of columns where you want to replace commas with dots\n",
    "columns_to_modify = [\"TotalYieldLF\", \"TotalYieldRF\", \"TotalYieldLR\", \"TotalYieldRR\",\n",
    "                     \"AverageFlowLF\", \"AverageFlowLR\", \"AverageFlowRF\", \"AverageFlowRR\",\n",
    "                     \"PeakFlowLF\", \"PeakFlowLR\", \"PeakFlowRF\", \"PeakFlowRR\",\n",
    "                     \"BloodLF\", \"BloodLR\", \"BloodRF\", \"BloodRR\",\n",
    "                     \"ConductivityLF\", \"ConductivityLR\", \"ConductivityRF\", \"ConductivityRR\",\n",
    "                     \"Occ\"]\n",
    "\n",
    "# Replace comma with dot and convert to float\n",
    "SCC2[columns_to_modify] = SCC2[columns_to_modify].replace(',', '.', regex=True).astype(float)\n",
    "SCC2.to_csv(\"MY8.csv\", index=False)\n",
    "\n",
    "# Change order of columns\n",
    "new_column_order = [\"FarmName_Pseudo\", \"SE_Number\", \"CalvingDate\", \"LactationNumber\",\n",
    "                    \"DaysInMilk\", \"StartDate\", \"StartTime\", \"SessionNumber\", \"TotalYield\",\n",
    "                    \"TotalYieldLF\", \"TotalYieldRF\", \"TotalYieldLR\", \"TotalYieldRR\",\n",
    "                    \"AverageFlowLF\", \"AverageFlowLR\", \"AverageFlowRF\", \"AverageFlowRR\",\n",
    "                    \"PeakFlowLF\", \"PeakFlowLR\", \"PeakFlowRF\", \"PeakFlowRR\",\n",
    "                    \"BloodLF\", \"BloodLR\", \"BloodRF\", \"BloodRR\",\n",
    "                    \"ConductivityLF\", \"ConductivityLR\", \"ConductivityRF\", \"ConductivityRR\",\n",
    "                    \"Occ\",\n",
    "                    \"Temperature\", \"RelativeHumidity\", \"WindSpeed\", \"WindDirection\", \"Crosswind\", \"Precipitation\",\n",
    "                    \"Snow\", \"PrecipitationType\", \"Cloudiness\", \"Visibility\", \"AirPressure\", \"GlobalIrradiance\",\n",
    "                    \"THI_adj\", \"HW\", \"cum_HW\", \"Temp15Threshold\"]\n",
    "SCC2 = SCC2[new_column_order]\n",
    "SCC2.to_csv(\"MY8.csv\", index=False)\n",
    "\n",
    "# Add final ID-numbers from DelPro\n",
    "df = pd.read_csv(\"Del_CowMilkYield_Common240823.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"SE_Number\", \"AnimalNumber\", \"Del_Cow_Id\"]\n",
    "df = df[col_keep]\n",
    "df = df.drop_duplicates(subset=[\"SE_Number\", \"AnimalNumber\", \"Del_Cow_Id\"])\n",
    "\n",
    "my = pd.read_csv(\"MY8.csv\", low_memory=False)\n",
    "# my = my.drop(columns=[\"AnimalNumber\", \"Del_Cow_Id\"])\n",
    "mdf = pd.merge(my, df, on=[\"SE_Number\"], how=\"left\")\n",
    "new_column_order = [\"FarmName_Pseudo\", \"SE_Number\", \"AnimalNumber\", \"Del_Cow_Id\", \"CalvingDate\", \"LactationNumber\",\n",
    "                    \"DaysInMilk\", \"StartDate\", \"StartTime\", \"SessionNumber\", \"TotalYield\",\n",
    "                    \"TotalYieldLF\", \"TotalYieldRF\", \"TotalYieldLR\", \"TotalYieldRR\",\n",
    "                    \"AverageFlowLF\", \"AverageFlowLR\", \"AverageFlowRF\", \"AverageFlowRR\",\n",
    "                    \"PeakFlowLF\", \"PeakFlowLR\", \"PeakFlowRF\", \"PeakFlowRR\",\n",
    "                    \"BloodLF\", \"BloodLR\", \"BloodRF\", \"BloodRR\",\n",
    "                    \"ConductivityLF\", \"ConductivityLR\", \"ConductivityRF\", \"ConductivityRR\",\n",
    "                    \"Occ\",\n",
    "                    \"Temperature\", \"RelativeHumidity\", \"WindSpeed\", \"WindDirection\", \"Crosswind\", \"Precipitation\",\n",
    "                    \"Snow\", \"PrecipitationType\", \"Cloudiness\", \"Visibility\", \"AirPressure\", \"GlobalIrradiance\",\n",
    "                    \"THI_adj\", \"HW\", \"cum_HW\", \"Temp15Threshold\"]\n",
    "mdf = mdf[new_column_order]\n",
    "mdf.to_csv(\"MY_weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISCELLANEOUS MINOR EDITS\n",
    "- Add full ID-numbers from DelPro\n",
    "- Retransfer breed\n",
    "- Double check for duplicates in MY \n",
    "\n",
    "Creates the following datasets:\n",
    "- updateDF.csv: containing data for cows for future use in HeatStress project\n",
    "- MY_weather.csv: containing MY and weather data for future use in HeatStress project\n",
    "- dfForSreten.csv: containing data for cows for delivery to Sreten Andonov\n",
    "- MY_weatherForSreten.csv: containing MY and weather data for delivery to Sreten Andonov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Add final ID-numbers from DelPro\n",
    "df = pd.read_csv(\"Del_CowMilkYield_Common240823.csv\", delimiter=';', low_memory=False)\n",
    "col_keep = [\"SE_Number\", \"AnimalNumber\", \"Del_Cow_Id\"]\n",
    "df = df[col_keep]\n",
    "df = df.drop_duplicates(subset=[\"SE_Number\", \"AnimalNumber\", \"Del_Cow_Id\"])\n",
    "\n",
    "my = pd.read_csv(\"updateDF.csv\", low_memory=False)\n",
    "mdf = pd.merge(my, df, on=[\"SE_Number\"], how=\"left\")\n",
    "new_column_order = [\"FarmName_Pseudo\", \"SE_Number\", \"AnimalNumber\", \"Del_Cow_Id\", \"Breed\", \"BirthDate\",\n",
    "                    \"Father_SE_Number\", \"Mother_SE_Number\", \"CalvingDate\", \"LactationNumber\",\n",
    "                    \"InseminationDate\", \"PregnancyCheckDate\", \"PregnancyStatus\", \"DryOffDate\", \"CullingDate\",\n",
    "                    \"ExitReason_PrimaryReasonKok\", \"ExitReason_SecondaryReason1Kok\", \"ExitReason_SecondaryReason2Kok\",\n",
    "                    \"CullingReason1\", \"CullingReason2\"]\n",
    "mdf = mdf[new_column_order]\n",
    "mdf.to_csv(\"updateDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# TRANSFER BREED CORRECTLY TO updateDF.csv\n",
    "df = pd.read_csv(\"breed.csv\", low_memory=False)\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\", \"Breed\"])\n",
    "print(df2.shape)  # 9,535\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(df2.shape)  # 9,535\n",
    "df.drop(columns=[\"FarmName_Pseudo\", \"SireBreedKok\", \"DamBreedKok\", \"MGSBreedKok\", \"BreedNameDelPro\", \"BreedKok\", \"BreedDelPro\"], inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"updateDF.csv\", low_memory=False)\n",
    "df3.drop(columns=[\"Breed\"], inplace=True)\n",
    "\n",
    "df4 = df.merge(df3, on=\"SE_Number\", how=\"left\")\n",
    "df4.to_csv(\"updateDF.csv\", index=False)\n",
    "df4.to_csv(\"dfForSreten.csv\", index=False)\n",
    "\n",
    "#\n",
    "#\n",
    "# TRANSFER BREED TO MY_weather.csv\n",
    "df = pd.read_csv(\"breed.csv\", low_memory=False)\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\", \"Breed\"])\n",
    "print(df2.shape)  # 9,535\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(df2.shape)  # 9,535\n",
    "df.drop(columns=[\"SireBreedKok\", \"DamBreedKok\", \"MGSBreedKok\", \"BreedNameDelPro\", \"BreedKok\", \"BreedDelPro\"], inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"MY_weather.csv\", low_memory=False)\n",
    "\n",
    "df4 = df.merge(df3, on=[\"FarmName_Pseudo\", \"SE_Number\"], how=\"left\")\n",
    "df4 = df4[df4['LactationNumber'].notna()]\n",
    "\n",
    "\"\"\"\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "df4 = df4[df4[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "df4.to_csv(\"MY_weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOUBLE CHECK FOR DUPLICATES IN MY_WEATHER FILE FROM MERGE DUE TO DATA EXTRACTION???\n",
    "df = pd.read_csv(\"MY_weather.csv\", low_memory=False)\n",
    "print(f\"No. of records in crude data: {df.shape}\")  # 2,307,309\n",
    "df3a = df.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"StartDate\", \"StartTime\", \"SessionNumber\", \"DaysInMilk\"])\n",
    "print(f\"No. of records in MY_weather.csv file: {df3a.shape}\")  # 1,868,019\n",
    "df3a.to_csv(\"MY_weather.csv\", index=False)\n",
    "df3a.to_csv(\"MY_weatherForSreten.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Descriptive statistics for milking file\n",
    "df = pd.read_csv(\"MY_weather.csv\", low_memory=False)\n",
    "print(f\"No. of unique milking events in database: {df.shape}\")  # 2,299,007 milking events\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "print(f\"No. of lactations in milking file: {df2.shape}\")  # 3,050 lactations\n",
    "df2 = df.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows in milking file: {df2.shape}\")  # 1,659 cows\n",
    "df2 = df.drop_duplicates(subset=[\"FarmName_Pseudo\"])\n",
    "print(f\"No. of herds in milking file: {df2.shape}\")  # 7 herds\n",
    "\n",
    "col_keep = [\"FarmName_Pseudo\"]\n",
    "df2 = df2[col_keep]\n",
    "print(f\"Herds in unfiltered data: \\n\", df2.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# SAVE IN updateDF.csv ONLY DATA FROM COWS AND LACTATIONS WITH MILK YIELD DATA\n",
    "df = pd.read_csv(\"updateDF.csv\", low_memory=False)\n",
    "\n",
    "dfa = df.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"InseminationDate\", \"PregnancyCheckDate\"])\n",
    "print(f\"No. of pregnancy checks in updateDF file: {dfa.shape}\")  # 47,326\n",
    "dfa = df.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"InseminationDate\"])\n",
    "print(f\"No. of inseminations in updateDF file: {dfa.shape}\")  # 36,506\n",
    "dfa = df.drop_duplicates(subset=['SE_Number', \"LactationNumber\"])\n",
    "print(f\"No. of lactations in updateDF file: {dfa.shape}\")  # 20,683\n",
    "dfa = df.drop_duplicates(subset=['SE_Number'])\n",
    "print(f\"No. of cows in updateDF: {dfa.shape}\")  # 9,535\n",
    "\n",
    "df2 = pd.read_csv(\"MY_weather.csv\", low_memory=False)\n",
    "df2[\"tag\"] = 1\n",
    "col_keep = [\"SE_Number\", \"LactationNumber\", \"tag\"]\n",
    "df2 = df2[col_keep]\n",
    "df2 = df2.drop_duplicates(subset=['SE_Number', \"LactationNumber\"])\n",
    "print(df2.shape)  # 3,050\n",
    "df2.to_csv(\"updateDF2.csv\", index=False)\n",
    "\n",
    "df3 = df2.merge(df, on=[\"SE_Number\", \"LactationNumber\"], how=\"left\")\n",
    "df3 = df3[df3['tag'] == 1]\n",
    "df3 = df3.drop(columns=[\"tag\"])\n",
    "\"\"\"\n",
    "SE_Number = [\"SE-064c0cec-1189\"]\n",
    "df3 = df3[df3[\"SE_Number\"].isin(SE_Number)]\n",
    "\"\"\"\n",
    "df3.to_csv(\"updateDF.csv\", index=False)\n",
    "df3.to_csv(\"dfForSreten.csv\", index=False)\n",
    "\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"InseminationDate\", \"PregnancyCheckDate\"])\n",
    "print(f\"No. of pregnancy checks in updateDF file: {df3a.shape}\")  # 8,336\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"InseminationDate\"])\n",
    "print(f\"No. of inseminations in updateDF file: {df3a.shape}\")  # 5,592\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\"])\n",
    "print(f\"No. of lactations in updateDF file: {df3a.shape}\")  # 3,050\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number'])\n",
    "print(f\"No. of cows in updateDF: {df3a.shape}\")  # 1,659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL COMMENTS:\n",
    "- MY and weather data can be found in MY_weather.csv\n",
    "- Basic data for each cow is in updateDF.csv\n",
    "- Structure and codes corresponding to cow database whenever possible,\n",
    "    see \"Produktbeskrivning\" and \"Kokförteckning\" from Växa\n",
    "- First data from milking parlours, then from VMSs followed by weather data\n",
    "- MESAN data from SMHI are on hourly basis, and has been matched to the closes hour of the milking event\n",
    "        e.g. if the cow was milked 6:20, corresponding weather data is from 6:00\n",
    "        e.g. if the cow was milked 16:45, corresponding weather data is from 17:00\n",
    "- MESAN data range covers 2022-01-01 to 2024-08-18 for all herds\n",
    "- Range of MY data from Gigacow herds depend on when the herd was connected\n",
    "- For basic production data, primary source is the cow database on the assumption that this information is superior\n",
    "    to the herd management system. In the event of missing data from the cow database, data from the management system\n",
    "    is added\n",
    "    Note: A lot of cows will lack AnimalNumber, Del_Cow_Id because of primary source is from the cow database\n",
    "- Complementary data from cow database is updated once every quarter \n",
    "- 'CullingReason1' and 'CullingReason2' are the combined culling reasons as recorded in herd management system and cow \n",
    "    database, however, kept originals due to free text recording can vary\n",
    "- PregnancyStatus was originally free text alternatives but has been changed to coincide with cow database codes,\n",
    "    see \"Kokförteckning\" from Växa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# PLOTTING TOTAL DAILY MILK YIELD BY HERD IN CRUDE DATA\n",
    "# Load data\n",
    "df_lact = pd.read_csv(\"MY_weather.csv\", low_memory=False)\n",
    "\n",
    "# Ensure the StartDate column is a datetime object\n",
    "df_lact['StartDate'] = pd.to_datetime(df_lact['StartDate'])\n",
    "\n",
    "# Keep only MY data from 2022-01-01 until 2024-08-18\n",
    "cutoff_date1 = '2022-01-01'\n",
    "cutoff_date2 = '2024-08-18'\n",
    "df_lact = df_lact[df_lact['StartDate'] >= cutoff_date1]\n",
    "df_lact = df_lact[df_lact['StartDate'] <= cutoff_date2]\n",
    "\n",
    "# list of farms\n",
    "list_of_farms = list(df_lact[\"FarmName_Pseudo\"].unique())\n",
    "\n",
    "# Dictionary to store farm color mapping\n",
    "farm_color_mapping = {}\n",
    "\n",
    "# Loop through each farm and create a separate plot for each\n",
    "for i, farm in enumerate(list_of_farms):\n",
    "    # Create a new figure for each farm\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    selected_farm = df_lact[df_lact['FarmName_Pseudo'] == farm]\n",
    "    number_of_cows = len(selected_farm['SE_Number'].unique())\n",
    "    daily_yield = selected_farm.groupby('StartDate')['TotalYield'].sum()\n",
    "\n",
    "    # Get color for this farm, ensuring enough colors\n",
    "    color = sns.color_palette('bright', n_colors=max(len(list_of_farms), 10))[i]\n",
    "    farm_color_mapping[farm] = color\n",
    "\n",
    "    # Generate a complete date range and reindex the daily yield\n",
    "    all_dates = pd.date_range(start=daily_yield.index.min(), end=daily_yield.index.max(), freq='D')\n",
    "    daily_yield = daily_yield.reindex(all_dates, fill_value=0)\n",
    "\n",
    "    # Plot data\n",
    "    plt.plot(daily_yield.index, daily_yield.values, label=f'Farm {farm} \\n{number_of_cows} cows', color=color)\n",
    "    plt.title(f'Milk Data for Farm {farm}', fontsize=16)\n",
    "    plt.ylabel('Daily Yield', fontsize=14)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Set x-axis label\n",
    "    plt.xlabel('Date', fontsize=14)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Number of Instances of TotalYield for Each Farm on Each Day\n",
    "data = pd.read_csv(\"MY_weather.csv\", low_memory=False)\n",
    "\n",
    "# Group the data by 'FarmName_Pseudo' and 'StartDate', and get the count of 'TotalYield'\n",
    "count_data = data.groupby(['FarmName_Pseudo', 'StartDate'])['TotalYield'].count().reset_index(name='Count')\n",
    "\n",
    "# Convert 'StartDate' to datetime\n",
    "count_data['StartDate'] = pd.to_datetime(count_data['StartDate'])\n",
    "\n",
    "# Sort the data by date to ensure the labels match the ticks\n",
    "count_data.sort_values('StartDate', inplace=True)\n",
    "\n",
    "# Pivot to have 'StartDate' as columns and 'FarmName_Pseudo' as index\n",
    "pivot_data = count_data.pivot(index='FarmName_Pseudo', columns='StartDate', values='Count').fillna(0)\n",
    "\n",
    "# Plot data\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.heatmap(pivot_data, cmap='Purples', cbar_kws={'label': 'Count'})\n",
    "\n",
    "num_days = len(pivot_data.columns)\n",
    "days_between_ticks = num_days // 6  # Adjust this as needed\n",
    "\n",
    "ax.set_xticks(range(0, num_days, days_between_ticks))\n",
    "ax.set_xticklabels([date.strftime('%Y-%m-%d') for date in pivot_data.columns[::days_between_ticks]], rotation=45, ha='right')\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('FarmName_Pseudo', fontsize=14)\n",
    "plt.title('Number of Instances of TotalYield for Each Farm on Each Day', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILTERING MILK YIELD DATA\n",
    "- keep only NRDC, SH, SJB and dairy crosses\n",
    "- keep only data between 2022-01-01 -- 2024-08-18\n",
    "- have to start milking by 1-30DIM and maintain milking until 100-400DIM\n",
    "- keep only 1-7 lactation (make parity 1, 2, +3)\n",
    "- set MY between 2.5-60kg to handle outliers, kick-offs and incomplete milkings\n",
    "- generates filtered dataset MY_weather2.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# FILTER MILK YIELD DATA\n",
    "df3 = pd.read_csv(\"MY_weather.csv\", low_memory=False)\n",
    "print(f\"No. milking events in MY_weather.csv: {df3.shape}\")  # 1,868,019\n",
    "\n",
    "value_counts = df3['Breed'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "# Pie chart over distribution of Breed\n",
    "value_counts = df3['Breed'].value_counts()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=140, pctdistance=0.85)\n",
    "plt.axis('equal')\n",
    "plt.title('Distribution of Milking Events Across Breeds in MY_weather.csv')\n",
    "plt.show()\n",
    "\n",
    "# Keep only SRB, SH, dairy crosses and SJB\n",
    "df3 = df3[(df3[\"Breed\"] == \"NRDC\") |\n",
    "          (df3[\"Breed\"] == \"SLB\") |\n",
    "          (df3[\"Breed\"] == \"DairyCross\") |\n",
    "          (df3[\"Breed\"] == \"SJB\")]\n",
    "print(f\"No. milking events in SRB, SH, dairy Crosses and SJB cows: {df3.shape}\")  # 1,825,106\n",
    "\n",
    "# No. lactations and cows in data\n",
    "test = df3.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "print(f\"No. of lactations from SRB, SH and SJB: {test.shape}\")  # 2,938\n",
    "test = test.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows from SRB, SH and SJB: {test.shape}\")  # 1,585\n",
    "\n",
    "# Keep only data where have both MY and weather information\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"StartDate\", \"StartTime\"])\n",
    "print(f\"No. of milking events in MY_weather.csv: {df3a.shape}\")  # 1,414,770\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"StartDate\"])\n",
    "print(f\"No. of milking days in MY_weather.csv: {df3a.shape}\")  # 633,247\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\"])\n",
    "print(f\"No. of lactations in MY_weather.csv: {df3a.shape}\")  # 2,938\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number'])\n",
    "print(f\"No. of cows in MY_weather.csv: {df3a.shape}\")  # 1,585\n",
    "\n",
    "# Keep only MY data from 2022-01-01 until 2024-08-18\n",
    "cutoff_date1 = '2022-01-01'\n",
    "cutoff_date2 = '2024-08-18'\n",
    "df3 = df3[df3['StartDate'] >= cutoff_date1]\n",
    "df3 = df3[df3['StartDate'] <= cutoff_date2]\n",
    "\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"StartDate\", \"StartTime\"])\n",
    "print(f\"No. of milking events in MY_weather.csv: {df3a.shape}\")  # 955,139 milking events\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"StartDate\"])\n",
    "print(f\"No. of milking days in MY_weather.csv: {df3a.shape}\")  # 469,384 milking days\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\"])\n",
    "print(f\"No. of lactations in MY_weather.csv: {df3a.shape}\")  # 2,305 lactations\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number'])\n",
    "print(f\"No. of cows in MY_weather.csv: {df3a.shape}\")  # 1,392 cows\n",
    "\n",
    "non_missing_count = df3['THI_adj'].notna().sum()\n",
    "missing_count = df3['THI_adj'].isna().sum()\n",
    "\n",
    "print(f\"Observations with data: {non_missing_count}\")  # 744,624 obs\n",
    "print(f\"Observations with missing data: {missing_count}\")  # 601,490 obs\n",
    "\n",
    "df3.dropna(subset=['THI_adj'], inplace=True)\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"StartDate\", \"StartTime\"])\n",
    "print(f\"No. of milking events in updateDF file: {df3a.shape}\")  # 744,624 milking events\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"StartDate\"])\n",
    "print(f\"No. of milking days in updateDF file: {df3a.shape}\")  # 261,709 milking days\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number', \"LactationNumber\"])\n",
    "print(f\"No. of lactations in updateDF file: {df3a.shape}\")  # 1,931 lactations\n",
    "df3a = df3.drop_duplicates(subset=['SE_Number'])\n",
    "print(f\"No. of cows in updateDF: {df3a.shape}\")  # 1,133 cows\n",
    "\n",
    "# Filter to demand started milking by 1-30 DIM and maintain milking until 100-400 DIM\n",
    "first_last_df = df3.groupby(['SE_Number', 'LactationNumber'])['DaysInMilk'].agg(['first', 'last']).reset_index()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(first_last_df[\"first\"], color='blue')\n",
    "plt.title(f\"First DIM in Lactation\")\n",
    "plt.xlabel('First DIM')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(first_last_df[\"last\"], color='blue')\n",
    "plt.title(f\"Last DIM in Lactation\")\n",
    "plt.xlabel('Last DIM')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "df3 = df3.merge(first_last_df, on=[\"SE_Number\", \"LactationNumber\"], how=\"left\")\n",
    "df3.to_csv(\"MY3.csv\", index=False)\n",
    "\n",
    "average_production = (df3.groupby(['FarmName_Pseudo'])['first']\n",
    "                      .agg(['mean', 'std']).reset_index())\n",
    "average_production['mean'] = average_production['mean'].round(0)\n",
    "average_production['std'] = average_production['std'].round(0)\n",
    "average_production.rename(columns={'mean': 'MeanFirstDIM', 'std': 'SDFirstDIM'}, inplace=True)\n",
    "print(f\"Mean and SD First DIM: \\n\", average_production.to_string(index=False))\n",
    "\n",
    "average_production = (df3.groupby(['FarmName_Pseudo'])['last']\n",
    "                      .agg(['mean', 'std']).reset_index())\n",
    "average_production['mean'] = average_production['mean'].round(0)\n",
    "average_production['std'] = average_production['std'].round(0)\n",
    "average_production.rename(columns={'mean': 'MeanLastDIM', 'std': 'SDLastDIM'}, inplace=True)\n",
    "print(f\"Mean and SD Last DIM: \\n\", average_production.to_string(index=False))\n",
    "\n",
    "\n",
    "def filter_first_last(group):\n",
    "    first_value = group['DaysInMilk'].iloc[0]\n",
    "    last_value = group['DaysInMilk'].iloc[-1]\n",
    "    return (1 <= first_value <= 30) and (100 <= last_value <= 400)\n",
    "\n",
    "\n",
    "filtered_df = df3.groupby([\"SE_Number\", \"LactationNumber\"]).filter(filter_first_last)\n",
    "print(f\"No. milking events in SRB, SH, SJB and dairy crosses cows within 1-30 DIM and 100-400 DIM: {filtered_df.shape}\")\n",
    "# 30DIM: 518,107\n",
    "\n",
    "# No. lactations and cows in data\n",
    "test = filtered_df.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "print(f\"No. of lactations from SRB, SH, SJB and dairy crosses within 1-30DIM and 100-400DIM: {test.shape}\")\n",
    "# 30DIM: 1,173\n",
    "test = filtered_df.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows from SRB, SH, SJB and dairy crosses within 1-30DIM and 100-400DIM: {test.shape}\")\n",
    "# 30DIM: 863\n",
    "\n",
    "# Distribution of milk yield data over various lactations\n",
    "value_counts = filtered_df['LactationNumber'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "# Keep only lactation 1-7\n",
    "df_lact = filtered_df[filtered_df[\"LactationNumber\"] <= 7]\n",
    "print(f\"No. milking events in SRB, SH, SJB and dairy crosses cows within 1-30 DIM and 100-400 DIM in lactation 1-7: \"\n",
    "      f\"{df_lact.shape}\")  # 30DIM: 517,235\n",
    "\n",
    "# No. lactations and cows in data\n",
    "test = df_lact.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "print(f\"No. of lactations from SRB, SH, SJB and dairy crosses within 1-30DIM and 100-400DIM in lactation 1-7: \"\n",
    "      f\"{test.shape}\")  # 30DIM: 1,168\n",
    "test = df_lact.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows from SRB, SH, SJB and dairy crosses within 1-30DIM and 100-400DIM in lactation 1-7: {test.shape}\")\n",
    "# 30DIM: 861\n",
    "\n",
    "# Make Parity 1-3\n",
    "df_lact = df_lact.copy()\n",
    "df_lact[\"Parity\"] = df_lact[\"LactationNumber\"]\n",
    "df_lact.loc[(df_lact['LactationNumber'] >= 3) & (df_lact['LactationNumber'] <= 7), 'Parity'] = 3\n",
    "\n",
    "# CHECK DISTRIBUTION OF TOTAL YIELD COLUMN\n",
    "# Basic statistics\n",
    "summary_stats = df_lact['TotalYield'].describe()\n",
    "percentiles = np.percentile(df_lact['TotalYield'], [1, 5, 10, 90, 95, 99])\n",
    "\n",
    "print(\"Descriptive Statistics:\\n\", summary_stats)\n",
    "print(\"\\nPercentiles (1%, 5%, 10%, 90%, 95%, 99%):\", percentiles)\n",
    "\n",
    "# count_my_rec = df.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "sns.boxplot(x='FarmName_Pseudo', y='TotalYield', data=df_lact)\n",
    "plt.title('Box Plot of Total Yield per Milking Event Grouped by Herd')\n",
    "plt.xlabel('Herd')\n",
    "plt.ylabel('Total Yield per Milking Event')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Count instances with TotalYield greater than 60 L\n",
    "count_invalid_total_yield = df_lact[df_lact['TotalYield'] > 60].shape[0]\n",
    "print(f\"Number of instances with TotalYield greater than 60: {count_invalid_total_yield}\")\n",
    "# 156 observations - have been handled already, code below technically redundant\n",
    "df_lact2 = df_lact[df_lact['TotalYield'] < 60]\n",
    "\n",
    "count_invalid_total_yield = df_lact2[df_lact2['TotalYield'] < 2.5].shape[0]\n",
    "print(f\"Number of instances with TotalYield less than 2.5 kg: {count_invalid_total_yield}\")  # 4839 observations\n",
    "df_lact2 = df_lact2[df_lact2['TotalYield'] > 2.5]\n",
    "\n",
    "df3a = df_lact2.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"StartDate\", \"StartTime\"])\n",
    "print(f\"No. of pregnancy checks in updateDF file: {df3a.shape}\")  # 512,388 milking events\n",
    "df3a = df_lact2.drop_duplicates(subset=['SE_Number', \"LactationNumber\", \"StartDate\"])\n",
    "print(f\"No. of inseminations in updateDF file: {df3a.shape}\")  # 179,683 milking days\n",
    "df3a = df_lact2.drop_duplicates(subset=['SE_Number', \"LactationNumber\"])\n",
    "print(f\"No. of lactations in updateDF file: {df3a.shape}\")  # 1,168 lactations\n",
    "df3a = df_lact2.drop_duplicates(subset=['SE_Number'])\n",
    "print(f\"No. of cows in updateDF: {df3a.shape}\")  # 861 cows\n",
    "\n",
    "# Basic statistics\n",
    "summary_stats = df_lact2['TotalYield'].describe()\n",
    "percentiles = np.percentile(df_lact2['TotalYield'], [1, 5, 10, 90, 95, 99])\n",
    "\n",
    "print(\"Descriptive Statistics:\\n\", summary_stats)\n",
    "print(\"\\nPercentiles (1%, 5%, 10%, 90%, 95%, 99%):\", percentiles)\n",
    "\n",
    "df_lact2.to_csv(\"MY_weather2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# DESCRIPTIVE STATISTICS FILTERED DATA\n",
    "# Milking records\n",
    "df_lact = pd.read_csv(\"MY_weather2.csv\", low_memory=False)\n",
    "\n",
    "count_my_rec = df_lact.groupby([\"Parity\"])[\"StartDate\"].count().reset_index()\n",
    "print(f\"No. of milking records divided over parities: \\n\", count_my_rec.to_string(index=False))\n",
    "\n",
    "count_my_rec = df_lact.groupby([\"Parity\", \"Breed\"])[\"StartDate\"].count().reset_index()\n",
    "print(f\"No. of milking records divided over parities and breeds: \\n\", count_my_rec.to_string(index=False))\n",
    "\n",
    "# By parity\n",
    "for_my_rec5 = df_lact.drop_duplicates(subset=[\"SE_Number\", \"LactationNumber\"])\n",
    "print(f\"No. of parities in milking file: {for_my_rec5.shape}\")  # 1,168\n",
    "\n",
    "count_my_rec = for_my_rec5.groupby([\"Parity\", \"Breed\"])[\"SE_Number\"].count().reset_index()\n",
    "print(f\"No. of parities from SRB, SH, SJB and dairy crosses: \\n\", count_my_rec.to_string(index=False))\n",
    "\n",
    "# By cows\n",
    "for_my_rec4 = df_lact.drop_duplicates(subset=[\"SE_Number\"])\n",
    "print(f\"No. of cows in milking file: {for_my_rec4.shape}\")  # 861\n",
    "\n",
    "for_my_rec5 = for_my_rec4.drop_duplicates(subset=[\"SE_Number\"])\n",
    "count_my_rec = for_my_rec5.groupby([\"Breed\"])[\"SE_Number\"].count().reset_index()\n",
    "print(f\"No. of cows from SRB, SH, SJB and dairy crosses: \\n\", count_my_rec.to_string(index=False))\n",
    "\n",
    "# Herd info\n",
    "df_lact = pd.read_csv(\"MY_weather2.csv\", low_memory=False)\n",
    "df_lact = df_lact.drop_duplicates(subset=[\"FarmName_Pseudo\"])\n",
    "col_keep = [\"FarmName_Pseudo\"]\n",
    "df_lact = df_lact[col_keep]\n",
    "print(df_lact.shape)  # 5 herds\n",
    "print(f\"Herds in filtered data: \\n\", df_lact.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# LOOK AT MILK YIELD BY HERD EACH DAY\n",
    "# Load data\n",
    "df_lact = pd.read_csv(\"MY_weather2.csv\", low_memory=False)\n",
    "\n",
    "# Ensure the StartDate column is a datetime object\n",
    "df_lact['StartDate'] = pd.to_datetime(df_lact['StartDate'])\n",
    "\n",
    "# list of farms\n",
    "list_of_farms = list(df_lact[\"FarmName_Pseudo\"].unique())\n",
    "\n",
    "# Create a subplot for each farm\n",
    "fig, axs = plt.subplots(len(list_of_farms), 1, figsize=(12, len(list_of_farms) * 4), sharex=True)\n",
    "\n",
    "# If there's only one subplot, convert axs to a list\n",
    "if len(list_of_farms) == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "# Dictionary to store farm color mapping\n",
    "farm_color_mapping = {}\n",
    "\n",
    "# Loop through each farm and plot in its subplot\n",
    "for i, farm in enumerate(list_of_farms):\n",
    "    ax = axs[i]\n",
    "\n",
    "    selected_farm = df_lact[df_lact['FarmName_Pseudo'] == farm]\n",
    "    number_of_cows = len(selected_farm['SE_Number'].unique())\n",
    "    daily_yield = selected_farm.groupby('StartDate')['TotalYield'].sum()\n",
    "\n",
    "    # Get color for this farm, ensuring enough colors\n",
    "    color = sns.color_palette('bright', n_colors=max(len(list_of_farms), 10))[i]\n",
    "    farm_color_mapping[farm] = color\n",
    "\n",
    "    # Generate a complete date range and reindex the daily yield\n",
    "    all_dates = pd.date_range(start=daily_yield.index.min(), end=daily_yield.index.max(), freq='D')\n",
    "    daily_yield = daily_yield.reindex(all_dates, fill_value=0)\n",
    "\n",
    "    # Plot data\n",
    "    ax.plot(daily_yield.index, daily_yield.values, label=f'Farm {farm} \\n{number_of_cows} cows', color=color)\n",
    "    ax.set_title(f'Milk Data for Farm {farm}', fontsize=16)\n",
    "    ax.set_ylabel('Daily Yield', fontsize=14)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True)\n",
    "\n",
    "# Set x-axis label for the last subplot\n",
    "axs[-1].set_xlabel('Date', fontsize=14)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# LIKE ABOVE BUT NOT SUBPLOTS\n",
    "# Load data\n",
    "df_lact = pd.read_csv(\"MY_weather2.csv\", low_memory=False)\n",
    "\n",
    "# Ensure the StartDate column is a datetime object\n",
    "df_lact['StartDate'] = pd.to_datetime(df_lact['StartDate'])\n",
    "\n",
    "# list of farms\n",
    "list_of_farms = list(df_lact[\"FarmName_Pseudo\"].unique())\n",
    "\n",
    "# Dictionary to store farm color mapping\n",
    "farm_color_mapping = {}\n",
    "\n",
    "# Loop through each farm and create a separate plot for each\n",
    "for i, farm in enumerate(list_of_farms):\n",
    "    # Create a new figure for each farm\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    selected_farm = df_lact[df_lact['FarmName_Pseudo'] == farm]\n",
    "    number_of_cows = len(selected_farm['SE_Number'].unique())\n",
    "    daily_yield = selected_farm.groupby('StartDate')['TotalYield'].sum()\n",
    "\n",
    "    # Get color for this farm, ensuring enough colors\n",
    "    color = sns.color_palette('bright', n_colors=max(len(list_of_farms), 10))[i]\n",
    "    farm_color_mapping[farm] = color\n",
    "\n",
    "    # Generate a complete date range and reindex the daily yield\n",
    "    all_dates = pd.date_range(start=daily_yield.index.min(), end=daily_yield.index.max(), freq='D')\n",
    "    daily_yield = daily_yield.reindex(all_dates, fill_value=0)\n",
    "\n",
    "    # Plot data\n",
    "    plt.plot(daily_yield.index, daily_yield.values, label=f'Farm {farm} \\n{number_of_cows} cows', color=color)\n",
    "    plt.title(f'Milk Data for Farm {farm}', fontsize=16)\n",
    "    plt.ylabel('Daily Yield', fontsize=14)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Set x-axis label\n",
    "    plt.xlabel('Date', fontsize=14)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
