{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tsfresh in /opt/conda/lib/python3.10/site-packages (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /opt/conda/lib/python3.10/site-packages (from tsfresh) (1.23.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from tsfresh) (1.1.3)\n",
      "Requirement already satisfied: tqdm>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from tsfresh) (4.64.1)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /opt/conda/lib/python3.10/site-packages (from tsfresh) (0.13.5)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tsfresh) (0.5.3)\n",
      "Requirement already satisfied: requests>=2.9.1 in /opt/conda/lib/python3.10/site-packages (from tsfresh) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from tsfresh) (1.9.3)\n",
      "Requirement already satisfied: stumpy>=1.7.2 in /opt/conda/lib/python3.10/site-packages (from tsfresh) (1.12.0)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /opt/conda/lib/python3.10/site-packages (from tsfresh) (1.5.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from tsfresh) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25.0->tsfresh) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25.0->tsfresh) (2022.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.4.1->tsfresh) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.9.1->tsfresh) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.9.1->tsfresh) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.9.1->tsfresh) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.9.1->tsfresh) (1.26.11)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->tsfresh) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->tsfresh) (1.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13->tsfresh) (21.3)\n",
      "Requirement already satisfied: numba>=0.55.2 in /opt/conda/lib/python3.10/site-packages (from stumpy>=1.7.2->tsfresh) (0.56.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from numba>=0.55.2->stumpy>=1.7.2->tsfresh) (65.5.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.55.2->stumpy>=1.7.2->tsfresh) (0.39.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->statsmodels>=0.13->tsfresh) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is used to generate the data file \"work/Data/processed/Cow_Prob_dataset_L1.csv\" \n",
    "# for Exp_3 based on the Lactation period 2. The actual analyses are in \n",
    "\n",
    "# work/HoldingPenTime/GP_Model/Cow_Detection_L2_Exp_3.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5613    17247\n",
      "4504    16330\n",
      "5046    15623\n",
      "5147    15440\n",
      "3147    15303\n",
      "478     14751\n",
      "6380    14514\n",
      "1181    14434\n",
      "4478    14434\n",
      "1985    14419\n",
      "Name: Gigacow_Cow_Id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Gigacow-tools# - data collection for fast/slow learner.\n",
    "This scripts used for single cow data collection work.\n",
    "Data Tables: gigacow_filter.csv, lactation_filter.csv, traffic_raw_filter.csv\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "pd.options.mode.chained_assignment = None\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, MinimalFCParameters\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "#access data from local directory\n",
    "dataDir = Path.cwd().parent.parent/'Data/processed'\n",
    "gigacow_cols = ['Gigacow_Cow_Id', 'FarmName_Pseudo', 'BreedName', 'BirthDate']\n",
    "lactation_cols = ['Gigacow_Cow_Id', 'FarmName_Pseudo', 'LactationInfoDate', 'LactationNumber', 'DaysInMilk']\n",
    "gigacow = pd.read_csv(dataDir/'gigacow_filter.csv', encoding='utf-8', usecols=gigacow_cols)\n",
    "lactation = pd.read_csv(dataDir/'lactation_filter.csv', encoding='utf-8', usecols=lactation_cols)\n",
    "traffic = pd.read_csv(dataDir/'traffic_raw_filter.csv', encoding='utf-8', index_col=False)\n",
    "#check out cows with most milking events\n",
    "print(traffic.Gigacow_Cow_Id.value_counts().nlargest(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 [2560, 3075, 2568, 2569, 4109, 3603, 1555, 6164, 5147, 3613, 3104, 1057, 544, 550, 5160, 2090, 4142, 48, 3638, 5691, 2112, 3657, 74, 3149, 6222, 1103, 4176, 2135, 1113, 6235, 603, 4704, 6241, 4195, 5225, 4714, 622, 5235, 5239, 3705, 4730, 3707, 645, 3206, 5767, 2694, 3718, 5262, 2702, 151, 6300, 4765, 1181, 5279, 3744, 4769, 2724, 1705, 6316, 3762, 5301, 182, 2742, 4280, 4792, 708, 4295, 5322, 2251, 1738, 1744, 5846, 4311, 1755, 1244, 5852, 2278, 2792, 6380, 3822, 5873, 2805, 5372, 1277, 769, 1796, 4871, 2844, 289, 6434, 4899, 6439, 4910, 1842, 1331, 6452, 2868, 3890, 1336, 6463, 2374, 6472, 4939, 2386, 855, 5465, 1905, 3446, 2423, 3447, 1910, 4990, 6018, 2956, 6039, 2460, 926, 3487, 5534, 2466, 2979, 4524, 4525, 4012, 943, 5555, 5046, 951, 1464, 4537, 1985, 961, 6086, 2510, 978, 5076, 2517, 985, 478, 5088, 5092, 3045, 2031, 5616, 6127, 2039, 2047]\n",
      "60 [2560, 769, 5767, 2569, 2702, 1555, 3603, 2039, 151, 5147, 2844, 3613, 4765, 2423, 926, 3487, 4899, 2979, 5160, 2090, 943, 3890, 5555, 3638, 182, 5046, 4537, 1985, 708, 6086, 3657, 74, 5322, 2251, 2510, 1103, 4176, 4311, 5465, 985, 5852, 478, 4704, 6241, 5088, 4195, 5092, 2278, 2792, 6380, 6127, 5616, 2031, 5235, 2805, 3446, 3447, 3705, 4990, 2047]\n"
     ]
    }
   ],
   "source": [
    "# Select cows with sufficient data points on single lactation periods\n",
    "# Try to collect cow's data that contain milking events on lactation periods 1\n",
    "# fetch all milking traffic events for merging\n",
    "traffic_milking = traffic.TrafficResult.str.contains('kg', regex=False)\n",
    "all_list = traffic_milking.index[traffic_milking.values == True].tolist()\n",
    "milking_total = traffic[traffic.index.isin(all_list)]\n",
    "milking_total.TrafficEventDateTime = pd.to_datetime(milking_total.TrafficEventDateTime)\n",
    "milking_total['milking_date'] = milking_total.TrafficEventDateTime.dt.date\n",
    "\n",
    "# convert data type\n",
    "milking_total.milking_date = pd.to_datetime(milking_total.milking_date)\n",
    "lactation.LactationInfoDate = pd.to_datetime(lactation.LactationInfoDate)\n",
    "# merge all milking events with lactation table for filtering\n",
    "milking_total = milking_total.merge(lactation, how='left', left_on=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'milking_date'], right_on=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'LactationInfoDate'])\n",
    "def lac_collect(NumLac, milking_total):\n",
    "    \"\"\"Generate cow list for multiple lactation periods.\n",
    "\n",
    "    Args:\n",
    "        NumLac: The number of lactaion period\n",
    "        milking_total: A dataframe contains all the milkings events\n",
    "\n",
    "    Returns:\n",
    "        A list contain all the cows events with sufficient data points within the lactation periods.\n",
    "    \"\"\"\n",
    "    cow_list = list()\n",
    "    for num in range(1, NumLac+1):\n",
    "        # select records that contains lactation period #num\n",
    "        milking_select1 = milking_total.loc[milking_total['LactationNumber'] == num]\n",
    "        milking_select1.drop_duplicates(subset=['Gigacow_Cow_Id', 'milking_date', 'LactationNumber', 'DaysInMilk'], inplace=True)\n",
    "        # drop the anomaly data point\n",
    "        milking_select1 = milking_select1.loc[milking_select1.DaysInMilk < 400]\n",
    "        # select sufficient data points on lactation\n",
    "        selected1 = milking_select1.Gigacow_Cow_Id.value_counts(ascending=True)\n",
    "        selected1 = selected1.loc[(selected1.values > 150) & (selected1.values < 365)]\n",
    "        selected_cow_list = selected1.index.to_list()\n",
    "        if num == 1:\n",
    "            cow_list = selected_cow_list\n",
    "        cow_list = list(set(cow_list) & set(selected_cow_list))\n",
    "        print(len(cow_list), cow_list)\n",
    "    return cow_list\n",
    "\n",
    "cow_list = lac_collect(2, milking_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countCowAge(birthDate, milkingDate):\n",
    "    '''\n",
    "    func: Calculate cows age based on birthDate and milkingDate\n",
    "    args: \n",
    "        birthDate: cow's birth datetime\n",
    "        milkingDate: milking events datetime\n",
    "    return: cow age in human years(float)\n",
    "    '''\n",
    "    birthDate = pd.to_datetime(birthDate)\n",
    "    milkingDate = pd.to_datetime(milkingDate)\n",
    "    days = np.float32(np.datetime64(milkingDate, 'D') - np.datetime64(birthDate, 'D'))\n",
    "    age = np.around(days/365, 2)\n",
    "    return age\n",
    "\n",
    "# select single cow from the traffic table\n",
    "\n",
    "def data_collector(traffic, gigacow, lactation, cow_id, lacNumList):\n",
    "    '''\n",
    "    func: collect features from for a single cow\n",
    "    args: \n",
    "        traffic: traffic data table\n",
    "        gigacow: gigacow data table\n",
    "        lactation: lactation data table\n",
    "        cow_id: gigacow_id of the cow\n",
    "        lacNumList: a list lactation period number\n",
    "    return: A dataframe contains all features for a single cow on specfic lactation period\n",
    "    '''\n",
    "\n",
    "    traffic_single_cow = traffic.loc[traffic['Gigacow_Cow_Id'] == cow_id]\n",
    "    traffic_single_cow.sort_values(by='TrafficEventDateTime', inplace=True)\n",
    "    traffic_single_cow.index = range(len(traffic_single_cow))\n",
    "\n",
    "    '''\n",
    "        Extract Milking Event and its most recent traffic event to calculate T2-T1\n",
    "        T1: Entry time into the Mjolkfalla\n",
    "        T2: Entry time into the milking robot\n",
    "        T2-T1: calculate time difference between T2&T1 (i.e., Time spend in Mjolkfalla/holding area)\n",
    "    '''\n",
    "    # locate mikling event by searching 'kg' keyword in traffic result\n",
    "    # the most recent traffic event to milking event should be pre_milking event\n",
    "    # need to filter out records with gate failure\n",
    "    track_milking = traffic_single_cow.TrafficResult.str.contains('kg', regex=False)\n",
    "    milking_index_list = track_milking.index[track_milking.values == True].tolist()\n",
    "    pre_milking_index_list = [x-1 for x in milking_index_list]\n",
    "    milking_traffic = traffic_single_cow[traffic_single_cow.index.isin(milking_index_list)]\n",
    "    pre_milking_traffic = traffic_single_cow[traffic_single_cow.index.isin(pre_milking_index_list)]\n",
    "\n",
    "    # drop rows that the gate failed to detect cows but have milking result\n",
    "    # previous area in milking_traffic table should only be Mjolkfalla\n",
    "    # previous area in pre_milking_traffic table should not be Mjolkfalla\n",
    "    failed_list_1_milk = milking_traffic.index[milking_traffic['PreviousArea'] == 'Koridor till Sorteringsgrind 2'].tolist()\n",
    "    failed_list_1_pre = [x-1 for x in failed_list_1_milk]\n",
    "    failed_list_2_pre = pre_milking_traffic.index[pre_milking_traffic['PreviousArea'] == 'Mjolkfalla'].tolist()\n",
    "    failed_list_2_milk = [x+1 for x in failed_list_2_pre]\n",
    "    # traffic result in pre_milking_traffic table should contain Mjolkfalla\n",
    "    track_pre_milking = pre_milking_traffic.TrafficResult.str.contains('Mjolkfalla', regex=False)\n",
    "    failed_list_3_pre = track_pre_milking.index[track_pre_milking.values == False].tolist()\n",
    "    failed_list_3_milk = [x+1 for x in failed_list_3_pre]\n",
    "\n",
    "    # remove failed records based on index list\n",
    "    milking_traffic_failed = failed_list_1_milk + failed_list_2_milk + failed_list_3_milk\n",
    "    pre_milking_traffic_failed = failed_list_1_pre + failed_list_2_pre + failed_list_3_pre\n",
    "    milking_traffic.drop(axis=0, index=milking_traffic_failed, inplace=True)\n",
    "    pre_milking_traffic.drop(axis=0, index=pre_milking_traffic_failed, inplace=True)\n",
    "    # concatenate two tables to track the traffic directly\n",
    "    all_milking_traffic = pd.concat([milking_traffic, pre_milking_traffic])\n",
    "    all_milking_traffic.sort_values(by=['TrafficEventDateTime'], inplace=True)\n",
    "    #rename table columns for merging\n",
    "    milking_traffic.rename(columns={\"TrafficEventDateTime\": \"MilkingEventDateTime\", \"TrafficResult\": \"MilkProduction\", \"TimeInArea_totalSeconds\": \"RoundedSecondsTimeInArea\"}, inplace=True)\n",
    "    pre_milking_traffic.rename(columns={\"TrafficEventDateTime\": \"Pre_MilkingEventDateTime\", \"TimeInArea_totalSeconds\": \"RoundedSecondsTimeInArea\"}, inplace=True)\n",
    "    # unify the index of two tables\n",
    "    milking_traffic.index = range(len(milking_traffic))\n",
    "    pre_milking_traffic.index = range(len(pre_milking_traffic))\n",
    "    # inert \"pre_traffic_milking\" to milking traffic table\n",
    "    milking_traffic.insert(5, 'Pre_MilkingEventDateTime', pre_milking_traffic['Pre_MilkingEventDateTime'])\n",
    "    # calculate T2-T1\n",
    "    milking_traffic.MilkingEventDateTime = pd.to_datetime(milking_traffic.MilkingEventDateTime)\n",
    "    milking_traffic.Pre_MilkingEventDateTime = pd.to_datetime(milking_traffic.Pre_MilkingEventDateTime)\n",
    "    milking_traffic['timeDelta_Seconds'] = (milking_traffic['MilkingEventDateTime'] - milking_traffic['Pre_MilkingEventDateTime']).dt.total_seconds()\n",
    "\n",
    "    # extract traffic result(milk production)\n",
    "    milking_traffic['MilkProduction'].replace(r\"[^0-9.,]+\",\" \", inplace=True, regex=True)\n",
    "    milking_traffic['MilkProduction'].replace(r\"\\s*\",\"\", inplace=True, regex=True)\n",
    "    milking_traffic['MilkProduction'].replace(r\"[,]+\",\".\", inplace=True, regex=True)\n",
    "    milking_traffic['MilkProduction'] = milking_traffic['MilkProduction'].astype('float64')\n",
    "\n",
    "    # merge all the other features into milking_traffic table\n",
    "    milking_traffic['MilkingDate'] = milking_traffic.MilkingEventDateTime.dt.date\n",
    "    milking_traffic.MilkingDate = pd.to_datetime(milking_traffic.MilkingDate)\n",
    "    lactation.LactationInfoDate = pd.to_datetime(lactation.LactationInfoDate)\n",
    "    single_cow_merge = milking_traffic.merge(lactation, how='left', left_on=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'MilkingDate'], right_on=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'LactationInfoDate'])\n",
    "    single_cow_merge = single_cow_merge.merge(gigacow, how='left', left_on=['FarmName_Pseudo', 'Gigacow_Cow_Id'], right_on=['FarmName_Pseudo', 'Gigacow_Cow_Id'])\n",
    "\n",
    "    # drop failed data points based on RoundedSecondsTimeInArea & timeDelta_Seconds\n",
    "    single_cow_merge.drop(single_cow_merge.loc[abs(single_cow_merge.timeDelta_Seconds - single_cow_merge.RoundedSecondsTimeInArea) > 300].index, inplace=True)\n",
    "    single_cow_merge['TrafficDeviceName'].replace(r\"[A-Za-z]+\\s*\",\"vms\", inplace=True, regex=True)\n",
    "    # calculate age of cows\n",
    "    single_cow_merge['Age'] = single_cow_merge.apply(lambda x: countCowAge(x['BirthDate'], x['MilkingEventDateTime']), axis=1)\n",
    "    single_cow_merge.drop(['BirthDate'], axis=1, inplace=True)\n",
    "    single_cow_merge.dropna(inplace=True)\n",
    "\n",
    "    # integrate multiple milking events for a single DIM\n",
    "    single_cow_merge = single_cow_merge[single_cow_merge.LactationNumber.isin(lacNumList)]\n",
    "    single_cow_merge.index = range(1,len(single_cow_merge)+1) \n",
    "    single_cow_merge.drop(['MilkingEventDateTime', 'Pre_MilkingEventDateTime', 'Traffic_Id', 'MilkingInterval_totalSeconds', 'RoundedSecondsTimeInArea', 'PreviousArea', 'GroupName', 'LactationInfoDate', 'TrafficDeviceName'], axis=1, inplace=True)\n",
    "\n",
    "    # uncomment following part to get combined milking events for each DIM\n",
    "    # comb_cows = single_cow_merge.groupby(by=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'MilkingDate', 'LactationNumber', 'DaysInMilk', 'BreedName', 'Age'], sort=False, as_index=False).sum(['MilkProduction', 'timeDelta_Seconds'])\n",
    "    # single_cow_merge_size = single_cow_merge.groupby(by=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'MilkingDate', 'LactationNumber', 'DaysInMilk', 'BreedName', 'Age'], sort=False, as_index=False).size()\n",
    "    # comb_cows = pd.concat([comb_cows, single_cow_merge_size['size']], axis=1, ignore_index=False)\n",
    "    # comb_cows.rename(columns={\"MilkProduction\": \"Total_MilkProduction\", \"timeDelta_Seconds\": \"Total_timeDelta_Seconds\", \"size\": \"milking_times\"}, inplace=True)\n",
    "    # comb_cows.index = range(1, len(comb_cows)+1)\n",
    "    # return comb_cows\n",
    "\n",
    "    single_cow_merge.rename(columns={\"MilkProduction\": \"Total_MilkProduction\", \"timeDelta_Seconds\": \"Total_timeDelta_Seconds\", \"size\": \"milking_times\"}, inplace=True)\n",
    "    single_cow_merge.index = range(1, len(single_cow_merge)+1)\n",
    "    return single_cow_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "labeling cow with problematic/normal(1/0)\n",
    "\"\"\"\n",
    "threshold_ratio = 0.05\n",
    "Path(dataDir/'Problematic_targetCows_L2').mkdir(parents=True, exist_ok=True)\n",
    "def labeling_problematic(threshold_ratio, cow_total): \n",
    "    '''\n",
    "    func: labeling problematic cows\n",
    "    args: \n",
    "        threshold_ratio: threshold ratio for the abnormal event milking events\n",
    "        cow_total: A dataframe contains all data points for a single cow\n",
    "    return: problematic cows dataset with label\n",
    "    '''\n",
    "    global learner\n",
    "    total_events = len(cow_total)\n",
    "    abnoramal_cows = cow_total.loc[cow_total.Total_timeDelta_Seconds > 7200]\n",
    "    abnoramal_ratio = len(abnoramal_cows)/total_events\n",
    "    print(abnoramal_ratio)\n",
    "    if abnoramal_ratio > threshold_ratio:\n",
    "        problematic = 1 # problematic cow\n",
    "    else:\n",
    "        problematic = 0 # normal cow\n",
    "    cow_total['problematic'] = problematic\n",
    "    return cow_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered:  60 [2560, 769, 5767, 2569, 2702, 1555, 3603, 2039, 151, 5147, 2844, 3613, 4765, 2423, 926, 3487, 4899, 2979, 5160, 2090, 943, 3890, 5555, 3638, 182, 5046, 4537, 1985, 708, 6086, 3657, 74, 5322, 2251, 2510, 1103, 4176, 4311, 5465, 985, 5852, 478, 4704, 6241, 5088, 4195, 5092, 2278, 2792, 6380, 6127, 5616, 2031, 5235, 2805, 3446, 3447, 3705, 4990, 2047]\n"
     ]
    }
   ],
   "source": [
    "# filter out cows' record start at the middle of the lactation\n",
    "filter_list = []\n",
    "for id in cow_list:\n",
    "    single_cow = data_collector(traffic, gigacow, lactation, id, [2])\n",
    "    if single_cow.DaysInMilk.min() < 60:\n",
    "        filter_list.append(id)\n",
    "\n",
    "print(\"filtered: \", len(filter_list), filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cow_id: 2560\n",
      "0.0\n",
      "cow_id: 769\n",
      "0.003121748178980229\n",
      "cow_id: 5767\n",
      "0.0012903225806451613\n",
      "cow_id: 2569\n",
      "0.0\n",
      "cow_id: 2702\n",
      "0.0\n",
      "cow_id: 1555\n",
      "0.0022624434389140274\n",
      "cow_id: 3603\n",
      "0.02286902286902287\n",
      "cow_id: 2039\n",
      "0.00234192037470726\n",
      "cow_id: 151\n",
      "0.0\n",
      "cow_id: 5147\n",
      "0.0\n",
      "cow_id: 2844\n",
      "0.0019801980198019802\n",
      "cow_id: 3613\n",
      "0.006952491309385863\n",
      "cow_id: 4765\n",
      "0.015552099533437015\n",
      "cow_id: 2423\n",
      "0.0\n",
      "cow_id: 926\n",
      "0.0\n",
      "cow_id: 3487\n",
      "0.22535211267605634\n",
      "cow_id: 4899\n",
      "0.026455026455026454\n",
      "cow_id: 2979\n",
      "0.07975460122699386\n",
      "cow_id: 5160\n",
      "0.0009523809523809524\n",
      "cow_id: 2090\n",
      "0.0019342359767891683\n",
      "cow_id: 943\n",
      "0.0010718113612004287\n",
      "cow_id: 3890\n",
      "0.002044989775051125\n",
      "cow_id: 5555\n",
      "0.01466544454628781\n",
      "cow_id: 3638\n",
      "0.017400204708290685\n",
      "cow_id: 182\n",
      "0.002617801047120419\n",
      "cow_id: 5046\n",
      "0.0\n",
      "cow_id: 4537\n",
      "0.3239130434782609\n",
      "cow_id: 1985\n",
      "0.0\n",
      "cow_id: 708\n",
      "0.0\n",
      "cow_id: 6086\n",
      "0.0\n",
      "cow_id: 3657\n",
      "0.17274939172749393\n",
      "cow_id: 74\n",
      "0.0\n",
      "cow_id: 5322\n",
      "0.002531645569620253\n",
      "cow_id: 2251\n",
      "0.0024125452352231603\n",
      "cow_id: 2510\n",
      "0.0\n",
      "cow_id: 1103\n",
      "0.0\n",
      "cow_id: 4176\n",
      "0.016\n",
      "cow_id: 4311\n",
      "0.14058355437665782\n",
      "cow_id: 5465\n",
      "0.0\n",
      "cow_id: 985\n",
      "0.008\n",
      "cow_id: 5852\n",
      "0.005417118093174431\n",
      "cow_id: 478\n",
      "0.0\n",
      "cow_id: 4704\n",
      "0.11205432937181664\n",
      "cow_id: 6241\n",
      "0.006775067750677507\n",
      "cow_id: 5088\n",
      "0.0\n",
      "cow_id: 4195\n",
      "0.0\n",
      "cow_id: 5092\n",
      "0.0\n",
      "cow_id: 2278\n",
      "0.0\n",
      "cow_id: 2792\n",
      "0.0\n",
      "cow_id: 6380\n",
      "0.0\n",
      "cow_id: 6127\n",
      "0.0017452006980802793\n",
      "cow_id: 5616\n",
      "0.0171990171990172\n",
      "cow_id: 2031\n",
      "0.0010964912280701754\n",
      "cow_id: 5235\n",
      "0.004225352112676056\n",
      "cow_id: 2805\n",
      "0.0017452006980802793\n",
      "cow_id: 3446\n",
      "0.001152073732718894\n",
      "cow_id: 3447\n",
      "0.0\n",
      "cow_id: 3705\n",
      "0.0\n",
      "cow_id: 4990\n",
      "0.0\n",
      "cow_id: 2047\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Uses the labeling_problematic function to label problematic cows and print distribution of time into a PDF\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import warnings\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "\"\"\" plot the relations between timeDelta and Lactation/DIM(DaysInMilk)\n",
    "        @@@ Total_timeDelta @@@\n",
    "    \"\"\" \n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    with PdfPages(dataDir/'100cows_timecost_scatters_lac2_with_label_scale30000.pdf') as pdf:\n",
    "        for id in filter_list:\n",
    "            print(\"cow_id:\", id)\n",
    "            single_cow_merge = data_collector(traffic, gigacow, lactation, id, [2])\n",
    "            single_cow_merge = labeling_problematic(0.05, single_cow_merge)\n",
    "            prob = single_cow_merge.problematic.unique()[0]\n",
    "            fig1 = plt.figure()\n",
    "            # fig2 = plt.figure()\n",
    "            if prob == 1:\n",
    "                title = \"Problematic_Cow_cow_id_\"+ str(id)\n",
    "            else:\n",
    "                title = \"Normal_Cow_cow_id_\"+ str(id)\n",
    "            #fig1 = single_cow_merge.loc[single_cow_merge.LactationNumber == 1].plot(x=\"DaysInMilk\", y=\"Total_timeDelta_Seconds\", kind='scatter', title=title+\"_Lac1\", xlim=[1, 360], ylim=[0, 30000], s=2, c='b')\n",
    "            fig2 = single_cow_merge.loc[single_cow_merge.LactationNumber == 2].plot(x=\"DaysInMilk\", y=\"Total_timeDelta_Seconds\", kind='scatter', title=title+\"_Lac2\", xlim=[1, 360], ylim=[0, 10000], s=2, c='b')\n",
    "            # pdf.savefig(fig1.get_figure())\n",
    "            pdf.savefig(fig2.get_figure())\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.003121748178980229\n",
      "0.0012903225806451613\n",
      "0.0\n",
      "0.0\n",
      "0.0022624434389140274\n",
      "0.02286902286902287\n",
      "0.00234192037470726\n",
      "0.0\n",
      "0.0\n",
      "0.0019801980198019802\n",
      "0.006952491309385863\n",
      "0.015552099533437015\n",
      "0.0\n",
      "0.0\n",
      "0.22535211267605634\n",
      "This cow is problematic: 3487\n",
      "0.026455026455026454\n",
      "0.07975460122699386\n",
      "This cow is problematic: 2979\n",
      "0.0009523809523809524\n",
      "0.0019342359767891683\n",
      "0.0010718113612004287\n",
      "0.002044989775051125\n",
      "0.01466544454628781\n",
      "0.017400204708290685\n",
      "0.002617801047120419\n",
      "0.0\n",
      "0.3239130434782609\n",
      "This cow is problematic: 4537\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.17274939172749393\n",
      "This cow is problematic: 3657\n",
      "0.0\n",
      "0.002531645569620253\n",
      "0.0024125452352231603\n",
      "0.0\n",
      "0.0\n",
      "0.016\n",
      "0.14058355437665782\n",
      "This cow is problematic: 4311\n",
      "0.0\n",
      "0.008\n",
      "0.005417118093174431\n",
      "0.0\n",
      "0.11205432937181664\n",
      "This cow is problematic: 4704\n",
      "0.006775067750677507\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0017452006980802793\n",
      "0.0171990171990172\n",
      "0.0010964912280701754\n",
      "0.004225352112676056\n",
      "0.0017452006980802793\n",
      "0.001152073732718894\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "num of cows:  60\n",
      "Mean of total time cost:  1053.3446487120177\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "mean_totalTimeCost = 0\n",
    "Path(dataDir/'Problematic_targetCows_L2').mkdir(parents=True, exist_ok=True)\n",
    "lactationNum = [2]\n",
    "\n",
    "# save a list of cow data for abnormal cows detection problem\n",
    "for i, cow_id in enumerate(filter_list):\n",
    "    single_cow_merge = data_collector(traffic, gigacow, lactation, cow_id, lactationNum)\n",
    "    mean_totalTimeCost += single_cow_merge.Total_timeDelta_Seconds.mean()\n",
    "    single_cow_merge = labeling_problematic(threshold_ratio, single_cow_merge)\n",
    "    problematic = single_cow_merge.problematic.unique()[0]\n",
    "    if problematic == 1:\n",
    "        print(\"This cow is problematic:\", cow_id)\n",
    "    single_cow_merge[\"id\"] = i+1\n",
    "    single_cow_merge.dropna(inplace=True)\n",
    "    fileName = 'Problematic_targetCows_L2/cow_' + str(i) + '.csv'\n",
    "    single_cow_merge.to_csv(dataDir/fileName)\n",
    "print(\"num of cows: \", len(cow_list))\n",
    "print(\"Mean of total time cost: \", mean_totalTimeCost/len(cow_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/Data/processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>5.76</td>\n",
       "      <td>271.0</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>7.76</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>6.79</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>6.47</td>\n",
       "      <td>266.0</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>7.15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.35</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45403</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45404</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>6.64</td>\n",
       "      <td>439.0</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45405</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>6.15</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45406</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.38</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45407 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "0            a624fb9a            2560                  5.76   \n",
       "1            a624fb9a            2560                  7.76   \n",
       "2            a624fb9a            2560                  6.79   \n",
       "3            a624fb9a            2560                  6.47   \n",
       "4            a624fb9a            2560                  7.15   \n",
       "...               ...             ...                   ...   \n",
       "45402        a624fb9a            2047                  5.35   \n",
       "45403        a624fb9a            2047                  7.88   \n",
       "45404        a624fb9a            2047                  6.64   \n",
       "45405        a624fb9a            2047                  6.15   \n",
       "45406        a624fb9a            2047                  5.38   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "0                        271.0  2023-01-31              2.0         2.0   \n",
       "1                         16.0  2023-01-31              2.0         2.0   \n",
       "2                        142.0  2023-01-31              2.0         2.0   \n",
       "3                        266.0  2023-01-31              2.0         2.0   \n",
       "4                         21.0  2023-02-01              2.0         3.0   \n",
       "...                        ...         ...              ...         ...   \n",
       "45402                    201.0  2023-10-13              2.0       277.0   \n",
       "45403                   1125.0  2023-10-13              2.0       277.0   \n",
       "45404                    439.0  2023-10-14              2.0       278.0   \n",
       "45405                     67.0  2023-10-15              2.0       279.0   \n",
       "45406                     36.0  2023-10-15              2.0       279.0   \n",
       "\n",
       "       BreedName   Age  problematic  id  \n",
       "0              1  3.11            0   1  \n",
       "1              1  3.11            0   1  \n",
       "2              1  3.11            0   1  \n",
       "3              1  3.11            0   1  \n",
       "4              1  3.11            0   1  \n",
       "...          ...   ...          ...  ..  \n",
       "45402          1  3.94            0  60  \n",
       "45403          1  3.94            0  60  \n",
       "45404          1  3.95            0  60  \n",
       "45405          1  3.95            0  60  \n",
       "45406          1  3.95            0  60  \n",
       "\n",
       "[45407 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Data Preparation L2 \"\"\"\n",
    "cow_total = None\n",
    "usecols = ['id', 'FarmName_Pseudo', 'Gigacow_Cow_Id', 'Total_MilkProduction', 'Total_timeDelta_Seconds', 'LactationNumber', 'DaysInMilk', 'BreedName', 'Age', 'MilkingDate', 'problematic']\n",
    "print(dataDir)\n",
    "\n",
    "dataDir_L2 = dataDir/'Problematic_targetCows_L2/'\n",
    "# integrate all the cows data into one dataset\n",
    "filelist = list(Path(dataDir_L2).glob('cow_*.csv'))\n",
    "#print(filelist)\n",
    "for i, _ in enumerate(filelist):\n",
    "    fileName = 'cow_' + str(i) + '.csv'\n",
    "    single_cow = pd.read_csv(dataDir_L2/fileName, encoding='utf-8', usecols=usecols)\n",
    "    single_cow.sort_values(by=['MilkingDate'], inplace=True)\n",
    "    if i == 0:\n",
    "        cow_total = single_cow\n",
    "    else:\n",
    "        cow_total = pd.concat([cow_total, single_cow], axis=0, ignore_index=True)\n",
    "\n",
    "cow_total.to_csv(dataDir/\"Cow_Prob_dataset_L2.csv\", index=False)\n",
    "cow_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7857ada9c2c05e5ee75d334d60fb77cca110ad03375c3b02029444557fa6212d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
