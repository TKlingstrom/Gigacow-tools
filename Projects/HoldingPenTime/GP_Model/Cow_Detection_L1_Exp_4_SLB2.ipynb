{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "396af3cf-0117-4f47-a509-3261e5d8cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "pd.options.mode.chained_assignment = None\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, MinimalFCParameters\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85bb1b24-e295-47ea-b4e1-fda41010b4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>9.38</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>8.46</td>\n",
       "      <td>352.0</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>6.68</td>\n",
       "      <td>997.0</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>7.34</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>8.15</td>\n",
       "      <td>407.0</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95849</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.96</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95850</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.53</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95851</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>3.24</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95852</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>9.23</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95853</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95854 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "0            a624fb9a            2560                  9.38   \n",
       "1            a624fb9a            2560                  8.46   \n",
       "2            a624fb9a            2560                  6.68   \n",
       "3            a624fb9a            2560                  7.34   \n",
       "4            a624fb9a            2560                  8.15   \n",
       "...               ...             ...                   ...   \n",
       "95849        a624fb9a            2047                  7.96   \n",
       "95850        a624fb9a            2047                  5.53   \n",
       "95851        a624fb9a            2047                  3.24   \n",
       "95852        a624fb9a            2047                  9.23   \n",
       "95853        a624fb9a            2047                  7.42   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "0                       3176.0  2022-02-14              1.0         2.0   \n",
       "1                        352.0  2022-02-14              1.0         2.0   \n",
       "2                        997.0  2022-02-15              1.0         3.0   \n",
       "3                       9274.0  2022-02-15              1.0         3.0   \n",
       "4                        407.0  2022-02-16              1.0         4.0   \n",
       "...                        ...         ...              ...         ...   \n",
       "95849                     59.0  2022-11-12              1.0       322.0   \n",
       "95850                    148.0  2022-11-13              1.0       323.0   \n",
       "95851                    287.0  2022-11-13              1.0       323.0   \n",
       "95852                    240.0  2022-11-13              1.0       323.0   \n",
       "95853                     10.0  2022-11-14              1.0       324.0   \n",
       "\n",
       "       BreedName   Age  problematic   id  \n",
       "0              1  2.15            0    1  \n",
       "1              1  2.15            0    1  \n",
       "2              1  2.15            0    1  \n",
       "3              1  2.15            0    1  \n",
       "4              1  2.15            0    1  \n",
       "...          ...   ...          ...  ...  \n",
       "95849          1  3.02            0  142  \n",
       "95850          1  3.03            0  142  \n",
       "95851          1  3.03            0  142  \n",
       "95852          1  3.03            0  142  \n",
       "95853          1  3.03            0  142  \n",
       "\n",
       "[95854 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cows = pd.DataFrame()\n",
    "\n",
    "dataDir = '../../Data/processed/'\n",
    "total_cows = pd.read_csv(dataDir+'Cow_Prob_dataset_L1.csv')\n",
    "total_cows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1ea9f6f-6b79-4400-ac99-d5e3d539504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cows_SLB2 = total_cows[total_cows['BreedName'] == 2]\n",
    "\n",
    "total_cows = total_cows_SLB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c42e8a3-5fce-4f84-9e68-f3297bf92301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87, 87, 114, 101, 61] 5\n"
     ]
    }
   ],
   "source": [
    "# Select IDs from the total_cows\n",
    "test_cow_list = []\n",
    "ids = total_cows['id']\n",
    "\n",
    "unique_cow_ids = ids.unique()\n",
    "\n",
    "# Select a few rows randomly\n",
    "num_of_selected_cows = 5\n",
    "\n",
    "#test_cow_list = [1]\n",
    "\n",
    "#test_cow_list = random.choices( unique_cow_ids, k=num_of_selected_cows)\n",
    "#test_cow_list.sort()\n",
    "\n",
    "test_cow_list =  [87, 87, 114, 101, 61]\n",
    "print(test_cow_list, len(test_cow_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "471088dc-15b0-4be2-a527-8967a8de7801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44521</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>5616</td>\n",
       "      <td>5.45</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44522</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>5616</td>\n",
       "      <td>5.76</td>\n",
       "      <td>207.0</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44523</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>5616</td>\n",
       "      <td>5.34</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44524</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>5616</td>\n",
       "      <td>6.36</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44525</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>5616</td>\n",
       "      <td>5.92</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "44521        a624fb9a            5616                  5.45   \n",
       "44522        a624fb9a            5616                  5.76   \n",
       "44523        a624fb9a            5616                  5.34   \n",
       "44524        a624fb9a            5616                  6.36   \n",
       "44525        a624fb9a            5616                  5.92   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "44521                      9.0  2022-09-26              1.0       299.0   \n",
       "44522                    207.0  2022-09-26              1.0       299.0   \n",
       "44523                   1175.0  2022-09-27              1.0       300.0   \n",
       "44524                    390.0  2022-09-27              1.0       300.0   \n",
       "44525                   1549.0  2022-09-27              1.0       300.0   \n",
       "\n",
       "       BreedName   Age  problematic   id  \n",
       "44521          2  2.84            0  139  \n",
       "44522          2  2.84            0  139  \n",
       "44523          2  2.85            0  139  \n",
       "44524          2  2.85            0  139  \n",
       "44525          2  2.85            0  139  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_total_cows = total_cows\n",
    "ts_length_test_data = 105\n",
    "\n",
    "for l in test_cow_list:\n",
    "    # Choose a specific duration\n",
    "    condition = modified_total_cows['id'] == l\n",
    "    test_cow = modified_total_cows[condition].copy()\n",
    "    test_cow = test_cow.reset_index()        \n",
    "    # print(test_cow)\n",
    "    if 'index' in test_cow:\n",
    "        test_cow = test_cow.drop('index', axis=1)\n",
    "        \n",
    "    modified_total_cows = modified_total_cows[~condition]\n",
    "            \n",
    "    test_cow['MilkingDate'] = pd.to_datetime(test_cow['MilkingDate'])\n",
    "    test_cow['MilkingDate'] = test_cow['MilkingDate'].dt.date\n",
    "            \n",
    "    start_date = test_cow['MilkingDate'][0]\n",
    "    #print('start_date: ',start_date)\n",
    "    end_date = pd.to_datetime(start_date + pd.DateOffset(days=ts_length_test_data)).date()\n",
    "    #print('end_date: ', end_date)\n",
    "    filtered_df = test_cow[(test_cow['MilkingDate'] >= start_date) & (test_cow['MilkingDate'] <= end_date)]   \n",
    "    \n",
    "    modified_total_cows = pd.concat([modified_total_cows, filtered_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "#modified_total_cows = modified_total_cows.drop('index', axis=1)\n",
    "#modified_total_cows = modified_total_cows.sort_values('id')\n",
    "modified_total_cows = modified_total_cows.sort_values(by=['id', 'MilkingDate'])\n",
    "\n",
    "modified_total_cows.to_csv(dataDir+\"upp.csv\", index=False)\n",
    "\n",
    "#modified_total_cows = modified_total_cows.reset_index()\n",
    "\n",
    "modified_total_cows.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "25a586e8-e3cc-4b2d-b73c-a1e5d235b14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45588, 11)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cow_total =  modified_total_cows\n",
    "cow_total.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "009c6a05-7081-436c-8d5e-bf0f1a184716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    45\n",
      "1    20\n",
      "Name: problematic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#original\n",
    "#df_static_features = cow_total[['FarmName_Pseudo']]\n",
    "static_cols = ['FarmName_Pseudo', 'TrafficDeviceName', 'LactationNumber', 'BreedName']\n",
    "timeSeries_cols = ['Age', 'Total_MilkProduction', 'Total_timeDelta_Seconds', 'DaysInMilk']\n",
    "output_col = ['problematic']\n",
    "\n",
    "cow_label = cow_total[['id', 'problematic']].copy()\n",
    "cow_timeseries = cow_total[['id', 'MilkingDate']].copy()\n",
    "cow_timeseries.index = range(len(cow_timeseries))\n",
    "# fetch y for feature extraction\n",
    "y = cow_label.drop_duplicates(subset=['id'])\n",
    "y = y[\"problematic\"]\n",
    "y.index = range(1,len(y)+1) \n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5ba0c709-0d26-4e73-a0fc-8d0681161b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_extracted_dataset shape:  (45588, 1)\n",
      "ts_extracted_dataset shape:  (65, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>DaysInMilk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>1.90</td>\n",
       "      <td>12.49</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>1.90</td>\n",
       "      <td>13.38</td>\n",
       "      <td>50204.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>1.90</td>\n",
       "      <td>14.00</td>\n",
       "      <td>54718.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>1.90</td>\n",
       "      <td>5.62</td>\n",
       "      <td>9269.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>1.90</td>\n",
       "      <td>7.36</td>\n",
       "      <td>13373.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45583</th>\n",
       "      <td>139</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>2.84</td>\n",
       "      <td>5.45</td>\n",
       "      <td>9.0</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45584</th>\n",
       "      <td>139</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>2.84</td>\n",
       "      <td>5.76</td>\n",
       "      <td>207.0</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45585</th>\n",
       "      <td>139</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>2.85</td>\n",
       "      <td>5.34</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45586</th>\n",
       "      <td>139</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>2.85</td>\n",
       "      <td>6.36</td>\n",
       "      <td>390.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45587</th>\n",
       "      <td>139</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>2.85</td>\n",
       "      <td>5.92</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45588 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id MilkingDate   Age  Total_MilkProduction  Total_timeDelta_Seconds  \\\n",
       "0        2  2022-04-20  1.90                 12.49                   6926.0   \n",
       "1        2  2022-04-21  1.90                 13.38                  50204.0   \n",
       "2        2  2022-04-22  1.90                 14.00                  54718.0   \n",
       "3        2  2022-04-23  1.90                  5.62                   9269.0   \n",
       "4        2  2022-04-23  1.90                  7.36                  13373.0   \n",
       "...    ...         ...   ...                   ...                      ...   \n",
       "45583  139  2022-09-26  2.84                  5.45                      9.0   \n",
       "45584  139  2022-09-26  2.84                  5.76                    207.0   \n",
       "45585  139  2022-09-27  2.85                  5.34                   1175.0   \n",
       "45586  139  2022-09-27  2.85                  6.36                    390.0   \n",
       "45587  139  2022-09-27  2.85                  5.92                   1549.0   \n",
       "\n",
       "       DaysInMilk  \n",
       "0            14.0  \n",
       "1            15.0  \n",
       "2            16.0  \n",
       "3            17.0  \n",
       "4            17.0  \n",
       "...           ...  \n",
       "45583       299.0  \n",
       "45584       299.0  \n",
       "45585       300.0  \n",
       "45586       300.0  \n",
       "45587       300.0  \n",
       "\n",
       "[45588 rows x 6 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "# Prepare datasert for Tsfresh extraction\n",
    "ts_extracted_dataset = cow_total[['id']].copy()\n",
    "print('ts_extracted_dataset shape: ', ts_extracted_dataset.shape)\n",
    "ts_extracted_dataset.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_dataset.index = range(1, len(ts_extracted_dataset)+1)\n",
    "print('ts_extracted_dataset shape: ',ts_extracted_dataset.shape)\n",
    "\n",
    "ts_processed = pd.DataFrame(cow_total[timeSeries_cols].copy())\n",
    "ts_processed.index = range(0,len(ts_processed)) \n",
    "\n",
    "ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "ts_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "833d7cef-efd5-40ca-b8bb-489abb16659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45588, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 17/17 [00:00<00:00, 116.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45588, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 17/17 [00:00<00:00, 129.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45588, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 17/17 [00:00<00:00, 131.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45588, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 17/17 [00:00<00:00, 120.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                 feature  \\\n",
      "feature                                                                                    \n",
      "DaysInMilk__minimum                                                  DaysInMilk__minimum   \n",
      "Total_MilkProduction__minimum                              Total_MilkProduction__minimum   \n",
      "Total_timeDelta_Seconds__minimum                        Total_timeDelta_Seconds__minimum   \n",
      "Total_MilkProduction__standard_deviation        Total_MilkProduction__standard_deviation   \n",
      "Total_MilkProduction__variance                            Total_MilkProduction__variance   \n",
      "Total_MilkProduction__maximum                              Total_MilkProduction__maximum   \n",
      "Total_MilkProduction__absolute_maximum            Total_MilkProduction__absolute_maximum   \n",
      "Total_MilkProduction__mean                                    Total_MilkProduction__mean   \n",
      "Total_MilkProduction__root_mean_square            Total_MilkProduction__root_mean_square   \n",
      "Total_MilkProduction__median                                Total_MilkProduction__median   \n",
      "Total_timeDelta_Seconds__median                          Total_timeDelta_Seconds__median   \n",
      "Total_timeDelta_Seconds__sum_values                  Total_timeDelta_Seconds__sum_values   \n",
      "Total_timeDelta_Seconds__maximum                        Total_timeDelta_Seconds__maximum   \n",
      "Total_timeDelta_Seconds__absolute_maximum      Total_timeDelta_Seconds__absolute_maximum   \n",
      "Total_timeDelta_Seconds__mean                              Total_timeDelta_Seconds__mean   \n",
      "Total_timeDelta_Seconds__root_mean_square      Total_timeDelta_Seconds__root_mean_square   \n",
      "Total_timeDelta_Seconds__standard_deviation  Total_timeDelta_Seconds__standard_deviation   \n",
      "Total_timeDelta_Seconds__variance                      Total_timeDelta_Seconds__variance   \n",
      "\n",
      "                                             type       p_value  relevant  \n",
      "feature                                                                    \n",
      "DaysInMilk__minimum                          real  6.751071e-04      True  \n",
      "Total_MilkProduction__minimum                real  6.060921e-04      True  \n",
      "Total_timeDelta_Seconds__minimum             real  4.998369e-06      True  \n",
      "Total_MilkProduction__standard_deviation     real  1.855204e-06      True  \n",
      "Total_MilkProduction__variance               real  1.855204e-06      True  \n",
      "Total_MilkProduction__maximum                real  7.292131e-07      True  \n",
      "Total_MilkProduction__absolute_maximum       real  7.292131e-07      True  \n",
      "Total_MilkProduction__mean                   real  1.193526e-07      True  \n",
      "Total_MilkProduction__root_mean_square       real  1.193526e-07      True  \n",
      "Total_MilkProduction__median                 real  1.192393e-07      True  \n",
      "Total_timeDelta_Seconds__median              real  7.878592e-10      True  \n",
      "Total_timeDelta_Seconds__sum_values          real  4.588514e-10      True  \n",
      "Total_timeDelta_Seconds__maximum             real  3.491677e-10      True  \n",
      "Total_timeDelta_Seconds__absolute_maximum    real  3.491677e-10      True  \n",
      "Total_timeDelta_Seconds__mean                real  1.833197e-10      True  \n",
      "Total_timeDelta_Seconds__root_mean_square    real  1.670671e-10      True  \n",
      "Total_timeDelta_Seconds__standard_deviation  real  1.670671e-10      True  \n",
      "Total_timeDelta_Seconds__variance            real  1.670671e-10      True  \n"
     ]
    }
   ],
   "source": [
    "#Original\n",
    "settings_1 = MinimalFCParameters() \n",
    "#settings_2 = ComprehensiveFCParameters\n",
    "\n",
    "for i, col in enumerate(timeSeries_cols):\n",
    "    ts_processed = pd.DataFrame(cow_total[col].copy())\n",
    "    ts_processed.index = range(0,len(ts_processed)) \n",
    "    ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "    \n",
    "    print(ts_processed.shape)\n",
    "    \n",
    "    #print(ts_processed[ts_processed['id'] == 122])\n",
    "    # extract time series features\n",
    "    extracted_features = extract_features(ts_processed, column_id=\"id\", column_sort=\"MilkingDate\", default_fc_parameters=settings_1)\n",
    "    #extracted_features.dropna(axis=1, inplace=True)\n",
    "    impute(extracted_features)\n",
    "\n",
    "    # calculate_relevance_table method is sensitive to the index of the rows.\n",
    "    # The following two lines are to align the indices. \n",
    "    \n",
    "    #extracted_features.reset_index(drop=True, inplace=True)\n",
    "    #y.reset_index(drop=True, inplace=True)\n",
    "    extracted_features.index = range(1, len(extracted_features)+1)\n",
    "    y.index = range(1, len(y)+1)\n",
    "    #print(extracted_features)\n",
    "    #print(y)\n",
    "    \n",
    "    # select most relevant features based on relevance table\n",
    "    if i == 0:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = temp\n",
    "    else:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = pd.concat([relevance_table, temp], axis=0)\n",
    "    features_filtered = select_features(extracted_features, y)\n",
    "    ts_extracted_dataset = pd.concat([ts_extracted_dataset, features_filtered], axis=1)\n",
    "\n",
    "# Select relevant features from the relevance table\n",
    "relevance_table = relevance_table[relevance_table.relevant]\n",
    "relevance_table.sort_values(\"p_value\", ascending=False, inplace=True)\n",
    "relevant_features_list = list(relevance_table.feature[:])\n",
    "print(relevance_table)\n",
    "\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset[relevant_features_list].copy()\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset_filtered.loc[:,~ts_extracted_dataset_filtered.columns.duplicated()]\n",
    "ts_extracted_dataset = ts_extracted_dataset_filtered\n",
    "ts_extracted_dataset\n",
    "ts_extracted_dataset.to_csv(dataDir+\"problematic_cows_7200s_5percent_extracted_features.csv\", index=False)\n",
    "relevance_table.to_csv(dataDir+\"problematic_cows_7200s_5percent_relevance_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f7621dc3-75b5-4db0-99ad-1a9a52619e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DaysInMilk__minimum</th>\n",
       "      <th>Total_MilkProduction__minimum</th>\n",
       "      <th>Total_timeDelta_Seconds__minimum</th>\n",
       "      <th>Total_MilkProduction__standard_deviation</th>\n",
       "      <th>Total_MilkProduction__variance</th>\n",
       "      <th>Total_MilkProduction__maximum</th>\n",
       "      <th>Total_MilkProduction__absolute_maximum</th>\n",
       "      <th>Total_MilkProduction__mean</th>\n",
       "      <th>Total_MilkProduction__root_mean_square</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_timeDelta_Seconds__median</th>\n",
       "      <th>Total_timeDelta_Seconds__sum_values</th>\n",
       "      <th>Total_timeDelta_Seconds__maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__absolute_maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.685839</td>\n",
       "      <td>0.165269</td>\n",
       "      <td>-0.521733</td>\n",
       "      <td>-0.837265</td>\n",
       "      <td>-0.763411</td>\n",
       "      <td>-0.908247</td>\n",
       "      <td>-0.908247</td>\n",
       "      <td>-0.566546</td>\n",
       "      <td>-0.602763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124254</td>\n",
       "      <td>0.381972</td>\n",
       "      <td>2.252784</td>\n",
       "      <td>2.252784</td>\n",
       "      <td>0.355866</td>\n",
       "      <td>1.046242</td>\n",
       "      <td>1.386496</td>\n",
       "      <td>1.198740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.194020</td>\n",
       "      <td>-0.038806</td>\n",
       "      <td>-0.322247</td>\n",
       "      <td>0.055227</td>\n",
       "      <td>-0.068564</td>\n",
       "      <td>0.375830</td>\n",
       "      <td>0.375830</td>\n",
       "      <td>-1.280244</td>\n",
       "      <td>-1.183755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008906</td>\n",
       "      <td>-0.804706</td>\n",
       "      <td>-0.537218</td>\n",
       "      <td>-0.537218</td>\n",
       "      <td>-0.038740</td>\n",
       "      <td>-0.208271</td>\n",
       "      <td>-0.306065</td>\n",
       "      <td>-0.425525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.294791</td>\n",
       "      <td>-0.365326</td>\n",
       "      <td>-0.521733</td>\n",
       "      <td>-0.171042</td>\n",
       "      <td>-0.262358</td>\n",
       "      <td>-0.365543</td>\n",
       "      <td>-0.365543</td>\n",
       "      <td>0.298177</td>\n",
       "      <td>0.261887</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594191</td>\n",
       "      <td>-0.937749</td>\n",
       "      <td>-0.794521</td>\n",
       "      <td>-0.794521</td>\n",
       "      <td>-0.797193</td>\n",
       "      <td>-0.862663</td>\n",
       "      <td>-0.882891</td>\n",
       "      <td>-0.679332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.096258</td>\n",
       "      <td>-0.569401</td>\n",
       "      <td>2.071586</td>\n",
       "      <td>2.981805</td>\n",
       "      <td>3.517261</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.902324</td>\n",
       "      <td>1.133085</td>\n",
       "      <td>...</td>\n",
       "      <td>1.753358</td>\n",
       "      <td>1.153392</td>\n",
       "      <td>2.119293</td>\n",
       "      <td>2.119293</td>\n",
       "      <td>1.915834</td>\n",
       "      <td>1.939362</td>\n",
       "      <td>1.938694</td>\n",
       "      <td>2.012487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>1.076888</td>\n",
       "      <td>-0.765312</td>\n",
       "      <td>-0.521733</td>\n",
       "      <td>0.769316</td>\n",
       "      <td>0.621581</td>\n",
       "      <td>-0.038466</td>\n",
       "      <td>-0.038466</td>\n",
       "      <td>-0.470113</td>\n",
       "      <td>-0.366254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366699</td>\n",
       "      <td>-0.570786</td>\n",
       "      <td>-1.028904</td>\n",
       "      <td>-1.028904</td>\n",
       "      <td>-0.633366</td>\n",
       "      <td>-0.809517</td>\n",
       "      <td>-0.905057</td>\n",
       "      <td>-0.686045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>133</td>\n",
       "      <td>0.588077</td>\n",
       "      <td>0.197921</td>\n",
       "      <td>-0.322247</td>\n",
       "      <td>-0.180971</td>\n",
       "      <td>-0.270587</td>\n",
       "      <td>-0.426112</td>\n",
       "      <td>-0.426112</td>\n",
       "      <td>-0.521800</td>\n",
       "      <td>-0.507636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.603269</td>\n",
       "      <td>-0.463927</td>\n",
       "      <td>-0.793782</td>\n",
       "      <td>-0.793782</td>\n",
       "      <td>-0.790689</td>\n",
       "      <td>-0.849234</td>\n",
       "      <td>-0.865585</td>\n",
       "      <td>-0.673935</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>135</td>\n",
       "      <td>-0.487307</td>\n",
       "      <td>-0.275533</td>\n",
       "      <td>-0.521733</td>\n",
       "      <td>-0.820631</td>\n",
       "      <td>-0.752165</td>\n",
       "      <td>-0.510910</td>\n",
       "      <td>-0.510910</td>\n",
       "      <td>-0.408791</td>\n",
       "      <td>-0.452658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.702063</td>\n",
       "      <td>-0.563695</td>\n",
       "      <td>-0.603224</td>\n",
       "      <td>-0.603224</td>\n",
       "      <td>-0.748090</td>\n",
       "      <td>-0.730043</td>\n",
       "      <td>-0.706002</td>\n",
       "      <td>-0.617699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>137</td>\n",
       "      <td>-0.194020</td>\n",
       "      <td>2.344790</td>\n",
       "      <td>3.667474</td>\n",
       "      <td>1.213163</td>\n",
       "      <td>1.110660</td>\n",
       "      <td>0.996064</td>\n",
       "      <td>0.996064</td>\n",
       "      <td>1.799378</td>\n",
       "      <td>1.781163</td>\n",
       "      <td>...</td>\n",
       "      <td>3.602133</td>\n",
       "      <td>1.090760</td>\n",
       "      <td>2.421026</td>\n",
       "      <td>2.421026</td>\n",
       "      <td>2.852420</td>\n",
       "      <td>2.396418</td>\n",
       "      <td>2.054625</td>\n",
       "      <td>2.201066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>138</td>\n",
       "      <td>2.934369</td>\n",
       "      <td>-0.169414</td>\n",
       "      <td>0.276211</td>\n",
       "      <td>-0.585067</td>\n",
       "      <td>-0.585951</td>\n",
       "      <td>-0.438226</td>\n",
       "      <td>-0.438226</td>\n",
       "      <td>-1.117510</td>\n",
       "      <td>-1.098553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386458</td>\n",
       "      <td>-1.129364</td>\n",
       "      <td>-0.771332</td>\n",
       "      <td>-0.771332</td>\n",
       "      <td>-0.614128</td>\n",
       "      <td>-0.745387</td>\n",
       "      <td>-0.809080</td>\n",
       "      <td>-0.655357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>139</td>\n",
       "      <td>-0.585069</td>\n",
       "      <td>-0.479608</td>\n",
       "      <td>-0.721219</td>\n",
       "      <td>-0.457952</td>\n",
       "      <td>-0.490867</td>\n",
       "      <td>0.034217</td>\n",
       "      <td>0.034217</td>\n",
       "      <td>-0.168367</td>\n",
       "      <td>-0.199178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408886</td>\n",
       "      <td>0.107558</td>\n",
       "      <td>-0.463617</td>\n",
       "      <td>-0.463617</td>\n",
       "      <td>-0.195015</td>\n",
       "      <td>-0.227937</td>\n",
       "      <td>-0.236016</td>\n",
       "      <td>-0.384328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  DaysInMilk__minimum  Total_MilkProduction__minimum  \\\n",
       "1     2             0.685839                       0.165269   \n",
       "2     6            -0.194020                      -0.038806   \n",
       "3     7             0.294791                      -0.365326   \n",
       "4     8            -0.096258                      -0.569401   \n",
       "5    10             1.076888                      -0.765312   \n",
       "..  ...                  ...                            ...   \n",
       "61  133             0.588077                       0.197921   \n",
       "62  135            -0.487307                      -0.275533   \n",
       "63  137            -0.194020                       2.344790   \n",
       "64  138             2.934369                      -0.169414   \n",
       "65  139            -0.585069                      -0.479608   \n",
       "\n",
       "    Total_timeDelta_Seconds__minimum  \\\n",
       "1                          -0.521733   \n",
       "2                          -0.322247   \n",
       "3                          -0.521733   \n",
       "4                           2.071586   \n",
       "5                          -0.521733   \n",
       "..                               ...   \n",
       "61                         -0.322247   \n",
       "62                         -0.521733   \n",
       "63                          3.667474   \n",
       "64                          0.276211   \n",
       "65                         -0.721219   \n",
       "\n",
       "    Total_MilkProduction__standard_deviation  Total_MilkProduction__variance  \\\n",
       "1                                  -0.837265                       -0.763411   \n",
       "2                                   0.055227                       -0.068564   \n",
       "3                                  -0.171042                       -0.262358   \n",
       "4                                   2.981805                        3.517261   \n",
       "5                                   0.769316                        0.621581   \n",
       "..                                       ...                             ...   \n",
       "61                                 -0.180971                       -0.270587   \n",
       "62                                 -0.820631                       -0.752165   \n",
       "63                                  1.213163                        1.110660   \n",
       "64                                 -0.585067                       -0.585951   \n",
       "65                                 -0.457952                       -0.490867   \n",
       "\n",
       "    Total_MilkProduction__maximum  Total_MilkProduction__absolute_maximum  \\\n",
       "1                       -0.908247                               -0.908247   \n",
       "2                        0.375830                                0.375830   \n",
       "3                       -0.365543                               -0.365543   \n",
       "4                        0.976682                                0.976682   \n",
       "5                       -0.038466                               -0.038466   \n",
       "..                            ...                                     ...   \n",
       "61                      -0.426112                               -0.426112   \n",
       "62                      -0.510910                               -0.510910   \n",
       "63                       0.996064                                0.996064   \n",
       "64                      -0.438226                               -0.438226   \n",
       "65                       0.034217                                0.034217   \n",
       "\n",
       "    Total_MilkProduction__mean  Total_MilkProduction__root_mean_square  ...  \\\n",
       "1                    -0.566546                               -0.602763  ...   \n",
       "2                    -1.280244                               -1.183755  ...   \n",
       "3                     0.298177                                0.261887  ...   \n",
       "4                     0.902324                                1.133085  ...   \n",
       "5                    -0.470113                               -0.366254  ...   \n",
       "..                         ...                                     ...  ...   \n",
       "61                   -0.521800                               -0.507636  ...   \n",
       "62                   -0.408791                               -0.452658  ...   \n",
       "63                    1.799378                                1.781163  ...   \n",
       "64                   -1.117510                               -1.098553  ...   \n",
       "65                   -0.168367                               -0.199178  ...   \n",
       "\n",
       "    Total_timeDelta_Seconds__median  Total_timeDelta_Seconds__sum_values  \\\n",
       "1                         -0.124254                             0.381972   \n",
       "2                         -0.008906                            -0.804706   \n",
       "3                         -0.594191                            -0.937749   \n",
       "4                          1.753358                             1.153392   \n",
       "5                         -0.366699                            -0.570786   \n",
       "..                              ...                                  ...   \n",
       "61                        -0.603269                            -0.463927   \n",
       "62                        -0.702063                            -0.563695   \n",
       "63                         3.602133                             1.090760   \n",
       "64                        -0.386458                            -1.129364   \n",
       "65                        -0.408886                             0.107558   \n",
       "\n",
       "    Total_timeDelta_Seconds__maximum  \\\n",
       "1                           2.252784   \n",
       "2                          -0.537218   \n",
       "3                          -0.794521   \n",
       "4                           2.119293   \n",
       "5                          -1.028904   \n",
       "..                               ...   \n",
       "61                         -0.793782   \n",
       "62                         -0.603224   \n",
       "63                          2.421026   \n",
       "64                         -0.771332   \n",
       "65                         -0.463617   \n",
       "\n",
       "    Total_timeDelta_Seconds__absolute_maximum  Total_timeDelta_Seconds__mean  \\\n",
       "1                                    2.252784                       0.355866   \n",
       "2                                   -0.537218                      -0.038740   \n",
       "3                                   -0.794521                      -0.797193   \n",
       "4                                    2.119293                       1.915834   \n",
       "5                                   -1.028904                      -0.633366   \n",
       "..                                        ...                            ...   \n",
       "61                                  -0.793782                      -0.790689   \n",
       "62                                  -0.603224                      -0.748090   \n",
       "63                                   2.421026                       2.852420   \n",
       "64                                  -0.771332                      -0.614128   \n",
       "65                                  -0.463617                      -0.195015   \n",
       "\n",
       "    Total_timeDelta_Seconds__root_mean_square  \\\n",
       "1                                    1.046242   \n",
       "2                                   -0.208271   \n",
       "3                                   -0.862663   \n",
       "4                                    1.939362   \n",
       "5                                   -0.809517   \n",
       "..                                        ...   \n",
       "61                                  -0.849234   \n",
       "62                                  -0.730043   \n",
       "63                                   2.396418   \n",
       "64                                  -0.745387   \n",
       "65                                  -0.227937   \n",
       "\n",
       "    Total_timeDelta_Seconds__standard_deviation  \\\n",
       "1                                      1.386496   \n",
       "2                                     -0.306065   \n",
       "3                                     -0.882891   \n",
       "4                                      1.938694   \n",
       "5                                     -0.905057   \n",
       "..                                          ...   \n",
       "61                                    -0.865585   \n",
       "62                                    -0.706002   \n",
       "63                                     2.054625   \n",
       "64                                    -0.809080   \n",
       "65                                    -0.236016   \n",
       "\n",
       "    Total_timeDelta_Seconds__variance  BreedName_2  problematic  \n",
       "1                            1.198740          1.0            1  \n",
       "2                           -0.425525          1.0            0  \n",
       "3                           -0.679332          1.0            0  \n",
       "4                            2.012487          1.0            1  \n",
       "5                           -0.686045          1.0            0  \n",
       "..                                ...          ...          ...  \n",
       "61                          -0.673935          1.0            0  \n",
       "62                          -0.617699          1.0            0  \n",
       "63                           2.201066          1.0            1  \n",
       "64                          -0.655357          1.0            0  \n",
       "65                          -0.384328          1.0            0  \n",
       "\n",
       "[65 rows x 21 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original\n",
    "# Construct extracted training data\n",
    "ts_extracted_id = cow_total[['id']].copy()\n",
    "ts_extracted_id.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_id.index = range(1, len(ts_extracted_id)+1)\n",
    "ts_extracted_dataset = pd.concat([ts_extracted_id, ts_extracted_dataset], axis=1)\n",
    "#print(ts_extracted_dataset)\n",
    "ts_extracted_features = ts_extracted_dataset.iloc[:, 1:len(ts_extracted_dataset.columns)].copy()\n",
    "#print(ts_extracted_features)\n",
    "#ts_extracted_features\n",
    "\n",
    "# normalize numerical features\n",
    "ts_extracted_cols = ts_extracted_features.columns\n",
    "scaler_std = StandardScaler()\n",
    "ts_std = scaler_std.fit_transform(ts_extracted_features)\n",
    "# transform standard data into dataframe\n",
    "ts_extracted_processed = pd.DataFrame(ts_std, columns=ts_extracted_cols)\n",
    "ts_extracted_processed.index = range(1,len(ts_extracted_processed)+1)\n",
    "# append id col to the dataframe\n",
    "ts_extracted_processed = pd.concat([ts_extracted_dataset['id'], ts_extracted_processed], axis=1)\n",
    "\n",
    "# One-Hot encoding categorical feature - BreedName\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "\n",
    "cow_breed = cow_total[['id', 'BreedName']].copy()\n",
    "cow_breed.drop_duplicates(subset=['id'], inplace=True)\n",
    "cat = ohe.fit_transform(np.array(cow_breed['BreedName']).reshape(-1, 1))\n",
    "col_names = ohe.get_feature_names_out(['BreedName'])\n",
    "cat_breed = pd.DataFrame(cat, columns=col_names)\n",
    "cat_breed.index = range(1,len(cow_breed)+1)\n",
    "\n",
    "# append features on extracted dataset\n",
    "ts_dataset = pd.concat([ts_extracted_processed, cat_breed], axis=1)\n",
    "ts_dataset = pd.concat([ts_dataset, y], axis=1)\n",
    "ts_dataset.to_csv(dataDir+\"problematic_100cows_7200s_5percent_features.csv\", index=False)\n",
    "ts_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "65c049f4-c9d5-4cf5-8ecf-f65f5e7e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation on Gaussian Process Classifier\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, Matern, RationalQuadratic, WhiteKernel, ExpSineSquared\n",
    "grid = dict()\n",
    "grid['kernel'] = [1*RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)), \n",
    "                  1*DotProduct(), 1*Matern(),  1*RationalQuadratic(),\n",
    "                  1*Matern()+1*WhiteKernel(noise_level=0.5),\n",
    "                  1*ExpSineSquared(),\n",
    "                  1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0, length_scale_bounds=(0.1, 10.0), periodicity_bounds=(1.0, 10.0)),\n",
    "                  1*Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)+1*WhiteKernel(noise_level=0.5),\n",
    "                ]\n",
    "\n",
    "\n",
    "#dataDir = Path.cwd().parent.parent/'Data/processed'\n",
    "#id used as index\n",
    "#ts_dataset = pd.read_csv(dataDir/'Problematic_targetCows/problematic_100cows_7200s_5percent_features.csv', index_col='id')\n",
    "\n",
    "#use id as normal column\n",
    "#ts_dataset = pd.read_csv(dataDir+'Problematic_targetCows/problematic_100cows_7200s_5percent_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f6da5b4f-a365-4ccf-8202-4fca2114d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cow_dataset = pd.DataFrame()\n",
    "\n",
    "train_cow_dataset = ts_dataset[~ts_dataset['id'].isin(test_cow_list)]\n",
    "\n",
    "train_cow_list = train_cow_dataset['id'].unique()\n",
    "\n",
    "#print(len(train_cow_list))\n",
    "#print(train_cow_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "caf3ba49-8aeb-492b-a3c5-15526f6363aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.DataFrame(train_cow_dataset['problematic'], columns=['problematic'])\n",
    "train_data = train_cow_dataset.drop('problematic', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "eca48f91-10a1-4202-83b4-12856a3e1cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DaysInMilk__minimum</th>\n",
       "      <th>Total_MilkProduction__minimum</th>\n",
       "      <th>Total_timeDelta_Seconds__minimum</th>\n",
       "      <th>Total_MilkProduction__standard_deviation</th>\n",
       "      <th>Total_MilkProduction__variance</th>\n",
       "      <th>Total_MilkProduction__maximum</th>\n",
       "      <th>Total_MilkProduction__absolute_maximum</th>\n",
       "      <th>Total_MilkProduction__mean</th>\n",
       "      <th>Total_MilkProduction__root_mean_square</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_timeDelta_Seconds__median</th>\n",
       "      <th>Total_timeDelta_Seconds__sum_values</th>\n",
       "      <th>Total_timeDelta_Seconds__maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__absolute_maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>0.197028</td>\n",
       "      <td>1.789706</td>\n",
       "      <td>4.066446</td>\n",
       "      <td>1.399914</td>\n",
       "      <td>1.330218</td>\n",
       "      <td>1.046943</td>\n",
       "      <td>1.046943</td>\n",
       "      <td>1.858890</td>\n",
       "      <td>1.852222</td>\n",
       "      <td>...</td>\n",
       "      <td>2.020368</td>\n",
       "      <td>0.046429</td>\n",
       "      <td>2.231544</td>\n",
       "      <td>2.231544</td>\n",
       "      <td>2.356573</td>\n",
       "      <td>2.773331</td>\n",
       "      <td>2.992385</td>\n",
       "      <td>3.952721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>0.197028</td>\n",
       "      <td>1.789706</td>\n",
       "      <td>4.066446</td>\n",
       "      <td>1.399914</td>\n",
       "      <td>1.330218</td>\n",
       "      <td>1.046943</td>\n",
       "      <td>1.046943</td>\n",
       "      <td>1.858890</td>\n",
       "      <td>1.852222</td>\n",
       "      <td>...</td>\n",
       "      <td>2.020368</td>\n",
       "      <td>0.046429</td>\n",
       "      <td>2.231544</td>\n",
       "      <td>2.231544</td>\n",
       "      <td>2.356573</td>\n",
       "      <td>2.773331</td>\n",
       "      <td>2.992385</td>\n",
       "      <td>3.952721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>1.663461</td>\n",
       "      <td>0.940754</td>\n",
       "      <td>-0.521733</td>\n",
       "      <td>0.068595</td>\n",
       "      <td>-0.056740</td>\n",
       "      <td>0.504238</td>\n",
       "      <td>0.504238</td>\n",
       "      <td>0.319505</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518360</td>\n",
       "      <td>-1.071989</td>\n",
       "      <td>-0.378790</td>\n",
       "      <td>-0.378790</td>\n",
       "      <td>-0.519639</td>\n",
       "      <td>-0.472187</td>\n",
       "      <td>-0.433532</td>\n",
       "      <td>-0.494727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>-0.585069</td>\n",
       "      <td>0.573419</td>\n",
       "      <td>0.076725</td>\n",
       "      <td>-1.072122</td>\n",
       "      <td>-0.915289</td>\n",
       "      <td>-1.041501</td>\n",
       "      <td>-1.041501</td>\n",
       "      <td>-0.460106</td>\n",
       "      <td>-0.518530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414761</td>\n",
       "      <td>-0.808893</td>\n",
       "      <td>0.074044</td>\n",
       "      <td>0.074044</td>\n",
       "      <td>-0.221077</td>\n",
       "      <td>-0.134086</td>\n",
       "      <td>-0.075925</td>\n",
       "      <td>-0.281737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>0.588077</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.076725</td>\n",
       "      <td>-0.292699</td>\n",
       "      <td>-0.361603</td>\n",
       "      <td>-0.409153</td>\n",
       "      <td>-0.409153</td>\n",
       "      <td>0.845342</td>\n",
       "      <td>0.770422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259172</td>\n",
       "      <td>-1.102411</td>\n",
       "      <td>-0.525792</td>\n",
       "      <td>-0.525792</td>\n",
       "      <td>0.126612</td>\n",
       "      <td>-0.017261</td>\n",
       "      <td>-0.099647</td>\n",
       "      <td>-0.297680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  DaysInMilk__minimum  Total_MilkProduction__minimum  \\\n",
       "0   87             0.197028                       1.789706   \n",
       "1   87             0.197028                       1.789706   \n",
       "2  114             1.663461                       0.940754   \n",
       "3  101            -0.585069                       0.573419   \n",
       "4   61             0.588077                       0.050987   \n",
       "\n",
       "   Total_timeDelta_Seconds__minimum  Total_MilkProduction__standard_deviation  \\\n",
       "0                          4.066446                                  1.399914   \n",
       "1                          4.066446                                  1.399914   \n",
       "2                         -0.521733                                  0.068595   \n",
       "3                          0.076725                                 -1.072122   \n",
       "4                          0.076725                                 -0.292699   \n",
       "\n",
       "   Total_MilkProduction__variance  Total_MilkProduction__maximum  \\\n",
       "0                        1.330218                       1.046943   \n",
       "1                        1.330218                       1.046943   \n",
       "2                       -0.056740                       0.504238   \n",
       "3                       -0.915289                      -1.041501   \n",
       "4                       -0.361603                      -0.409153   \n",
       "\n",
       "   Total_MilkProduction__absolute_maximum  Total_MilkProduction__mean  \\\n",
       "0                                1.046943                    1.858890   \n",
       "1                                1.046943                    1.858890   \n",
       "2                                0.504238                    0.319505   \n",
       "3                               -1.041501                   -0.460106   \n",
       "4                               -0.409153                    0.845342   \n",
       "\n",
       "   Total_MilkProduction__root_mean_square  ...  \\\n",
       "0                                1.852222  ...   \n",
       "1                                1.852222  ...   \n",
       "2                                0.300522  ...   \n",
       "3                               -0.518530  ...   \n",
       "4                                0.770422  ...   \n",
       "\n",
       "   Total_timeDelta_Seconds__median  Total_timeDelta_Seconds__sum_values  \\\n",
       "0                         2.020368                             0.046429   \n",
       "1                         2.020368                             0.046429   \n",
       "2                        -0.518360                            -1.071989   \n",
       "3                        -0.414761                            -0.808893   \n",
       "4                         0.259172                            -1.102411   \n",
       "\n",
       "   Total_timeDelta_Seconds__maximum  \\\n",
       "0                          2.231544   \n",
       "1                          2.231544   \n",
       "2                         -0.378790   \n",
       "3                          0.074044   \n",
       "4                         -0.525792   \n",
       "\n",
       "   Total_timeDelta_Seconds__absolute_maximum  Total_timeDelta_Seconds__mean  \\\n",
       "0                                   2.231544                       2.356573   \n",
       "1                                   2.231544                       2.356573   \n",
       "2                                  -0.378790                      -0.519639   \n",
       "3                                   0.074044                      -0.221077   \n",
       "4                                  -0.525792                       0.126612   \n",
       "\n",
       "   Total_timeDelta_Seconds__root_mean_square  \\\n",
       "0                                   2.773331   \n",
       "1                                   2.773331   \n",
       "2                                  -0.472187   \n",
       "3                                  -0.134086   \n",
       "4                                  -0.017261   \n",
       "\n",
       "   Total_timeDelta_Seconds__standard_deviation  \\\n",
       "0                                     2.992385   \n",
       "1                                     2.992385   \n",
       "2                                    -0.433532   \n",
       "3                                    -0.075925   \n",
       "4                                    -0.099647   \n",
       "\n",
       "   Total_timeDelta_Seconds__variance  BreedName_2  problematic  \n",
       "0                           3.952721          1.0            1  \n",
       "1                           3.952721          1.0            1  \n",
       "2                          -0.494727          1.0            0  \n",
       "3                          -0.281737          1.0            0  \n",
       "4                          -0.297680          1.0            0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cow_dataset = pd.DataFrame()\n",
    "\n",
    "for tc in test_cow_list:\n",
    "    test_data = ts_dataset[ts_dataset['id'] == tc]\n",
    "    frames = [test_cow_dataset, test_data]\n",
    "    test_cow_dataset = pd.concat(frames, ignore_index=True)\n",
    "    \n",
    "test_cow_dataset\n",
    "#test_cow_dataset.to_csv(dataDir+\"test_cow_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "44e23afb-169a-4b3a-949f-f590c68f8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.DataFrame(test_cow_dataset['problematic'], columns=['problematic'])\n",
    "test_data = test_cow_dataset.drop('problematic', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c528233d-dc85-4217-876a-fe7e70c285be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py:472: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py:472: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py:472: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py:472: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 40-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 38-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 33-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 41-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 36-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 42-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 37-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 44-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 39-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 35-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 48-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 3-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 46-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 34-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 32-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 43-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 47-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.92666667 0.99666667 0.88794872 0.98       0.8074359         nan\n",
      "        nan 0.84897436]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.9966666666666666\n",
      "Best estimator parameters:  {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.927 with: {'kernel': 1**2 * RBF(length_scale=1)}\n",
      "Accuracy 0.997 with: {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.888 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      "Accuracy 0.980 with: {'kernel': 1**2 * RationalQuadratic(alpha=1, length_scale=1)}\n",
      "Accuracy 0.807 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=1)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=3)}\n",
      "Accuracy 0.849 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n"
     ]
    }
   ],
   "source": [
    "#%%capture --no-stderr\n",
    "#%%capture --no-display\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_labels, test_labels\n",
    "\n",
    "model = GaussianProcessClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=5)\n",
    "# exhausive search over different kernels\n",
    "search = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# fit model into the dataset\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", result.best_score_)\n",
    "print(\"Best estimator parameters: \", result.best_params_)\n",
    "\n",
    "means = result.cv_results_['mean_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"Accuracy %.3f with: %r\" % (mean, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8b4a4de1-86d4-4489-be2f-6ccec8061d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 1**2 * DotProduct(sigma_0=1)}"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6de6e667-a6a3-4067-a2a8-8baaf1763601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              3\n",
       "1              2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "abddfa0d-f554-4c49-a721-704861548ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              42\n",
       "1              19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "78291d70-c611-4ff8-a397-e4afb82711be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training data:  1.0\n",
      "Prediction on test data:  [1 1 0 0 0]\n",
      "True values of test data:  [1, 1, 0, 0, 0]\n",
      "Prediction accuracy on test data:  1.0\n"
     ]
    }
   ],
   "source": [
    "best_kernel = 1**2 * DotProduct(sigma_0=1)\n",
    "#best_kernel = 1**2 * RationalQuadratic(alpha=1, length_scale=1)\n",
    "#best_kernel = 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)\n",
    "# best_kernel = 1**2 * Matern(length_scale=1, nu=1.5)\n",
    "#best_kernel = 1**2 * RBF(length_scale=1)\n",
    "model = GaussianProcessClassifier(kernel=best_kernel, random_state=30, n_jobs=-1)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model.score(X_train, y_train))\n",
    "\n",
    "# My guess is to look at what we have in X_test dataset and see if I can reduce the number of days.\n",
    "# The challenge is how do we ensure that the number of days we have found for correct prediction will always \n",
    "# be the correct one? \n",
    "\n",
    "print(\"Prediction on test data: \", model.predict(X_test))\n",
    "print(\"True values of test data: \", y_test['problematic'].tolist())\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"Prediction accuracy on test data: \", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "1ab5b6fe-3c2e-43fc-88af-5af744ba93ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08505514, 0.91494486],\n",
       "       [0.08505514, 0.91494486],\n",
       "       [0.76275218, 0.23724782],\n",
       "       [0.79884644, 0.20115356],\n",
       "       [0.73229369, 0.26770631]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_list = model.predict_proba(X_test)\n",
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ae0a5d15-268c-4a11-9d9f-faa6c891a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "cow_id = X_test.index.copy()\n",
    "cow_id = cow_id.astype(str)\n",
    "\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "facecolor = '#eaeaf2'\n",
    "color_red = '#f44336'\n",
    "color_blue = '#4496df'\n",
    "index = cow_id\n",
    "column0 = prob_list[:, 0]\n",
    "column1 = prob_list[:, 1]\n",
    "title0 = 'Problematic Cows, test set'\n",
    "title1 = 'Normal Cows, test set'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5), facecolor=facecolor, ncols=2, sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0].barh(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes[0].set_title(title0, fontsize=18, pad=15, color=color_red, **hfont)\n",
    "axes[1].barh(index, column1, align='center', color=color_blue, zorder=10)\n",
    "axes[1].set_title(title1, fontsize=18, pad=15, color=color_blue, **hfont)\n",
    "\n",
    "# If you have positive numbers and want to invert the x-axis of the left plot\n",
    "axes[0].invert_xaxis() \n",
    "\n",
    "# To show data from highest to lowest\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "axes[0].set(yticks=cow_id, yticklabels=cow_id)\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[0].tick_params(axis='y', colors='black') # tick color\n",
    "\n",
    "axes[0].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[0].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "for label in (axes[0].get_xticklabels() + axes[0].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "for label in (axes[1].get_xticklabels() + axes[1].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, top=0.85, bottom=0.1, left=0.18, right=0.95)\n",
    "filename = 'Problematic_Cows'\n",
    "plt.savefig(filename+'.png', facecolor=facecolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "5b35c659-e272-4de7-9c88-68deee33fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# Total_timeDelta_Seconds__minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "25d87e85-9998-4bf1-bbff-622b6174bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [480], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Plot decision boundary with uncertainty\u001b[39;00m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m---> 18\u001b[0m x_min, x_max \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m y_min, y_max \u001b[38;5;241m=\u001b[39m X[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39mlinspace(x_min, x_max, \u001b[38;5;241m100\u001b[39m),\n\u001b[1;32m     21\u001b[0m                      np\u001b[38;5;241m.\u001b[39mlinspace(y_min, y_max, \u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3810\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3810\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:5966\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5964\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5965\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5966\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = pd.DataFrame(ts_dataset['problematic'], columns=['problematic'])\n",
    "#X = pd.DataFrame(ts_dataset['Total_timeDelta_Seconds__minimum', 'Total_timeDelta_Seconds__root_mean_square'], columns=['Total_timeDelta_Seconds__minimum', 'Total_timeDelta_Seconds__root_mean_square'])\n",
    "\n",
    "X = pd.DataFrame(ts_dataset['Total_timeDelta_Seconds__minimum'], columns=['Total_timeDelta_Seconds__minimum'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the Gaussian Process model with an RBF kernel\n",
    "kernel = 1.0 * RBF(length_scale=1.0)\n",
    "gpc = GaussianProcessClassifier(kernel=kernel)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gpc.fit(X_train, y_train)\n",
    "\n",
    "# Plot decision boundary with uncertainty\n",
    "plt.figure(figsize=(10, 5))\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# Obtain predictions and uncertainties\n",
    "Z = gpc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "probs_mesh = gpc.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]  # Probability for class 1\n",
    "Z = Z.reshape(xx.shape)\n",
    "probs_mesh = probs_mesh.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundaries\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# Plot class probabilities as uncertainty\n",
    "plt.contourf(xx, yy, probs_mesh, cmap='RdYlBu', alpha=0.2)\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k')\n",
    "plt.title('Gaussian Process Classification with Uncertainty')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b89d5-1a20-4699-9c27-a83383e6918e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b17f1-6d3e-4567-b626-f2e78548914e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b08fc-5890-4205-9910-2501ef77cb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
