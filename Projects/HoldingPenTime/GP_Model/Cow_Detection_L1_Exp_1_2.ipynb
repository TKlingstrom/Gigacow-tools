{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "396af3cf-0117-4f47-a509-3261e5d8cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "pd.options.mode.chained_assignment = None\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, MinimalFCParameters\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85bb1b24-e295-47ea-b4e1-fda41010b4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>9.38</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>8.46</td>\n",
       "      <td>352.0</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>6.68</td>\n",
       "      <td>997.0</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>7.34</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>8.15</td>\n",
       "      <td>407.0</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95849</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.96</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95850</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.53</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95851</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>3.24</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95852</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>9.23</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95853</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95854 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "0            a624fb9a            2560                  9.38   \n",
       "1            a624fb9a            2560                  8.46   \n",
       "2            a624fb9a            2560                  6.68   \n",
       "3            a624fb9a            2560                  7.34   \n",
       "4            a624fb9a            2560                  8.15   \n",
       "...               ...             ...                   ...   \n",
       "95849        a624fb9a            2047                  7.96   \n",
       "95850        a624fb9a            2047                  5.53   \n",
       "95851        a624fb9a            2047                  3.24   \n",
       "95852        a624fb9a            2047                  9.23   \n",
       "95853        a624fb9a            2047                  7.42   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "0                       3176.0  2022-02-14              1.0         2.0   \n",
       "1                        352.0  2022-02-14              1.0         2.0   \n",
       "2                        997.0  2022-02-15              1.0         3.0   \n",
       "3                       9274.0  2022-02-15              1.0         3.0   \n",
       "4                        407.0  2022-02-16              1.0         4.0   \n",
       "...                        ...         ...              ...         ...   \n",
       "95849                     59.0  2022-11-12              1.0       322.0   \n",
       "95850                    148.0  2022-11-13              1.0       323.0   \n",
       "95851                    287.0  2022-11-13              1.0       323.0   \n",
       "95852                    240.0  2022-11-13              1.0       323.0   \n",
       "95853                     10.0  2022-11-14              1.0       324.0   \n",
       "\n",
       "       BreedName   Age  problematic   id  \n",
       "0              1  2.15            0    1  \n",
       "1              1  2.15            0    1  \n",
       "2              1  2.15            0    1  \n",
       "3              1  2.15            0    1  \n",
       "4              1  2.15            0    1  \n",
       "...          ...   ...          ...  ...  \n",
       "95849          1  3.02            0  142  \n",
       "95850          1  3.03            0  142  \n",
       "95851          1  3.03            0  142  \n",
       "95852          1  3.03            0  142  \n",
       "95853          1  3.03            0  142  \n",
       "\n",
       "[95854 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cows = pd.DataFrame()\n",
    "\n",
    "dataDir = '../../Data/processed/'\n",
    "total_cows = pd.read_csv(dataDir+'Cow_Prob_dataset_L1.csv')\n",
    "total_cows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c42e8a3-5fce-4f84-9e68-f3297bf92301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "[3, 5, 6, 7, 9, 15, 17, 18, 26, 28, 29, 30, 31, 34, 46, 51, 58, 61, 68, 70, 71, 72, 75, 76, 77, 79, 81, 87, 89, 90, 101, 107, 108, 109, 111, 115, 116, 119, 122, 126, 127, 132, 134, 138, 140] 45\n"
     ]
    }
   ],
   "source": [
    "# Select IDs from the total_cows\n",
    "test_cow_list = []\n",
    "ids = total_cows['id']\n",
    "\n",
    "unique_cow_ids = ids.unique()\n",
    "\n",
    "print(len(unique_cow_ids))\n",
    "# Select a few rows randomly\n",
    "num_of_selected_cows = 45\n",
    "\n",
    "#test_cow_list = [1]\n",
    "\n",
    "#test_cow_list = random.choices(unique_cow_ids, k=num_of_selected_cows)\n",
    "\n",
    "#test_cow_list.sort()\n",
    "\n",
    "test_cow_list = [3, 5, 6, 7, 9, 15, 17, 18, 26, 28, 29, 30, 31, 34, 46, 51, 58, 61, 68, 70, 71, 72, 75, 76, 77, 79, 81, 87, 89, 90, 101, 107, 108, 109, 111, 115, 116, 119, 122, 126, 127, 132, 134, 138, 140]\n",
    "print(test_cow_list, len(test_cow_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "471088dc-15b0-4be2-a527-8967a8de7801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65511</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.96</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65512</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.53</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65513</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>3.24</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65514</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>9.23</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65515</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "65511        a624fb9a            2047                  7.96   \n",
       "65512        a624fb9a            2047                  5.53   \n",
       "65513        a624fb9a            2047                  3.24   \n",
       "65514        a624fb9a            2047                  9.23   \n",
       "65515        a624fb9a            2047                  7.42   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "65511                     59.0  2022-11-12              1.0       322.0   \n",
       "65512                    148.0  2022-11-13              1.0       323.0   \n",
       "65513                    287.0  2022-11-13              1.0       323.0   \n",
       "65514                    240.0  2022-11-13              1.0       323.0   \n",
       "65515                     10.0  2022-11-14              1.0       324.0   \n",
       "\n",
       "       BreedName   Age  problematic   id  \n",
       "65511          1  3.02            0  142  \n",
       "65512          1  3.03            0  142  \n",
       "65513          1  3.03            0  142  \n",
       "65514          1  3.03            0  142  \n",
       "65515          1  3.03            0  142  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This new section sets the initial days limit for the test cows and \n",
    "# merge them back to the original list of cows so that TSFresh can extract\n",
    "# the features. \n",
    "\n",
    "modified_total_cows = total_cows\n",
    "\n",
    "# Modify this number to set the time series length. \n",
    "# For example, ts_length_test_data = 5 for the first five days. \n",
    "\n",
    "ts_length_test_data = 3\n",
    "\n",
    "for l in test_cow_list:\n",
    "    # Choose a specific duration\n",
    "    condition = modified_total_cows['id'] == l\n",
    "    test_cow = modified_total_cows[condition].copy()\n",
    "    test_cow = test_cow.reset_index()        \n",
    "    # print(test_cow)\n",
    "    if 'index' in test_cow:\n",
    "        test_cow = test_cow.drop('index', axis=1)\n",
    "        \n",
    "    modified_total_cows = modified_total_cows[~condition]\n",
    "            \n",
    "    test_cow['MilkingDate'] = pd.to_datetime(test_cow['MilkingDate'])\n",
    "    test_cow['MilkingDate'] = test_cow['MilkingDate'].dt.date\n",
    "            \n",
    "    start_date = test_cow['MilkingDate'][0]\n",
    "    #print('start_date: ',start_date)\n",
    "    end_date = pd.to_datetime(start_date + pd.DateOffset(days=ts_length_test_data)).date()\n",
    "    #print('end_date: ', end_date)\n",
    "    filtered_df = test_cow[(test_cow['MilkingDate'] >= start_date) & (test_cow['MilkingDate'] <= end_date)]   \n",
    "    \n",
    "    modified_total_cows = pd.concat([modified_total_cows, filtered_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "#modified_total_cows = modified_total_cows.drop('index', axis=1)\n",
    "#modified_total_cows = modified_total_cows.sort_values('id')\n",
    "modified_total_cows = modified_total_cows.sort_values(by=['id', 'MilkingDate'])\n",
    "\n",
    "modified_total_cows.to_csv(dataDir+\"upp.csv\", index=False)\n",
    "\n",
    "#modified_total_cows = modified_total_cows.reset_index()\n",
    "\n",
    "modified_total_cows.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25a586e8-e3cc-4b2d-b73c-a1e5d235b14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65823, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cow_total =  modified_total_cows\n",
    "cow_total.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "009c6a05-7081-436c-8d5e-bf0f1a184716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problematic\n",
      "0    97\n",
      "1    45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#original\n",
    "#df_static_features = cow_total[['FarmName_Pseudo']]\n",
    "static_cols = ['FarmName_Pseudo', 'TrafficDeviceName', 'LactationNumber', 'BreedName']\n",
    "timeSeries_cols = ['Age', 'Total_MilkProduction', 'Total_timeDelta_Seconds', 'DaysInMilk']\n",
    "output_col = ['problematic']\n",
    "\n",
    "cow_label = cow_total[['id', 'problematic']].copy()\n",
    "cow_timeseries = cow_total[['id', 'MilkingDate']].copy()\n",
    "cow_timeseries.index = range(len(cow_timeseries))\n",
    "# fetch y for feature extraction\n",
    "y = cow_label.drop_duplicates(subset=['id'])\n",
    "y = y[\"problematic\"]\n",
    "y.index = range(1,len(y)+1) \n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ba0c709-0d26-4e73-a0fc-8d0681161b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_extracted_dataset shape:  (65823, 1)\n",
      "ts_extracted_dataset shape:  (142, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>DaysInMilk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>2.15</td>\n",
       "      <td>9.38</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.46</td>\n",
       "      <td>352.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>6.68</td>\n",
       "      <td>997.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>7.34</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.15</td>\n",
       "      <td>407.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65818</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>3.02</td>\n",
       "      <td>7.96</td>\n",
       "      <td>59.0</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65819</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>3.03</td>\n",
       "      <td>5.53</td>\n",
       "      <td>148.0</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65820</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>3.03</td>\n",
       "      <td>3.24</td>\n",
       "      <td>287.0</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65821</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>3.03</td>\n",
       "      <td>9.23</td>\n",
       "      <td>240.0</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65822</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>3.03</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65823 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id MilkingDate   Age  Total_MilkProduction  Total_timeDelta_Seconds  \\\n",
       "0        1  2022-02-14  2.15                  9.38                   3176.0   \n",
       "1        1  2022-02-14  2.15                  8.46                    352.0   \n",
       "2        1  2022-02-15  2.15                  6.68                    997.0   \n",
       "3        1  2022-02-15  2.15                  7.34                   9274.0   \n",
       "4        1  2022-02-16  2.15                  8.15                    407.0   \n",
       "...    ...         ...   ...                   ...                      ...   \n",
       "65818  142  2022-11-12  3.02                  7.96                     59.0   \n",
       "65819  142  2022-11-13  3.03                  5.53                    148.0   \n",
       "65820  142  2022-11-13  3.03                  3.24                    287.0   \n",
       "65821  142  2022-11-13  3.03                  9.23                    240.0   \n",
       "65822  142  2022-11-14  3.03                  7.42                     10.0   \n",
       "\n",
       "       DaysInMilk  \n",
       "0             2.0  \n",
       "1             2.0  \n",
       "2             3.0  \n",
       "3             3.0  \n",
       "4             4.0  \n",
       "...           ...  \n",
       "65818       322.0  \n",
       "65819       323.0  \n",
       "65820       323.0  \n",
       "65821       323.0  \n",
       "65822       324.0  \n",
       "\n",
       "[65823 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "# Prepare datasert for Tsfresh extraction\n",
    "ts_extracted_dataset = cow_total[['id']].copy()\n",
    "print('ts_extracted_dataset shape: ', ts_extracted_dataset.shape)\n",
    "ts_extracted_dataset.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_dataset.index = range(1, len(ts_extracted_dataset)+1)\n",
    "print('ts_extracted_dataset shape: ',ts_extracted_dataset.shape)\n",
    "\n",
    "ts_processed = pd.DataFrame(cow_total[timeSeries_cols].copy())\n",
    "ts_processed.index = range(0,len(ts_processed)) \n",
    "\n",
    "ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "ts_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "833d7cef-efd5-40ca-b8bb-489abb16659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65823, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:00<00:00, 816.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65823, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:00<00:00, 999.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65823, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:00<00:00, 997.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65823, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:00<00:00, 1022.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                 feature  \\\n",
      "feature                                                                                    \n",
      "Total_MilkProduction__absolute_maximum            Total_MilkProduction__absolute_maximum   \n",
      "Total_MilkProduction__maximum                              Total_MilkProduction__maximum   \n",
      "Total_MilkProduction__minimum                              Total_MilkProduction__minimum   \n",
      "Age__sum_values                                                          Age__sum_values   \n",
      "Total_timeDelta_Seconds__sum_values                  Total_timeDelta_Seconds__sum_values   \n",
      "Age__length                                                                  Age__length   \n",
      "Total_timeDelta_Seconds__length                          Total_timeDelta_Seconds__length   \n",
      "DaysInMilk__length                                                    DaysInMilk__length   \n",
      "Total_MilkProduction__length                                Total_MilkProduction__length   \n",
      "Total_MilkProduction__variance                            Total_MilkProduction__variance   \n",
      "Total_MilkProduction__standard_deviation        Total_MilkProduction__standard_deviation   \n",
      "Total_timeDelta_Seconds__minimum                        Total_timeDelta_Seconds__minimum   \n",
      "DaysInMilk__minimum                                                  DaysInMilk__minimum   \n",
      "Total_MilkProduction__mean                                    Total_MilkProduction__mean   \n",
      "Total_MilkProduction__root_mean_square            Total_MilkProduction__root_mean_square   \n",
      "Total_MilkProduction__median                                Total_MilkProduction__median   \n",
      "Total_timeDelta_Seconds__median                          Total_timeDelta_Seconds__median   \n",
      "Total_timeDelta_Seconds__maximum                        Total_timeDelta_Seconds__maximum   \n",
      "Total_timeDelta_Seconds__absolute_maximum      Total_timeDelta_Seconds__absolute_maximum   \n",
      "Total_timeDelta_Seconds__standard_deviation  Total_timeDelta_Seconds__standard_deviation   \n",
      "Total_timeDelta_Seconds__variance                      Total_timeDelta_Seconds__variance   \n",
      "Total_timeDelta_Seconds__mean                              Total_timeDelta_Seconds__mean   \n",
      "Total_timeDelta_Seconds__root_mean_square      Total_timeDelta_Seconds__root_mean_square   \n",
      "\n",
      "                                             type       p_value  relevant  \n",
      "feature                                                                    \n",
      "Total_MilkProduction__absolute_maximum       real  1.478630e-03      True  \n",
      "Total_MilkProduction__maximum                real  1.478630e-03      True  \n",
      "Total_MilkProduction__minimum                real  1.093019e-03      True  \n",
      "Age__sum_values                              real  7.468820e-04      True  \n",
      "Total_timeDelta_Seconds__sum_values          real  2.510904e-04      True  \n",
      "Age__length                                  real  2.358541e-04      True  \n",
      "Total_timeDelta_Seconds__length              real  2.358541e-04      True  \n",
      "DaysInMilk__length                           real  2.358541e-04      True  \n",
      "Total_MilkProduction__length                 real  2.358541e-04      True  \n",
      "Total_MilkProduction__variance               real  1.552719e-05      True  \n",
      "Total_MilkProduction__standard_deviation     real  1.552719e-05      True  \n",
      "Total_timeDelta_Seconds__minimum             real  1.575076e-06      True  \n",
      "DaysInMilk__minimum                          real  6.826637e-07      True  \n",
      "Total_MilkProduction__mean                   real  1.208415e-07      True  \n",
      "Total_MilkProduction__root_mean_square       real  6.129308e-08      True  \n",
      "Total_MilkProduction__median                 real  1.995663e-08      True  \n",
      "Total_timeDelta_Seconds__median              real  1.297727e-16      True  \n",
      "Total_timeDelta_Seconds__maximum             real  5.540967e-17      True  \n",
      "Total_timeDelta_Seconds__absolute_maximum    real  5.540967e-17      True  \n",
      "Total_timeDelta_Seconds__standard_deviation  real  1.302250e-17      True  \n",
      "Total_timeDelta_Seconds__variance            real  1.302250e-17      True  \n",
      "Total_timeDelta_Seconds__mean                real  2.653257e-18      True  \n",
      "Total_timeDelta_Seconds__root_mean_square    real  2.185432e-18      True  \n"
     ]
    }
   ],
   "source": [
    "#Original\n",
    "settings_1 = MinimalFCParameters() \n",
    "#settings_2 = ComprehensiveFCParameters\n",
    "\n",
    "for i, col in enumerate(timeSeries_cols):\n",
    "    ts_processed = pd.DataFrame(cow_total[col].copy())\n",
    "    ts_processed.index = range(0,len(ts_processed)) \n",
    "    ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "    \n",
    "    print(ts_processed.shape)\n",
    "    \n",
    "    #print(ts_processed[ts_processed['id'] == 122])\n",
    "    # extract time series features\n",
    "    extracted_features = extract_features(ts_processed, column_id=\"id\", column_sort=\"MilkingDate\", default_fc_parameters=settings_1)\n",
    "    #extracted_features.dropna(axis=1, inplace=True)\n",
    "    impute(extracted_features)\n",
    "\n",
    "    # calculate_relevance_table method is sensitive to the index of the rows.\n",
    "    # The following two lines are to align the indices. \n",
    "    \n",
    "    #extracted_features.reset_index(drop=True, inplace=True)\n",
    "    #y.reset_index(drop=True, inplace=True)\n",
    "    extracted_features.index = range(1, len(extracted_features)+1)\n",
    "    y.index = range(1, len(y)+1)\n",
    "    #print(extracted_features)\n",
    "    #print(y)\n",
    "    \n",
    "    # select most relevant features based on relevance table\n",
    "    if i == 0:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = temp\n",
    "    else:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = pd.concat([relevance_table, temp], axis=0)\n",
    "    features_filtered = select_features(extracted_features, y)\n",
    "    ts_extracted_dataset = pd.concat([ts_extracted_dataset, features_filtered], axis=1)\n",
    "\n",
    "# Select relevant features from the relevance table\n",
    "relevance_table = relevance_table[relevance_table.relevant]\n",
    "relevance_table.sort_values(\"p_value\", ascending=False, inplace=True)\n",
    "relevant_features_list = list(relevance_table.feature[:])\n",
    "print(relevance_table)\n",
    "\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset[relevant_features_list].copy()\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset_filtered.loc[:,~ts_extracted_dataset_filtered.columns.duplicated()]\n",
    "ts_extracted_dataset = ts_extracted_dataset_filtered\n",
    "ts_extracted_dataset\n",
    "ts_extracted_dataset.to_csv(dataDir+\"problematic_cows_7200s_5percent_extracted_features.csv\", index=False)\n",
    "relevance_table.to_csv(dataDir+\"problematic_cows_7200s_5percent_relevance_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7621dc3-75b5-4db0-99ad-1a9a52619e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Total_MilkProduction__absolute_maximum</th>\n",
       "      <th>Total_MilkProduction__maximum</th>\n",
       "      <th>Total_MilkProduction__minimum</th>\n",
       "      <th>Age__sum_values</th>\n",
       "      <th>Total_timeDelta_Seconds__sum_values</th>\n",
       "      <th>Age__length</th>\n",
       "      <th>Total_timeDelta_Seconds__length</th>\n",
       "      <th>DaysInMilk__length</th>\n",
       "      <th>Total_MilkProduction__length</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_timeDelta_Seconds__absolute_maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>-0.700194</td>\n",
       "      <td>1.076994</td>\n",
       "      <td>-0.155646</td>\n",
       "      <td>1.097377</td>\n",
       "      <td>1.097377</td>\n",
       "      <td>1.097377</td>\n",
       "      <td>1.097377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653409</td>\n",
       "      <td>-0.600476</td>\n",
       "      <td>-0.350245</td>\n",
       "      <td>-0.525452</td>\n",
       "      <td>-0.575163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>-0.509030</td>\n",
       "      <td>0.314488</td>\n",
       "      <td>0.955011</td>\n",
       "      <td>0.461626</td>\n",
       "      <td>0.461626</td>\n",
       "      <td>0.461626</td>\n",
       "      <td>0.461626</td>\n",
       "      <td>...</td>\n",
       "      <td>2.460326</td>\n",
       "      <td>0.377808</td>\n",
       "      <td>-0.038044</td>\n",
       "      <td>-0.223560</td>\n",
       "      <td>0.053859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.252533</td>\n",
       "      <td>-0.252533</td>\n",
       "      <td>1.574656</td>\n",
       "      <td>-1.219140</td>\n",
       "      <td>-0.873796</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>...</td>\n",
       "      <td>1.986318</td>\n",
       "      <td>3.918861</td>\n",
       "      <td>4.375196</td>\n",
       "      <td>3.506463</td>\n",
       "      <td>3.687049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.045755</td>\n",
       "      <td>0.045755</td>\n",
       "      <td>-0.524960</td>\n",
       "      <td>0.765707</td>\n",
       "      <td>-0.660630</td>\n",
       "      <td>0.869932</td>\n",
       "      <td>0.869932</td>\n",
       "      <td>0.869932</td>\n",
       "      <td>0.869932</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.040742</td>\n",
       "      <td>-0.779503</td>\n",
       "      <td>-0.364872</td>\n",
       "      <td>-0.603194</td>\n",
       "      <td>-0.698932</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.777689</td>\n",
       "      <td>-0.777689</td>\n",
       "      <td>2.587824</td>\n",
       "      <td>-1.221659</td>\n",
       "      <td>-0.926207</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425202</td>\n",
       "      <td>0.722839</td>\n",
       "      <td>0.165738</td>\n",
       "      <td>2.399368</td>\n",
       "      <td>1.919867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>-0.744079</td>\n",
       "      <td>-0.744079</td>\n",
       "      <td>3.167688</td>\n",
       "      <td>-1.225512</td>\n",
       "      <td>-0.989053</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.213544</td>\n",
       "      <td>-0.889106</td>\n",
       "      <td>-0.367336</td>\n",
       "      <td>-0.457792</td>\n",
       "      <td>-0.611151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>0.640232</td>\n",
       "      <td>0.640232</td>\n",
       "      <td>-0.760729</td>\n",
       "      <td>0.799777</td>\n",
       "      <td>0.675459</td>\n",
       "      <td>0.894595</td>\n",
       "      <td>0.894595</td>\n",
       "      <td>0.894595</td>\n",
       "      <td>0.894595</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308695</td>\n",
       "      <td>-0.320949</td>\n",
       "      <td>-0.301111</td>\n",
       "      <td>-0.362141</td>\n",
       "      <td>-0.361997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>-1.395273</td>\n",
       "      <td>-1.395273</td>\n",
       "      <td>0.988420</td>\n",
       "      <td>-1.204570</td>\n",
       "      <td>-0.973529</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.022790</td>\n",
       "      <td>-0.496800</td>\n",
       "      <td>-0.335762</td>\n",
       "      <td>-0.443137</td>\n",
       "      <td>-0.485500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>1.293525</td>\n",
       "      <td>1.293525</td>\n",
       "      <td>1.033025</td>\n",
       "      <td>0.493389</td>\n",
       "      <td>0.222792</td>\n",
       "      <td>0.661668</td>\n",
       "      <td>0.661668</td>\n",
       "      <td>0.661668</td>\n",
       "      <td>0.661668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284809</td>\n",
       "      <td>-0.393741</td>\n",
       "      <td>-0.316993</td>\n",
       "      <td>-0.417576</td>\n",
       "      <td>-0.423712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>0.434370</td>\n",
       "      <td>0.434370</td>\n",
       "      <td>-0.524960</td>\n",
       "      <td>1.314196</td>\n",
       "      <td>0.076732</td>\n",
       "      <td>1.300160</td>\n",
       "      <td>1.300160</td>\n",
       "      <td>1.300160</td>\n",
       "      <td>1.300160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.533982</td>\n",
       "      <td>-0.548957</td>\n",
       "      <td>-0.343599</td>\n",
       "      <td>-0.500937</td>\n",
       "      <td>-0.538516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Total_MilkProduction__absolute_maximum  \\\n",
       "1      1                                0.001642   \n",
       "2      2                               -0.176911   \n",
       "3      3                               -0.252533   \n",
       "4      4                                0.045755   \n",
       "5      5                               -0.777689   \n",
       "..   ...                                     ...   \n",
       "138  138                               -0.744079   \n",
       "139  139                                0.640232   \n",
       "140  140                               -1.395273   \n",
       "141  141                                1.293525   \n",
       "142  142                                0.434370   \n",
       "\n",
       "     Total_MilkProduction__maximum  Total_MilkProduction__minimum  \\\n",
       "1                         0.001642                      -0.700194   \n",
       "2                        -0.176911                      -0.509030   \n",
       "3                        -0.252533                       1.574656   \n",
       "4                         0.045755                      -0.524960   \n",
       "5                        -0.777689                       2.587824   \n",
       "..                             ...                            ...   \n",
       "138                      -0.744079                       3.167688   \n",
       "139                       0.640232                      -0.760729   \n",
       "140                      -1.395273                       0.988420   \n",
       "141                       1.293525                       1.033025   \n",
       "142                       0.434370                      -0.524960   \n",
       "\n",
       "     Age__sum_values  Total_timeDelta_Seconds__sum_values  Age__length  \\\n",
       "1           1.076994                            -0.155646     1.097377   \n",
       "2           0.314488                             0.955011     0.461626   \n",
       "3          -1.219140                            -0.873796    -1.259287   \n",
       "4           0.765707                            -0.660630     0.869932   \n",
       "5          -1.221659                            -0.926207    -1.262027   \n",
       "..               ...                                  ...          ...   \n",
       "138        -1.225512                            -0.989053    -1.267508   \n",
       "139         0.799777                             0.675459     0.894595   \n",
       "140        -1.204570                            -0.973529    -1.240105   \n",
       "141         0.493389                             0.222792     0.661668   \n",
       "142         1.314196                             0.076732     1.300160   \n",
       "\n",
       "     Total_timeDelta_Seconds__length  DaysInMilk__length  \\\n",
       "1                           1.097377            1.097377   \n",
       "2                           0.461626            0.461626   \n",
       "3                          -1.259287           -1.259287   \n",
       "4                           0.869932            0.869932   \n",
       "5                          -1.262027           -1.262027   \n",
       "..                               ...                 ...   \n",
       "138                        -1.267508           -1.267508   \n",
       "139                         0.894595            0.894595   \n",
       "140                        -1.240105           -1.240105   \n",
       "141                         0.661668            0.661668   \n",
       "142                         1.300160            1.300160   \n",
       "\n",
       "     Total_MilkProduction__length  ...  \\\n",
       "1                        1.097377  ...   \n",
       "2                        0.461626  ...   \n",
       "3                       -1.259287  ...   \n",
       "4                        0.869932  ...   \n",
       "5                       -1.262027  ...   \n",
       "..                            ...  ...   \n",
       "138                     -1.267508  ...   \n",
       "139                      0.894595  ...   \n",
       "140                     -1.240105  ...   \n",
       "141                      0.661668  ...   \n",
       "142                      1.300160  ...   \n",
       "\n",
       "     Total_timeDelta_Seconds__absolute_maximum  \\\n",
       "1                                    -0.653409   \n",
       "2                                     2.460326   \n",
       "3                                     1.986318   \n",
       "4                                    -1.040742   \n",
       "5                                     0.425202   \n",
       "..                                         ...   \n",
       "138                                  -1.213544   \n",
       "139                                  -0.308695   \n",
       "140                                  -1.022790   \n",
       "141                                   0.284809   \n",
       "142                                  -0.533982   \n",
       "\n",
       "     Total_timeDelta_Seconds__standard_deviation  \\\n",
       "1                                      -0.600476   \n",
       "2                                       0.377808   \n",
       "3                                       3.918861   \n",
       "4                                      -0.779503   \n",
       "5                                       0.722839   \n",
       "..                                           ...   \n",
       "138                                    -0.889106   \n",
       "139                                    -0.320949   \n",
       "140                                    -0.496800   \n",
       "141                                    -0.393741   \n",
       "142                                    -0.548957   \n",
       "\n",
       "     Total_timeDelta_Seconds__variance  Total_timeDelta_Seconds__mean  \\\n",
       "1                            -0.350245                      -0.525452   \n",
       "2                            -0.038044                      -0.223560   \n",
       "3                             4.375196                       3.506463   \n",
       "4                            -0.364872                      -0.603194   \n",
       "5                             0.165738                       2.399368   \n",
       "..                                 ...                            ...   \n",
       "138                          -0.367336                      -0.457792   \n",
       "139                          -0.301111                      -0.362141   \n",
       "140                          -0.335762                      -0.443137   \n",
       "141                          -0.316993                      -0.417576   \n",
       "142                          -0.343599                      -0.500937   \n",
       "\n",
       "     Total_timeDelta_Seconds__root_mean_square  BreedName_1  BreedName_2  \\\n",
       "1                                    -0.575163          1.0          0.0   \n",
       "2                                     0.053859          0.0          1.0   \n",
       "3                                     3.687049          0.0          0.0   \n",
       "4                                    -0.698932          1.0          0.0   \n",
       "5                                     1.919867          0.0          0.0   \n",
       "..                                         ...          ...          ...   \n",
       "138                                  -0.611151          0.0          1.0   \n",
       "139                                  -0.361997          0.0          1.0   \n",
       "140                                  -0.485500          1.0          0.0   \n",
       "141                                  -0.423712          1.0          0.0   \n",
       "142                                  -0.538516          1.0          0.0   \n",
       "\n",
       "     BreedName_4  BreedName_99  problematic  \n",
       "1            0.0           0.0            0  \n",
       "2            0.0           0.0            1  \n",
       "3            0.0           1.0            1  \n",
       "4            0.0           0.0            0  \n",
       "5            1.0           0.0            1  \n",
       "..           ...           ...          ...  \n",
       "138          0.0           0.0            0  \n",
       "139          0.0           0.0            0  \n",
       "140          0.0           0.0            0  \n",
       "141          0.0           0.0            0  \n",
       "142          0.0           0.0            0  \n",
       "\n",
       "[142 rows x 29 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original\n",
    "# Construct extracted training data\n",
    "ts_extracted_id = cow_total[['id']].copy()\n",
    "ts_extracted_id.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_id.index = range(1, len(ts_extracted_id)+1)\n",
    "ts_extracted_dataset = pd.concat([ts_extracted_id, ts_extracted_dataset], axis=1)\n",
    "#print(ts_extracted_dataset)\n",
    "ts_extracted_features = ts_extracted_dataset.iloc[:, 1:len(ts_extracted_dataset.columns)].copy()\n",
    "#print(ts_extracted_features)\n",
    "#ts_extracted_features\n",
    "\n",
    "# normalize numerical features\n",
    "ts_extracted_cols = ts_extracted_features.columns\n",
    "scaler_std = StandardScaler()\n",
    "ts_std = scaler_std.fit_transform(ts_extracted_features)\n",
    "# transform standard data into dataframe\n",
    "ts_extracted_processed = pd.DataFrame(ts_std, columns=ts_extracted_cols)\n",
    "ts_extracted_processed.index = range(1,len(ts_extracted_processed)+1)\n",
    "# append id col to the dataframe\n",
    "ts_extracted_processed = pd.concat([ts_extracted_dataset['id'], ts_extracted_processed], axis=1)\n",
    "\n",
    "# One-Hot encoding categorical feature - BreedName\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "\n",
    "cow_breed = cow_total[['id', 'BreedName']].copy()\n",
    "cow_breed.drop_duplicates(subset=['id'], inplace=True)\n",
    "cat = ohe.fit_transform(np.array(cow_breed['BreedName']).reshape(-1, 1))\n",
    "col_names = ohe.get_feature_names_out(['BreedName'])\n",
    "cat_breed = pd.DataFrame(cat, columns=col_names)\n",
    "cat_breed.index = range(1,len(cow_breed)+1)\n",
    "\n",
    "# append features on extracted dataset\n",
    "ts_dataset = pd.concat([ts_extracted_processed, cat_breed], axis=1)\n",
    "ts_dataset = pd.concat([ts_dataset, y], axis=1)\n",
    "ts_dataset.to_csv(dataDir+\"problematic_100cows_7200s_5percent_features.csv\", index=False)\n",
    "ts_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65c049f4-c9d5-4cf5-8ecf-f65f5e7e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation on Gaussian Process Classifier\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, Matern, RationalQuadratic, WhiteKernel, ExpSineSquared\n",
    "grid = dict()\n",
    "grid['kernel'] = [1*RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)), \n",
    "                  1*DotProduct(), 1*Matern(),  1*RationalQuadratic(),\n",
    "                  1*Matern()+1*WhiteKernel(noise_level=0.5),\n",
    "                  1*ExpSineSquared(),\n",
    "                  1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0, length_scale_bounds=(0.1, 10.0), periodicity_bounds=(1.0, 10.0)),\n",
    "                  1*Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)+1*WhiteKernel(noise_level=0.5),\n",
    "                ]\n",
    "\n",
    "\n",
    "#dataDir = Path.cwd().parent.parent/'Data/processed'\n",
    "#id used as index\n",
    "#ts_dataset = pd.read_csv(dataDir/'Problematic_targetCows/problematic_100cows_7200s_5percent_features.csv', index_col='id')\n",
    "\n",
    "#use id as normal column\n",
    "#ts_dataset = pd.read_csv(dataDir+'Problematic_targetCows/problematic_100cows_7200s_5percent_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6da5b4f-a365-4ccf-8202-4fca2114d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cow_dataset = pd.DataFrame()\n",
    "\n",
    "train_cow_dataset = ts_dataset[~ts_dataset['id'].isin(test_cow_list)]\n",
    "\n",
    "train_cow_list = train_cow_dataset['id'].unique()\n",
    "\n",
    "#print(len(train_cow_list))\n",
    "#print(train_cow_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caf3ba49-8aeb-492b-a3c5-15526f6363aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.DataFrame(train_cow_dataset['problematic'], columns=['problematic'])\n",
    "train_data = train_cow_dataset.drop('problematic', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eca48f91-10a1-4202-83b4-12856a3e1cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Total_MilkProduction__absolute_maximum</th>\n",
       "      <th>Total_MilkProduction__maximum</th>\n",
       "      <th>Total_MilkProduction__minimum</th>\n",
       "      <th>Age__sum_values</th>\n",
       "      <th>Total_timeDelta_Seconds__sum_values</th>\n",
       "      <th>Age__length</th>\n",
       "      <th>Total_timeDelta_Seconds__length</th>\n",
       "      <th>DaysInMilk__length</th>\n",
       "      <th>Total_MilkProduction__length</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_timeDelta_Seconds__absolute_maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.252533</td>\n",
       "      <td>-0.252533</td>\n",
       "      <td>1.574656</td>\n",
       "      <td>-1.219140</td>\n",
       "      <td>-0.873796</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>...</td>\n",
       "      <td>1.986318</td>\n",
       "      <td>3.918861</td>\n",
       "      <td>4.375196</td>\n",
       "      <td>3.506463</td>\n",
       "      <td>3.687049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.777689</td>\n",
       "      <td>-0.777689</td>\n",
       "      <td>2.587824</td>\n",
       "      <td>-1.221659</td>\n",
       "      <td>-0.926207</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425202</td>\n",
       "      <td>0.722839</td>\n",
       "      <td>0.165738</td>\n",
       "      <td>2.399368</td>\n",
       "      <td>1.919867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.338659</td>\n",
       "      <td>-0.338659</td>\n",
       "      <td>2.772616</td>\n",
       "      <td>-1.215842</td>\n",
       "      <td>-0.943842</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.529460</td>\n",
       "      <td>-0.076630</td>\n",
       "      <td>-0.231909</td>\n",
       "      <td>0.670043</td>\n",
       "      <td>0.419876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>-1.231424</td>\n",
       "      <td>-1.231424</td>\n",
       "      <td>0.421301</td>\n",
       "      <td>-1.210580</td>\n",
       "      <td>-0.969425</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.911311</td>\n",
       "      <td>-0.404030</td>\n",
       "      <td>-0.319063</td>\n",
       "      <td>-0.287150</td>\n",
       "      <td>-0.357535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>-1.483499</td>\n",
       "      <td>-1.483499</td>\n",
       "      <td>0.918327</td>\n",
       "      <td>-1.210921</td>\n",
       "      <td>-0.977540</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.094117</td>\n",
       "      <td>-0.645780</td>\n",
       "      <td>-0.355190</td>\n",
       "      <td>-0.432141</td>\n",
       "      <td>-0.541539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>-1.502404</td>\n",
       "      <td>-1.502404</td>\n",
       "      <td>0.497766</td>\n",
       "      <td>-1.210014</td>\n",
       "      <td>-0.979402</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.863006</td>\n",
       "      <td>-0.391543</td>\n",
       "      <td>-0.316546</td>\n",
       "      <td>-0.487417</td>\n",
       "      <td>-0.451810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>0.220107</td>\n",
       "      <td>0.220107</td>\n",
       "      <td>0.370324</td>\n",
       "      <td>-1.211049</td>\n",
       "      <td>-0.968369</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870337</td>\n",
       "      <td>-0.354550</td>\n",
       "      <td>-0.308713</td>\n",
       "      <td>-0.268286</td>\n",
       "      <td>-0.326035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.601237</td>\n",
       "      <td>-0.601237</td>\n",
       "      <td>-0.521774</td>\n",
       "      <td>-1.204848</td>\n",
       "      <td>-0.953952</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829775</td>\n",
       "      <td>-0.374469</td>\n",
       "      <td>-0.313000</td>\n",
       "      <td>-0.188751</td>\n",
       "      <td>-0.284307</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>-1.878416</td>\n",
       "      <td>-1.878416</td>\n",
       "      <td>0.717605</td>\n",
       "      <td>-1.198081</td>\n",
       "      <td>-0.976881</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.135708</td>\n",
       "      <td>-0.684060</td>\n",
       "      <td>-0.358711</td>\n",
       "      <td>-0.486695</td>\n",
       "      <td>-0.590902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.052974</td>\n",
       "      <td>-0.052974</td>\n",
       "      <td>1.106305</td>\n",
       "      <td>-1.214273</td>\n",
       "      <td>-0.874569</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725997</td>\n",
       "      <td>1.935667</td>\n",
       "      <td>1.269685</td>\n",
       "      <td>2.098042</td>\n",
       "      <td>2.046671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.804997</td>\n",
       "      <td>-0.804997</td>\n",
       "      <td>1.351632</td>\n",
       "      <td>-1.211092</td>\n",
       "      <td>-0.969165</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.642789</td>\n",
       "      <td>-0.138683</td>\n",
       "      <td>-0.251805</td>\n",
       "      <td>-0.282492</td>\n",
       "      <td>-0.235861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>-0.983550</td>\n",
       "      <td>-0.983550</td>\n",
       "      <td>1.526865</td>\n",
       "      <td>-1.219300</td>\n",
       "      <td>-0.865130</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>...</td>\n",
       "      <td>1.359583</td>\n",
       "      <td>2.157016</td>\n",
       "      <td>1.536291</td>\n",
       "      <td>3.816152</td>\n",
       "      <td>3.331566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31</td>\n",
       "      <td>-1.954038</td>\n",
       "      <td>-1.954038</td>\n",
       "      <td>-0.352913</td>\n",
       "      <td>-1.208050</td>\n",
       "      <td>-0.967739</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850262</td>\n",
       "      <td>-0.268139</td>\n",
       "      <td>-0.288228</td>\n",
       "      <td>-0.302199</td>\n",
       "      <td>-0.306971</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34</td>\n",
       "      <td>-1.760781</td>\n",
       "      <td>-1.760781</td>\n",
       "      <td>-0.142632</td>\n",
       "      <td>-1.203770</td>\n",
       "      <td>-0.939223</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127012</td>\n",
       "      <td>0.572958</td>\n",
       "      <td>0.071215</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.245977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46</td>\n",
       "      <td>-1.235625</td>\n",
       "      <td>-1.235625</td>\n",
       "      <td>1.294282</td>\n",
       "      <td>-1.204570</td>\n",
       "      <td>-0.974115</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.977979</td>\n",
       "      <td>-0.584545</td>\n",
       "      <td>-0.348307</td>\n",
       "      <td>-0.450745</td>\n",
       "      <td>-0.528933</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>51</td>\n",
       "      <td>-0.704167</td>\n",
       "      <td>-0.704167</td>\n",
       "      <td>1.698913</td>\n",
       "      <td>-1.210548</td>\n",
       "      <td>-0.984873</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.149343</td>\n",
       "      <td>-0.721249</td>\n",
       "      <td>-0.361556</td>\n",
       "      <td>-0.563159</td>\n",
       "      <td>-0.651315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58</td>\n",
       "      <td>-1.017160</td>\n",
       "      <td>-1.017160</td>\n",
       "      <td>2.753500</td>\n",
       "      <td>-1.225149</td>\n",
       "      <td>-0.985193</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.011622</td>\n",
       "      <td>-0.889106</td>\n",
       "      <td>-0.367336</td>\n",
       "      <td>0.093992</td>\n",
       "      <td>-0.156154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>61</td>\n",
       "      <td>-0.910029</td>\n",
       "      <td>-0.910029</td>\n",
       "      <td>2.915989</td>\n",
       "      <td>-1.225843</td>\n",
       "      <td>-0.989077</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.214778</td>\n",
       "      <td>-0.889106</td>\n",
       "      <td>-0.367336</td>\n",
       "      <td>-0.461162</td>\n",
       "      <td>-0.613930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>68</td>\n",
       "      <td>-0.815500</td>\n",
       "      <td>-0.815500</td>\n",
       "      <td>-0.136260</td>\n",
       "      <td>-1.218638</td>\n",
       "      <td>-0.883789</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638362</td>\n",
       "      <td>1.850962</td>\n",
       "      <td>1.172980</td>\n",
       "      <td>3.149404</td>\n",
       "      <td>2.758777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>70</td>\n",
       "      <td>0.612923</td>\n",
       "      <td>0.612923</td>\n",
       "      <td>1.530051</td>\n",
       "      <td>-1.217795</td>\n",
       "      <td>-0.925419</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>...</td>\n",
       "      <td>1.676685</td>\n",
       "      <td>3.759376</td>\n",
       "      <td>4.065785</td>\n",
       "      <td>1.661767</td>\n",
       "      <td>2.578312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>71</td>\n",
       "      <td>-1.584329</td>\n",
       "      <td>-1.584329</td>\n",
       "      <td>0.443603</td>\n",
       "      <td>-1.208626</td>\n",
       "      <td>-0.969602</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.590989</td>\n",
       "      <td>-0.103335</td>\n",
       "      <td>-0.240665</td>\n",
       "      <td>-0.331782</td>\n",
       "      <td>-0.240259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>72</td>\n",
       "      <td>-1.311248</td>\n",
       "      <td>-1.311248</td>\n",
       "      <td>0.201462</td>\n",
       "      <td>-1.212447</td>\n",
       "      <td>-0.949212</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429149</td>\n",
       "      <td>0.459219</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.319862</td>\n",
       "      <td>0.358301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>75</td>\n",
       "      <td>-1.218820</td>\n",
       "      <td>-1.218820</td>\n",
       "      <td>-0.442122</td>\n",
       "      <td>-1.207687</td>\n",
       "      <td>-0.973035</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>-1.245585</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.014431</td>\n",
       "      <td>-0.530326</td>\n",
       "      <td>-0.340928</td>\n",
       "      <td>-0.386310</td>\n",
       "      <td>-0.468444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>76</td>\n",
       "      <td>-0.065578</td>\n",
       "      <td>-0.065578</td>\n",
       "      <td>0.239695</td>\n",
       "      <td>-1.205894</td>\n",
       "      <td>-0.981246</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.115632</td>\n",
       "      <td>-0.708036</td>\n",
       "      <td>-0.360610</td>\n",
       "      <td>-0.531395</td>\n",
       "      <td>-0.627792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77</td>\n",
       "      <td>-1.202015</td>\n",
       "      <td>-1.202015</td>\n",
       "      <td>1.912379</td>\n",
       "      <td>-1.221894</td>\n",
       "      <td>-0.939051</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333525</td>\n",
       "      <td>1.084026</td>\n",
       "      <td>0.431393</td>\n",
       "      <td>1.787418</td>\n",
       "      <td>1.554829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>79</td>\n",
       "      <td>-1.353260</td>\n",
       "      <td>-1.353260</td>\n",
       "      <td>0.383068</td>\n",
       "      <td>-1.201123</td>\n",
       "      <td>-0.979387</td>\n",
       "      <td>-1.237365</td>\n",
       "      <td>-1.237365</td>\n",
       "      <td>-1.237365</td>\n",
       "      <td>-1.237365</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.059927</td>\n",
       "      <td>-0.644034</td>\n",
       "      <td>-0.355015</td>\n",
       "      <td>-0.531282</td>\n",
       "      <td>-0.599054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>81</td>\n",
       "      <td>1.877499</td>\n",
       "      <td>1.877499</td>\n",
       "      <td>1.832727</td>\n",
       "      <td>-1.221211</td>\n",
       "      <td>-0.921097</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>...</td>\n",
       "      <td>2.266900</td>\n",
       "      <td>5.410235</td>\n",
       "      <td>7.773658</td>\n",
       "      <td>2.642837</td>\n",
       "      <td>3.845545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>87</td>\n",
       "      <td>0.110874</td>\n",
       "      <td>0.110874</td>\n",
       "      <td>3.362038</td>\n",
       "      <td>-1.219588</td>\n",
       "      <td>-0.840988</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252695</td>\n",
       "      <td>1.246546</td>\n",
       "      <td>0.568389</td>\n",
       "      <td>4.678842</td>\n",
       "      <td>3.803101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>89</td>\n",
       "      <td>-1.758680</td>\n",
       "      <td>-1.758680</td>\n",
       "      <td>-0.104400</td>\n",
       "      <td>-1.195124</td>\n",
       "      <td>-0.957562</td>\n",
       "      <td>-1.234624</td>\n",
       "      <td>-1.234624</td>\n",
       "      <td>-1.234624</td>\n",
       "      <td>-1.234624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769068</td>\n",
       "      <td>-0.286265</td>\n",
       "      <td>-0.292779</td>\n",
       "      <td>-0.301493</td>\n",
       "      <td>-0.314912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>90</td>\n",
       "      <td>-0.956242</td>\n",
       "      <td>-0.956242</td>\n",
       "      <td>1.192328</td>\n",
       "      <td>-1.215159</td>\n",
       "      <td>-0.928362</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>-1.253806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026880</td>\n",
       "      <td>0.678392</td>\n",
       "      <td>0.136746</td>\n",
       "      <td>0.816568</td>\n",
       "      <td>0.753653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>101</td>\n",
       "      <td>-1.601134</td>\n",
       "      <td>-1.601134</td>\n",
       "      <td>0.389440</td>\n",
       "      <td>-1.213376</td>\n",
       "      <td>-0.986505</td>\n",
       "      <td>-1.251066</td>\n",
       "      <td>-1.251066</td>\n",
       "      <td>-1.251066</td>\n",
       "      <td>-1.251066</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164211</td>\n",
       "      <td>-0.730196</td>\n",
       "      <td>-0.362156</td>\n",
       "      <td>-0.582144</td>\n",
       "      <td>-0.665081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>107</td>\n",
       "      <td>-1.538115</td>\n",
       "      <td>-1.538115</td>\n",
       "      <td>-0.203168</td>\n",
       "      <td>-1.204634</td>\n",
       "      <td>-0.969314</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.652861</td>\n",
       "      <td>-0.193673</td>\n",
       "      <td>-0.268117</td>\n",
       "      <td>-0.388362</td>\n",
       "      <td>-0.309917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>108</td>\n",
       "      <td>-0.395376</td>\n",
       "      <td>-0.395376</td>\n",
       "      <td>-0.493100</td>\n",
       "      <td>-1.206833</td>\n",
       "      <td>-0.976406</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.952011</td>\n",
       "      <td>-0.533362</td>\n",
       "      <td>-0.341373</td>\n",
       "      <td>-0.462211</td>\n",
       "      <td>-0.512276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>109</td>\n",
       "      <td>-1.044468</td>\n",
       "      <td>-1.044468</td>\n",
       "      <td>-0.610984</td>\n",
       "      <td>-1.205307</td>\n",
       "      <td>-0.970292</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.023407</td>\n",
       "      <td>-0.592183</td>\n",
       "      <td>-0.349249</td>\n",
       "      <td>-0.374828</td>\n",
       "      <td>-0.484646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>111</td>\n",
       "      <td>-0.248332</td>\n",
       "      <td>-0.248332</td>\n",
       "      <td>1.711657</td>\n",
       "      <td>-1.212469</td>\n",
       "      <td>-0.938371</td>\n",
       "      <td>-1.251066</td>\n",
       "      <td>-1.251066</td>\n",
       "      <td>-1.251066</td>\n",
       "      <td>-1.251066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060180</td>\n",
       "      <td>0.716211</td>\n",
       "      <td>0.161363</td>\n",
       "      <td>0.400739</td>\n",
       "      <td>0.514337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>115</td>\n",
       "      <td>-0.334458</td>\n",
       "      <td>-0.334458</td>\n",
       "      <td>1.074444</td>\n",
       "      <td>-1.216888</td>\n",
       "      <td>-0.809009</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>...</td>\n",
       "      <td>2.044147</td>\n",
       "      <td>3.166531</td>\n",
       "      <td>3.007132</td>\n",
       "      <td>4.524559</td>\n",
       "      <td>4.127591</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>116</td>\n",
       "      <td>-1.160003</td>\n",
       "      <td>-1.160003</td>\n",
       "      <td>-0.372029</td>\n",
       "      <td>-1.217229</td>\n",
       "      <td>-0.848176</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586036</td>\n",
       "      <td>3.355726</td>\n",
       "      <td>3.329312</td>\n",
       "      <td>3.404888</td>\n",
       "      <td>3.414192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>119</td>\n",
       "      <td>-1.407876</td>\n",
       "      <td>-1.407876</td>\n",
       "      <td>1.026653</td>\n",
       "      <td>-1.217955</td>\n",
       "      <td>-0.940106</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>-1.256547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545836</td>\n",
       "      <td>0.145093</td>\n",
       "      <td>-0.147907</td>\n",
       "      <td>0.776842</td>\n",
       "      <td>0.556065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>122</td>\n",
       "      <td>-0.905827</td>\n",
       "      <td>-0.905827</td>\n",
       "      <td>2.922361</td>\n",
       "      <td>-1.225662</td>\n",
       "      <td>-0.989437</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.233620</td>\n",
       "      <td>-0.889106</td>\n",
       "      <td>-0.367336</td>\n",
       "      <td>-0.512652</td>\n",
       "      <td>-0.656388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>126</td>\n",
       "      <td>-0.468898</td>\n",
       "      <td>-0.468898</td>\n",
       "      <td>1.399423</td>\n",
       "      <td>-1.207975</td>\n",
       "      <td>-0.978557</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>-1.242845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.910283</td>\n",
       "      <td>-0.472407</td>\n",
       "      <td>-0.331713</td>\n",
       "      <td>-0.492955</td>\n",
       "      <td>-0.496363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>127</td>\n",
       "      <td>-1.817498</td>\n",
       "      <td>-1.817498</td>\n",
       "      <td>0.586976</td>\n",
       "      <td>-1.220282</td>\n",
       "      <td>-0.947673</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>-1.262027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254661</td>\n",
       "      <td>1.303142</td>\n",
       "      <td>0.618640</td>\n",
       "      <td>1.376622</td>\n",
       "      <td>1.345702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>132</td>\n",
       "      <td>-0.470998</td>\n",
       "      <td>-0.470998</td>\n",
       "      <td>1.020281</td>\n",
       "      <td>-1.219663</td>\n",
       "      <td>-0.930285</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>-1.259287</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101955</td>\n",
       "      <td>2.657591</td>\n",
       "      <td>2.213351</td>\n",
       "      <td>1.487918</td>\n",
       "      <td>1.971599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>134</td>\n",
       "      <td>-1.699863</td>\n",
       "      <td>-1.699863</td>\n",
       "      <td>0.204649</td>\n",
       "      <td>-1.211572</td>\n",
       "      <td>-0.959610</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>-1.248326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.592839</td>\n",
       "      <td>-0.117693</td>\n",
       "      <td>-0.245252</td>\n",
       "      <td>-0.111780</td>\n",
       "      <td>-0.135446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>138</td>\n",
       "      <td>-0.744079</td>\n",
       "      <td>-0.744079</td>\n",
       "      <td>3.167688</td>\n",
       "      <td>-1.225512</td>\n",
       "      <td>-0.989053</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>-1.267508</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.213544</td>\n",
       "      <td>-0.889106</td>\n",
       "      <td>-0.367336</td>\n",
       "      <td>-0.457792</td>\n",
       "      <td>-0.611151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>140</td>\n",
       "      <td>-1.395273</td>\n",
       "      <td>-1.395273</td>\n",
       "      <td>0.988420</td>\n",
       "      <td>-1.204570</td>\n",
       "      <td>-0.973529</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>-1.240105</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.022790</td>\n",
       "      <td>-0.496800</td>\n",
       "      <td>-0.335762</td>\n",
       "      <td>-0.443137</td>\n",
       "      <td>-0.485500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Total_MilkProduction__absolute_maximum  \\\n",
       "0     3                               -0.252533   \n",
       "1     5                               -0.777689   \n",
       "2     6                               -0.338659   \n",
       "3     7                               -1.231424   \n",
       "4     9                               -1.483499   \n",
       "5    15                               -1.502404   \n",
       "6    17                                0.220107   \n",
       "7    18                               -0.601237   \n",
       "8    26                               -1.878416   \n",
       "9    28                               -0.052974   \n",
       "10   29                               -0.804997   \n",
       "11   30                               -0.983550   \n",
       "12   31                               -1.954038   \n",
       "13   34                               -1.760781   \n",
       "14   46                               -1.235625   \n",
       "15   51                               -0.704167   \n",
       "16   58                               -1.017160   \n",
       "17   61                               -0.910029   \n",
       "18   68                               -0.815500   \n",
       "19   70                                0.612923   \n",
       "20   71                               -1.584329   \n",
       "21   72                               -1.311248   \n",
       "22   75                               -1.218820   \n",
       "23   76                               -0.065578   \n",
       "24   77                               -1.202015   \n",
       "25   79                               -1.353260   \n",
       "26   81                                1.877499   \n",
       "27   87                                0.110874   \n",
       "28   89                               -1.758680   \n",
       "29   90                               -0.956242   \n",
       "30  101                               -1.601134   \n",
       "31  107                               -1.538115   \n",
       "32  108                               -0.395376   \n",
       "33  109                               -1.044468   \n",
       "34  111                               -0.248332   \n",
       "35  115                               -0.334458   \n",
       "36  116                               -1.160003   \n",
       "37  119                               -1.407876   \n",
       "38  122                               -0.905827   \n",
       "39  126                               -0.468898   \n",
       "40  127                               -1.817498   \n",
       "41  132                               -0.470998   \n",
       "42  134                               -1.699863   \n",
       "43  138                               -0.744079   \n",
       "44  140                               -1.395273   \n",
       "\n",
       "    Total_MilkProduction__maximum  Total_MilkProduction__minimum  \\\n",
       "0                       -0.252533                       1.574656   \n",
       "1                       -0.777689                       2.587824   \n",
       "2                       -0.338659                       2.772616   \n",
       "3                       -1.231424                       0.421301   \n",
       "4                       -1.483499                       0.918327   \n",
       "5                       -1.502404                       0.497766   \n",
       "6                        0.220107                       0.370324   \n",
       "7                       -0.601237                      -0.521774   \n",
       "8                       -1.878416                       0.717605   \n",
       "9                       -0.052974                       1.106305   \n",
       "10                      -0.804997                       1.351632   \n",
       "11                      -0.983550                       1.526865   \n",
       "12                      -1.954038                      -0.352913   \n",
       "13                      -1.760781                      -0.142632   \n",
       "14                      -1.235625                       1.294282   \n",
       "15                      -0.704167                       1.698913   \n",
       "16                      -1.017160                       2.753500   \n",
       "17                      -0.910029                       2.915989   \n",
       "18                      -0.815500                      -0.136260   \n",
       "19                       0.612923                       1.530051   \n",
       "20                      -1.584329                       0.443603   \n",
       "21                      -1.311248                       0.201462   \n",
       "22                      -1.218820                      -0.442122   \n",
       "23                      -0.065578                       0.239695   \n",
       "24                      -1.202015                       1.912379   \n",
       "25                      -1.353260                       0.383068   \n",
       "26                       1.877499                       1.832727   \n",
       "27                       0.110874                       3.362038   \n",
       "28                      -1.758680                      -0.104400   \n",
       "29                      -0.956242                       1.192328   \n",
       "30                      -1.601134                       0.389440   \n",
       "31                      -1.538115                      -0.203168   \n",
       "32                      -0.395376                      -0.493100   \n",
       "33                      -1.044468                      -0.610984   \n",
       "34                      -0.248332                       1.711657   \n",
       "35                      -0.334458                       1.074444   \n",
       "36                      -1.160003                      -0.372029   \n",
       "37                      -1.407876                       1.026653   \n",
       "38                      -0.905827                       2.922361   \n",
       "39                      -0.468898                       1.399423   \n",
       "40                      -1.817498                       0.586976   \n",
       "41                      -0.470998                       1.020281   \n",
       "42                      -1.699863                       0.204649   \n",
       "43                      -0.744079                       3.167688   \n",
       "44                      -1.395273                       0.988420   \n",
       "\n",
       "    Age__sum_values  Total_timeDelta_Seconds__sum_values  Age__length  \\\n",
       "0         -1.219140                            -0.873796    -1.259287   \n",
       "1         -1.221659                            -0.926207    -1.262027   \n",
       "2         -1.215842                            -0.943842    -1.256547   \n",
       "3         -1.210580                            -0.969425    -1.248326   \n",
       "4         -1.210921                            -0.977540    -1.248326   \n",
       "5         -1.210014                            -0.979402    -1.245585   \n",
       "6         -1.211049                            -0.968369    -1.248326   \n",
       "7         -1.204848                            -0.953952    -1.240105   \n",
       "8         -1.198081                            -0.976881    -1.240105   \n",
       "9         -1.214273                            -0.874569    -1.253806   \n",
       "10        -1.211092                            -0.969165    -1.248326   \n",
       "11        -1.219300                            -0.865130    -1.259287   \n",
       "12        -1.208050                            -0.967739    -1.245585   \n",
       "13        -1.203770                            -0.939223    -1.240105   \n",
       "14        -1.204570                            -0.974115    -1.240105   \n",
       "15        -1.210548                            -0.984873    -1.248326   \n",
       "16        -1.225149                            -0.985193    -1.267508   \n",
       "17        -1.225843                            -0.989077    -1.267508   \n",
       "18        -1.218638                            -0.883789    -1.259287   \n",
       "19        -1.217795                            -0.925419    -1.259287   \n",
       "20        -1.208626                            -0.969602    -1.245585   \n",
       "21        -1.212447                            -0.949212    -1.253806   \n",
       "22        -1.207687                            -0.973035    -1.245585   \n",
       "23        -1.205894                            -0.981246    -1.242845   \n",
       "24        -1.221894                            -0.939051    -1.262027   \n",
       "25        -1.201123                            -0.979387    -1.237365   \n",
       "26        -1.221211                            -0.921097    -1.262027   \n",
       "27        -1.219588                            -0.840988    -1.259287   \n",
       "28        -1.195124                            -0.957562    -1.234624   \n",
       "29        -1.215159                            -0.928362    -1.253806   \n",
       "30        -1.213376                            -0.986505    -1.251066   \n",
       "31        -1.204634                            -0.969314    -1.240105   \n",
       "32        -1.206833                            -0.976406    -1.242845   \n",
       "33        -1.205307                            -0.970292    -1.242845   \n",
       "34        -1.212469                            -0.938371    -1.251066   \n",
       "35        -1.216888                            -0.809009    -1.256547   \n",
       "36        -1.217229                            -0.848176    -1.256547   \n",
       "37        -1.217955                            -0.940106    -1.256547   \n",
       "38        -1.225662                            -0.989437    -1.267508   \n",
       "39        -1.207975                            -0.978557    -1.242845   \n",
       "40        -1.220282                            -0.947673    -1.262027   \n",
       "41        -1.219663                            -0.930285    -1.259287   \n",
       "42        -1.211572                            -0.959610    -1.248326   \n",
       "43        -1.225512                            -0.989053    -1.267508   \n",
       "44        -1.204570                            -0.973529    -1.240105   \n",
       "\n",
       "    Total_timeDelta_Seconds__length  DaysInMilk__length  \\\n",
       "0                         -1.259287           -1.259287   \n",
       "1                         -1.262027           -1.262027   \n",
       "2                         -1.256547           -1.256547   \n",
       "3                         -1.248326           -1.248326   \n",
       "4                         -1.248326           -1.248326   \n",
       "5                         -1.245585           -1.245585   \n",
       "6                         -1.248326           -1.248326   \n",
       "7                         -1.240105           -1.240105   \n",
       "8                         -1.240105           -1.240105   \n",
       "9                         -1.253806           -1.253806   \n",
       "10                        -1.248326           -1.248326   \n",
       "11                        -1.259287           -1.259287   \n",
       "12                        -1.245585           -1.245585   \n",
       "13                        -1.240105           -1.240105   \n",
       "14                        -1.240105           -1.240105   \n",
       "15                        -1.248326           -1.248326   \n",
       "16                        -1.267508           -1.267508   \n",
       "17                        -1.267508           -1.267508   \n",
       "18                        -1.259287           -1.259287   \n",
       "19                        -1.259287           -1.259287   \n",
       "20                        -1.245585           -1.245585   \n",
       "21                        -1.253806           -1.253806   \n",
       "22                        -1.245585           -1.245585   \n",
       "23                        -1.242845           -1.242845   \n",
       "24                        -1.262027           -1.262027   \n",
       "25                        -1.237365           -1.237365   \n",
       "26                        -1.262027           -1.262027   \n",
       "27                        -1.259287           -1.259287   \n",
       "28                        -1.234624           -1.234624   \n",
       "29                        -1.253806           -1.253806   \n",
       "30                        -1.251066           -1.251066   \n",
       "31                        -1.240105           -1.240105   \n",
       "32                        -1.242845           -1.242845   \n",
       "33                        -1.242845           -1.242845   \n",
       "34                        -1.251066           -1.251066   \n",
       "35                        -1.256547           -1.256547   \n",
       "36                        -1.256547           -1.256547   \n",
       "37                        -1.256547           -1.256547   \n",
       "38                        -1.267508           -1.267508   \n",
       "39                        -1.242845           -1.242845   \n",
       "40                        -1.262027           -1.262027   \n",
       "41                        -1.259287           -1.259287   \n",
       "42                        -1.248326           -1.248326   \n",
       "43                        -1.267508           -1.267508   \n",
       "44                        -1.240105           -1.240105   \n",
       "\n",
       "    Total_MilkProduction__length  ...  \\\n",
       "0                      -1.259287  ...   \n",
       "1                      -1.262027  ...   \n",
       "2                      -1.256547  ...   \n",
       "3                      -1.248326  ...   \n",
       "4                      -1.248326  ...   \n",
       "5                      -1.245585  ...   \n",
       "6                      -1.248326  ...   \n",
       "7                      -1.240105  ...   \n",
       "8                      -1.240105  ...   \n",
       "9                      -1.253806  ...   \n",
       "10                     -1.248326  ...   \n",
       "11                     -1.259287  ...   \n",
       "12                     -1.245585  ...   \n",
       "13                     -1.240105  ...   \n",
       "14                     -1.240105  ...   \n",
       "15                     -1.248326  ...   \n",
       "16                     -1.267508  ...   \n",
       "17                     -1.267508  ...   \n",
       "18                     -1.259287  ...   \n",
       "19                     -1.259287  ...   \n",
       "20                     -1.245585  ...   \n",
       "21                     -1.253806  ...   \n",
       "22                     -1.245585  ...   \n",
       "23                     -1.242845  ...   \n",
       "24                     -1.262027  ...   \n",
       "25                     -1.237365  ...   \n",
       "26                     -1.262027  ...   \n",
       "27                     -1.259287  ...   \n",
       "28                     -1.234624  ...   \n",
       "29                     -1.253806  ...   \n",
       "30                     -1.251066  ...   \n",
       "31                     -1.240105  ...   \n",
       "32                     -1.242845  ...   \n",
       "33                     -1.242845  ...   \n",
       "34                     -1.251066  ...   \n",
       "35                     -1.256547  ...   \n",
       "36                     -1.256547  ...   \n",
       "37                     -1.256547  ...   \n",
       "38                     -1.267508  ...   \n",
       "39                     -1.242845  ...   \n",
       "40                     -1.262027  ...   \n",
       "41                     -1.259287  ...   \n",
       "42                     -1.248326  ...   \n",
       "43                     -1.267508  ...   \n",
       "44                     -1.240105  ...   \n",
       "\n",
       "    Total_timeDelta_Seconds__absolute_maximum  \\\n",
       "0                                    1.986318   \n",
       "1                                    0.425202   \n",
       "2                                   -0.529460   \n",
       "3                                   -0.911311   \n",
       "4                                   -1.094117   \n",
       "5                                   -0.863006   \n",
       "6                                   -0.870337   \n",
       "7                                   -0.829775   \n",
       "8                                   -1.135708   \n",
       "9                                    0.725997   \n",
       "10                                  -0.642789   \n",
       "11                                   1.359583   \n",
       "12                                  -0.850262   \n",
       "13                                   0.127012   \n",
       "14                                  -0.977979   \n",
       "15                                  -1.149343   \n",
       "16                                  -1.011622   \n",
       "17                                  -1.214778   \n",
       "18                                   0.638362   \n",
       "19                                   1.676685   \n",
       "20                                  -0.590989   \n",
       "21                                  -0.429149   \n",
       "22                                  -1.014431   \n",
       "23                                  -1.115632   \n",
       "24                                   0.333525   \n",
       "25                                  -1.059927   \n",
       "26                                   2.266900   \n",
       "27                                   1.252695   \n",
       "28                                  -0.769068   \n",
       "29                                  -0.026880   \n",
       "30                                  -1.164211   \n",
       "31                                  -0.652861   \n",
       "32                                  -0.952011   \n",
       "33                                  -1.023407   \n",
       "34                                  -0.060180   \n",
       "35                                   2.044147   \n",
       "36                                   1.586036   \n",
       "37                                  -0.545836   \n",
       "38                                  -1.233620   \n",
       "39                                  -0.910283   \n",
       "40                                   0.254661   \n",
       "41                                   1.101955   \n",
       "42                                  -0.592839   \n",
       "43                                  -1.213544   \n",
       "44                                  -1.022790   \n",
       "\n",
       "    Total_timeDelta_Seconds__standard_deviation  \\\n",
       "0                                      3.918861   \n",
       "1                                      0.722839   \n",
       "2                                     -0.076630   \n",
       "3                                     -0.404030   \n",
       "4                                     -0.645780   \n",
       "5                                     -0.391543   \n",
       "6                                     -0.354550   \n",
       "7                                     -0.374469   \n",
       "8                                     -0.684060   \n",
       "9                                      1.935667   \n",
       "10                                    -0.138683   \n",
       "11                                     2.157016   \n",
       "12                                    -0.268139   \n",
       "13                                     0.572958   \n",
       "14                                    -0.584545   \n",
       "15                                    -0.721249   \n",
       "16                                    -0.889106   \n",
       "17                                    -0.889106   \n",
       "18                                     1.850962   \n",
       "19                                     3.759376   \n",
       "20                                    -0.103335   \n",
       "21                                     0.459219   \n",
       "22                                    -0.530326   \n",
       "23                                    -0.708036   \n",
       "24                                     1.084026   \n",
       "25                                    -0.644034   \n",
       "26                                     5.410235   \n",
       "27                                     1.246546   \n",
       "28                                    -0.286265   \n",
       "29                                     0.678392   \n",
       "30                                    -0.730196   \n",
       "31                                    -0.193673   \n",
       "32                                    -0.533362   \n",
       "33                                    -0.592183   \n",
       "34                                     0.716211   \n",
       "35                                     3.166531   \n",
       "36                                     3.355726   \n",
       "37                                     0.145093   \n",
       "38                                    -0.889106   \n",
       "39                                    -0.472407   \n",
       "40                                     1.303142   \n",
       "41                                     2.657591   \n",
       "42                                    -0.117693   \n",
       "43                                    -0.889106   \n",
       "44                                    -0.496800   \n",
       "\n",
       "    Total_timeDelta_Seconds__variance  Total_timeDelta_Seconds__mean  \\\n",
       "0                            4.375196                       3.506463   \n",
       "1                            0.165738                       2.399368   \n",
       "2                           -0.231909                       0.670043   \n",
       "3                           -0.319063                      -0.287150   \n",
       "4                           -0.355190                      -0.432141   \n",
       "5                           -0.316546                      -0.487417   \n",
       "6                           -0.308713                      -0.268286   \n",
       "7                           -0.313000                      -0.188751   \n",
       "8                           -0.358711                      -0.486695   \n",
       "9                            1.269685                       2.098042   \n",
       "10                          -0.251805                      -0.282492   \n",
       "11                           1.536291                       3.816152   \n",
       "12                          -0.288228                      -0.302199   \n",
       "13                           0.071215                       0.002638   \n",
       "14                          -0.348307                      -0.450745   \n",
       "15                          -0.361556                      -0.563159   \n",
       "16                          -0.367336                       0.093992   \n",
       "17                          -0.367336                      -0.461162   \n",
       "18                           1.172980                       3.149404   \n",
       "19                           4.065785                       1.661767   \n",
       "20                          -0.240665                      -0.331782   \n",
       "21                           0.005636                       0.319862   \n",
       "22                          -0.340928                      -0.386310   \n",
       "23                          -0.360610                      -0.531395   \n",
       "24                           0.431393                       1.787418   \n",
       "25                          -0.355015                      -0.531282   \n",
       "26                           7.773658                       2.642837   \n",
       "27                           0.568389                       4.678842   \n",
       "28                          -0.292779                      -0.301493   \n",
       "29                           0.136746                       0.816568   \n",
       "30                          -0.362156                      -0.582144   \n",
       "31                          -0.268117                      -0.388362   \n",
       "32                          -0.341373                      -0.462211   \n",
       "33                          -0.349249                      -0.374828   \n",
       "34                           0.161363                       0.400739   \n",
       "35                           3.007132                       4.524559   \n",
       "36                           3.329312                       3.404888   \n",
       "37                          -0.147907                       0.776842   \n",
       "38                          -0.367336                      -0.512652   \n",
       "39                          -0.331713                      -0.492955   \n",
       "40                           0.618640                       1.376622   \n",
       "41                           2.213351                       1.487918   \n",
       "42                          -0.245252                      -0.111780   \n",
       "43                          -0.367336                      -0.457792   \n",
       "44                          -0.335762                      -0.443137   \n",
       "\n",
       "    Total_timeDelta_Seconds__root_mean_square  BreedName_1  BreedName_2  \\\n",
       "0                                    3.687049          0.0          0.0   \n",
       "1                                    1.919867          0.0          0.0   \n",
       "2                                    0.419876          0.0          1.0   \n",
       "3                                   -0.357535          0.0          1.0   \n",
       "4                                   -0.541539          1.0          0.0   \n",
       "5                                   -0.451810          1.0          0.0   \n",
       "6                                   -0.326035          0.0          1.0   \n",
       "7                                   -0.284307          1.0          0.0   \n",
       "8                                   -0.590902          0.0          1.0   \n",
       "9                                    2.046671          0.0          0.0   \n",
       "10                                  -0.235861          1.0          0.0   \n",
       "11                                   3.331566          1.0          0.0   \n",
       "12                                  -0.306971          1.0          0.0   \n",
       "13                                   0.245977          1.0          0.0   \n",
       "14                                  -0.528933          1.0          0.0   \n",
       "15                                  -0.651315          1.0          0.0   \n",
       "16                                  -0.156154          0.0          0.0   \n",
       "17                                  -0.613930          0.0          1.0   \n",
       "18                                   2.758777          0.0          1.0   \n",
       "19                                   2.578312          0.0          0.0   \n",
       "20                                  -0.240259          1.0          0.0   \n",
       "21                                   0.358301          0.0          0.0   \n",
       "22                                  -0.468444          1.0          0.0   \n",
       "23                                  -0.627792          1.0          0.0   \n",
       "24                                   1.554829          0.0          0.0   \n",
       "25                                  -0.599054          0.0          1.0   \n",
       "26                                   3.845545          0.0          1.0   \n",
       "27                                   3.803101          0.0          1.0   \n",
       "28                                  -0.314912          0.0          1.0   \n",
       "29                                   0.753653          0.0          1.0   \n",
       "30                                  -0.665081          0.0          1.0   \n",
       "31                                  -0.309917          0.0          1.0   \n",
       "32                                  -0.512276          1.0          0.0   \n",
       "33                                  -0.484646          1.0          0.0   \n",
       "34                                   0.514337          0.0          1.0   \n",
       "35                                   4.127591          1.0          0.0   \n",
       "36                                   3.414192          0.0          0.0   \n",
       "37                                   0.556065          0.0          0.0   \n",
       "38                                  -0.656388          0.0          1.0   \n",
       "39                                  -0.496363          0.0          1.0   \n",
       "40                                   1.345702          0.0          0.0   \n",
       "41                                   1.971599          0.0          0.0   \n",
       "42                                  -0.135446          1.0          0.0   \n",
       "43                                  -0.611151          0.0          1.0   \n",
       "44                                  -0.485500          1.0          0.0   \n",
       "\n",
       "    BreedName_4  BreedName_99  problematic  \n",
       "0           0.0           1.0            1  \n",
       "1           1.0           0.0            1  \n",
       "2           0.0           0.0            0  \n",
       "3           0.0           0.0            0  \n",
       "4           0.0           0.0            0  \n",
       "5           0.0           0.0            0  \n",
       "6           0.0           0.0            1  \n",
       "7           0.0           0.0            0  \n",
       "8           0.0           0.0            0  \n",
       "9           0.0           1.0            1  \n",
       "10          0.0           0.0            0  \n",
       "11          0.0           0.0            1  \n",
       "12          0.0           0.0            0  \n",
       "13          0.0           0.0            0  \n",
       "14          0.0           0.0            0  \n",
       "15          0.0           0.0            0  \n",
       "16          0.0           1.0            1  \n",
       "17          0.0           0.0            0  \n",
       "18          0.0           0.0            1  \n",
       "19          0.0           1.0            1  \n",
       "20          0.0           0.0            0  \n",
       "21          1.0           0.0            0  \n",
       "22          0.0           0.0            0  \n",
       "23          0.0           0.0            0  \n",
       "24          0.0           1.0            1  \n",
       "25          0.0           0.0            0  \n",
       "26          0.0           0.0            1  \n",
       "27          0.0           0.0            1  \n",
       "28          0.0           0.0            0  \n",
       "29          0.0           0.0            0  \n",
       "30          0.0           0.0            0  \n",
       "31          0.0           0.0            0  \n",
       "32          0.0           0.0            0  \n",
       "33          0.0           0.0            0  \n",
       "34          0.0           0.0            0  \n",
       "35          0.0           0.0            1  \n",
       "36          1.0           0.0            1  \n",
       "37          0.0           1.0            0  \n",
       "38          0.0           0.0            0  \n",
       "39          0.0           0.0            0  \n",
       "40          1.0           0.0            1  \n",
       "41          1.0           0.0            1  \n",
       "42          0.0           0.0            0  \n",
       "43          0.0           0.0            0  \n",
       "44          0.0           0.0            0  \n",
       "\n",
       "[45 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cow_dataset = pd.DataFrame()\n",
    "\n",
    "for tc in test_cow_list:\n",
    "    test_data = ts_dataset[ts_dataset['id'] == tc]\n",
    "    frames = [test_cow_dataset, test_data]\n",
    "    test_cow_dataset = pd.concat(frames, ignore_index=True)\n",
    "    \n",
    "test_cow_dataset\n",
    "#test_cow_dataset.to_csv(dataDir+\"test_cow_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44e23afb-169a-4b3a-949f-f590c68f8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.DataFrame(test_cow_dataset['problematic'], columns=['problematic'])\n",
    "test_data = test_cow_dataset.drop('problematic', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c528233d-dc85-4217-876a-fe7e70c285be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py:477: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py:477: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py:477: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py:477: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py:477: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "50 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 51-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 45-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 47-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 48-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 46-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 49-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 41-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 39-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 43-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 50-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 36-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 40-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 35-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 38-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 42-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 37-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 33-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.84778947 0.944      0.94421053 0.94       0.94421053        nan\n",
      "        nan 0.86978947]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.9442105263157895\n",
      "Best estimator parameters:  {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      "Accuracy 0.848 with: {'kernel': 1**2 * RBF(length_scale=1)}\n",
      "Accuracy 0.944 with: {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.944 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      "Accuracy 0.940 with: {'kernel': 1**2 * RationalQuadratic(alpha=1, length_scale=1)}\n",
      "Accuracy 0.944 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=1)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=3)}\n",
      "Accuracy 0.870 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#%%capture --no-stderr\n",
    "#%%capture --no-display\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_labels, test_labels\n",
    "\n",
    "model = GaussianProcessClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=5)\n",
    "# exhausive search over different kernels\n",
    "search = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# fit model into the dataset\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", result.best_score_)\n",
    "print(\"Best estimator parameters: \", result.best_params_)\n",
    "\n",
    "means = result.cv_results_['mean_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"Accuracy %.3f with: %r\" % (mean, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b4a4de1-86d4-4489-be2f-6ccec8061d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6de6e667-a6a3-4067-a2a8-8baaf1763601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              30\n",
       "1              15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abddfa0d-f554-4c49-a721-704861548ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              67\n",
       "1              30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78291d70-c611-4ff8-a397-e4afb82711be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training data:  0.9896907216494846\n",
      "Prediction on test data:  [1 1 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 0 1 1 1 0 0 0]\n",
      "True values of test data:  [1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "Prediction accuracy on test data:  0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "best_kernel = 1**2 * DotProduct(sigma_0=1)\n",
    "#best_kernel = 1**2 * RationalQuadratic(alpha=1, length_scale=1)\n",
    "#best_kernel = 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)\n",
    "# best_kernel = 1**2 * Matern(length_scale=1, nu=1.5)\n",
    "#best_kernel = 1**2 * RBF(length_scale=1)\n",
    "model = GaussianProcessClassifier(kernel=best_kernel, random_state=30, n_jobs=-1)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model.score(X_train, y_train))\n",
    "\n",
    "# My guess is to look at what we have in X_test dataset and see if I can reduce the number of days.\n",
    "# The challenge is how do we ensure that the number of days we have found for correct prediction will always \n",
    "# be the correct one? \n",
    "\n",
    "print(\"Prediction on test data: \", model.predict(X_test))\n",
    "print(\"True values of test data: \", y_test['problematic'].tolist())\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"Prediction accuracy on test data: \", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ab5b6fe-3c2e-43fc-88af-5af744ba93ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03800428, 0.96199572],\n",
       "       [0.1642332 , 0.8357668 ],\n",
       "       [0.14766761, 0.85233239],\n",
       "       [0.44145995, 0.55854005],\n",
       "       [0.79316883, 0.20683117],\n",
       "       [0.75021805, 0.24978195],\n",
       "       [0.17787863, 0.82212137],\n",
       "       [0.40259812, 0.59740188],\n",
       "       [0.65796588, 0.34203412],\n",
       "       [0.02104356, 0.97895644],\n",
       "       [0.517235  , 0.482765  ],\n",
       "       [0.1267929 , 0.8732071 ],\n",
       "       [0.73125774, 0.26874226],\n",
       "       [0.346858  , 0.653142  ],\n",
       "       [0.74200307, 0.25799693],\n",
       "       [0.7249285 , 0.2750715 ],\n",
       "       [0.55751293, 0.44248707],\n",
       "       [0.55000522, 0.44999478],\n",
       "       [0.05320287, 0.94679713],\n",
       "       [0.05100361, 0.94899639],\n",
       "       [0.66589372, 0.33410628],\n",
       "       [0.09048962, 0.90951038],\n",
       "       [0.70682018, 0.29317982],\n",
       "       [0.4388959 , 0.5611041 ],\n",
       "       [0.11892125, 0.88107875],\n",
       "       [0.58234004, 0.41765996],\n",
       "       [0.06762561, 0.93237439],\n",
       "       [0.14886287, 0.85113713],\n",
       "       [0.43045913, 0.56954087],\n",
       "       [0.03275284, 0.96724716],\n",
       "       [0.62829791, 0.37170209],\n",
       "       [0.44436757, 0.55563243],\n",
       "       [0.42612603, 0.57387397],\n",
       "       [0.53513034, 0.46486966],\n",
       "       [0.04654479, 0.95345521],\n",
       "       [0.06422911, 0.93577089],\n",
       "       [0.05767707, 0.94232293],\n",
       "       [0.14768466, 0.85231534],\n",
       "       [0.59104533, 0.40895467],\n",
       "       [0.34851255, 0.65148745],\n",
       "       [0.07099198, 0.92900802],\n",
       "       [0.03327459, 0.96672541],\n",
       "       [0.58891461, 0.41108539],\n",
       "       [0.55322676, 0.44677324],\n",
       "       [0.73614713, 0.26385287]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_list = model.predict_proba(X_test)\n",
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae0a5d15-268c-4a11-9d9f-faa6c891a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "cow_id = X_test.index.copy()\n",
    "cow_id = cow_id.astype(str)\n",
    "\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "facecolor = '#eaeaf2'\n",
    "color_red = '#f44336'\n",
    "color_blue = '#4496df'\n",
    "index = cow_id\n",
    "column0 = prob_list[:, 0]\n",
    "column1 = prob_list[:, 1]\n",
    "title0 = 'Problematic Cows, test set'\n",
    "title1 = 'Normal Cows, test set'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5), facecolor=facecolor, ncols=2, sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0].barh(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes[0].set_title(title0, fontsize=18, pad=15, color=color_red, **hfont)\n",
    "axes[1].barh(index, column1, align='center', color=color_blue, zorder=10)\n",
    "axes[1].set_title(title1, fontsize=18, pad=15, color=color_blue, **hfont)\n",
    "\n",
    "# If you have positive numbers and want to invert the x-axis of the left plot\n",
    "axes[0].invert_xaxis() \n",
    "\n",
    "# To show data from highest to lowest\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "axes[0].set(yticks=cow_id, yticklabels=cow_id)\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[0].tick_params(axis='y', colors='black') # tick color\n",
    "\n",
    "axes[0].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[0].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "for label in (axes[0].get_xticklabels() + axes[0].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "for label in (axes[1].get_xticklabels() + axes[1].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, top=0.85, bottom=0.1, left=0.18, right=0.95)\n",
    "filename = 'Problematic_Cows'\n",
    "plt.savefig(filename+'.png', facecolor=facecolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b35c659-e272-4de7-9c88-68deee33fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# Total_timeDelta_Seconds__minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25d87e85-9998-4bf1-bbff-622b6174bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Plot decision boundary with uncertainty\u001b[39;00m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m---> 18\u001b[0m x_min, x_max \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m y_min, y_max \u001b[38;5;241m=\u001b[39m X[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39mlinspace(x_min, x_max, \u001b[38;5;241m100\u001b[39m),\n\u001b[1;32m     21\u001b[0m                      np\u001b[38;5;241m.\u001b[39mlinspace(y_min, y_max, \u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3810\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3810\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:5966\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5964\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5965\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5966\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = pd.DataFrame(ts_dataset['problematic'], columns=['problematic'])\n",
    "#X = pd.DataFrame(ts_dataset['Total_timeDelta_Seconds__minimum', 'Total_timeDelta_Seconds__root_mean_square'], columns=['Total_timeDelta_Seconds__minimum', 'Total_timeDelta_Seconds__root_mean_square'])\n",
    "\n",
    "X = pd.DataFrame(ts_dataset['Total_timeDelta_Seconds__minimum'], columns=['Total_timeDelta_Seconds__minimum'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the Gaussian Process model with an RBF kernel\n",
    "kernel = 1.0 * RBF(length_scale=1.0)\n",
    "gpc = GaussianProcessClassifier(kernel=kernel)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gpc.fit(X_train, y_train)\n",
    "\n",
    "# Plot decision boundary with uncertainty\n",
    "plt.figure(figsize=(10, 5))\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# Obtain predictions and uncertainties\n",
    "Z = gpc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "probs_mesh = gpc.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]  # Probability for class 1\n",
    "Z = Z.reshape(xx.shape)\n",
    "probs_mesh = probs_mesh.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundaries\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# Plot class probabilities as uncertainty\n",
    "plt.contourf(xx, yy, probs_mesh, cmap='RdYlBu', alpha=0.2)\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k')\n",
    "plt.title('Gaussian Process Classification with Uncertainty')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b89d5-1a20-4699-9c27-a83383e6918e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b17f1-6d3e-4567-b626-f2e78548914e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b08fc-5890-4205-9910-2501ef77cb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
