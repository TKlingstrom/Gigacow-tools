{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396af3cf-0117-4f47-a509-3261e5d8cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "pd.options.mode.chained_assignment = None\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, MinimalFCParameters\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85bb1b24-e295-47ea-b4e1-fda41010b4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>5.76</td>\n",
       "      <td>271.0</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>7.76</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>6.79</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>6.47</td>\n",
       "      <td>266.0</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>7.15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.35</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45403</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45404</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>6.64</td>\n",
       "      <td>439.0</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45405</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>6.15</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45406</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.38</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45407 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "0            a624fb9a            2560                  5.76   \n",
       "1            a624fb9a            2560                  7.76   \n",
       "2            a624fb9a            2560                  6.79   \n",
       "3            a624fb9a            2560                  6.47   \n",
       "4            a624fb9a            2560                  7.15   \n",
       "...               ...             ...                   ...   \n",
       "45402        a624fb9a            2047                  5.35   \n",
       "45403        a624fb9a            2047                  7.88   \n",
       "45404        a624fb9a            2047                  6.64   \n",
       "45405        a624fb9a            2047                  6.15   \n",
       "45406        a624fb9a            2047                  5.38   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "0                        271.0  2023-01-31              2.0         2.0   \n",
       "1                         16.0  2023-01-31              2.0         2.0   \n",
       "2                        142.0  2023-01-31              2.0         2.0   \n",
       "3                        266.0  2023-01-31              2.0         2.0   \n",
       "4                         21.0  2023-02-01              2.0         3.0   \n",
       "...                        ...         ...              ...         ...   \n",
       "45402                    201.0  2023-10-13              2.0       277.0   \n",
       "45403                   1125.0  2023-10-13              2.0       277.0   \n",
       "45404                    439.0  2023-10-14              2.0       278.0   \n",
       "45405                     67.0  2023-10-15              2.0       279.0   \n",
       "45406                     36.0  2023-10-15              2.0       279.0   \n",
       "\n",
       "       BreedName   Age  problematic  id  \n",
       "0              1  3.11            0   1  \n",
       "1              1  3.11            0   1  \n",
       "2              1  3.11            0   1  \n",
       "3              1  3.11            0   1  \n",
       "4              1  3.11            0   1  \n",
       "...          ...   ...          ...  ..  \n",
       "45402          1  3.94            0  60  \n",
       "45403          1  3.94            0  60  \n",
       "45404          1  3.95            0  60  \n",
       "45405          1  3.95            0  60  \n",
       "45406          1  3.95            0  60  \n",
       "\n",
       "[45407 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cows = pd.DataFrame()\n",
    "\n",
    "dataDir = '/home/jovyan/work/Data/processed/'\n",
    "total_cows = pd.read_csv(dataDir+'Cow_Prob_dataset_L2.csv')\n",
    "total_cows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c42e8a3-5fce-4f84-9e68-f3297bf92301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 18, 19, 21, 23, 24, 25, 27, 29, 31, 32, 40, 38, 4, 7, 5, 45, 46, 47, 52] 20\n"
     ]
    }
   ],
   "source": [
    "# Select IDs from the total_cows\n",
    "test_cow_list = []\n",
    "ids = total_cows['id']\n",
    "\n",
    "unique_cow_ids = ids.unique()\n",
    "\n",
    "# Select a few rows randomly\n",
    "num_of_selected_cows = 20\n",
    "\n",
    "#test_cow_list = [1]\n",
    "\n",
    "test_cow_list = random.choices( unique_cow_ids, k=num_of_selected_cows)\n",
    "test_cow_list.sort()\n",
    "\n",
    "test_cow_list = [2, 18, 19, 21, 23, 24, 25, 27, 29, 31, 32, 40, 38, 4, 7, 5, 45, 46, 47, 52]\n",
    "print(test_cow_list, len(test_cow_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "471088dc-15b0-4be2-a527-8967a8de7801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29568</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.35</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29569</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29570</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>6.64</td>\n",
       "      <td>439.0</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29571</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>6.15</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29572</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.38</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "29568        a624fb9a            2047                  5.35   \n",
       "29569        a624fb9a            2047                  7.88   \n",
       "29570        a624fb9a            2047                  6.64   \n",
       "29571        a624fb9a            2047                  6.15   \n",
       "29572        a624fb9a            2047                  5.38   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "29568                    201.0  2023-10-13              2.0       277.0   \n",
       "29569                   1125.0  2023-10-13              2.0       277.0   \n",
       "29570                    439.0  2023-10-14              2.0       278.0   \n",
       "29571                     67.0  2023-10-15              2.0       279.0   \n",
       "29572                     36.0  2023-10-15              2.0       279.0   \n",
       "\n",
       "       BreedName   Age  problematic  id  \n",
       "29568          1  3.94            0  60  \n",
       "29569          1  3.94            0  60  \n",
       "29570          1  3.95            0  60  \n",
       "29571          1  3.95            0  60  \n",
       "29572          1  3.95            0  60  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_total_cows = total_cows\n",
    "ts_length_test_data = 28\n",
    "\n",
    "for l in test_cow_list:\n",
    "    # Choose a specific duration\n",
    "    condition = modified_total_cows['id'] == l\n",
    "    test_cow = modified_total_cows[condition].copy()\n",
    "    test_cow = test_cow.reset_index()        \n",
    "    # print(test_cow)\n",
    "    if 'index' in test_cow:\n",
    "        test_cow = test_cow.drop('index', axis=1)\n",
    "        \n",
    "    modified_total_cows = modified_total_cows[~condition]\n",
    "            \n",
    "    test_cow['MilkingDate'] = pd.to_datetime(test_cow['MilkingDate'])\n",
    "    test_cow['MilkingDate'] = test_cow['MilkingDate'].dt.date\n",
    "            \n",
    "    start_date = test_cow['MilkingDate'][0]\n",
    "    #print('start_date: ',start_date)\n",
    "    end_date = pd.to_datetime(start_date + pd.DateOffset(days=ts_length_test_data)).date()\n",
    "    #print('end_date: ', end_date)\n",
    "    filtered_df = test_cow[(test_cow['MilkingDate'] >= start_date) & (test_cow['MilkingDate'] <= end_date)]   \n",
    "    \n",
    "    modified_total_cows = pd.concat([modified_total_cows, filtered_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "#modified_total_cows = modified_total_cows.drop('index', axis=1)\n",
    "#modified_total_cows = modified_total_cows.sort_values('id')\n",
    "modified_total_cows = modified_total_cows.sort_values(by=['id', 'MilkingDate'])\n",
    "\n",
    "modified_total_cows.to_csv(dataDir+\"upp.csv\", index=False)\n",
    "\n",
    "#modified_total_cows = modified_total_cows.reset_index()\n",
    "\n",
    "modified_total_cows.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25a586e8-e3cc-4b2d-b73c-a1e5d235b14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31330, 11)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cow_total =  modified_total_cows\n",
    "cow_total.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "009c6a05-7081-436c-8d5e-bf0f1a184716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    54\n",
      "1     6\n",
      "Name: problematic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#original\n",
    "#df_static_features = cow_total[['FarmName_Pseudo']]\n",
    "static_cols = ['FarmName_Pseudo', 'TrafficDeviceName', 'LactationNumber', 'BreedName']\n",
    "timeSeries_cols = ['Age', 'Total_MilkProduction', 'Total_timeDelta_Seconds', 'DaysInMilk']\n",
    "output_col = ['problematic']\n",
    "\n",
    "cow_label = cow_total[['id', 'problematic']].copy()\n",
    "cow_timeseries = cow_total[['id', 'MilkingDate']].copy()\n",
    "cow_timeseries.index = range(len(cow_timeseries))\n",
    "# fetch y for feature extraction\n",
    "y = cow_label.drop_duplicates(subset=['id'])\n",
    "y = y[\"problematic\"]\n",
    "y.index = range(1,len(y)+1) \n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ba0c709-0d26-4e73-a0fc-8d0681161b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_extracted_dataset shape:  (31330, 1)\n",
      "ts_extracted_dataset shape:  (60, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>DaysInMilk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5.76</td>\n",
       "      <td>271.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>3.11</td>\n",
       "      <td>7.76</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>3.11</td>\n",
       "      <td>6.79</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>3.11</td>\n",
       "      <td>6.47</td>\n",
       "      <td>266.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>3.11</td>\n",
       "      <td>7.15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31325</th>\n",
       "      <td>60</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>3.94</td>\n",
       "      <td>5.35</td>\n",
       "      <td>201.0</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31326</th>\n",
       "      <td>60</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>3.94</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31327</th>\n",
       "      <td>60</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>3.95</td>\n",
       "      <td>6.64</td>\n",
       "      <td>439.0</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31328</th>\n",
       "      <td>60</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>3.95</td>\n",
       "      <td>6.15</td>\n",
       "      <td>67.0</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31329</th>\n",
       "      <td>60</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>3.95</td>\n",
       "      <td>5.38</td>\n",
       "      <td>36.0</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31330 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id MilkingDate   Age  Total_MilkProduction  Total_timeDelta_Seconds  \\\n",
       "0       1  2023-01-31  3.11                  5.76                    271.0   \n",
       "1       1  2023-01-31  3.11                  7.76                     16.0   \n",
       "2       1  2023-01-31  3.11                  6.79                    142.0   \n",
       "3       1  2023-01-31  3.11                  6.47                    266.0   \n",
       "4       1  2023-02-01  3.11                  7.15                     21.0   \n",
       "...    ..         ...   ...                   ...                      ...   \n",
       "31325  60  2023-10-13  3.94                  5.35                    201.0   \n",
       "31326  60  2023-10-13  3.94                  7.88                   1125.0   \n",
       "31327  60  2023-10-14  3.95                  6.64                    439.0   \n",
       "31328  60  2023-10-15  3.95                  6.15                     67.0   \n",
       "31329  60  2023-10-15  3.95                  5.38                     36.0   \n",
       "\n",
       "       DaysInMilk  \n",
       "0             2.0  \n",
       "1             2.0  \n",
       "2             2.0  \n",
       "3             2.0  \n",
       "4             3.0  \n",
       "...           ...  \n",
       "31325       277.0  \n",
       "31326       277.0  \n",
       "31327       278.0  \n",
       "31328       279.0  \n",
       "31329       279.0  \n",
       "\n",
       "[31330 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "# Prepare datasert for Tsfresh extraction\n",
    "ts_extracted_dataset = cow_total[['id']].copy()\n",
    "print('ts_extracted_dataset shape: ', ts_extracted_dataset.shape)\n",
    "ts_extracted_dataset.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_dataset.index = range(1, len(ts_extracted_dataset)+1)\n",
    "print('ts_extracted_dataset shape: ',ts_extracted_dataset.shape)\n",
    "\n",
    "ts_processed = pd.DataFrame(cow_total[timeSeries_cols].copy())\n",
    "ts_processed.index = range(0,len(ts_processed)) \n",
    "\n",
    "ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "ts_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "833d7cef-efd5-40ca-b8bb-489abb16659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31330, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:00<00:00, 161.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31330, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:00<00:00, 167.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31330, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:00<00:00, 192.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31330, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:00<00:00, 172.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                 feature  \\\n",
      "feature                                                                                    \n",
      "Total_MilkProduction__median                                Total_MilkProduction__median   \n",
      "Total_MilkProduction__mean                                    Total_MilkProduction__mean   \n",
      "Total_MilkProduction__root_mean_square            Total_MilkProduction__root_mean_square   \n",
      "Total_MilkProduction__standard_deviation        Total_MilkProduction__standard_deviation   \n",
      "Total_MilkProduction__variance                            Total_MilkProduction__variance   \n",
      "Total_timeDelta_Seconds__minimum                        Total_timeDelta_Seconds__minimum   \n",
      "Age__length                                                                  Age__length   \n",
      "Total_MilkProduction__length                                Total_MilkProduction__length   \n",
      "Total_timeDelta_Seconds__length                          Total_timeDelta_Seconds__length   \n",
      "Age__sum_values                                                          Age__sum_values   \n",
      "Total_timeDelta_Seconds__standard_deviation  Total_timeDelta_Seconds__standard_deviation   \n",
      "Total_timeDelta_Seconds__variance                      Total_timeDelta_Seconds__variance   \n",
      "Total_timeDelta_Seconds__median                          Total_timeDelta_Seconds__median   \n",
      "Total_timeDelta_Seconds__root_mean_square      Total_timeDelta_Seconds__root_mean_square   \n",
      "Total_timeDelta_Seconds__mean                              Total_timeDelta_Seconds__mean   \n",
      "\n",
      "                                             type   p_value  relevant  \n",
      "feature                                                                \n",
      "Total_MilkProduction__median                 real  0.008075      True  \n",
      "Total_MilkProduction__mean                   real  0.006202      True  \n",
      "Total_MilkProduction__root_mean_square       real  0.005655      True  \n",
      "Total_MilkProduction__standard_deviation     real  0.003848      True  \n",
      "Total_MilkProduction__variance               real  0.003848      True  \n",
      "Total_timeDelta_Seconds__minimum             real  0.002944      True  \n",
      "Age__length                                  real  0.002865      True  \n",
      "Total_MilkProduction__length                 real  0.002865      True  \n",
      "Total_timeDelta_Seconds__length              real  0.002865      True  \n",
      "Age__sum_values                              real  0.002053      True  \n",
      "Total_timeDelta_Seconds__standard_deviation  real  0.000293      True  \n",
      "Total_timeDelta_Seconds__variance            real  0.000293      True  \n",
      "Total_timeDelta_Seconds__median              real  0.000253      True  \n",
      "Total_timeDelta_Seconds__root_mean_square    real  0.000129      True  \n",
      "Total_timeDelta_Seconds__mean                real  0.000020      True  \n"
     ]
    }
   ],
   "source": [
    "#Original\n",
    "settings_1 = MinimalFCParameters() \n",
    "#settings_2 = ComprehensiveFCParameters\n",
    "\n",
    "for i, col in enumerate(timeSeries_cols):\n",
    "    ts_processed = pd.DataFrame(cow_total[col].copy())\n",
    "    ts_processed.index = range(0,len(ts_processed)) \n",
    "    ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "    \n",
    "    print(ts_processed.shape)\n",
    "    \n",
    "    #print(ts_processed[ts_processed['id'] == 122])\n",
    "    # extract time series features\n",
    "    extracted_features = extract_features(ts_processed, column_id=\"id\", column_sort=\"MilkingDate\", default_fc_parameters=settings_1)\n",
    "    #extracted_features.dropna(axis=1, inplace=True)\n",
    "    impute(extracted_features)\n",
    "\n",
    "    # calculate_relevance_table method is sensitive to the index of the rows.\n",
    "    # The following two lines are to align the indices. \n",
    "    \n",
    "    #extracted_features.reset_index(drop=True, inplace=True)\n",
    "    #y.reset_index(drop=True, inplace=True)\n",
    "    extracted_features.index = range(1, len(extracted_features)+1)\n",
    "    y.index = range(1, len(y)+1)\n",
    "    #print(extracted_features)\n",
    "    #print(y)\n",
    "    \n",
    "    # select most relevant features based on relevance table\n",
    "    if i == 0:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = temp\n",
    "    else:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = pd.concat([relevance_table, temp], axis=0)\n",
    "    features_filtered = select_features(extracted_features, y)\n",
    "    ts_extracted_dataset = pd.concat([ts_extracted_dataset, features_filtered], axis=1)\n",
    "\n",
    "# Select relevant features from the relevance table\n",
    "relevance_table = relevance_table[relevance_table.relevant]\n",
    "relevance_table.sort_values(\"p_value\", ascending=False, inplace=True)\n",
    "relevant_features_list = list(relevance_table.feature[:])\n",
    "print(relevance_table)\n",
    "\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset[relevant_features_list].copy()\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset_filtered.loc[:,~ts_extracted_dataset_filtered.columns.duplicated()]\n",
    "ts_extracted_dataset = ts_extracted_dataset_filtered\n",
    "ts_extracted_dataset\n",
    "ts_extracted_dataset.to_csv(dataDir+\"problematic_cows_7200s_5percent_extracted_features.csv\", index=False)\n",
    "relevance_table.to_csv(dataDir+\"problematic_cows_7200s_5percent_relevance_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7621dc3-75b5-4db0-99ad-1a9a52619e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Total_MilkProduction__median</th>\n",
       "      <th>Total_MilkProduction__mean</th>\n",
       "      <th>Total_MilkProduction__root_mean_square</th>\n",
       "      <th>Total_MilkProduction__standard_deviation</th>\n",
       "      <th>Total_MilkProduction__variance</th>\n",
       "      <th>Total_timeDelta_Seconds__minimum</th>\n",
       "      <th>Age__length</th>\n",
       "      <th>Total_MilkProduction__length</th>\n",
       "      <th>Total_timeDelta_Seconds__length</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>Total_timeDelta_Seconds__median</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.368681</td>\n",
       "      <td>-0.298642</td>\n",
       "      <td>-0.357890</td>\n",
       "      <td>-0.969843</td>\n",
       "      <td>-0.890778</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>0.639769</td>\n",
       "      <td>0.639769</td>\n",
       "      <td>0.639769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462777</td>\n",
       "      <td>-0.336598</td>\n",
       "      <td>-0.380941</td>\n",
       "      <td>-0.460791</td>\n",
       "      <td>-0.446712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.135462</td>\n",
       "      <td>-0.213517</td>\n",
       "      <td>-0.243649</td>\n",
       "      <td>-0.495157</td>\n",
       "      <td>-0.542947</td>\n",
       "      <td>0.096884</td>\n",
       "      <td>-1.226896</td>\n",
       "      <td>-1.226896</td>\n",
       "      <td>-1.226896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201635</td>\n",
       "      <td>-0.104917</td>\n",
       "      <td>-0.153190</td>\n",
       "      <td>0.139347</td>\n",
       "      <td>0.062871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.266064</td>\n",
       "      <td>-0.296577</td>\n",
       "      <td>-0.229153</td>\n",
       "      <td>0.532593</td>\n",
       "      <td>0.398038</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275404</td>\n",
       "      <td>-0.288535</td>\n",
       "      <td>-0.231043</td>\n",
       "      <td>-0.270557</td>\n",
       "      <td>-0.251185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.031024</td>\n",
       "      <td>-0.951309</td>\n",
       "      <td>-0.914826</td>\n",
       "      <td>-0.307539</td>\n",
       "      <td>-0.390348</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.740296</td>\n",
       "      <td>-0.382850</td>\n",
       "      <td>-0.545944</td>\n",
       "      <td>-0.711919</td>\n",
       "      <td>-0.660877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.905086</td>\n",
       "      <td>-1.133597</td>\n",
       "      <td>-1.119767</td>\n",
       "      <td>-0.704511</td>\n",
       "      <td>-0.703113</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>-1.147221</td>\n",
       "      <td>-1.147221</td>\n",
       "      <td>-1.147221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715119</td>\n",
       "      <td>-0.379881</td>\n",
       "      <td>-0.552916</td>\n",
       "      <td>-0.696593</td>\n",
       "      <td>-0.661546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.044940</td>\n",
       "      <td>0.150125</td>\n",
       "      <td>0.017829</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>1.029606</td>\n",
       "      <td>1.029606</td>\n",
       "      <td>1.029606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325744</td>\n",
       "      <td>-0.302781</td>\n",
       "      <td>-0.443688</td>\n",
       "      <td>-0.387841</td>\n",
       "      <td>-0.485322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.678985</td>\n",
       "      <td>1.465927</td>\n",
       "      <td>1.413098</td>\n",
       "      <td>0.591823</td>\n",
       "      <td>0.460102</td>\n",
       "      <td>1.420641</td>\n",
       "      <td>-1.289497</td>\n",
       "      <td>-1.289497</td>\n",
       "      <td>-1.289497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487628</td>\n",
       "      <td>0.047339</td>\n",
       "      <td>1.113385</td>\n",
       "      <td>0.685299</td>\n",
       "      <td>0.911508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.733137</td>\n",
       "      <td>2.849418</td>\n",
       "      <td>2.859449</td>\n",
       "      <td>2.446820</td>\n",
       "      <td>2.835927</td>\n",
       "      <td>0.384657</td>\n",
       "      <td>-0.270799</td>\n",
       "      <td>-0.270799</td>\n",
       "      <td>-0.270799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081325</td>\n",
       "      <td>-0.224445</td>\n",
       "      <td>0.172169</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.121611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-1.376189</td>\n",
       "      <td>-1.431972</td>\n",
       "      <td>-1.359796</td>\n",
       "      <td>-0.328640</td>\n",
       "      <td>-0.407938</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>0.796273</td>\n",
       "      <td>0.796273</td>\n",
       "      <td>0.796273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.512135</td>\n",
       "      <td>-0.347000</td>\n",
       "      <td>-0.376293</td>\n",
       "      <td>-0.494722</td>\n",
       "      <td>-0.457901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-1.674710</td>\n",
       "      <td>-1.664202</td>\n",
       "      <td>-1.680814</td>\n",
       "      <td>-1.516320</td>\n",
       "      <td>-1.223311</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>0.764972</td>\n",
       "      <td>0.764972</td>\n",
       "      <td>0.764972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.665091</td>\n",
       "      <td>-0.373256</td>\n",
       "      <td>-0.518056</td>\n",
       "      <td>-0.649808</td>\n",
       "      <td>-0.618554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.904697</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.696100</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>-0.169858</td>\n",
       "      <td>-0.018226</td>\n",
       "      <td>-0.048848</td>\n",
       "      <td>-0.048848</td>\n",
       "      <td>-0.048848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196927</td>\n",
       "      <td>-0.264373</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>-0.114937</td>\n",
       "      <td>-0.001870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1.674321</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>1.739760</td>\n",
       "      <td>2.050451</td>\n",
       "      <td>2.257919</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>0.969850</td>\n",
       "      <td>0.969850</td>\n",
       "      <td>0.969850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067060</td>\n",
       "      <td>-0.165623</td>\n",
       "      <td>0.302312</td>\n",
       "      <td>0.141099</td>\n",
       "      <td>0.242641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.163059</td>\n",
       "      <td>0.470057</td>\n",
       "      <td>0.544260</td>\n",
       "      <td>1.212108</td>\n",
       "      <td>1.161353</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>0.343834</td>\n",
       "      <td>0.343834</td>\n",
       "      <td>0.343834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187519</td>\n",
       "      <td>-0.111613</td>\n",
       "      <td>-0.366997</td>\n",
       "      <td>0.043155</td>\n",
       "      <td>-0.179873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.713846</td>\n",
       "      <td>-0.663955</td>\n",
       "      <td>-0.687013</td>\n",
       "      <td>-0.773967</td>\n",
       "      <td>-0.753893</td>\n",
       "      <td>-0.363554</td>\n",
       "      <td>1.652776</td>\n",
       "      <td>1.652776</td>\n",
       "      <td>1.652776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384156</td>\n",
       "      <td>-0.318083</td>\n",
       "      <td>-0.446012</td>\n",
       "      <td>-0.411846</td>\n",
       "      <td>-0.445167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.275005</td>\n",
       "      <td>0.387266</td>\n",
       "      <td>0.305763</td>\n",
       "      <td>-0.713984</td>\n",
       "      <td>-0.710108</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>0.770663</td>\n",
       "      <td>0.770663</td>\n",
       "      <td>0.770663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378090</td>\n",
       "      <td>-0.316555</td>\n",
       "      <td>-0.415800</td>\n",
       "      <td>-0.403440</td>\n",
       "      <td>-0.432371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.512888</td>\n",
       "      <td>0.520057</td>\n",
       "      <td>0.535439</td>\n",
       "      <td>0.640285</td>\n",
       "      <td>0.511519</td>\n",
       "      <td>0.442212</td>\n",
       "      <td>-1.283806</td>\n",
       "      <td>-1.283806</td>\n",
       "      <td>-1.283806</td>\n",
       "      <td>...</td>\n",
       "      <td>3.432491</td>\n",
       "      <td>3.453876</td>\n",
       "      <td>2.316049</td>\n",
       "      <td>3.280086</td>\n",
       "      <td>3.072105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.722786</td>\n",
       "      <td>0.660650</td>\n",
       "      <td>0.727618</td>\n",
       "      <td>1.292955</td>\n",
       "      <td>1.259650</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>0.665379</td>\n",
       "      <td>0.665379</td>\n",
       "      <td>0.665379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496597</td>\n",
       "      <td>0.052626</td>\n",
       "      <td>0.290111</td>\n",
       "      <td>0.472525</td>\n",
       "      <td>0.450198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.648156</td>\n",
       "      <td>0.535790</td>\n",
       "      <td>0.664535</td>\n",
       "      <td>1.776195</td>\n",
       "      <td>1.880363</td>\n",
       "      <td>0.211993</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180399</td>\n",
       "      <td>-0.258981</td>\n",
       "      <td>-0.117168</td>\n",
       "      <td>-0.128525</td>\n",
       "      <td>-0.049780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>-1.264243</td>\n",
       "      <td>-1.324654</td>\n",
       "      <td>-1.238982</td>\n",
       "      <td>-0.114161</td>\n",
       "      <td>-0.224099</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.427561</td>\n",
       "      <td>-0.328600</td>\n",
       "      <td>-0.308897</td>\n",
       "      <td>-0.418852</td>\n",
       "      <td>-0.394313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.205427</td>\n",
       "      <td>-0.130832</td>\n",
       "      <td>-0.184612</td>\n",
       "      <td>-0.747467</td>\n",
       "      <td>-0.734658</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>-0.014702</td>\n",
       "      <td>-0.014702</td>\n",
       "      <td>-0.014702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337662</td>\n",
       "      <td>-0.306010</td>\n",
       "      <td>-0.451822</td>\n",
       "      <td>-0.387217</td>\n",
       "      <td>-0.459323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.709181</td>\n",
       "      <td>-0.693716</td>\n",
       "      <td>-0.709774</td>\n",
       "      <td>-0.708711</td>\n",
       "      <td>-0.706217</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291335</td>\n",
       "      <td>-0.293149</td>\n",
       "      <td>-0.407666</td>\n",
       "      <td>-0.329607</td>\n",
       "      <td>-0.377873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.302991</td>\n",
       "      <td>0.427148</td>\n",
       "      <td>0.454061</td>\n",
       "      <td>0.691959</td>\n",
       "      <td>0.566972</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>-0.094377</td>\n",
       "      <td>-0.094377</td>\n",
       "      <td>-0.094377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>-0.192425</td>\n",
       "      <td>-0.178754</td>\n",
       "      <td>-0.035083</td>\n",
       "      <td>-0.075548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1.595026</td>\n",
       "      <td>1.462600</td>\n",
       "      <td>1.426389</td>\n",
       "      <td>0.797906</td>\n",
       "      <td>0.682698</td>\n",
       "      <td>0.327102</td>\n",
       "      <td>-1.278115</td>\n",
       "      <td>-1.278115</td>\n",
       "      <td>-1.278115</td>\n",
       "      <td>...</td>\n",
       "      <td>2.298778</td>\n",
       "      <td>1.745602</td>\n",
       "      <td>0.798484</td>\n",
       "      <td>1.913355</td>\n",
       "      <td>1.355766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1.928530</td>\n",
       "      <td>1.685016</td>\n",
       "      <td>1.685591</td>\n",
       "      <td>1.409168</td>\n",
       "      <td>1.403733</td>\n",
       "      <td>0.557321</td>\n",
       "      <td>-1.286652</td>\n",
       "      <td>-1.286652</td>\n",
       "      <td>-1.286652</td>\n",
       "      <td>...</td>\n",
       "      <td>2.626971</td>\n",
       "      <td>2.189030</td>\n",
       "      <td>0.409797</td>\n",
       "      <td>2.136327</td>\n",
       "      <td>1.402555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>-1.273572</td>\n",
       "      <td>-1.205175</td>\n",
       "      <td>-1.192911</td>\n",
       "      <td>-0.780247</td>\n",
       "      <td>-0.758427</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>-1.235432</td>\n",
       "      <td>-1.235432</td>\n",
       "      <td>-1.235432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026083</td>\n",
       "      <td>-0.203540</td>\n",
       "      <td>-0.412314</td>\n",
       "      <td>-0.124447</td>\n",
       "      <td>-0.270813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.793140</td>\n",
       "      <td>-0.758133</td>\n",
       "      <td>-0.814060</td>\n",
       "      <td>-1.316737</td>\n",
       "      <td>-1.110289</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>1.271476</td>\n",
       "      <td>1.271476</td>\n",
       "      <td>1.271476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626974</td>\n",
       "      <td>-0.367559</td>\n",
       "      <td>-0.475062</td>\n",
       "      <td>-0.608881</td>\n",
       "      <td>-0.572117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.979327</td>\n",
       "      <td>0.893606</td>\n",
       "      <td>0.997278</td>\n",
       "      <td>1.833644</td>\n",
       "      <td>1.957935</td>\n",
       "      <td>0.384657</td>\n",
       "      <td>-1.369172</td>\n",
       "      <td>-1.369172</td>\n",
       "      <td>-1.369172</td>\n",
       "      <td>...</td>\n",
       "      <td>4.643907</td>\n",
       "      <td>5.828271</td>\n",
       "      <td>6.120420</td>\n",
       "      <td>5.056603</td>\n",
       "      <td>5.473723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.280058</td>\n",
       "      <td>-0.097401</td>\n",
       "      <td>-0.144133</td>\n",
       "      <td>-0.620728</td>\n",
       "      <td>-0.640295</td>\n",
       "      <td>-0.421108</td>\n",
       "      <td>1.769443</td>\n",
       "      <td>1.769443</td>\n",
       "      <td>1.769443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444553</td>\n",
       "      <td>-0.332519</td>\n",
       "      <td>-0.457051</td>\n",
       "      <td>-0.465975</td>\n",
       "      <td>-0.490735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>-1.231593</td>\n",
       "      <td>-1.293107</td>\n",
       "      <td>-1.343553</td>\n",
       "      <td>-1.700762</td>\n",
       "      <td>-1.319141</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.590369</td>\n",
       "      <td>-0.361559</td>\n",
       "      <td>-0.451822</td>\n",
       "      <td>-0.566590</td>\n",
       "      <td>-0.520859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>1.184560</td>\n",
       "      <td>1.206175</td>\n",
       "      <td>1.148683</td>\n",
       "      <td>0.317272</td>\n",
       "      <td>0.179609</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>0.153184</td>\n",
       "      <td>0.153184</td>\n",
       "      <td>0.153184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.259362</td>\n",
       "      <td>-0.283789</td>\n",
       "      <td>-0.034666</td>\n",
       "      <td>-0.190467</td>\n",
       "      <td>-0.091268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.240022</td>\n",
       "      <td>0.344104</td>\n",
       "      <td>0.305589</td>\n",
       "      <td>-0.145172</td>\n",
       "      <td>-0.251372</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>-1.252506</td>\n",
       "      <td>-1.252506</td>\n",
       "      <td>-1.252506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161726</td>\n",
       "      <td>-0.123649</td>\n",
       "      <td>0.505080</td>\n",
       "      <td>0.233833</td>\n",
       "      <td>0.332210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>-1.660716</td>\n",
       "      <td>-1.591776</td>\n",
       "      <td>-1.627929</td>\n",
       "      <td>-1.737535</td>\n",
       "      <td>-1.337257</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>-1.206977</td>\n",
       "      <td>-1.206977</td>\n",
       "      <td>-1.206977</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621310</td>\n",
       "      <td>-0.366664</td>\n",
       "      <td>-0.369321</td>\n",
       "      <td>-0.580052</td>\n",
       "      <td>-0.510199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>-0.984380</td>\n",
       "      <td>-0.864839</td>\n",
       "      <td>-0.834032</td>\n",
       "      <td>-0.299456</td>\n",
       "      <td>-0.383582</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>-0.361856</td>\n",
       "      <td>-0.361856</td>\n",
       "      <td>-0.361856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071770</td>\n",
       "      <td>-0.163616</td>\n",
       "      <td>0.136147</td>\n",
       "      <td>0.103804</td>\n",
       "      <td>0.156181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.107475</td>\n",
       "      <td>-0.139136</td>\n",
       "      <td>-0.157401</td>\n",
       "      <td>-0.283847</td>\n",
       "      <td>-0.370469</td>\n",
       "      <td>-0.363554</td>\n",
       "      <td>0.873102</td>\n",
       "      <td>0.873102</td>\n",
       "      <td>0.873102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351530</td>\n",
       "      <td>-0.309698</td>\n",
       "      <td>-0.353053</td>\n",
       "      <td>-0.364812</td>\n",
       "      <td>-0.372943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.760490</td>\n",
       "      <td>-0.828844</td>\n",
       "      <td>-0.857078</td>\n",
       "      <td>-0.978554</td>\n",
       "      <td>-0.896649</td>\n",
       "      <td>-0.363554</td>\n",
       "      <td>1.075134</td>\n",
       "      <td>1.075134</td>\n",
       "      <td>1.075134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.480508</td>\n",
       "      <td>-0.340443</td>\n",
       "      <td>-0.439040</td>\n",
       "      <td>-0.479069</td>\n",
       "      <td>-0.466131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>-0.387339</td>\n",
       "      <td>-0.367472</td>\n",
       "      <td>-0.376723</td>\n",
       "      <td>-0.358838</td>\n",
       "      <td>-0.432923</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>0.847492</td>\n",
       "      <td>0.847492</td>\n",
       "      <td>0.847492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.622541</td>\n",
       "      <td>-0.366860</td>\n",
       "      <td>-0.446593</td>\n",
       "      <td>-0.606721</td>\n",
       "      <td>-0.573494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>2.880065</td>\n",
       "      <td>2.816925</td>\n",
       "      <td>2.836384</td>\n",
       "      <td>2.522912</td>\n",
       "      <td>2.951263</td>\n",
       "      <td>-0.018226</td>\n",
       "      <td>-0.063076</td>\n",
       "      <td>-0.063076</td>\n",
       "      <td>-0.063076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280327</td>\n",
       "      <td>-0.066175</td>\n",
       "      <td>0.244213</td>\n",
       "      <td>0.281434</td>\n",
       "      <td>0.293264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>1.711636</td>\n",
       "      <td>1.770416</td>\n",
       "      <td>1.795954</td>\n",
       "      <td>1.751349</td>\n",
       "      <td>1.847064</td>\n",
       "      <td>7.348773</td>\n",
       "      <td>-1.298034</td>\n",
       "      <td>-1.298034</td>\n",
       "      <td>-1.298034</td>\n",
       "      <td>...</td>\n",
       "      <td>1.444864</td>\n",
       "      <td>0.786941</td>\n",
       "      <td>2.238776</td>\n",
       "      <td>1.731999</td>\n",
       "      <td>2.041786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>-0.310376</td>\n",
       "      <td>-0.264157</td>\n",
       "      <td>-0.341948</td>\n",
       "      <td>-1.229299</td>\n",
       "      <td>-1.057719</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>0.824728</td>\n",
       "      <td>0.824728</td>\n",
       "      <td>0.824728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621253</td>\n",
       "      <td>-0.366655</td>\n",
       "      <td>-0.447755</td>\n",
       "      <td>-0.597978</td>\n",
       "      <td>-0.553189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.137794</td>\n",
       "      <td>-0.293324</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>-1.016669</td>\n",
       "      <td>-0.922119</td>\n",
       "      <td>0.039329</td>\n",
       "      <td>-1.275270</td>\n",
       "      <td>-1.275270</td>\n",
       "      <td>-1.275270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.602939</td>\n",
       "      <td>-0.363678</td>\n",
       "      <td>-0.291467</td>\n",
       "      <td>-0.532403</td>\n",
       "      <td>-0.427787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>-0.564585</td>\n",
       "      <td>-0.748907</td>\n",
       "      <td>-0.641195</td>\n",
       "      <td>0.551468</td>\n",
       "      <td>0.417724</td>\n",
       "      <td>-0.363554</td>\n",
       "      <td>1.140582</td>\n",
       "      <td>1.140582</td>\n",
       "      <td>1.140582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115616</td>\n",
       "      <td>-0.236827</td>\n",
       "      <td>-0.396047</td>\n",
       "      <td>-0.193883</td>\n",
       "      <td>-0.306982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>-0.662537</td>\n",
       "      <td>-0.570948</td>\n",
       "      <td>-0.640031</td>\n",
       "      <td>-1.360747</td>\n",
       "      <td>-1.136045</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>0.907248</td>\n",
       "      <td>0.907248</td>\n",
       "      <td>0.907248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516163</td>\n",
       "      <td>-0.347807</td>\n",
       "      <td>-0.487844</td>\n",
       "      <td>-0.524507</td>\n",
       "      <td>-0.528933</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.937348</td>\n",
       "      <td>0.889083</td>\n",
       "      <td>0.897780</td>\n",
       "      <td>0.861724</td>\n",
       "      <td>0.753726</td>\n",
       "      <td>-0.075780</td>\n",
       "      <td>0.190176</td>\n",
       "      <td>0.190176</td>\n",
       "      <td>0.190176</td>\n",
       "      <td>...</td>\n",
       "      <td>1.618814</td>\n",
       "      <td>0.959370</td>\n",
       "      <td>1.660684</td>\n",
       "      <td>1.653034</td>\n",
       "      <td>1.692235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.601512</td>\n",
       "      <td>0.491029</td>\n",
       "      <td>0.500458</td>\n",
       "      <td>0.550615</td>\n",
       "      <td>0.416832</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>0.614159</td>\n",
       "      <td>0.614159</td>\n",
       "      <td>0.614159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241133</td>\n",
       "      <td>-0.085770</td>\n",
       "      <td>0.234917</td>\n",
       "      <td>0.275829</td>\n",
       "      <td>0.329784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>-0.741832</td>\n",
       "      <td>-0.835729</td>\n",
       "      <td>-0.836552</td>\n",
       "      <td>-0.636522</td>\n",
       "      <td>-0.652268</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.598879</td>\n",
       "      <td>-0.363000</td>\n",
       "      <td>-0.523866</td>\n",
       "      <td>-0.595375</td>\n",
       "      <td>-0.582187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>-1.261911</td>\n",
       "      <td>-1.648131</td>\n",
       "      <td>-1.493779</td>\n",
       "      <td>0.219559</td>\n",
       "      <td>0.084208</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425833</td>\n",
       "      <td>-0.328195</td>\n",
       "      <td>-0.199088</td>\n",
       "      <td>-0.383514</td>\n",
       "      <td>-0.313861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>-0.501616</td>\n",
       "      <td>-0.511010</td>\n",
       "      <td>-0.488453</td>\n",
       "      <td>-0.106485</td>\n",
       "      <td>-0.217312</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>-1.178522</td>\n",
       "      <td>-1.178522</td>\n",
       "      <td>-1.178522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693166</td>\n",
       "      <td>-0.377093</td>\n",
       "      <td>-0.524447</td>\n",
       "      <td>-0.661545</td>\n",
       "      <td>-0.604880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>-0.399000</td>\n",
       "      <td>-0.409409</td>\n",
       "      <td>-0.381845</td>\n",
       "      <td>0.029738</td>\n",
       "      <td>-0.094482</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>0.449119</td>\n",
       "      <td>0.449119</td>\n",
       "      <td>0.449119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468963</td>\n",
       "      <td>-0.337953</td>\n",
       "      <td>-0.426258</td>\n",
       "      <td>-0.472789</td>\n",
       "      <td>-0.468075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.396667</td>\n",
       "      <td>-0.319274</td>\n",
       "      <td>-0.334738</td>\n",
       "      <td>-0.395820</td>\n",
       "      <td>-0.463219</td>\n",
       "      <td>-0.075780</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452751</td>\n",
       "      <td>-0.334369</td>\n",
       "      <td>-0.369321</td>\n",
       "      <td>-0.443240</td>\n",
       "      <td>-0.417668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>-0.597236</td>\n",
       "      <td>-0.665346</td>\n",
       "      <td>-0.702204</td>\n",
       "      <td>-0.959727</td>\n",
       "      <td>-0.883937</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>1.120663</td>\n",
       "      <td>1.120663</td>\n",
       "      <td>1.120663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509065</td>\n",
       "      <td>-0.346380</td>\n",
       "      <td>-0.458213</td>\n",
       "      <td>-0.505646</td>\n",
       "      <td>-0.490075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>-0.060831</td>\n",
       "      <td>0.149585</td>\n",
       "      <td>0.113509</td>\n",
       "      <td>-0.273555</td>\n",
       "      <td>-0.361791</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>0.144648</td>\n",
       "      <td>0.144648</td>\n",
       "      <td>0.144648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168840</td>\n",
       "      <td>-0.255147</td>\n",
       "      <td>-0.272875</td>\n",
       "      <td>-0.194205</td>\n",
       "      <td>-0.218510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>-0.168112</td>\n",
       "      <td>-0.265915</td>\n",
       "      <td>-0.307873</td>\n",
       "      <td>-0.696013</td>\n",
       "      <td>-0.696819</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370960</td>\n",
       "      <td>-0.314741</td>\n",
       "      <td>-0.333880</td>\n",
       "      <td>-0.382260</td>\n",
       "      <td>-0.387591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>1.016642</td>\n",
       "      <td>1.047862</td>\n",
       "      <td>0.985627</td>\n",
       "      <td>0.122789</td>\n",
       "      <td>-0.007983</td>\n",
       "      <td>-0.075780</td>\n",
       "      <td>1.109281</td>\n",
       "      <td>1.109281</td>\n",
       "      <td>1.109281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330491</td>\n",
       "      <td>-0.304073</td>\n",
       "      <td>-0.177592</td>\n",
       "      <td>-0.292046</td>\n",
       "      <td>-0.228055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>0.109419</td>\n",
       "      <td>0.183499</td>\n",
       "      <td>0.184780</td>\n",
       "      <td>0.210701</td>\n",
       "      <td>0.075674</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>0.534485</td>\n",
       "      <td>0.534485</td>\n",
       "      <td>0.534485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146386</td>\n",
       "      <td>-0.247552</td>\n",
       "      <td>-0.333880</td>\n",
       "      <td>-0.196031</td>\n",
       "      <td>-0.258900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0.386950</td>\n",
       "      <td>0.613588</td>\n",
       "      <td>0.647334</td>\n",
       "      <td>0.914155</td>\n",
       "      <td>0.812822</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>0.144648</td>\n",
       "      <td>0.144648</td>\n",
       "      <td>0.144648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108343</td>\n",
       "      <td>-0.234239</td>\n",
       "      <td>-0.191535</td>\n",
       "      <td>-0.133039</td>\n",
       "      <td>-0.155758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>-0.116119</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.363554</td>\n",
       "      <td>0.984078</td>\n",
       "      <td>0.984078</td>\n",
       "      <td>0.984078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287465</td>\n",
       "      <td>-0.292037</td>\n",
       "      <td>-0.353634</td>\n",
       "      <td>-0.317083</td>\n",
       "      <td>-0.350370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>-0.508613</td>\n",
       "      <td>-0.403390</td>\n",
       "      <td>-0.431540</td>\n",
       "      <td>-0.625692</td>\n",
       "      <td>-0.644064</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>1.109281</td>\n",
       "      <td>1.109281</td>\n",
       "      <td>1.109281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462469</td>\n",
       "      <td>-0.336530</td>\n",
       "      <td>-0.401857</td>\n",
       "      <td>-0.466729</td>\n",
       "      <td>-0.462575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>-0.513277</td>\n",
       "      <td>-0.466609</td>\n",
       "      <td>-0.469065</td>\n",
       "      <td>-0.357427</td>\n",
       "      <td>-0.431761</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>1.348305</td>\n",
       "      <td>1.348305</td>\n",
       "      <td>1.348305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452005</td>\n",
       "      <td>-0.334202</td>\n",
       "      <td>-0.372226</td>\n",
       "      <td>-0.452159</td>\n",
       "      <td>-0.441260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>-0.280058</td>\n",
       "      <td>-0.330416</td>\n",
       "      <td>-0.367955</td>\n",
       "      <td>-0.689754</td>\n",
       "      <td>-0.692173</td>\n",
       "      <td>-0.305999</td>\n",
       "      <td>1.117817</td>\n",
       "      <td>1.117817</td>\n",
       "      <td>1.117817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.340901</td>\n",
       "      <td>-0.354215</td>\n",
       "      <td>-0.467932</td>\n",
       "      <td>-0.434883</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>0.237531</td>\n",
       "      <td>0.273856</td>\n",
       "      <td>0.640953</td>\n",
       "      <td>0.512231</td>\n",
       "      <td>-0.018226</td>\n",
       "      <td>0.770663</td>\n",
       "      <td>0.770663</td>\n",
       "      <td>0.770663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451811</td>\n",
       "      <td>-0.334158</td>\n",
       "      <td>-0.366997</td>\n",
       "      <td>-0.451599</td>\n",
       "      <td>-0.440126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Total_MilkProduction__median  Total_MilkProduction__mean  \\\n",
       "1    1                     -0.368681                   -0.298642   \n",
       "2    2                     -0.135462                   -0.213517   \n",
       "3    3                     -0.266064                   -0.296577   \n",
       "4    4                     -1.031024                   -0.951309   \n",
       "5    5                     -0.905086                   -1.133597   \n",
       "6    6                      0.006802                    0.038803   \n",
       "7    7                      1.678985                    1.465927   \n",
       "8    8                      2.733137                    2.849418   \n",
       "9    9                     -1.376189                   -1.431972   \n",
       "10  10                     -1.674710                   -1.664202   \n",
       "11  11                      0.904697                    0.753231   \n",
       "12  12                      1.674321                    1.678331   \n",
       "13  13                      0.163059                    0.470057   \n",
       "14  14                     -0.713846                   -0.663955   \n",
       "15  15                      0.275005                    0.387266   \n",
       "16  16                      0.512888                    0.520057   \n",
       "17  17                      0.722786                    0.660650   \n",
       "18  18                      0.648156                    0.535790   \n",
       "19  19                     -1.264243                   -1.324654   \n",
       "20  20                     -0.205427                   -0.130832   \n",
       "21  21                     -0.709181                   -0.693716   \n",
       "22  22                      0.302991                    0.427148   \n",
       "23  23                      1.595026                    1.462600   \n",
       "24  24                      1.928530                    1.685016   \n",
       "25  25                     -1.273572                   -1.205175   \n",
       "26  26                     -0.793140                   -0.758133   \n",
       "27  27                      0.979327                    0.893606   \n",
       "28  28                     -0.280058                   -0.097401   \n",
       "29  29                     -1.231593                   -1.293107   \n",
       "30  30                      1.184560                    1.206175   \n",
       "31  31                      0.240022                    0.344104   \n",
       "32  32                     -1.660716                   -1.591776   \n",
       "33  33                     -0.984380                   -0.864839   \n",
       "34  34                     -0.107475                   -0.139136   \n",
       "35  35                     -0.760490                   -0.828844   \n",
       "36  36                     -0.387339                   -0.367472   \n",
       "37  37                      2.880065                    2.816925   \n",
       "38  38                      1.711636                    1.770416   \n",
       "39  39                     -0.310376                   -0.264157   \n",
       "40  40                     -0.137794                   -0.293324   \n",
       "41  41                     -0.564585                   -0.748907   \n",
       "42  42                     -0.662537                   -0.570948   \n",
       "43  43                      0.937348                    0.889083   \n",
       "44  44                      0.601512                    0.491029   \n",
       "45  45                     -0.741832                   -0.835729   \n",
       "46  46                     -1.261911                   -1.648131   \n",
       "47  47                     -0.501616                   -0.511010   \n",
       "48  48                     -0.399000                   -0.409409   \n",
       "49  49                     -0.396667                   -0.319274   \n",
       "50  50                     -0.597236                   -0.665346   \n",
       "51  51                     -0.060831                    0.149585   \n",
       "52  52                     -0.168112                   -0.265915   \n",
       "53  53                      1.016642                    1.047862   \n",
       "54  54                      0.109419                    0.183499   \n",
       "55  55                      0.386950                    0.613588   \n",
       "56  56                      0.011467                    0.103725   \n",
       "57  57                     -0.508613                   -0.403390   \n",
       "58  58                     -0.513277                   -0.466609   \n",
       "59  59                     -0.280058                   -0.330416   \n",
       "60  60                      0.027792                    0.237531   \n",
       "\n",
       "    Total_MilkProduction__root_mean_square  \\\n",
       "1                                -0.357890   \n",
       "2                                -0.243649   \n",
       "3                                -0.229153   \n",
       "4                                -0.914826   \n",
       "5                                -1.119767   \n",
       "6                                 0.044940   \n",
       "7                                 1.413098   \n",
       "8                                 2.859449   \n",
       "9                                -1.359796   \n",
       "10                               -1.680814   \n",
       "11                                0.696100   \n",
       "12                                1.739760   \n",
       "13                                0.544260   \n",
       "14                               -0.687013   \n",
       "15                                0.305763   \n",
       "16                                0.535439   \n",
       "17                                0.727618   \n",
       "18                                0.664535   \n",
       "19                               -1.238982   \n",
       "20                               -0.184612   \n",
       "21                               -0.709774   \n",
       "22                                0.454061   \n",
       "23                                1.426389   \n",
       "24                                1.685591   \n",
       "25                               -1.192911   \n",
       "26                               -0.814060   \n",
       "27                                0.997278   \n",
       "28                               -0.144133   \n",
       "29                               -1.343553   \n",
       "30                                1.148683   \n",
       "31                                0.305589   \n",
       "32                               -1.627929   \n",
       "33                               -0.834032   \n",
       "34                               -0.157401   \n",
       "35                               -0.857078   \n",
       "36                               -0.376723   \n",
       "37                                2.836384   \n",
       "38                                1.795954   \n",
       "39                               -0.341948   \n",
       "40                               -0.356000   \n",
       "41                               -0.641195   \n",
       "42                               -0.640031   \n",
       "43                                0.897780   \n",
       "44                                0.500458   \n",
       "45                               -0.836552   \n",
       "46                               -1.493779   \n",
       "47                               -0.488453   \n",
       "48                               -0.381845   \n",
       "49                               -0.334738   \n",
       "50                               -0.702204   \n",
       "51                                0.113509   \n",
       "52                               -0.307873   \n",
       "53                                0.985627   \n",
       "54                                0.184780   \n",
       "55                                0.647334   \n",
       "56                                0.083037   \n",
       "57                               -0.431540   \n",
       "58                               -0.469065   \n",
       "59                               -0.367955   \n",
       "60                                0.273856   \n",
       "\n",
       "    Total_MilkProduction__standard_deviation  Total_MilkProduction__variance  \\\n",
       "1                                  -0.969843                       -0.890778   \n",
       "2                                  -0.495157                       -0.542947   \n",
       "3                                   0.532593                        0.398038   \n",
       "4                                  -0.307539                       -0.390348   \n",
       "5                                  -0.704511                       -0.703113   \n",
       "6                                   0.150125                        0.017829   \n",
       "7                                   0.591823                        0.460102   \n",
       "8                                   2.446820                        2.835927   \n",
       "9                                  -0.328640                       -0.407938   \n",
       "10                                 -1.516320                       -1.223311   \n",
       "11                                 -0.053261                       -0.169858   \n",
       "12                                  2.050451                        2.257919   \n",
       "13                                  1.212108                        1.161353   \n",
       "14                                 -0.773967                       -0.753893   \n",
       "15                                 -0.713984                       -0.710108   \n",
       "16                                  0.640285                        0.511519   \n",
       "17                                  1.292955                        1.259650   \n",
       "18                                  1.776195                        1.880363   \n",
       "19                                 -0.114161                       -0.224099   \n",
       "20                                 -0.747467                       -0.734658   \n",
       "21                                 -0.708711                       -0.706217   \n",
       "22                                  0.691959                        0.566972   \n",
       "23                                  0.797906                        0.682698   \n",
       "24                                  1.409168                        1.403733   \n",
       "25                                 -0.780247                       -0.758427   \n",
       "26                                 -1.316737                       -1.110289   \n",
       "27                                  1.833644                        1.957935   \n",
       "28                                 -0.620728                       -0.640295   \n",
       "29                                 -1.700762                       -1.319141   \n",
       "30                                  0.317272                        0.179609   \n",
       "31                                 -0.145172                       -0.251372   \n",
       "32                                 -1.737535                       -1.337257   \n",
       "33                                 -0.299456                       -0.383582   \n",
       "34                                 -0.283847                       -0.370469   \n",
       "35                                 -0.978554                       -0.896649   \n",
       "36                                 -0.358838                       -0.432923   \n",
       "37                                  2.522912                        2.951263   \n",
       "38                                  1.751349                        1.847064   \n",
       "39                                 -1.229299                       -1.057719   \n",
       "40                                 -1.016669                       -0.922119   \n",
       "41                                  0.551468                        0.417724   \n",
       "42                                 -1.360747                       -1.136045   \n",
       "43                                  0.861724                        0.753726   \n",
       "44                                  0.550615                        0.416832   \n",
       "45                                 -0.636522                       -0.652268   \n",
       "46                                  0.219559                        0.084208   \n",
       "47                                 -0.106485                       -0.217312   \n",
       "48                                  0.029738                       -0.094482   \n",
       "49                                 -0.395820                       -0.463219   \n",
       "50                                 -0.959727                       -0.883937   \n",
       "51                                 -0.273555                       -0.361791   \n",
       "52                                 -0.696013                       -0.696819   \n",
       "53                                  0.122789                       -0.007983   \n",
       "54                                  0.210701                        0.075674   \n",
       "55                                  0.914155                        0.812822   \n",
       "56                                 -0.116119                       -0.225828   \n",
       "57                                 -0.625692                       -0.644064   \n",
       "58                                 -0.357427                       -0.431761   \n",
       "59                                 -0.689754                       -0.692173   \n",
       "60                                  0.640953                        0.512231   \n",
       "\n",
       "    Total_timeDelta_Seconds__minimum  Age__length  \\\n",
       "1                          -0.305999     0.639769   \n",
       "2                           0.096884    -1.226896   \n",
       "3                          -0.190890     0.719444   \n",
       "4                          -0.248444    -1.209823   \n",
       "5                          -0.190890    -1.147221   \n",
       "6                          -0.305999     1.029606   \n",
       "7                           1.420641    -1.289497   \n",
       "8                           0.384657    -0.270799   \n",
       "9                          -0.305999     0.796273   \n",
       "10                         -0.305999     0.764972   \n",
       "11                         -0.018226    -0.048848   \n",
       "12                         -0.190890     0.969850   \n",
       "13                         -0.190890     0.343834   \n",
       "14                         -0.363554     1.652776   \n",
       "15                         -0.305999     0.770663   \n",
       "16                          0.442212    -1.283806   \n",
       "17                         -0.305999     0.665379   \n",
       "18                          0.211993    -1.221205   \n",
       "19                         -0.133335    -1.209823   \n",
       "20                         -0.190890    -0.014702   \n",
       "21                         -0.248444    -1.221205   \n",
       "22                         -0.133335    -0.094377   \n",
       "23                          0.327102    -1.278115   \n",
       "24                          0.557321    -1.286652   \n",
       "25                         -0.190890    -1.235432   \n",
       "26                         -0.305999     1.271476   \n",
       "27                          0.384657    -1.369172   \n",
       "28                         -0.421108     1.769443   \n",
       "29                         -0.248444    -1.181367   \n",
       "30                         -0.305999     0.153184   \n",
       "31                         -0.190890    -1.252506   \n",
       "32                         -0.133335    -1.206977   \n",
       "33                         -0.190890    -0.361856   \n",
       "34                         -0.363554     0.873102   \n",
       "35                         -0.363554     1.075134   \n",
       "36                         -0.133335     0.847492   \n",
       "37                         -0.018226    -0.063076   \n",
       "38                          7.348773    -1.298034   \n",
       "39                         -0.248444     0.824728   \n",
       "40                          0.039329    -1.275270   \n",
       "41                         -0.363554     1.140582   \n",
       "42                         -0.305999     0.907248   \n",
       "43                         -0.075780     0.190176   \n",
       "44                         -0.133335     0.614159   \n",
       "45                         -0.248444    -1.181367   \n",
       "46                         -0.133335    -1.224050   \n",
       "47                         -0.133335    -1.178522   \n",
       "48                         -0.190890     0.449119   \n",
       "49                         -0.075780     0.002371   \n",
       "50                         -0.248444     1.120663   \n",
       "51                         -0.305999     0.144648   \n",
       "52                         -0.190890    -1.224050   \n",
       "53                         -0.075780     1.109281   \n",
       "54                         -0.248444     0.534485   \n",
       "55                         -0.133335     0.144648   \n",
       "56                         -0.363554     0.984078   \n",
       "57                         -0.305999     1.109281   \n",
       "58                         -0.305999     1.348305   \n",
       "59                         -0.305999     1.117817   \n",
       "60                         -0.018226     0.770663   \n",
       "\n",
       "    Total_MilkProduction__length  Total_timeDelta_Seconds__length  ...  \\\n",
       "1                       0.639769                         0.639769  ...   \n",
       "2                      -1.226896                        -1.226896  ...   \n",
       "3                       0.719444                         0.719444  ...   \n",
       "4                      -1.209823                        -1.209823  ...   \n",
       "5                      -1.147221                        -1.147221  ...   \n",
       "6                       1.029606                         1.029606  ...   \n",
       "7                      -1.289497                        -1.289497  ...   \n",
       "8                      -0.270799                        -0.270799  ...   \n",
       "9                       0.796273                         0.796273  ...   \n",
       "10                      0.764972                         0.764972  ...   \n",
       "11                     -0.048848                        -0.048848  ...   \n",
       "12                      0.969850                         0.969850  ...   \n",
       "13                      0.343834                         0.343834  ...   \n",
       "14                      1.652776                         1.652776  ...   \n",
       "15                      0.770663                         0.770663  ...   \n",
       "16                     -1.283806                        -1.283806  ...   \n",
       "17                      0.665379                         0.665379  ...   \n",
       "18                     -1.221205                        -1.221205  ...   \n",
       "19                     -1.209823                        -1.209823  ...   \n",
       "20                     -0.014702                        -0.014702  ...   \n",
       "21                     -1.221205                        -1.221205  ...   \n",
       "22                     -0.094377                        -0.094377  ...   \n",
       "23                     -1.278115                        -1.278115  ...   \n",
       "24                     -1.286652                        -1.286652  ...   \n",
       "25                     -1.235432                        -1.235432  ...   \n",
       "26                      1.271476                         1.271476  ...   \n",
       "27                     -1.369172                        -1.369172  ...   \n",
       "28                      1.769443                         1.769443  ...   \n",
       "29                     -1.181367                        -1.181367  ...   \n",
       "30                      0.153184                         0.153184  ...   \n",
       "31                     -1.252506                        -1.252506  ...   \n",
       "32                     -1.206977                        -1.206977  ...   \n",
       "33                     -0.361856                        -0.361856  ...   \n",
       "34                      0.873102                         0.873102  ...   \n",
       "35                      1.075134                         1.075134  ...   \n",
       "36                      0.847492                         0.847492  ...   \n",
       "37                     -0.063076                        -0.063076  ...   \n",
       "38                     -1.298034                        -1.298034  ...   \n",
       "39                      0.824728                         0.824728  ...   \n",
       "40                     -1.275270                        -1.275270  ...   \n",
       "41                      1.140582                         1.140582  ...   \n",
       "42                      0.907248                         0.907248  ...   \n",
       "43                      0.190176                         0.190176  ...   \n",
       "44                      0.614159                         0.614159  ...   \n",
       "45                     -1.181367                        -1.181367  ...   \n",
       "46                     -1.224050                        -1.224050  ...   \n",
       "47                     -1.178522                        -1.178522  ...   \n",
       "48                      0.449119                         0.449119  ...   \n",
       "49                      0.002371                         0.002371  ...   \n",
       "50                      1.120663                         1.120663  ...   \n",
       "51                      0.144648                         0.144648  ...   \n",
       "52                     -1.224050                        -1.224050  ...   \n",
       "53                      1.109281                         1.109281  ...   \n",
       "54                      0.534485                         0.534485  ...   \n",
       "55                      0.144648                         0.144648  ...   \n",
       "56                      0.984078                         0.984078  ...   \n",
       "57                      1.109281                         1.109281  ...   \n",
       "58                      1.348305                         1.348305  ...   \n",
       "59                      1.117817                         1.117817  ...   \n",
       "60                      0.770663                         0.770663  ...   \n",
       "\n",
       "    Total_timeDelta_Seconds__standard_deviation  \\\n",
       "1                                     -0.462777   \n",
       "2                                      0.201635   \n",
       "3                                     -0.275404   \n",
       "4                                     -0.740296   \n",
       "5                                     -0.715119   \n",
       "6                                     -0.325744   \n",
       "7                                      0.487628   \n",
       "8                                     -0.081325   \n",
       "9                                     -0.512135   \n",
       "10                                    -0.665091   \n",
       "11                                    -0.196927   \n",
       "12                                     0.067060   \n",
       "13                                     0.187519   \n",
       "14                                    -0.384156   \n",
       "15                                    -0.378090   \n",
       "16                                     3.432491   \n",
       "17                                     0.496597   \n",
       "18                                    -0.180399   \n",
       "19                                    -0.427561   \n",
       "20                                    -0.337662   \n",
       "21                                    -0.291335   \n",
       "22                                     0.002090   \n",
       "23                                     2.298778   \n",
       "24                                     2.626971   \n",
       "25                                    -0.026083   \n",
       "26                                    -0.626974   \n",
       "27                                     4.643907   \n",
       "28                                    -0.444553   \n",
       "29                                    -0.590369   \n",
       "30                                    -0.259362   \n",
       "31                                     0.161726   \n",
       "32                                    -0.621310   \n",
       "33                                     0.071770   \n",
       "34                                    -0.351530   \n",
       "35                                    -0.480508   \n",
       "36                                    -0.622541   \n",
       "37                                     0.280327   \n",
       "38                                     1.444864   \n",
       "39                                    -0.621253   \n",
       "40                                    -0.602939   \n",
       "41                                    -0.115616   \n",
       "42                                    -0.516163   \n",
       "43                                     1.618814   \n",
       "44                                     0.241133   \n",
       "45                                    -0.598879   \n",
       "46                                    -0.425833   \n",
       "47                                    -0.693166   \n",
       "48                                    -0.468963   \n",
       "49                                    -0.452751   \n",
       "50                                    -0.509065   \n",
       "51                                    -0.168840   \n",
       "52                                    -0.370960   \n",
       "53                                    -0.330491   \n",
       "54                                    -0.146386   \n",
       "55                                    -0.108343   \n",
       "56                                    -0.287465   \n",
       "57                                    -0.462469   \n",
       "58                                    -0.452005   \n",
       "59                                    -0.482659   \n",
       "60                                    -0.451811   \n",
       "\n",
       "    Total_timeDelta_Seconds__variance  Total_timeDelta_Seconds__median  \\\n",
       "1                           -0.336598                        -0.380941   \n",
       "2                           -0.104917                        -0.153190   \n",
       "3                           -0.288535                        -0.231043   \n",
       "4                           -0.382850                        -0.545944   \n",
       "5                           -0.379881                        -0.552916   \n",
       "6                           -0.302781                        -0.443688   \n",
       "7                            0.047339                         1.113385   \n",
       "8                           -0.224445                         0.172169   \n",
       "9                           -0.347000                        -0.376293   \n",
       "10                          -0.373256                        -0.518056   \n",
       "11                          -0.264373                         0.074561   \n",
       "12                          -0.165623                         0.302312   \n",
       "13                          -0.111613                        -0.366997   \n",
       "14                          -0.318083                        -0.446012   \n",
       "15                          -0.316555                        -0.415800   \n",
       "16                           3.453876                         2.316049   \n",
       "17                           0.052626                         0.290111   \n",
       "18                          -0.258981                        -0.117168   \n",
       "19                          -0.328600                        -0.308897   \n",
       "20                          -0.306010                        -0.451822   \n",
       "21                          -0.293149                        -0.407666   \n",
       "22                          -0.192425                        -0.178754   \n",
       "23                           1.745602                         0.798484   \n",
       "24                           2.189030                         0.409797   \n",
       "25                          -0.203540                        -0.412314   \n",
       "26                          -0.367559                        -0.475062   \n",
       "27                           5.828271                         6.120420   \n",
       "28                          -0.332519                        -0.457051   \n",
       "29                          -0.361559                        -0.451822   \n",
       "30                          -0.283789                        -0.034666   \n",
       "31                          -0.123649                         0.505080   \n",
       "32                          -0.366664                        -0.369321   \n",
       "33                          -0.163616                         0.136147   \n",
       "34                          -0.309698                        -0.353053   \n",
       "35                          -0.340443                        -0.439040   \n",
       "36                          -0.366860                        -0.446593   \n",
       "37                          -0.066175                         0.244213   \n",
       "38                           0.786941                         2.238776   \n",
       "39                          -0.366655                        -0.447755   \n",
       "40                          -0.363678                        -0.291467   \n",
       "41                          -0.236827                        -0.396047   \n",
       "42                          -0.347807                        -0.487844   \n",
       "43                           0.959370                         1.660684   \n",
       "44                          -0.085770                         0.234917   \n",
       "45                          -0.363000                        -0.523866   \n",
       "46                          -0.328195                        -0.199088   \n",
       "47                          -0.377093                        -0.524447   \n",
       "48                          -0.337953                        -0.426258   \n",
       "49                          -0.334369                        -0.369321   \n",
       "50                          -0.346380                        -0.458213   \n",
       "51                          -0.255147                        -0.272875   \n",
       "52                          -0.314741                        -0.333880   \n",
       "53                          -0.304073                        -0.177592   \n",
       "54                          -0.247552                        -0.333880   \n",
       "55                          -0.234239                        -0.191535   \n",
       "56                          -0.292037                        -0.353634   \n",
       "57                          -0.336530                        -0.401857   \n",
       "58                          -0.334202                        -0.372226   \n",
       "59                          -0.340901                        -0.354215   \n",
       "60                          -0.334158                        -0.366997   \n",
       "\n",
       "    Total_timeDelta_Seconds__root_mean_square  Total_timeDelta_Seconds__mean  \\\n",
       "1                                   -0.460791                      -0.446712   \n",
       "2                                    0.139347                       0.062871   \n",
       "3                                   -0.270557                      -0.251185   \n",
       "4                                   -0.711919                      -0.660877   \n",
       "5                                   -0.696593                      -0.661546   \n",
       "6                                   -0.387841                      -0.485322   \n",
       "7                                    0.685299                       0.911508   \n",
       "8                                    0.004986                       0.121611   \n",
       "9                                   -0.494722                      -0.457901   \n",
       "10                                  -0.649808                      -0.618554   \n",
       "11                                  -0.114937                      -0.001870   \n",
       "12                                   0.141099                       0.242641   \n",
       "13                                   0.043155                      -0.179873   \n",
       "14                                  -0.411846                      -0.445167   \n",
       "15                                  -0.403440                      -0.432371   \n",
       "16                                   3.280086                       3.072105   \n",
       "17                                   0.472525                       0.450198   \n",
       "18                                  -0.128525                      -0.049780   \n",
       "19                                  -0.418852                      -0.394313   \n",
       "20                                  -0.387217                      -0.459323   \n",
       "21                                  -0.329607                      -0.377873   \n",
       "22                                  -0.035083                      -0.075548   \n",
       "23                                   1.913355                       1.355766   \n",
       "24                                   2.136327                       1.402555   \n",
       "25                                  -0.124447                      -0.270813   \n",
       "26                                  -0.608881                      -0.572117   \n",
       "27                                   5.056603                       5.473723   \n",
       "28                                  -0.465975                      -0.490735   \n",
       "29                                  -0.566590                      -0.520859   \n",
       "30                                  -0.190467                      -0.091268   \n",
       "31                                   0.233833                       0.332210   \n",
       "32                                  -0.580052                      -0.510199   \n",
       "33                                   0.103804                       0.156181   \n",
       "34                                  -0.364812                      -0.372943   \n",
       "35                                  -0.479069                      -0.466131   \n",
       "36                                  -0.606721                      -0.573494   \n",
       "37                                   0.281434                       0.293264   \n",
       "38                                   1.731999                       2.041786   \n",
       "39                                  -0.597978                      -0.553189   \n",
       "40                                  -0.532403                      -0.427787   \n",
       "41                                  -0.193883                      -0.306982   \n",
       "42                                  -0.524507                      -0.528933   \n",
       "43                                   1.653034                       1.692235   \n",
       "44                                   0.275829                       0.329784   \n",
       "45                                  -0.595375                      -0.582187   \n",
       "46                                  -0.383514                      -0.313861   \n",
       "47                                  -0.661545                      -0.604880   \n",
       "48                                  -0.472789                      -0.468075   \n",
       "49                                  -0.443240                      -0.417668   \n",
       "50                                  -0.505646                      -0.490075   \n",
       "51                                  -0.194205                      -0.218510   \n",
       "52                                  -0.382260                      -0.387591   \n",
       "53                                  -0.292046                      -0.228055   \n",
       "54                                  -0.196031                      -0.258900   \n",
       "55                                  -0.133039                      -0.155758   \n",
       "56                                  -0.317083                      -0.350370   \n",
       "57                                  -0.466729                      -0.462575   \n",
       "58                                  -0.452159                      -0.441260   \n",
       "59                                  -0.467932                      -0.434883   \n",
       "60                                  -0.451599                      -0.440126   \n",
       "\n",
       "    BreedName_1  BreedName_2  BreedName_4  BreedName_99  problematic  \n",
       "1           1.0          0.0          0.0           0.0            0  \n",
       "2           0.0          1.0          0.0           0.0            0  \n",
       "3           0.0          1.0          0.0           0.0            0  \n",
       "4           1.0          0.0          0.0           0.0            0  \n",
       "5           0.0          1.0          0.0           0.0            0  \n",
       "6           0.0          1.0          0.0           0.0            0  \n",
       "7           0.0          1.0          0.0           0.0            0  \n",
       "8           1.0          0.0          0.0           0.0            0  \n",
       "9           0.0          1.0          0.0           0.0            0  \n",
       "10          1.0          0.0          0.0           0.0            0  \n",
       "11          1.0          0.0          0.0           0.0            0  \n",
       "12          0.0          1.0          0.0           0.0            0  \n",
       "13          1.0          0.0          0.0           0.0            0  \n",
       "14          0.0          1.0          0.0           0.0            0  \n",
       "15          0.0          1.0          0.0           0.0            0  \n",
       "16          0.0          0.0          1.0           0.0            1  \n",
       "17          0.0          1.0          0.0           0.0            0  \n",
       "18          0.0          1.0          0.0           0.0            1  \n",
       "19          1.0          0.0          0.0           0.0            0  \n",
       "20          0.0          1.0          0.0           0.0            0  \n",
       "21          0.0          1.0          0.0           0.0            0  \n",
       "22          1.0          0.0          0.0           0.0            0  \n",
       "23          0.0          1.0          0.0           0.0            0  \n",
       "24          0.0          0.0          0.0           1.0            0  \n",
       "25          1.0          0.0          0.0           0.0            0  \n",
       "26          0.0          1.0          0.0           0.0            0  \n",
       "27          0.0          0.0          1.0           0.0            1  \n",
       "28          0.0          1.0          0.0           0.0            0  \n",
       "29          1.0          0.0          0.0           0.0            0  \n",
       "30          1.0          0.0          0.0           0.0            0  \n",
       "31          0.0          1.0          0.0           0.0            1  \n",
       "32          1.0          0.0          0.0           0.0            0  \n",
       "33          0.0          0.0          1.0           0.0            0  \n",
       "34          0.0          1.0          0.0           0.0            0  \n",
       "35          1.0          0.0          0.0           0.0            0  \n",
       "36          0.0          1.0          0.0           0.0            0  \n",
       "37          1.0          0.0          0.0           0.0            0  \n",
       "38          0.0          0.0          0.0           1.0            1  \n",
       "39          1.0          0.0          0.0           0.0            0  \n",
       "40          0.0          1.0          0.0           0.0            0  \n",
       "41          0.0          1.0          0.0           0.0            0  \n",
       "42          1.0          0.0          0.0           0.0            0  \n",
       "43          0.0          0.0          1.0           0.0            1  \n",
       "44          0.0          1.0          0.0           0.0            0  \n",
       "45          0.0          1.0          0.0           0.0            0  \n",
       "46          1.0          0.0          0.0           0.0            0  \n",
       "47          1.0          0.0          0.0           0.0            0  \n",
       "48          1.0          0.0          0.0           0.0            0  \n",
       "49          1.0          0.0          0.0           0.0            0  \n",
       "50          1.0          0.0          0.0           0.0            0  \n",
       "51          1.0          0.0          0.0           0.0            0  \n",
       "52          0.0          1.0          0.0           0.0            0  \n",
       "53          0.0          1.0          0.0           0.0            0  \n",
       "54          0.0          1.0          0.0           0.0            0  \n",
       "55          0.0          1.0          0.0           0.0            0  \n",
       "56          0.0          1.0          0.0           0.0            0  \n",
       "57          0.0          1.0          0.0           0.0            0  \n",
       "58          0.0          1.0          0.0           0.0            0  \n",
       "59          1.0          0.0          0.0           0.0            0  \n",
       "60          1.0          0.0          0.0           0.0            0  \n",
       "\n",
       "[60 rows x 21 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original\n",
    "# Construct extracted training data\n",
    "ts_extracted_id = cow_total[['id']].copy()\n",
    "ts_extracted_id.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_id.index = range(1, len(ts_extracted_id)+1)\n",
    "ts_extracted_dataset = pd.concat([ts_extracted_id, ts_extracted_dataset], axis=1)\n",
    "#print(ts_extracted_dataset)\n",
    "ts_extracted_features = ts_extracted_dataset.iloc[:, 1:len(ts_extracted_dataset.columns)].copy()\n",
    "#print(ts_extracted_features)\n",
    "#ts_extracted_features\n",
    "\n",
    "# normalize numerical features\n",
    "ts_extracted_cols = ts_extracted_features.columns\n",
    "scaler_std = StandardScaler()\n",
    "ts_std = scaler_std.fit_transform(ts_extracted_features)\n",
    "# transform standard data into dataframe\n",
    "ts_extracted_processed = pd.DataFrame(ts_std, columns=ts_extracted_cols)\n",
    "ts_extracted_processed.index = range(1,len(ts_extracted_processed)+1)\n",
    "# append id col to the dataframe\n",
    "ts_extracted_processed = pd.concat([ts_extracted_dataset['id'], ts_extracted_processed], axis=1)\n",
    "\n",
    "# One-Hot encoding categorical feature - BreedName\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "\n",
    "cow_breed = cow_total[['id', 'BreedName']].copy()\n",
    "cow_breed.drop_duplicates(subset=['id'], inplace=True)\n",
    "cat = ohe.fit_transform(np.array(cow_breed['BreedName']).reshape(-1, 1))\n",
    "col_names = ohe.get_feature_names_out(['BreedName'])\n",
    "cat_breed = pd.DataFrame(cat, columns=col_names)\n",
    "cat_breed.index = range(1,len(cow_breed)+1)\n",
    "\n",
    "# append features on extracted dataset\n",
    "ts_dataset = pd.concat([ts_extracted_processed, cat_breed], axis=1)\n",
    "ts_dataset = pd.concat([ts_dataset, y], axis=1)\n",
    "ts_dataset.to_csv(dataDir+\"problematic_100cows_7200s_5percent_features.csv\", index=False)\n",
    "ts_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65c049f4-c9d5-4cf5-8ecf-f65f5e7e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation on Gaussian Process Classifier\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, Matern, RationalQuadratic, WhiteKernel, ExpSineSquared\n",
    "grid = dict()\n",
    "grid['kernel'] = [1*RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)), \n",
    "                  1*DotProduct(), 1*Matern(),  1*RationalQuadratic(),\n",
    "                  1*Matern()+1*WhiteKernel(noise_level=0.5),\n",
    "                  1*ExpSineSquared(),\n",
    "                  1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0, length_scale_bounds=(0.1, 10.0), periodicity_bounds=(1.0, 10.0)),\n",
    "                  1*Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)+1*WhiteKernel(noise_level=0.5),\n",
    "                ]\n",
    "\n",
    "\n",
    "#dataDir = Path.cwd().parent.parent/'Data/processed'\n",
    "#id used as index\n",
    "#ts_dataset = pd.read_csv(dataDir/'Problematic_targetCows/problematic_100cows_7200s_5percent_features.csv', index_col='id')\n",
    "\n",
    "#use id as normal column\n",
    "#ts_dataset = pd.read_csv(dataDir+'Problematic_targetCows/problematic_100cows_7200s_5percent_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6da5b4f-a365-4ccf-8202-4fca2114d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cow_dataset = pd.DataFrame()\n",
    "\n",
    "train_cow_dataset = ts_dataset[~ts_dataset['id'].isin(test_cow_list)]\n",
    "\n",
    "train_cow_list = train_cow_dataset['id'].unique()\n",
    "\n",
    "#print(len(train_cow_list))\n",
    "#print(train_cow_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "caf3ba49-8aeb-492b-a3c5-15526f6363aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.DataFrame(train_cow_dataset['problematic'], columns=['problematic'])\n",
    "train_data = train_cow_dataset.drop('problematic', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eca48f91-10a1-4202-83b4-12856a3e1cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Total_MilkProduction__median</th>\n",
       "      <th>Total_MilkProduction__mean</th>\n",
       "      <th>Total_MilkProduction__root_mean_square</th>\n",
       "      <th>Total_MilkProduction__standard_deviation</th>\n",
       "      <th>Total_MilkProduction__variance</th>\n",
       "      <th>Total_timeDelta_Seconds__minimum</th>\n",
       "      <th>Age__length</th>\n",
       "      <th>Total_MilkProduction__length</th>\n",
       "      <th>Total_timeDelta_Seconds__length</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>Total_timeDelta_Seconds__median</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.135462</td>\n",
       "      <td>-0.213517</td>\n",
       "      <td>-0.243649</td>\n",
       "      <td>-0.495157</td>\n",
       "      <td>-0.542947</td>\n",
       "      <td>0.096884</td>\n",
       "      <td>-1.226896</td>\n",
       "      <td>-1.226896</td>\n",
       "      <td>-1.226896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201635</td>\n",
       "      <td>-0.104917</td>\n",
       "      <td>-0.153190</td>\n",
       "      <td>0.139347</td>\n",
       "      <td>0.062871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0.648156</td>\n",
       "      <td>0.535790</td>\n",
       "      <td>0.664535</td>\n",
       "      <td>1.776195</td>\n",
       "      <td>1.880363</td>\n",
       "      <td>0.211993</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180399</td>\n",
       "      <td>-0.258981</td>\n",
       "      <td>-0.117168</td>\n",
       "      <td>-0.128525</td>\n",
       "      <td>-0.049780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>-1.264243</td>\n",
       "      <td>-1.324654</td>\n",
       "      <td>-1.238982</td>\n",
       "      <td>-0.114161</td>\n",
       "      <td>-0.224099</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.427561</td>\n",
       "      <td>-0.328600</td>\n",
       "      <td>-0.308897</td>\n",
       "      <td>-0.418852</td>\n",
       "      <td>-0.394313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.709181</td>\n",
       "      <td>-0.693716</td>\n",
       "      <td>-0.709774</td>\n",
       "      <td>-0.708711</td>\n",
       "      <td>-0.706217</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>-1.221205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291335</td>\n",
       "      <td>-0.293149</td>\n",
       "      <td>-0.407666</td>\n",
       "      <td>-0.329607</td>\n",
       "      <td>-0.377873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>1.595026</td>\n",
       "      <td>1.462600</td>\n",
       "      <td>1.426389</td>\n",
       "      <td>0.797906</td>\n",
       "      <td>0.682698</td>\n",
       "      <td>0.327102</td>\n",
       "      <td>-1.278115</td>\n",
       "      <td>-1.278115</td>\n",
       "      <td>-1.278115</td>\n",
       "      <td>...</td>\n",
       "      <td>2.298778</td>\n",
       "      <td>1.745602</td>\n",
       "      <td>0.798484</td>\n",
       "      <td>1.913355</td>\n",
       "      <td>1.355766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>1.928530</td>\n",
       "      <td>1.685016</td>\n",
       "      <td>1.685591</td>\n",
       "      <td>1.409168</td>\n",
       "      <td>1.403733</td>\n",
       "      <td>0.557321</td>\n",
       "      <td>-1.286652</td>\n",
       "      <td>-1.286652</td>\n",
       "      <td>-1.286652</td>\n",
       "      <td>...</td>\n",
       "      <td>2.626971</td>\n",
       "      <td>2.189030</td>\n",
       "      <td>0.409797</td>\n",
       "      <td>2.136327</td>\n",
       "      <td>1.402555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>-1.273572</td>\n",
       "      <td>-1.205175</td>\n",
       "      <td>-1.192911</td>\n",
       "      <td>-0.780247</td>\n",
       "      <td>-0.758427</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>-1.235432</td>\n",
       "      <td>-1.235432</td>\n",
       "      <td>-1.235432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026083</td>\n",
       "      <td>-0.203540</td>\n",
       "      <td>-0.412314</td>\n",
       "      <td>-0.124447</td>\n",
       "      <td>-0.270813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27</td>\n",
       "      <td>0.979327</td>\n",
       "      <td>0.893606</td>\n",
       "      <td>0.997278</td>\n",
       "      <td>1.833644</td>\n",
       "      <td>1.957935</td>\n",
       "      <td>0.384657</td>\n",
       "      <td>-1.369172</td>\n",
       "      <td>-1.369172</td>\n",
       "      <td>-1.369172</td>\n",
       "      <td>...</td>\n",
       "      <td>4.643907</td>\n",
       "      <td>5.828271</td>\n",
       "      <td>6.120420</td>\n",
       "      <td>5.056603</td>\n",
       "      <td>5.473723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>-1.231593</td>\n",
       "      <td>-1.293107</td>\n",
       "      <td>-1.343553</td>\n",
       "      <td>-1.700762</td>\n",
       "      <td>-1.319141</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.590369</td>\n",
       "      <td>-0.361559</td>\n",
       "      <td>-0.451822</td>\n",
       "      <td>-0.566590</td>\n",
       "      <td>-0.520859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31</td>\n",
       "      <td>0.240022</td>\n",
       "      <td>0.344104</td>\n",
       "      <td>0.305589</td>\n",
       "      <td>-0.145172</td>\n",
       "      <td>-0.251372</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>-1.252506</td>\n",
       "      <td>-1.252506</td>\n",
       "      <td>-1.252506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161726</td>\n",
       "      <td>-0.123649</td>\n",
       "      <td>0.505080</td>\n",
       "      <td>0.233833</td>\n",
       "      <td>0.332210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>-1.660716</td>\n",
       "      <td>-1.591776</td>\n",
       "      <td>-1.627929</td>\n",
       "      <td>-1.737535</td>\n",
       "      <td>-1.337257</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>-1.206977</td>\n",
       "      <td>-1.206977</td>\n",
       "      <td>-1.206977</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621310</td>\n",
       "      <td>-0.366664</td>\n",
       "      <td>-0.369321</td>\n",
       "      <td>-0.580052</td>\n",
       "      <td>-0.510199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.137794</td>\n",
       "      <td>-0.293324</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>-1.016669</td>\n",
       "      <td>-0.922119</td>\n",
       "      <td>0.039329</td>\n",
       "      <td>-1.275270</td>\n",
       "      <td>-1.275270</td>\n",
       "      <td>-1.275270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.602939</td>\n",
       "      <td>-0.363678</td>\n",
       "      <td>-0.291467</td>\n",
       "      <td>-0.532403</td>\n",
       "      <td>-0.427787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38</td>\n",
       "      <td>1.711636</td>\n",
       "      <td>1.770416</td>\n",
       "      <td>1.795954</td>\n",
       "      <td>1.751349</td>\n",
       "      <td>1.847064</td>\n",
       "      <td>7.348773</td>\n",
       "      <td>-1.298034</td>\n",
       "      <td>-1.298034</td>\n",
       "      <td>-1.298034</td>\n",
       "      <td>...</td>\n",
       "      <td>1.444864</td>\n",
       "      <td>0.786941</td>\n",
       "      <td>2.238776</td>\n",
       "      <td>1.731999</td>\n",
       "      <td>2.041786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.031024</td>\n",
       "      <td>-0.951309</td>\n",
       "      <td>-0.914826</td>\n",
       "      <td>-0.307539</td>\n",
       "      <td>-0.390348</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>-1.209823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.740296</td>\n",
       "      <td>-0.382850</td>\n",
       "      <td>-0.545944</td>\n",
       "      <td>-0.711919</td>\n",
       "      <td>-0.660877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>1.678985</td>\n",
       "      <td>1.465927</td>\n",
       "      <td>1.413098</td>\n",
       "      <td>0.591823</td>\n",
       "      <td>0.460102</td>\n",
       "      <td>1.420641</td>\n",
       "      <td>-1.289497</td>\n",
       "      <td>-1.289497</td>\n",
       "      <td>-1.289497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487628</td>\n",
       "      <td>0.047339</td>\n",
       "      <td>1.113385</td>\n",
       "      <td>0.685299</td>\n",
       "      <td>0.911508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.905086</td>\n",
       "      <td>-1.133597</td>\n",
       "      <td>-1.119767</td>\n",
       "      <td>-0.704511</td>\n",
       "      <td>-0.703113</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>-1.147221</td>\n",
       "      <td>-1.147221</td>\n",
       "      <td>-1.147221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715119</td>\n",
       "      <td>-0.379881</td>\n",
       "      <td>-0.552916</td>\n",
       "      <td>-0.696593</td>\n",
       "      <td>-0.661546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>45</td>\n",
       "      <td>-0.741832</td>\n",
       "      <td>-0.835729</td>\n",
       "      <td>-0.836552</td>\n",
       "      <td>-0.636522</td>\n",
       "      <td>-0.652268</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>-1.181367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.598879</td>\n",
       "      <td>-0.363000</td>\n",
       "      <td>-0.523866</td>\n",
       "      <td>-0.595375</td>\n",
       "      <td>-0.582187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46</td>\n",
       "      <td>-1.261911</td>\n",
       "      <td>-1.648131</td>\n",
       "      <td>-1.493779</td>\n",
       "      <td>0.219559</td>\n",
       "      <td>0.084208</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425833</td>\n",
       "      <td>-0.328195</td>\n",
       "      <td>-0.199088</td>\n",
       "      <td>-0.383514</td>\n",
       "      <td>-0.313861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>47</td>\n",
       "      <td>-0.501616</td>\n",
       "      <td>-0.511010</td>\n",
       "      <td>-0.488453</td>\n",
       "      <td>-0.106485</td>\n",
       "      <td>-0.217312</td>\n",
       "      <td>-0.133335</td>\n",
       "      <td>-1.178522</td>\n",
       "      <td>-1.178522</td>\n",
       "      <td>-1.178522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693166</td>\n",
       "      <td>-0.377093</td>\n",
       "      <td>-0.524447</td>\n",
       "      <td>-0.661545</td>\n",
       "      <td>-0.604880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>52</td>\n",
       "      <td>-0.168112</td>\n",
       "      <td>-0.265915</td>\n",
       "      <td>-0.307873</td>\n",
       "      <td>-0.696013</td>\n",
       "      <td>-0.696819</td>\n",
       "      <td>-0.190890</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>-1.224050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370960</td>\n",
       "      <td>-0.314741</td>\n",
       "      <td>-0.333880</td>\n",
       "      <td>-0.382260</td>\n",
       "      <td>-0.387591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Total_MilkProduction__median  Total_MilkProduction__mean  \\\n",
       "0    2                     -0.135462                   -0.213517   \n",
       "1   18                      0.648156                    0.535790   \n",
       "2   19                     -1.264243                   -1.324654   \n",
       "3   21                     -0.709181                   -0.693716   \n",
       "4   23                      1.595026                    1.462600   \n",
       "5   24                      1.928530                    1.685016   \n",
       "6   25                     -1.273572                   -1.205175   \n",
       "7   27                      0.979327                    0.893606   \n",
       "8   29                     -1.231593                   -1.293107   \n",
       "9   31                      0.240022                    0.344104   \n",
       "10  32                     -1.660716                   -1.591776   \n",
       "11  40                     -0.137794                   -0.293324   \n",
       "12  38                      1.711636                    1.770416   \n",
       "13   4                     -1.031024                   -0.951309   \n",
       "14   7                      1.678985                    1.465927   \n",
       "15   5                     -0.905086                   -1.133597   \n",
       "16  45                     -0.741832                   -0.835729   \n",
       "17  46                     -1.261911                   -1.648131   \n",
       "18  47                     -0.501616                   -0.511010   \n",
       "19  52                     -0.168112                   -0.265915   \n",
       "\n",
       "    Total_MilkProduction__root_mean_square  \\\n",
       "0                                -0.243649   \n",
       "1                                 0.664535   \n",
       "2                                -1.238982   \n",
       "3                                -0.709774   \n",
       "4                                 1.426389   \n",
       "5                                 1.685591   \n",
       "6                                -1.192911   \n",
       "7                                 0.997278   \n",
       "8                                -1.343553   \n",
       "9                                 0.305589   \n",
       "10                               -1.627929   \n",
       "11                               -0.356000   \n",
       "12                                1.795954   \n",
       "13                               -0.914826   \n",
       "14                                1.413098   \n",
       "15                               -1.119767   \n",
       "16                               -0.836552   \n",
       "17                               -1.493779   \n",
       "18                               -0.488453   \n",
       "19                               -0.307873   \n",
       "\n",
       "    Total_MilkProduction__standard_deviation  Total_MilkProduction__variance  \\\n",
       "0                                  -0.495157                       -0.542947   \n",
       "1                                   1.776195                        1.880363   \n",
       "2                                  -0.114161                       -0.224099   \n",
       "3                                  -0.708711                       -0.706217   \n",
       "4                                   0.797906                        0.682698   \n",
       "5                                   1.409168                        1.403733   \n",
       "6                                  -0.780247                       -0.758427   \n",
       "7                                   1.833644                        1.957935   \n",
       "8                                  -1.700762                       -1.319141   \n",
       "9                                  -0.145172                       -0.251372   \n",
       "10                                 -1.737535                       -1.337257   \n",
       "11                                 -1.016669                       -0.922119   \n",
       "12                                  1.751349                        1.847064   \n",
       "13                                 -0.307539                       -0.390348   \n",
       "14                                  0.591823                        0.460102   \n",
       "15                                 -0.704511                       -0.703113   \n",
       "16                                 -0.636522                       -0.652268   \n",
       "17                                  0.219559                        0.084208   \n",
       "18                                 -0.106485                       -0.217312   \n",
       "19                                 -0.696013                       -0.696819   \n",
       "\n",
       "    Total_timeDelta_Seconds__minimum  Age__length  \\\n",
       "0                           0.096884    -1.226896   \n",
       "1                           0.211993    -1.221205   \n",
       "2                          -0.133335    -1.209823   \n",
       "3                          -0.248444    -1.221205   \n",
       "4                           0.327102    -1.278115   \n",
       "5                           0.557321    -1.286652   \n",
       "6                          -0.190890    -1.235432   \n",
       "7                           0.384657    -1.369172   \n",
       "8                          -0.248444    -1.181367   \n",
       "9                          -0.190890    -1.252506   \n",
       "10                         -0.133335    -1.206977   \n",
       "11                          0.039329    -1.275270   \n",
       "12                          7.348773    -1.298034   \n",
       "13                         -0.248444    -1.209823   \n",
       "14                          1.420641    -1.289497   \n",
       "15                         -0.190890    -1.147221   \n",
       "16                         -0.248444    -1.181367   \n",
       "17                         -0.133335    -1.224050   \n",
       "18                         -0.133335    -1.178522   \n",
       "19                         -0.190890    -1.224050   \n",
       "\n",
       "    Total_MilkProduction__length  Total_timeDelta_Seconds__length  ...  \\\n",
       "0                      -1.226896                        -1.226896  ...   \n",
       "1                      -1.221205                        -1.221205  ...   \n",
       "2                      -1.209823                        -1.209823  ...   \n",
       "3                      -1.221205                        -1.221205  ...   \n",
       "4                      -1.278115                        -1.278115  ...   \n",
       "5                      -1.286652                        -1.286652  ...   \n",
       "6                      -1.235432                        -1.235432  ...   \n",
       "7                      -1.369172                        -1.369172  ...   \n",
       "8                      -1.181367                        -1.181367  ...   \n",
       "9                      -1.252506                        -1.252506  ...   \n",
       "10                     -1.206977                        -1.206977  ...   \n",
       "11                     -1.275270                        -1.275270  ...   \n",
       "12                     -1.298034                        -1.298034  ...   \n",
       "13                     -1.209823                        -1.209823  ...   \n",
       "14                     -1.289497                        -1.289497  ...   \n",
       "15                     -1.147221                        -1.147221  ...   \n",
       "16                     -1.181367                        -1.181367  ...   \n",
       "17                     -1.224050                        -1.224050  ...   \n",
       "18                     -1.178522                        -1.178522  ...   \n",
       "19                     -1.224050                        -1.224050  ...   \n",
       "\n",
       "    Total_timeDelta_Seconds__standard_deviation  \\\n",
       "0                                      0.201635   \n",
       "1                                     -0.180399   \n",
       "2                                     -0.427561   \n",
       "3                                     -0.291335   \n",
       "4                                      2.298778   \n",
       "5                                      2.626971   \n",
       "6                                     -0.026083   \n",
       "7                                      4.643907   \n",
       "8                                     -0.590369   \n",
       "9                                      0.161726   \n",
       "10                                    -0.621310   \n",
       "11                                    -0.602939   \n",
       "12                                     1.444864   \n",
       "13                                    -0.740296   \n",
       "14                                     0.487628   \n",
       "15                                    -0.715119   \n",
       "16                                    -0.598879   \n",
       "17                                    -0.425833   \n",
       "18                                    -0.693166   \n",
       "19                                    -0.370960   \n",
       "\n",
       "    Total_timeDelta_Seconds__variance  Total_timeDelta_Seconds__median  \\\n",
       "0                           -0.104917                        -0.153190   \n",
       "1                           -0.258981                        -0.117168   \n",
       "2                           -0.328600                        -0.308897   \n",
       "3                           -0.293149                        -0.407666   \n",
       "4                            1.745602                         0.798484   \n",
       "5                            2.189030                         0.409797   \n",
       "6                           -0.203540                        -0.412314   \n",
       "7                            5.828271                         6.120420   \n",
       "8                           -0.361559                        -0.451822   \n",
       "9                           -0.123649                         0.505080   \n",
       "10                          -0.366664                        -0.369321   \n",
       "11                          -0.363678                        -0.291467   \n",
       "12                           0.786941                         2.238776   \n",
       "13                          -0.382850                        -0.545944   \n",
       "14                           0.047339                         1.113385   \n",
       "15                          -0.379881                        -0.552916   \n",
       "16                          -0.363000                        -0.523866   \n",
       "17                          -0.328195                        -0.199088   \n",
       "18                          -0.377093                        -0.524447   \n",
       "19                          -0.314741                        -0.333880   \n",
       "\n",
       "    Total_timeDelta_Seconds__root_mean_square  Total_timeDelta_Seconds__mean  \\\n",
       "0                                    0.139347                       0.062871   \n",
       "1                                   -0.128525                      -0.049780   \n",
       "2                                   -0.418852                      -0.394313   \n",
       "3                                   -0.329607                      -0.377873   \n",
       "4                                    1.913355                       1.355766   \n",
       "5                                    2.136327                       1.402555   \n",
       "6                                   -0.124447                      -0.270813   \n",
       "7                                    5.056603                       5.473723   \n",
       "8                                   -0.566590                      -0.520859   \n",
       "9                                    0.233833                       0.332210   \n",
       "10                                  -0.580052                      -0.510199   \n",
       "11                                  -0.532403                      -0.427787   \n",
       "12                                   1.731999                       2.041786   \n",
       "13                                  -0.711919                      -0.660877   \n",
       "14                                   0.685299                       0.911508   \n",
       "15                                  -0.696593                      -0.661546   \n",
       "16                                  -0.595375                      -0.582187   \n",
       "17                                  -0.383514                      -0.313861   \n",
       "18                                  -0.661545                      -0.604880   \n",
       "19                                  -0.382260                      -0.387591   \n",
       "\n",
       "    BreedName_1  BreedName_2  BreedName_4  BreedName_99  problematic  \n",
       "0           0.0          1.0          0.0           0.0            0  \n",
       "1           0.0          1.0          0.0           0.0            1  \n",
       "2           1.0          0.0          0.0           0.0            0  \n",
       "3           0.0          1.0          0.0           0.0            0  \n",
       "4           0.0          1.0          0.0           0.0            0  \n",
       "5           0.0          0.0          0.0           1.0            0  \n",
       "6           1.0          0.0          0.0           0.0            0  \n",
       "7           0.0          0.0          1.0           0.0            1  \n",
       "8           1.0          0.0          0.0           0.0            0  \n",
       "9           0.0          1.0          0.0           0.0            1  \n",
       "10          1.0          0.0          0.0           0.0            0  \n",
       "11          0.0          1.0          0.0           0.0            0  \n",
       "12          0.0          0.0          0.0           1.0            1  \n",
       "13          1.0          0.0          0.0           0.0            0  \n",
       "14          0.0          1.0          0.0           0.0            0  \n",
       "15          0.0          1.0          0.0           0.0            0  \n",
       "16          0.0          1.0          0.0           0.0            0  \n",
       "17          1.0          0.0          0.0           0.0            0  \n",
       "18          1.0          0.0          0.0           0.0            0  \n",
       "19          0.0          1.0          0.0           0.0            0  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cow_dataset = pd.DataFrame()\n",
    "\n",
    "for tc in test_cow_list:\n",
    "    test_data = ts_dataset[ts_dataset['id'] == tc]\n",
    "    frames = [test_cow_dataset, test_data]\n",
    "    test_cow_dataset = pd.concat(frames, ignore_index=True)\n",
    "    \n",
    "test_cow_dataset\n",
    "#test_cow_dataset.to_csv(dataDir+\"test_cow_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44e23afb-169a-4b3a-949f-f590c68f8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.DataFrame(test_cow_dataset['problematic'], columns=['problematic'])\n",
    "test_data = test_cow_dataset.drop('problematic', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c528233d-dc85-4217-876a-fe7e70c285be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py:472: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py:472: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.975\n",
      "Best estimator parameters:  {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.950 with: {'kernel': 1**2 * RBF(length_scale=1)}\n",
      "Accuracy 0.975 with: {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.950 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      "Accuracy 0.950 with: {'kernel': 1**2 * RationalQuadratic(alpha=1, length_scale=1)}\n",
      "Accuracy 0.950 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=1)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=3)}\n",
      "Accuracy 0.950 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "38 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 29-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 32-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 30-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 32-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 306, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 31-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 23-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 6-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 11-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 24-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 20-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 5-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 13-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 4-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.95  0.975 0.95  0.95  0.95    nan   nan 0.95 ]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#%%capture --no-stderr\n",
    "#%%capture --no-display\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_labels, test_labels\n",
    "\n",
    "model = GaussianProcessClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=5)\n",
    "# exhausive search over different kernels\n",
    "search = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# fit model into the dataset\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", result.best_score_)\n",
    "print(\"Best estimator parameters: \", result.best_params_)\n",
    "\n",
    "means = result.cv_results_['mean_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"Accuracy %.3f with: %r\" % (mean, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b4a4de1-86d4-4489-be2f-6ccec8061d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 1**2 * DotProduct(sigma_0=1)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6de6e667-a6a3-4067-a2a8-8baaf1763601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              16\n",
       "1               4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "abddfa0d-f554-4c49-a721-704861548ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              38\n",
       "1               2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78291d70-c611-4ff8-a397-e4afb82711be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training data:  1.0\n",
      "Prediction on test data:  [0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "True values of test data:  [0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Prediction accuracy on test data:  0.8\n"
     ]
    }
   ],
   "source": [
    "best_kernel = 1**2 * DotProduct(sigma_0=1)\n",
    "#best_kernel = 1**2 * RationalQuadratic(alpha=1, length_scale=1)\n",
    "#best_kernel = 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)\n",
    "# best_kernel = 1**2 * Matern(length_scale=1, nu=1.5)\n",
    "#best_kernel = 1**2 * RBF(length_scale=1)\n",
    "model = GaussianProcessClassifier(kernel=best_kernel, random_state=30, n_jobs=-1)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model.score(X_train, y_train))\n",
    "\n",
    "# My guess is to look at what we have in X_test dataset and see if I can reduce the number of days.\n",
    "# The challenge is how do we ensure that the number of days we have found for correct prediction will always \n",
    "# be the correct one? \n",
    "\n",
    "print(\"Prediction on test data: \", model.predict(X_test))\n",
    "print(\"True values of test data: \", y_test['problematic'].tolist())\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"Prediction accuracy on test data: \", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ab5b6fe-3c2e-43fc-88af-5af744ba93ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71852368, 0.28147632],\n",
       "       [0.77476285, 0.22523715],\n",
       "       [0.79295566, 0.20704434],\n",
       "       [0.79042423, 0.20957577],\n",
       "       [0.40765202, 0.59234798],\n",
       "       [0.37995352, 0.62004648],\n",
       "       [0.76485768, 0.23514232],\n",
       "       [0.11022461, 0.88977539],\n",
       "       [0.79344048, 0.20655952],\n",
       "       [0.69382052, 0.30617948],\n",
       "       [0.78301519, 0.21698481],\n",
       "       [0.77642516, 0.22357484],\n",
       "       [0.42429418, 0.57570582],\n",
       "       [0.81531408, 0.18468592],\n",
       "       [0.59306807, 0.40693193],\n",
       "       [0.81179912, 0.18820088],\n",
       "       [0.7949309 , 0.2050691 ],\n",
       "       [0.74823198, 0.25176802],\n",
       "       [0.80634287, 0.19365713],\n",
       "       [0.75071421, 0.24928579]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_list = model.predict_proba(X_test)\n",
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "ae0a5d15-268c-4a11-9d9f-faa6c891a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "cow_id = X_test.index.copy()\n",
    "cow_id = cow_id.astype(str)\n",
    "\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "facecolor = '#eaeaf2'\n",
    "color_red = '#f44336'\n",
    "color_blue = '#4496df'\n",
    "index = cow_id\n",
    "column0 = prob_list[:, 0]\n",
    "column1 = prob_list[:, 1]\n",
    "title0 = 'Problematic Cows, test set'\n",
    "title1 = 'Normal Cows, test set'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5), facecolor=facecolor, ncols=2, sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0].barh(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes[0].set_title(title0, fontsize=18, pad=15, color=color_red, **hfont)\n",
    "axes[1].barh(index, column1, align='center', color=color_blue, zorder=10)\n",
    "axes[1].set_title(title1, fontsize=18, pad=15, color=color_blue, **hfont)\n",
    "\n",
    "# If you have positive numbers and want to invert the x-axis of the left plot\n",
    "axes[0].invert_xaxis() \n",
    "\n",
    "# To show data from highest to lowest\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "axes[0].set(yticks=cow_id, yticklabels=cow_id)\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[0].tick_params(axis='y', colors='black') # tick color\n",
    "\n",
    "axes[0].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[0].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "for label in (axes[0].get_xticklabels() + axes[0].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "for label in (axes[1].get_xticklabels() + axes[1].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, top=0.85, bottom=0.1, left=0.18, right=0.95)\n",
    "filename = 'Problematic_Cows'\n",
    "plt.savefig(filename+'.png', facecolor=facecolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "5b35c659-e272-4de7-9c88-68deee33fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# Total_timeDelta_Seconds__minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "25d87e85-9998-4bf1-bbff-622b6174bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [507], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Plot decision boundary with uncertainty\u001b[39;00m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m---> 18\u001b[0m x_min, x_max \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m y_min, y_max \u001b[38;5;241m=\u001b[39m X[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39mlinspace(x_min, x_max, \u001b[38;5;241m100\u001b[39m),\n\u001b[1;32m     21\u001b[0m                      np\u001b[38;5;241m.\u001b[39mlinspace(y_min, y_max, \u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3810\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3810\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:5966\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5964\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5965\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5966\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = pd.DataFrame(ts_dataset['problematic'], columns=['problematic'])\n",
    "#X = pd.DataFrame(ts_dataset['Total_timeDelta_Seconds__minimum', 'Total_timeDelta_Seconds__root_mean_square'], columns=['Total_timeDelta_Seconds__minimum', 'Total_timeDelta_Seconds__root_mean_square'])\n",
    "\n",
    "X = pd.DataFrame(ts_dataset['Total_timeDelta_Seconds__minimum'], columns=['Total_timeDelta_Seconds__minimum'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the Gaussian Process model with an RBF kernel\n",
    "kernel = 1.0 * RBF(length_scale=1.0)\n",
    "gpc = GaussianProcessClassifier(kernel=kernel)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gpc.fit(X_train, y_train)\n",
    "\n",
    "# Plot decision boundary with uncertainty\n",
    "plt.figure(figsize=(10, 5))\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# Obtain predictions and uncertainties\n",
    "Z = gpc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "probs_mesh = gpc.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]  # Probability for class 1\n",
    "Z = Z.reshape(xx.shape)\n",
    "probs_mesh = probs_mesh.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundaries\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# Plot class probabilities as uncertainty\n",
    "plt.contourf(xx, yy, probs_mesh, cmap='RdYlBu', alpha=0.2)\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k')\n",
    "plt.title('Gaussian Process Classification with Uncertainty')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b89d5-1a20-4699-9c27-a83383e6918e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf66a9-8595-4bc3-abc3-61066e7e3755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
