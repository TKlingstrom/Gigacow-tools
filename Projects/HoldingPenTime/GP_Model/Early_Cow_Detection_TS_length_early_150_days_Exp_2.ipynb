{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "396af3cf-0117-4f47-a509-3261e5d8cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "pd.options.mode.chained_assignment = None\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, MinimalFCParameters\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85bb1b24-e295-47ea-b4e1-fda41010b4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>9.38</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>8.46</td>\n",
       "      <td>352.0</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>6.68</td>\n",
       "      <td>997.0</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>7.34</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>8.15</td>\n",
       "      <td>407.0</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95849</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.96</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95850</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.53</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95851</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>3.24</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95852</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>9.23</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95853</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95854 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "0            a624fb9a            2560                  9.38   \n",
       "1            a624fb9a            2560                  8.46   \n",
       "2            a624fb9a            2560                  6.68   \n",
       "3            a624fb9a            2560                  7.34   \n",
       "4            a624fb9a            2560                  8.15   \n",
       "...               ...             ...                   ...   \n",
       "95849        a624fb9a            2047                  7.96   \n",
       "95850        a624fb9a            2047                  5.53   \n",
       "95851        a624fb9a            2047                  3.24   \n",
       "95852        a624fb9a            2047                  9.23   \n",
       "95853        a624fb9a            2047                  7.42   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "0                       3176.0  2022-02-14              1.0         2.0   \n",
       "1                        352.0  2022-02-14              1.0         2.0   \n",
       "2                        997.0  2022-02-15              1.0         3.0   \n",
       "3                       9274.0  2022-02-15              1.0         3.0   \n",
       "4                        407.0  2022-02-16              1.0         4.0   \n",
       "...                        ...         ...              ...         ...   \n",
       "95849                     59.0  2022-11-12              1.0       322.0   \n",
       "95850                    148.0  2022-11-13              1.0       323.0   \n",
       "95851                    287.0  2022-11-13              1.0       323.0   \n",
       "95852                    240.0  2022-11-13              1.0       323.0   \n",
       "95853                     10.0  2022-11-14              1.0       324.0   \n",
       "\n",
       "       BreedName   Age  problematic   id  \n",
       "0              1  2.15            0    1  \n",
       "1              1  2.15            0    1  \n",
       "2              1  2.15            0    1  \n",
       "3              1  2.15            0    1  \n",
       "4              1  2.15            0    1  \n",
       "...          ...   ...          ...  ...  \n",
       "95849          1  3.02            0  142  \n",
       "95850          1  3.03            0  142  \n",
       "95851          1  3.03            0  142  \n",
       "95852          1  3.03            0  142  \n",
       "95853          1  3.03            0  142  \n",
       "\n",
       "[95854 rows x 11 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cows = pd.DataFrame()\n",
    "\n",
    "dataDir = '../../Data/processed/'\n",
    "total_cows = pd.read_csv(dataDir+'Cow_Prob_dataset_L1.csv')\n",
    "total_cows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07292a37-e1fb-4196-aed7-5bd426e16a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51780</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>13.34</td>\n",
       "      <td>401.0</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51781</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>8.77</td>\n",
       "      <td>258.0</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51782</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>8.71</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51783</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>14.28</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51784</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>12.64</td>\n",
       "      <td>725.0</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "51780        a624fb9a            2047                 13.34   \n",
       "51781        a624fb9a            2047                  8.77   \n",
       "51782        a624fb9a            2047                  8.71   \n",
       "51783        a624fb9a            2047                 14.28   \n",
       "51784        a624fb9a            2047                 12.64   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "51780                    401.0  2022-05-24              1.0       150.0   \n",
       "51781                    258.0  2022-05-24              1.0       150.0   \n",
       "51782                    155.0  2022-05-24              1.0       150.0   \n",
       "51783                   1066.0  2022-05-25              1.0       151.0   \n",
       "51784                    725.0  2022-05-25              1.0       151.0   \n",
       "\n",
       "       BreedName   Age  problematic   id  \n",
       "51780          1  2.55            0  142  \n",
       "51781          1  2.55            0  142  \n",
       "51782          1  2.55            0  142  \n",
       "51783          1  2.56            0  142  \n",
       "51784          1  2.56            0  142  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cow_list = total_cows['id'].unique()\n",
    "\n",
    "modified_total_cows = total_cows\n",
    "\n",
    "#This length is based on the first 150 days\n",
    "ts_length_test_data = 150\n",
    "\n",
    "for l in total_cow_list:\n",
    "    # Choose a specific duration\n",
    "    condition = modified_total_cows['id'] == l\n",
    "    test_cow = modified_total_cows[condition].copy()\n",
    "    test_cow = test_cow.reset_index()        \n",
    "    # print(test_cow)\n",
    "    if 'index' in test_cow:\n",
    "        test_cow = test_cow.drop('index', axis=1)\n",
    "        \n",
    "    modified_total_cows = modified_total_cows[~condition]\n",
    "            \n",
    "    test_cow['MilkingDate'] = pd.to_datetime(test_cow['MilkingDate'])\n",
    "    test_cow['MilkingDate'] = test_cow['MilkingDate'].dt.date\n",
    "            \n",
    "    start_date = test_cow['MilkingDate'][0]\n",
    "    #print('start_date: ',start_date)\n",
    "    end_date = pd.to_datetime(start_date + pd.DateOffset(days=ts_length_test_data)).date()\n",
    "    #print('end_date: ', end_date)\n",
    "    filtered_df = test_cow[(test_cow['MilkingDate'] >= start_date) & (test_cow['MilkingDate'] <= end_date)]   \n",
    "    \n",
    "    modified_total_cows = pd.concat([modified_total_cows, filtered_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "#modified_total_cows = modified_total_cows.drop('index', axis=1)\n",
    "#modified_total_cows = modified_total_cows.sort_values('id')\n",
    "modified_total_cows = modified_total_cows.sort_values(by=['id', 'MilkingDate'])\n",
    "\n",
    "modified_total_cows.to_csv(dataDir+\"upp.csv\", index=False)\n",
    "\n",
    "#modified_total_cows = modified_total_cows.reset_index()\n",
    "\n",
    "total_cows = modified_total_cows\n",
    "modified_total_cows.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c42e8a3-5fce-4f84-9e68-f3297bf92301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48, 99, 25, 75, 19, 121, 136, 75, 77, 140, 93, 117, 78, 119, 118, 82, 14, 23, 17, 101] 20\n"
     ]
    }
   ],
   "source": [
    "# Select IDs from the total_cows\n",
    "test_cow_list = []\n",
    "ids = total_cows['id']\n",
    "\n",
    "unique_cow_ids = ids.unique()\n",
    "\n",
    "# Select a few rows randomly\n",
    "num_of_selected_cows = 20\n",
    "\n",
    "#test_cow_list = [1]\n",
    "\n",
    "test_cow_list = random.choices( unique_cow_ids, k=num_of_selected_cows)\n",
    "#test_cow_list.sort()\n",
    "\n",
    "test_cow_list = [48, 99, 25, 75, 19, 121, 136, 75, 77, 140, 93, 117, 78, 119, 118, 82, 14, 23, 17, 101]\n",
    "print(test_cow_list, len(test_cow_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "471088dc-15b0-4be2-a527-8967a8de7801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44309</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>13.34</td>\n",
       "      <td>401.0</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44310</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>8.77</td>\n",
       "      <td>258.0</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44311</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>8.71</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44312</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>14.28</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44313</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>12.64</td>\n",
       "      <td>725.0</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "44309        a624fb9a            2047                 13.34   \n",
       "44310        a624fb9a            2047                  8.77   \n",
       "44311        a624fb9a            2047                  8.71   \n",
       "44312        a624fb9a            2047                 14.28   \n",
       "44313        a624fb9a            2047                 12.64   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "44309                    401.0  2022-05-24              1.0       150.0   \n",
       "44310                    258.0  2022-05-24              1.0       150.0   \n",
       "44311                    155.0  2022-05-24              1.0       150.0   \n",
       "44312                   1066.0  2022-05-25              1.0       151.0   \n",
       "44313                    725.0  2022-05-25              1.0       151.0   \n",
       "\n",
       "       BreedName   Age  problematic   id  \n",
       "44309          1  2.55            0  142  \n",
       "44310          1  2.55            0  142  \n",
       "44311          1  2.55            0  142  \n",
       "44312          1  2.56            0  142  \n",
       "44313          1  2.56            0  142  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_total_cows = total_cows\n",
    "ts_length_test_data = 150\n",
    "\n",
    "for l in test_cow_list:\n",
    "    # Choose a specific duration\n",
    "    condition = modified_total_cows['id'] == l\n",
    "    test_cow = modified_total_cows[condition].copy()\n",
    "    test_cow = test_cow.reset_index()        \n",
    "    # print(test_cow)\n",
    "    if 'index' in test_cow:\n",
    "        test_cow = test_cow.drop('index', axis=1)\n",
    "        \n",
    "    modified_total_cows = modified_total_cows[~condition]\n",
    "            \n",
    "    test_cow['MilkingDate'] = pd.to_datetime(test_cow['MilkingDate'])\n",
    "    test_cow['MilkingDate'] = test_cow['MilkingDate'].dt.date\n",
    "            \n",
    "    start_date = test_cow['MilkingDate'][0]\n",
    "    #print('start_date: ',start_date)\n",
    "    end_date = pd.to_datetime(start_date + pd.DateOffset(days=ts_length_test_data)).date()\n",
    "    #print('end_date: ', end_date)\n",
    "    filtered_df = test_cow[(test_cow['MilkingDate'] >= start_date) & (test_cow['MilkingDate'] <= end_date)]   \n",
    "    \n",
    "    modified_total_cows = pd.concat([modified_total_cows, filtered_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "#modified_total_cows = modified_total_cows.drop('index', axis=1)\n",
    "#modified_total_cows = modified_total_cows.sort_values('id')\n",
    "modified_total_cows = modified_total_cows.sort_values(by=['id', 'MilkingDate'])\n",
    "\n",
    "modified_total_cows.to_csv(dataDir+\"upp.csv\", index=False)\n",
    "\n",
    "#modified_total_cows = modified_total_cows.reset_index()\n",
    "\n",
    "modified_total_cows.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25a586e8-e3cc-4b2d-b73c-a1e5d235b14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51785, 11)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cow_total =  modified_total_cows\n",
    "cow_total.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "009c6a05-7081-436c-8d5e-bf0f1a184716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problematic\n",
      "0    97\n",
      "1    45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#original\n",
    "#df_static_features = cow_total[['FarmName_Pseudo']]\n",
    "static_cols = ['FarmName_Pseudo', 'TrafficDeviceName', 'LactationNumber', 'BreedName']\n",
    "timeSeries_cols = ['Age', 'Total_MilkProduction', 'Total_timeDelta_Seconds', 'DaysInMilk']\n",
    "output_col = ['problematic']\n",
    "\n",
    "cow_label = cow_total[['id', 'problematic']].copy()\n",
    "cow_timeseries = cow_total[['id', 'MilkingDate']].copy()\n",
    "cow_timeseries.index = range(len(cow_timeseries))\n",
    "# fetch y for feature extraction\n",
    "y = cow_label.drop_duplicates(subset=['id'])\n",
    "y = y[\"problematic\"]\n",
    "y.index = range(1,len(y)+1) \n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ba0c709-0d26-4e73-a0fc-8d0681161b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_extracted_dataset shape:  (51785, 1)\n",
      "ts_extracted_dataset shape:  (142, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>DaysInMilk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>2.15</td>\n",
       "      <td>9.38</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.46</td>\n",
       "      <td>352.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>6.68</td>\n",
       "      <td>997.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>7.34</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.15</td>\n",
       "      <td>407.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51780</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>2.55</td>\n",
       "      <td>13.34</td>\n",
       "      <td>401.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51781</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>2.55</td>\n",
       "      <td>8.77</td>\n",
       "      <td>258.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51782</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>2.55</td>\n",
       "      <td>8.71</td>\n",
       "      <td>155.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51783</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>2.56</td>\n",
       "      <td>14.28</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51784</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>2.56</td>\n",
       "      <td>12.64</td>\n",
       "      <td>725.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51785 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id MilkingDate   Age  Total_MilkProduction  Total_timeDelta_Seconds  \\\n",
       "0        1  2022-02-14  2.15                  9.38                   3176.0   \n",
       "1        1  2022-02-14  2.15                  8.46                    352.0   \n",
       "2        1  2022-02-15  2.15                  6.68                    997.0   \n",
       "3        1  2022-02-15  2.15                  7.34                   9274.0   \n",
       "4        1  2022-02-16  2.15                  8.15                    407.0   \n",
       "...    ...         ...   ...                   ...                      ...   \n",
       "51780  142  2022-05-24  2.55                 13.34                    401.0   \n",
       "51781  142  2022-05-24  2.55                  8.77                    258.0   \n",
       "51782  142  2022-05-24  2.55                  8.71                    155.0   \n",
       "51783  142  2022-05-25  2.56                 14.28                   1066.0   \n",
       "51784  142  2022-05-25  2.56                 12.64                    725.0   \n",
       "\n",
       "       DaysInMilk  \n",
       "0             2.0  \n",
       "1             2.0  \n",
       "2             3.0  \n",
       "3             3.0  \n",
       "4             4.0  \n",
       "...           ...  \n",
       "51780       150.0  \n",
       "51781       150.0  \n",
       "51782       150.0  \n",
       "51783       151.0  \n",
       "51784       151.0  \n",
       "\n",
       "[51785 rows x 6 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "# Prepare datasert for Tsfresh extraction\n",
    "ts_extracted_dataset = cow_total[['id']].copy()\n",
    "print('ts_extracted_dataset shape: ', ts_extracted_dataset.shape)\n",
    "ts_extracted_dataset.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_dataset.index = range(1, len(ts_extracted_dataset)+1)\n",
    "print('ts_extracted_dataset shape: ',ts_extracted_dataset.shape)\n",
    "\n",
    "ts_processed = pd.DataFrame(cow_total[timeSeries_cols].copy())\n",
    "ts_processed.index = range(0,len(ts_processed)) \n",
    "\n",
    "ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "ts_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "833d7cef-efd5-40ca-b8bb-489abb16659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51785, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 110.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51785, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 97.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51785, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 104.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51785, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 111.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                 feature  \\\n",
      "feature                                                                                    \n",
      "Total_MilkProduction__sum_values                        Total_MilkProduction__sum_values   \n",
      "DaysInMilk__median                                                    DaysInMilk__median   \n",
      "DaysInMilk__absolute_maximum                                DaysInMilk__absolute_maximum   \n",
      "DaysInMilk__maximum                                                  DaysInMilk__maximum   \n",
      "DaysInMilk__mean                                                        DaysInMilk__mean   \n",
      "DaysInMilk__root_mean_square                                DaysInMilk__root_mean_square   \n",
      "Total_MilkProduction__absolute_maximum            Total_MilkProduction__absolute_maximum   \n",
      "Total_MilkProduction__maximum                              Total_MilkProduction__maximum   \n",
      "Total_MilkProduction__minimum                              Total_MilkProduction__minimum   \n",
      "Total_MilkProduction__variance                            Total_MilkProduction__variance   \n",
      "Total_MilkProduction__standard_deviation        Total_MilkProduction__standard_deviation   \n",
      "DaysInMilk__minimum                                                  DaysInMilk__minimum   \n",
      "Total_MilkProduction__root_mean_square            Total_MilkProduction__root_mean_square   \n",
      "Total_MilkProduction__mean                                    Total_MilkProduction__mean   \n",
      "Total_MilkProduction__median                                Total_MilkProduction__median   \n",
      "Age__sum_values                                                          Age__sum_values   \n",
      "DaysInMilk__sum_values                                            DaysInMilk__sum_values   \n",
      "Total_timeDelta_Seconds__length                          Total_timeDelta_Seconds__length   \n",
      "DaysInMilk__length                                                    DaysInMilk__length   \n",
      "Age__length                                                                  Age__length   \n",
      "Total_MilkProduction__length                                Total_MilkProduction__length   \n",
      "Total_timeDelta_Seconds__minimum                        Total_timeDelta_Seconds__minimum   \n",
      "Total_timeDelta_Seconds__sum_values                  Total_timeDelta_Seconds__sum_values   \n",
      "Total_timeDelta_Seconds__absolute_maximum      Total_timeDelta_Seconds__absolute_maximum   \n",
      "Total_timeDelta_Seconds__maximum                        Total_timeDelta_Seconds__maximum   \n",
      "Total_timeDelta_Seconds__variance                      Total_timeDelta_Seconds__variance   \n",
      "Total_timeDelta_Seconds__standard_deviation  Total_timeDelta_Seconds__standard_deviation   \n",
      "Total_timeDelta_Seconds__median                          Total_timeDelta_Seconds__median   \n",
      "Total_timeDelta_Seconds__mean                              Total_timeDelta_Seconds__mean   \n",
      "Total_timeDelta_Seconds__root_mean_square      Total_timeDelta_Seconds__root_mean_square   \n",
      "\n",
      "                                             type       p_value  relevant  \n",
      "feature                                                                    \n",
      "Total_MilkProduction__sum_values             real  2.210015e-03      True  \n",
      "DaysInMilk__median                           real  8.767791e-04      True  \n",
      "DaysInMilk__absolute_maximum                 real  2.709337e-04      True  \n",
      "DaysInMilk__maximum                          real  2.709337e-04      True  \n",
      "DaysInMilk__mean                             real  1.490281e-04      True  \n",
      "DaysInMilk__root_mean_square                 real  1.182707e-04      True  \n",
      "Total_MilkProduction__absolute_maximum       real  5.801827e-05      True  \n",
      "Total_MilkProduction__maximum                real  5.801827e-05      True  \n",
      "Total_MilkProduction__minimum                real  8.543085e-06      True  \n",
      "Total_MilkProduction__variance               real  1.238522e-06      True  \n",
      "Total_MilkProduction__standard_deviation     real  1.238522e-06      True  \n",
      "DaysInMilk__minimum                          real  6.826637e-07      True  \n",
      "Total_MilkProduction__root_mean_square       real  3.411793e-09      True  \n",
      "Total_MilkProduction__mean                   real  2.682915e-09      True  \n",
      "Total_MilkProduction__median                 real  1.038216e-09      True  \n",
      "Age__sum_values                              real  1.010424e-09      True  \n",
      "DaysInMilk__sum_values                       real  1.775507e-10      True  \n",
      "Total_timeDelta_Seconds__length              real  1.103291e-10      True  \n",
      "DaysInMilk__length                           real  1.103291e-10      True  \n",
      "Age__length                                  real  1.103291e-10      True  \n",
      "Total_MilkProduction__length                 real  1.103291e-10      True  \n",
      "Total_timeDelta_Seconds__minimum             real  5.143628e-11      True  \n",
      "Total_timeDelta_Seconds__sum_values          real  5.094819e-11      True  \n",
      "Total_timeDelta_Seconds__absolute_maximum    real  2.015726e-16      True  \n",
      "Total_timeDelta_Seconds__maximum             real  2.015726e-16      True  \n",
      "Total_timeDelta_Seconds__variance            real  3.219697e-18      True  \n",
      "Total_timeDelta_Seconds__standard_deviation  real  3.219697e-18      True  \n",
      "Total_timeDelta_Seconds__median              real  2.021514e-18      True  \n",
      "Total_timeDelta_Seconds__mean                real  2.940962e-19      True  \n",
      "Total_timeDelta_Seconds__root_mean_square    real  2.053748e-19      True  \n"
     ]
    }
   ],
   "source": [
    "#Original\n",
    "settings_1 = MinimalFCParameters() \n",
    "#settings_2 = ComprehensiveFCParameters\n",
    "\n",
    "for i, col in enumerate(timeSeries_cols):\n",
    "    ts_processed = pd.DataFrame(cow_total[col].copy())\n",
    "    ts_processed.index = range(0,len(ts_processed)) \n",
    "    ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "    \n",
    "    print(ts_processed.shape)\n",
    "    \n",
    "    #print(ts_processed[ts_processed['id'] == 122])\n",
    "    # extract time series features\n",
    "    extracted_features = extract_features(ts_processed, column_id=\"id\", column_sort=\"MilkingDate\", default_fc_parameters=settings_1)\n",
    "    #extracted_features.dropna(axis=1, inplace=True)\n",
    "    impute(extracted_features)\n",
    "\n",
    "    # calculate_relevance_table method is sensitive to the index of the rows.\n",
    "    # The following two lines are to align the indices. \n",
    "    \n",
    "    #extracted_features.reset_index(drop=True, inplace=True)\n",
    "    #y.reset_index(drop=True, inplace=True)\n",
    "    extracted_features.index = range(1, len(extracted_features)+1)\n",
    "    y.index = range(1, len(y)+1)\n",
    "    #print(extracted_features)\n",
    "    #print(y)\n",
    "    \n",
    "    # select most relevant features based on relevance table\n",
    "    if i == 0:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = temp\n",
    "    else:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = pd.concat([relevance_table, temp], axis=0)\n",
    "    features_filtered = select_features(extracted_features, y)\n",
    "    ts_extracted_dataset = pd.concat([ts_extracted_dataset, features_filtered], axis=1)\n",
    "\n",
    "# Select relevant features from the relevance table\n",
    "relevance_table = relevance_table[relevance_table.relevant]\n",
    "relevance_table.sort_values(\"p_value\", ascending=False, inplace=True)\n",
    "relevant_features_list = list(relevance_table.feature[:])\n",
    "print(relevance_table)\n",
    "\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset[relevant_features_list].copy()\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset_filtered.loc[:,~ts_extracted_dataset_filtered.columns.duplicated()]\n",
    "ts_extracted_dataset = ts_extracted_dataset_filtered\n",
    "ts_extracted_dataset\n",
    "ts_extracted_dataset.to_csv(dataDir+\"problematic_cows_7200s_5percent_extracted_features.csv\", index=False)\n",
    "relevance_table.to_csv(dataDir+\"problematic_cows_7200s_5percent_relevance_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f7621dc3-75b5-4db0-99ad-1a9a52619e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Total_MilkProduction__sum_values</th>\n",
       "      <th>DaysInMilk__median</th>\n",
       "      <th>DaysInMilk__absolute_maximum</th>\n",
       "      <th>DaysInMilk__maximum</th>\n",
       "      <th>DaysInMilk__mean</th>\n",
       "      <th>DaysInMilk__root_mean_square</th>\n",
       "      <th>Total_MilkProduction__absolute_maximum</th>\n",
       "      <th>Total_MilkProduction__maximum</th>\n",
       "      <th>Total_MilkProduction__minimum</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__median</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.794122</td>\n",
       "      <td>-0.656472</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.622599</td>\n",
       "      <td>-0.610447</td>\n",
       "      <td>-0.422034</td>\n",
       "      <td>-0.422034</td>\n",
       "      <td>-0.380984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.535640</td>\n",
       "      <td>-0.806062</td>\n",
       "      <td>-0.693368</td>\n",
       "      <td>-0.774553</td>\n",
       "      <td>-0.801087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.197417</td>\n",
       "      <td>0.363377</td>\n",
       "      <td>0.790630</td>\n",
       "      <td>0.790630</td>\n",
       "      <td>0.425136</td>\n",
       "      <td>0.429080</td>\n",
       "      <td>-0.663053</td>\n",
       "      <td>-0.663053</td>\n",
       "      <td>-0.376343</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047174</td>\n",
       "      <td>1.433355</td>\n",
       "      <td>-0.105964</td>\n",
       "      <td>0.425001</td>\n",
       "      <td>1.046551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.279842</td>\n",
       "      <td>0.169120</td>\n",
       "      <td>-0.183086</td>\n",
       "      <td>-0.183086</td>\n",
       "      <td>0.047386</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.695163</td>\n",
       "      <td>0.695163</td>\n",
       "      <td>-0.394906</td>\n",
       "      <td>...</td>\n",
       "      <td>1.622342</td>\n",
       "      <td>1.877353</td>\n",
       "      <td>0.978579</td>\n",
       "      <td>1.252626</td>\n",
       "      <td>1.621385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.149997</td>\n",
       "      <td>1.383225</td>\n",
       "      <td>0.498515</td>\n",
       "      <td>0.498515</td>\n",
       "      <td>1.373371</td>\n",
       "      <td>1.198986</td>\n",
       "      <td>-0.362488</td>\n",
       "      <td>-0.362488</td>\n",
       "      <td>-0.399546</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.579898</td>\n",
       "      <td>-1.098270</td>\n",
       "      <td>-0.749279</td>\n",
       "      <td>-0.961988</td>\n",
       "      <td>-1.051869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.372671</td>\n",
       "      <td>0.363377</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>0.169842</td>\n",
       "      <td>0.171498</td>\n",
       "      <td>0.817090</td>\n",
       "      <td>0.817090</td>\n",
       "      <td>0.491442</td>\n",
       "      <td>...</td>\n",
       "      <td>1.980453</td>\n",
       "      <td>2.124820</td>\n",
       "      <td>2.336614</td>\n",
       "      <td>2.464302</td>\n",
       "      <td>2.289872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>-2.198146</td>\n",
       "      <td>1.577482</td>\n",
       "      <td>2.738062</td>\n",
       "      <td>2.738062</td>\n",
       "      <td>1.528182</td>\n",
       "      <td>1.561512</td>\n",
       "      <td>-0.112962</td>\n",
       "      <td>-0.112962</td>\n",
       "      <td>2.050673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545167</td>\n",
       "      <td>-0.852447</td>\n",
       "      <td>-0.575146</td>\n",
       "      <td>-0.701069</td>\n",
       "      <td>-0.797913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>0.697853</td>\n",
       "      <td>-0.413651</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.459062</td>\n",
       "      <td>-0.433475</td>\n",
       "      <td>0.439966</td>\n",
       "      <td>0.439966</td>\n",
       "      <td>0.291898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380097</td>\n",
       "      <td>-0.322469</td>\n",
       "      <td>-0.568747</td>\n",
       "      <td>-0.367972</td>\n",
       "      <td>-0.348457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>0.814577</td>\n",
       "      <td>-0.607908</td>\n",
       "      <td>-0.280458</td>\n",
       "      <td>-0.280458</td>\n",
       "      <td>-0.538866</td>\n",
       "      <td>-0.524992</td>\n",
       "      <td>0.164920</td>\n",
       "      <td>0.164920</td>\n",
       "      <td>-0.589809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458063</td>\n",
       "      <td>-0.525997</td>\n",
       "      <td>-0.630721</td>\n",
       "      <td>-0.560692</td>\n",
       "      <td>-0.547422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>0.268823</td>\n",
       "      <td>0.533351</td>\n",
       "      <td>0.401144</td>\n",
       "      <td>0.401144</td>\n",
       "      <td>0.538158</td>\n",
       "      <td>0.471810</td>\n",
       "      <td>0.181933</td>\n",
       "      <td>0.181933</td>\n",
       "      <td>1.869690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380336</td>\n",
       "      <td>-0.323029</td>\n",
       "      <td>-0.475112</td>\n",
       "      <td>-0.490719</td>\n",
       "      <td>-0.394887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>1.018585</td>\n",
       "      <td>-0.437933</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.471413</td>\n",
       "      <td>-0.493557</td>\n",
       "      <td>0.060005</td>\n",
       "      <td>0.060005</td>\n",
       "      <td>-0.399546</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521574</td>\n",
       "      <td>-0.744648</td>\n",
       "      <td>-0.666086</td>\n",
       "      <td>-0.737098</td>\n",
       "      <td>-0.749008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Total_MilkProduction__sum_values  DaysInMilk__median  \\\n",
       "1      1                          0.794122           -0.656472   \n",
       "2      2                         -0.197417            0.363377   \n",
       "3      3                          0.279842            0.169120   \n",
       "4      4                         -0.149997            1.383225   \n",
       "5      5                         -1.372671            0.363377   \n",
       "..   ...                               ...                 ...   \n",
       "138  138                         -2.198146            1.577482   \n",
       "139  139                          0.697853           -0.413651   \n",
       "140  140                          0.814577           -0.607908   \n",
       "141  141                          0.268823            0.533351   \n",
       "142  142                          1.018585           -0.437933   \n",
       "\n",
       "     DaysInMilk__absolute_maximum  DaysInMilk__maximum  DaysInMilk__mean  \\\n",
       "1                       -0.377829            -0.377829         -0.622599   \n",
       "2                        0.790630             0.790630          0.425136   \n",
       "3                       -0.183086            -0.183086          0.047386   \n",
       "4                        0.498515             0.498515          1.373371   \n",
       "5                       -0.085714            -0.085714          0.169842   \n",
       "..                            ...                  ...               ...   \n",
       "138                      2.738062             2.738062          1.528182   \n",
       "139                     -0.475201            -0.475201         -0.459062   \n",
       "140                     -0.280458            -0.280458         -0.538866   \n",
       "141                      0.401144             0.401144          0.538158   \n",
       "142                     -0.475201            -0.475201         -0.471413   \n",
       "\n",
       "     DaysInMilk__root_mean_square  Total_MilkProduction__absolute_maximum  \\\n",
       "1                       -0.610447                               -0.422034   \n",
       "2                        0.429080                               -0.663053   \n",
       "3                        0.002397                                0.695163   \n",
       "4                        1.198986                               -0.362488   \n",
       "5                        0.171498                                0.817090   \n",
       "..                            ...                                     ...   \n",
       "138                      1.561512                               -0.112962   \n",
       "139                     -0.433475                                0.439966   \n",
       "140                     -0.524992                                0.164920   \n",
       "141                      0.471810                                0.181933   \n",
       "142                     -0.493557                                0.060005   \n",
       "\n",
       "     Total_MilkProduction__maximum  Total_MilkProduction__minimum  ...  \\\n",
       "1                        -0.422034                      -0.380984  ...   \n",
       "2                        -0.663053                      -0.376343  ...   \n",
       "3                         0.695163                      -0.394906  ...   \n",
       "4                        -0.362488                      -0.399546  ...   \n",
       "5                         0.817090                       0.491442  ...   \n",
       "..                             ...                            ...  ...   \n",
       "138                      -0.112962                       2.050673  ...   \n",
       "139                       0.439966                       0.291898  ...   \n",
       "140                       0.164920                      -0.589809  ...   \n",
       "141                       0.181933                       1.869690  ...   \n",
       "142                       0.060005                      -0.399546  ...   \n",
       "\n",
       "     Total_timeDelta_Seconds__variance  \\\n",
       "1                            -0.535640   \n",
       "2                             1.047174   \n",
       "3                             1.622342   \n",
       "4                            -0.579898   \n",
       "5                             1.980453   \n",
       "..                                 ...   \n",
       "138                          -0.545167   \n",
       "139                          -0.380097   \n",
       "140                          -0.458063   \n",
       "141                          -0.380336   \n",
       "142                          -0.521574   \n",
       "\n",
       "     Total_timeDelta_Seconds__standard_deviation  \\\n",
       "1                                      -0.806062   \n",
       "2                                       1.433355   \n",
       "3                                       1.877353   \n",
       "4                                      -1.098270   \n",
       "5                                       2.124820   \n",
       "..                                           ...   \n",
       "138                                    -0.852447   \n",
       "139                                    -0.322469   \n",
       "140                                    -0.525997   \n",
       "141                                    -0.323029   \n",
       "142                                    -0.744648   \n",
       "\n",
       "     Total_timeDelta_Seconds__median  Total_timeDelta_Seconds__mean  \\\n",
       "1                          -0.693368                      -0.774553   \n",
       "2                          -0.105964                       0.425001   \n",
       "3                           0.978579                       1.252626   \n",
       "4                          -0.749279                      -0.961988   \n",
       "5                           2.336614                       2.464302   \n",
       "..                               ...                            ...   \n",
       "138                        -0.575146                      -0.701069   \n",
       "139                        -0.568747                      -0.367972   \n",
       "140                        -0.630721                      -0.560692   \n",
       "141                        -0.475112                      -0.490719   \n",
       "142                        -0.666086                      -0.737098   \n",
       "\n",
       "     Total_timeDelta_Seconds__root_mean_square  BreedName_1  BreedName_2  \\\n",
       "1                                    -0.801087          1.0          0.0   \n",
       "2                                     1.046551          0.0          1.0   \n",
       "3                                     1.621385          0.0          0.0   \n",
       "4                                    -1.051869          1.0          0.0   \n",
       "5                                     2.289872          0.0          0.0   \n",
       "..                                         ...          ...          ...   \n",
       "138                                  -0.797913          0.0          1.0   \n",
       "139                                  -0.348457          0.0          1.0   \n",
       "140                                  -0.547422          1.0          0.0   \n",
       "141                                  -0.394887          1.0          0.0   \n",
       "142                                  -0.749008          1.0          0.0   \n",
       "\n",
       "     BreedName_4  BreedName_99  problematic  \n",
       "1            0.0           0.0            0  \n",
       "2            0.0           0.0            1  \n",
       "3            0.0           1.0            1  \n",
       "4            0.0           0.0            0  \n",
       "5            1.0           0.0            1  \n",
       "..           ...           ...          ...  \n",
       "138          0.0           0.0            0  \n",
       "139          0.0           0.0            0  \n",
       "140          0.0           0.0            0  \n",
       "141          0.0           0.0            0  \n",
       "142          0.0           0.0            0  \n",
       "\n",
       "[142 rows x 36 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original\n",
    "# Construct extracted training data\n",
    "ts_extracted_id = cow_total[['id']].copy()\n",
    "ts_extracted_id.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_id.index = range(1, len(ts_extracted_id)+1)\n",
    "ts_extracted_dataset = pd.concat([ts_extracted_id, ts_extracted_dataset], axis=1)\n",
    "#print(ts_extracted_dataset)\n",
    "ts_extracted_features = ts_extracted_dataset.iloc[:, 1:len(ts_extracted_dataset.columns)].copy()\n",
    "#print(ts_extracted_features)\n",
    "#ts_extracted_features\n",
    "\n",
    "# normalize numerical features\n",
    "ts_extracted_cols = ts_extracted_features.columns\n",
    "scaler_std = StandardScaler()\n",
    "ts_std = scaler_std.fit_transform(ts_extracted_features)\n",
    "# transform standard data into dataframe\n",
    "ts_extracted_processed = pd.DataFrame(ts_std, columns=ts_extracted_cols)\n",
    "ts_extracted_processed.index = range(1,len(ts_extracted_processed)+1)\n",
    "# append id col to the dataframe\n",
    "ts_extracted_processed = pd.concat([ts_extracted_dataset['id'], ts_extracted_processed], axis=1)\n",
    "\n",
    "# One-Hot encoding categorical feature - BreedName\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "\n",
    "cow_breed = cow_total[['id', 'BreedName']].copy()\n",
    "cow_breed.drop_duplicates(subset=['id'], inplace=True)\n",
    "cat = ohe.fit_transform(np.array(cow_breed['BreedName']).reshape(-1, 1))\n",
    "col_names = ohe.get_feature_names_out(['BreedName'])\n",
    "cat_breed = pd.DataFrame(cat, columns=col_names)\n",
    "cat_breed.index = range(1,len(cow_breed)+1)\n",
    "\n",
    "# append features on extracted dataset\n",
    "ts_dataset = pd.concat([ts_extracted_processed, cat_breed], axis=1)\n",
    "ts_dataset = pd.concat([ts_dataset, y], axis=1)\n",
    "ts_dataset.to_csv(dataDir+\"problematic_100cows_7200s_5percent_features.csv\", index=False)\n",
    "ts_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "65c049f4-c9d5-4cf5-8ecf-f65f5e7e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation on Gaussian Process Classifier\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, Matern, RationalQuadratic, WhiteKernel, ExpSineSquared\n",
    "grid = dict()\n",
    "grid['kernel'] = [1*RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)), \n",
    "                  1*DotProduct(), 1*Matern(),  1*RationalQuadratic(),\n",
    "                  1*Matern()+1*WhiteKernel(noise_level=0.5),\n",
    "                  1*ExpSineSquared(),\n",
    "                  1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0, length_scale_bounds=(0.1, 10.0), periodicity_bounds=(1.0, 10.0)),\n",
    "                  1*Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)+1*WhiteKernel(noise_level=0.5),\n",
    "                ]\n",
    "\n",
    "\n",
    "#dataDir = Path.cwd().parent.parent/'Data/processed'\n",
    "#id used as index\n",
    "#ts_dataset = pd.read_csv(dataDir/'Problematic_targetCows/problematic_100cows_7200s_5percent_features.csv', index_col='id')\n",
    "\n",
    "#use id as normal column\n",
    "#ts_dataset = pd.read_csv(dataDir+'Problematic_targetCows/problematic_100cows_7200s_5percent_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f6da5b4f-a365-4ccf-8202-4fca2114d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cow_dataset = pd.DataFrame()\n",
    "\n",
    "train_cow_dataset = ts_dataset[~ts_dataset['id'].isin(test_cow_list)]\n",
    "\n",
    "train_cow_list = train_cow_dataset['id'].unique()\n",
    "\n",
    "#print(len(train_cow_list))\n",
    "#print(train_cow_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "caf3ba49-8aeb-492b-a3c5-15526f6363aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.DataFrame(train_cow_dataset['problematic'], columns=['problematic'])\n",
    "train_data = train_cow_dataset.drop('problematic', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eca48f91-10a1-4202-83b4-12856a3e1cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Total_MilkProduction__sum_values</th>\n",
       "      <th>DaysInMilk__median</th>\n",
       "      <th>DaysInMilk__absolute_maximum</th>\n",
       "      <th>DaysInMilk__maximum</th>\n",
       "      <th>DaysInMilk__mean</th>\n",
       "      <th>DaysInMilk__root_mean_square</th>\n",
       "      <th>Total_MilkProduction__absolute_maximum</th>\n",
       "      <th>Total_MilkProduction__maximum</th>\n",
       "      <th>Total_MilkProduction__minimum</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__median</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>0.374547</td>\n",
       "      <td>-0.510779</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.514118</td>\n",
       "      <td>-0.471843</td>\n",
       "      <td>-1.431481</td>\n",
       "      <td>-1.431481</td>\n",
       "      <td>-0.854322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571997</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.783634</td>\n",
       "      <td>-0.932023</td>\n",
       "      <td>-0.994034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>-1.533458</td>\n",
       "      <td>2.985844</td>\n",
       "      <td>1.569603</td>\n",
       "      <td>1.569603</td>\n",
       "      <td>3.205999</td>\n",
       "      <td>3.022995</td>\n",
       "      <td>-0.050580</td>\n",
       "      <td>-0.050580</td>\n",
       "      <td>0.653862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516250</td>\n",
       "      <td>-0.723112</td>\n",
       "      <td>-0.408423</td>\n",
       "      <td>-0.523979</td>\n",
       "      <td>-0.645444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.807911</td>\n",
       "      <td>-0.413651</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.481307</td>\n",
       "      <td>-0.455983</td>\n",
       "      <td>0.913498</td>\n",
       "      <td>0.913498</td>\n",
       "      <td>-0.905368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332436</td>\n",
       "      <td>-0.216770</td>\n",
       "      <td>-0.190167</td>\n",
       "      <td>-0.191084</td>\n",
       "      <td>-0.213088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>0.158165</td>\n",
       "      <td>-0.365087</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.425365</td>\n",
       "      <td>-0.362592</td>\n",
       "      <td>-0.155495</td>\n",
       "      <td>-0.155495</td>\n",
       "      <td>-0.278891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438043</td>\n",
       "      <td>-0.468950</td>\n",
       "      <td>-0.493300</td>\n",
       "      <td>-0.461073</td>\n",
       "      <td>-0.473615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>-2.349180</td>\n",
       "      <td>0.436223</td>\n",
       "      <td>1.277488</td>\n",
       "      <td>1.277488</td>\n",
       "      <td>0.867494</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>-0.138481</td>\n",
       "      <td>-0.138481</td>\n",
       "      <td>-0.422749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538855</td>\n",
       "      <td>-0.821209</td>\n",
       "      <td>-0.746248</td>\n",
       "      <td>-0.705858</td>\n",
       "      <td>-0.782359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>121</td>\n",
       "      <td>0.657099</td>\n",
       "      <td>-0.267958</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.324695</td>\n",
       "      <td>-0.319013</td>\n",
       "      <td>-1.060027</td>\n",
       "      <td>-1.060027</td>\n",
       "      <td>-0.162877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.539444</td>\n",
       "      <td>-0.824039</td>\n",
       "      <td>-0.766794</td>\n",
       "      <td>-0.848469</td>\n",
       "      <td>-0.838479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>136</td>\n",
       "      <td>0.663555</td>\n",
       "      <td>-0.777882</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.755130</td>\n",
       "      <td>-0.743318</td>\n",
       "      <td>-0.288764</td>\n",
       "      <td>-0.288764</td>\n",
       "      <td>-0.905368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571695</td>\n",
       "      <td>-1.019825</td>\n",
       "      <td>-0.751974</td>\n",
       "      <td>-0.914208</td>\n",
       "      <td>-0.985688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>0.158165</td>\n",
       "      <td>-0.365087</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.425365</td>\n",
       "      <td>-0.362592</td>\n",
       "      <td>-0.155495</td>\n",
       "      <td>-0.155495</td>\n",
       "      <td>-0.278891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438043</td>\n",
       "      <td>-0.468950</td>\n",
       "      <td>-0.493300</td>\n",
       "      <td>-0.461073</td>\n",
       "      <td>-0.473615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>0.066749</td>\n",
       "      <td>0.071991</td>\n",
       "      <td>-0.280458</td>\n",
       "      <td>-0.280458</td>\n",
       "      <td>0.124524</td>\n",
       "      <td>0.125922</td>\n",
       "      <td>0.371913</td>\n",
       "      <td>0.371913</td>\n",
       "      <td>-0.111831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796741</td>\n",
       "      <td>1.215639</td>\n",
       "      <td>2.083330</td>\n",
       "      <td>1.611460</td>\n",
       "      <td>1.401271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>140</td>\n",
       "      <td>0.814577</td>\n",
       "      <td>-0.607908</td>\n",
       "      <td>-0.280458</td>\n",
       "      <td>-0.280458</td>\n",
       "      <td>-0.538866</td>\n",
       "      <td>-0.524992</td>\n",
       "      <td>0.164920</td>\n",
       "      <td>0.164920</td>\n",
       "      <td>-0.589809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458063</td>\n",
       "      <td>-0.525997</td>\n",
       "      <td>-0.630721</td>\n",
       "      <td>-0.560692</td>\n",
       "      <td>-0.547422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>93</td>\n",
       "      <td>0.676549</td>\n",
       "      <td>-0.267958</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.333286</td>\n",
       "      <td>-0.305812</td>\n",
       "      <td>-0.280258</td>\n",
       "      <td>-0.280258</td>\n",
       "      <td>-0.687261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393962</td>\n",
       "      <td>-0.355444</td>\n",
       "      <td>-0.621963</td>\n",
       "      <td>-0.492450</td>\n",
       "      <td>-0.416001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>117</td>\n",
       "      <td>1.090335</td>\n",
       "      <td>-0.510779</td>\n",
       "      <td>-0.280458</td>\n",
       "      <td>-0.280458</td>\n",
       "      <td>-0.518487</td>\n",
       "      <td>-0.488857</td>\n",
       "      <td>1.355840</td>\n",
       "      <td>1.355840</td>\n",
       "      <td>-0.729026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166607</td>\n",
       "      <td>0.089586</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>0.038075</td>\n",
       "      <td>0.062078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>78</td>\n",
       "      <td>-0.497741</td>\n",
       "      <td>0.217684</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.032245</td>\n",
       "      <td>-0.002511</td>\n",
       "      <td>0.998564</td>\n",
       "      <td>0.998564</td>\n",
       "      <td>-0.000458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807483</td>\n",
       "      <td>1.225364</td>\n",
       "      <td>1.291816</td>\n",
       "      <td>1.250969</td>\n",
       "      <td>1.238412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>119</td>\n",
       "      <td>-0.561491</td>\n",
       "      <td>-0.025137</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>-0.148319</td>\n",
       "      <td>-0.112512</td>\n",
       "      <td>-0.555304</td>\n",
       "      <td>-0.555304</td>\n",
       "      <td>0.032026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206858</td>\n",
       "      <td>0.021780</td>\n",
       "      <td>-0.095186</td>\n",
       "      <td>-0.078190</td>\n",
       "      <td>-0.025813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>118</td>\n",
       "      <td>0.018999</td>\n",
       "      <td>-0.680754</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.646419</td>\n",
       "      <td>-0.636769</td>\n",
       "      <td>-1.173448</td>\n",
       "      <td>-1.173448</td>\n",
       "      <td>-0.617653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482788</td>\n",
       "      <td>-0.602885</td>\n",
       "      <td>-0.563358</td>\n",
       "      <td>-0.585397</td>\n",
       "      <td>-0.603815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>82</td>\n",
       "      <td>0.116797</td>\n",
       "      <td>-0.607908</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.596117</td>\n",
       "      <td>-0.566341</td>\n",
       "      <td>-0.592165</td>\n",
       "      <td>-0.592165</td>\n",
       "      <td>-0.854322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.427711</td>\n",
       "      <td>-0.440995</td>\n",
       "      <td>-0.536412</td>\n",
       "      <td>-0.493665</td>\n",
       "      <td>-0.469610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.035174</td>\n",
       "      <td>0.047709</td>\n",
       "      <td>0.109029</td>\n",
       "      <td>0.109029</td>\n",
       "      <td>0.131111</td>\n",
       "      <td>0.091836</td>\n",
       "      <td>0.326545</td>\n",
       "      <td>0.326545</td>\n",
       "      <td>-0.905368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842489</td>\n",
       "      <td>1.256796</td>\n",
       "      <td>-0.242710</td>\n",
       "      <td>0.344634</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.202188</td>\n",
       "      <td>-0.510779</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.546195</td>\n",
       "      <td>-0.572978</td>\n",
       "      <td>-1.593106</td>\n",
       "      <td>-1.593106</td>\n",
       "      <td>-0.264970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.540362</td>\n",
       "      <td>-0.828478</td>\n",
       "      <td>-0.696063</td>\n",
       "      <td>-0.803112</td>\n",
       "      <td>-0.825628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>0.632338</td>\n",
       "      <td>-0.486497</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.377829</td>\n",
       "      <td>-0.468569</td>\n",
       "      <td>-0.439272</td>\n",
       "      <td>1.259432</td>\n",
       "      <td>1.259432</td>\n",
       "      <td>0.319742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163391</td>\n",
       "      <td>0.094861</td>\n",
       "      <td>0.097472</td>\n",
       "      <td>0.162137</td>\n",
       "      <td>0.118548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>101</td>\n",
       "      <td>0.833111</td>\n",
       "      <td>-0.462215</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.475201</td>\n",
       "      <td>-0.394108</td>\n",
       "      <td>-0.373769</td>\n",
       "      <td>-0.648876</td>\n",
       "      <td>-0.648876</td>\n",
       "      <td>-0.144315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382920</td>\n",
       "      <td>-0.329092</td>\n",
       "      <td>-0.557295</td>\n",
       "      <td>-0.445108</td>\n",
       "      <td>-0.382198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Total_MilkProduction__sum_values  DaysInMilk__median  \\\n",
       "0    48                          0.374547           -0.510779   \n",
       "1    99                         -1.533458            2.985844   \n",
       "2    25                          0.807911           -0.413651   \n",
       "3    75                          0.158165           -0.365087   \n",
       "4    19                         -2.349180            0.436223   \n",
       "5   121                          0.657099           -0.267958   \n",
       "6   136                          0.663555           -0.777882   \n",
       "7    75                          0.158165           -0.365087   \n",
       "8    77                          0.066749            0.071991   \n",
       "9   140                          0.814577           -0.607908   \n",
       "10   93                          0.676549           -0.267958   \n",
       "11  117                          1.090335           -0.510779   \n",
       "12   78                         -0.497741            0.217684   \n",
       "13  119                         -0.561491           -0.025137   \n",
       "14  118                          0.018999           -0.680754   \n",
       "15   82                          0.116797           -0.607908   \n",
       "16   14                         -0.035174            0.047709   \n",
       "17   23                         -0.202188           -0.510779   \n",
       "18   17                          0.632338           -0.486497   \n",
       "19  101                          0.833111           -0.462215   \n",
       "\n",
       "    DaysInMilk__absolute_maximum  DaysInMilk__maximum  DaysInMilk__mean  \\\n",
       "0                      -0.475201            -0.475201         -0.514118   \n",
       "1                       1.569603             1.569603          3.205999   \n",
       "2                      -0.377829            -0.377829         -0.481307   \n",
       "3                      -0.377829            -0.377829         -0.425365   \n",
       "4                       1.277488             1.277488          0.867494   \n",
       "5                      -0.377829            -0.377829         -0.324695   \n",
       "6                      -0.377829            -0.377829         -0.755130   \n",
       "7                      -0.377829            -0.377829         -0.425365   \n",
       "8                      -0.280458            -0.280458          0.124524   \n",
       "9                      -0.280458            -0.280458         -0.538866   \n",
       "10                     -0.377829            -0.377829         -0.333286   \n",
       "11                     -0.280458            -0.280458         -0.518487   \n",
       "12                      0.011657             0.011657          0.032245   \n",
       "13                     -0.085714            -0.085714         -0.148319   \n",
       "14                     -0.475201            -0.475201         -0.646419   \n",
       "15                     -0.475201            -0.475201         -0.596117   \n",
       "16                      0.109029             0.109029          0.131111   \n",
       "17                     -0.475201            -0.475201         -0.546195   \n",
       "18                     -0.377829            -0.377829         -0.468569   \n",
       "19                     -0.475201            -0.475201         -0.394108   \n",
       "\n",
       "    DaysInMilk__root_mean_square  Total_MilkProduction__absolute_maximum  \\\n",
       "0                      -0.471843                               -1.431481   \n",
       "1                       3.022995                               -0.050580   \n",
       "2                      -0.455983                                0.913498   \n",
       "3                      -0.362592                               -0.155495   \n",
       "4                       0.898063                               -0.138481   \n",
       "5                      -0.319013                               -1.060027   \n",
       "6                      -0.743318                               -0.288764   \n",
       "7                      -0.362592                               -0.155495   \n",
       "8                       0.125922                                0.371913   \n",
       "9                      -0.524992                                0.164920   \n",
       "10                     -0.305812                               -0.280258   \n",
       "11                     -0.488857                                1.355840   \n",
       "12                     -0.002511                                0.998564   \n",
       "13                     -0.112512                               -0.555304   \n",
       "14                     -0.636769                               -1.173448   \n",
       "15                     -0.566341                               -0.592165   \n",
       "16                      0.091836                                0.326545   \n",
       "17                     -0.572978                               -1.593106   \n",
       "18                     -0.439272                                1.259432   \n",
       "19                     -0.373769                               -0.648876   \n",
       "\n",
       "    Total_MilkProduction__maximum  Total_MilkProduction__minimum  ...  \\\n",
       "0                       -1.431481                      -0.854322  ...   \n",
       "1                       -0.050580                       0.653862  ...   \n",
       "2                        0.913498                      -0.905368  ...   \n",
       "3                       -0.155495                      -0.278891  ...   \n",
       "4                       -0.138481                      -0.422749  ...   \n",
       "5                       -1.060027                      -0.162877  ...   \n",
       "6                       -0.288764                      -0.905368  ...   \n",
       "7                       -0.155495                      -0.278891  ...   \n",
       "8                        0.371913                      -0.111831  ...   \n",
       "9                        0.164920                      -0.589809  ...   \n",
       "10                      -0.280258                      -0.687261  ...   \n",
       "11                       1.355840                      -0.729026  ...   \n",
       "12                       0.998564                      -0.000458  ...   \n",
       "13                      -0.555304                       0.032026  ...   \n",
       "14                      -1.173448                      -0.617653  ...   \n",
       "15                      -0.592165                      -0.854322  ...   \n",
       "16                       0.326545                      -0.905368  ...   \n",
       "17                      -1.593106                      -0.264970  ...   \n",
       "18                       1.259432                       0.319742  ...   \n",
       "19                      -0.648876                      -0.144315  ...   \n",
       "\n",
       "    Total_timeDelta_Seconds__variance  \\\n",
       "0                           -0.571997   \n",
       "1                           -0.516250   \n",
       "2                           -0.332436   \n",
       "3                           -0.438043   \n",
       "4                           -0.538855   \n",
       "5                           -0.539444   \n",
       "6                           -0.571695   \n",
       "7                           -0.438043   \n",
       "8                            0.796741   \n",
       "9                           -0.458063   \n",
       "10                          -0.393962   \n",
       "11                          -0.166607   \n",
       "12                           0.807483   \n",
       "13                          -0.206858   \n",
       "14                          -0.482788   \n",
       "15                          -0.427711   \n",
       "16                           0.842489   \n",
       "17                          -0.540362   \n",
       "18                          -0.163391   \n",
       "19                          -0.382920   \n",
       "\n",
       "    Total_timeDelta_Seconds__standard_deviation  \\\n",
       "0                                     -1.022309   \n",
       "1                                     -0.723112   \n",
       "2                                     -0.216770   \n",
       "3                                     -0.468950   \n",
       "4                                     -0.821209   \n",
       "5                                     -0.824039   \n",
       "6                                     -1.019825   \n",
       "7                                     -0.468950   \n",
       "8                                      1.215639   \n",
       "9                                     -0.525997   \n",
       "10                                    -0.355444   \n",
       "11                                     0.089586   \n",
       "12                                     1.225364   \n",
       "13                                     0.021780   \n",
       "14                                    -0.602885   \n",
       "15                                    -0.440995   \n",
       "16                                     1.256796   \n",
       "17                                    -0.828478   \n",
       "18                                     0.094861   \n",
       "19                                    -0.329092   \n",
       "\n",
       "    Total_timeDelta_Seconds__median  Total_timeDelta_Seconds__mean  \\\n",
       "0                         -0.783634                      -0.932023   \n",
       "1                         -0.408423                      -0.523979   \n",
       "2                         -0.190167                      -0.191084   \n",
       "3                         -0.493300                      -0.461073   \n",
       "4                         -0.746248                      -0.705858   \n",
       "5                         -0.766794                      -0.848469   \n",
       "6                         -0.751974                      -0.914208   \n",
       "7                         -0.493300                      -0.461073   \n",
       "8                          2.083330                       1.611460   \n",
       "9                         -0.630721                      -0.560692   \n",
       "10                        -0.621963                      -0.492450   \n",
       "11                         0.021352                       0.038075   \n",
       "12                         1.291816                       1.250969   \n",
       "13                        -0.095186                      -0.078190   \n",
       "14                        -0.563358                      -0.585397   \n",
       "15                        -0.536412                      -0.493665   \n",
       "16                        -0.242710                       0.344634   \n",
       "17                        -0.696063                      -0.803112   \n",
       "18                         0.097472                       0.162137   \n",
       "19                        -0.557295                      -0.445108   \n",
       "\n",
       "    Total_timeDelta_Seconds__root_mean_square  BreedName_1  BreedName_2  \\\n",
       "0                                   -0.994034          0.0          1.0   \n",
       "1                                   -0.645444          0.0          0.0   \n",
       "2                                   -0.213088          1.0          0.0   \n",
       "3                                   -0.473615          1.0          0.0   \n",
       "4                                   -0.782359          0.0          0.0   \n",
       "5                                   -0.838479          0.0          1.0   \n",
       "6                                   -0.985688          1.0          0.0   \n",
       "7                                   -0.473615          1.0          0.0   \n",
       "8                                    1.401271          0.0          0.0   \n",
       "9                                   -0.547422          1.0          0.0   \n",
       "10                                  -0.416001          0.0          1.0   \n",
       "11                                   0.062078          0.0          1.0   \n",
       "12                                   1.238412          0.0          0.0   \n",
       "13                                  -0.025813          0.0          0.0   \n",
       "14                                  -0.603815          0.0          1.0   \n",
       "15                                  -0.469610          0.0          1.0   \n",
       "16                                   0.905240          0.0          1.0   \n",
       "17                                  -0.825628          1.0          0.0   \n",
       "18                                   0.118548          0.0          1.0   \n",
       "19                                  -0.382198          0.0          1.0   \n",
       "\n",
       "    BreedName_4  BreedName_99  problematic  \n",
       "0           0.0           0.0            0  \n",
       "1           1.0           0.0            0  \n",
       "2           0.0           0.0            0  \n",
       "3           0.0           0.0            0  \n",
       "4           0.0           1.0            0  \n",
       "5           0.0           0.0            0  \n",
       "6           0.0           0.0            0  \n",
       "7           0.0           0.0            0  \n",
       "8           0.0           1.0            1  \n",
       "9           0.0           0.0            0  \n",
       "10          0.0           0.0            0  \n",
       "11          0.0           0.0            1  \n",
       "12          0.0           1.0            1  \n",
       "13          0.0           1.0            0  \n",
       "14          0.0           0.0            0  \n",
       "15          0.0           0.0            0  \n",
       "16          0.0           0.0            1  \n",
       "17          0.0           0.0            0  \n",
       "18          0.0           0.0            1  \n",
       "19          0.0           0.0            0  \n",
       "\n",
       "[20 rows x 36 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cow_dataset = pd.DataFrame()\n",
    "\n",
    "for tc in test_cow_list:\n",
    "    test_data = ts_dataset[ts_dataset['id'] == tc]\n",
    "    frames = [test_cow_dataset, test_data]\n",
    "    test_cow_dataset = pd.concat(frames, ignore_index=True)\n",
    "    \n",
    "test_cow_dataset\n",
    "#test_cow_dataset.to_csv(dataDir+\"test_cow_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "44e23afb-169a-4b3a-949f-f590c68f8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.DataFrame(test_cow_dataset['problematic'], columns=['problematic'])\n",
    "test_data = test_cow_dataset.drop('problematic', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c528233d-dc85-4217-876a-fe7e70c285be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py:477: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py:477: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py:477: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py:477: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py:477: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "50 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 57-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 50-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 56-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 52-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 53-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 60-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 63-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 51-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 49-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 59-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 67-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 55-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 54-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 45-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 38-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 40-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 41-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 37-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 39-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 36-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 46-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 43-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 741, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 229, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 474, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py\", line 710, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py\", line 307, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 383, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 77, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/optimize/_optimize.py\", line 71, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 220, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 385, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/gaussian_process/_gpc.py\", line 444, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 42-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.93313333 0.93966667 0.90686667 0.9348     0.92493333        nan\n",
      "        nan 0.92506667]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.9396666666666665\n",
      "Best estimator parameters:  {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.933 with: {'kernel': 1**2 * RBF(length_scale=1)}\n",
      "Accuracy 0.940 with: {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.907 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      "Accuracy 0.935 with: {'kernel': 1**2 * RationalQuadratic(alpha=1, length_scale=1)}\n",
      "Accuracy 0.925 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=1)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=3)}\n",
      "Accuracy 0.925 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n"
     ]
    }
   ],
   "source": [
    "#%%capture --no-stderr\n",
    "#%%capture --no-display\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_labels, test_labels\n",
    "\n",
    "model = GaussianProcessClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=5)\n",
    "# exhausive search over different kernels\n",
    "search = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# fit model into the dataset\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", result.best_score_)\n",
    "print(\"Best estimator parameters: \", result.best_params_)\n",
    "\n",
    "means = result.cv_results_['mean_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"Accuracy %.3f with: %r\" % (mean, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b4a4de1-86d4-4489-be2f-6ccec8061d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 1**2 * DotProduct(sigma_0=1)}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6de6e667-a6a3-4067-a2a8-8baaf1763601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              15\n",
       "1               5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "abddfa0d-f554-4c49-a721-704861548ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              83\n",
       "1              40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78291d70-c611-4ff8-a397-e4afb82711be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training data:  0.967479674796748\n",
      "Prediction on test data:  [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "True values of test data:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "Prediction accuracy on test data:  0.9\n"
     ]
    }
   ],
   "source": [
    "best_kernel = 1**2 * DotProduct(sigma_0=1)\n",
    "#best_kernel = 1**2 * RationalQuadratic(alpha=1, length_scale=1)\n",
    "#best_kernel = 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)\n",
    "# best_kernel = 1**2 * Matern(length_scale=1, nu=1.5)\n",
    "#best_kernel = 1**2 * RBF(length_scale=1)\n",
    "model = GaussianProcessClassifier(kernel=best_kernel, random_state=30, n_jobs=-1)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model.score(X_train, y_train))\n",
    "\n",
    "# My guess is to look at what we have in X_test dataset and see if I can reduce the number of days.\n",
    "# The challenge is how do we ensure that the number of days we have found for correct prediction will always \n",
    "# be the correct one? \n",
    "\n",
    "print(\"Prediction on test data: \", model.predict(X_test))\n",
    "print(\"True values of test data: \", y_test['problematic'].tolist())\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"Prediction accuracy on test data: \", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1ab5b6fe-3c2e-43fc-88af-5af744ba93ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99520819, 0.00479181],\n",
       "       [0.64691143, 0.35308857],\n",
       "       [0.92551052, 0.07448948],\n",
       "       [0.98068648, 0.01931352],\n",
       "       [0.91273766, 0.08726234],\n",
       "       [0.99172046, 0.00827954],\n",
       "       [0.9982739 , 0.0017261 ],\n",
       "       [0.98068648, 0.01931352],\n",
       "       [0.01071616, 0.98928384],\n",
       "       [0.99189956, 0.00810044],\n",
       "       [0.97722356, 0.02277644],\n",
       "       [0.78070653, 0.21929347],\n",
       "       [0.01777185, 0.98222815],\n",
       "       [0.782957  , 0.217043  ],\n",
       "       [0.98948286, 0.01051714],\n",
       "       [0.97973449, 0.02026551],\n",
       "       [0.19812688, 0.80187312],\n",
       "       [0.99212652, 0.00787348],\n",
       "       [0.57212294, 0.42787706],\n",
       "       [0.95028588, 0.04971412]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_list = model.predict_proba(X_test)\n",
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ae0a5d15-268c-4a11-9d9f-faa6c891a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "cow_id = X_test.index.copy()\n",
    "cow_id = cow_id.astype(str)\n",
    "\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "facecolor = '#eaeaf2'\n",
    "color_red = '#f44336'\n",
    "color_blue = '#4496df'\n",
    "index = cow_id\n",
    "column0 = prob_list[:, 0]\n",
    "column1 = prob_list[:, 1]\n",
    "title0 = 'Problematic Cows, test set'\n",
    "title1 = 'Normal Cows, test set'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5), facecolor=facecolor, ncols=2, sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0].barh(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes[0].set_title(title0, fontsize=18, pad=15, color=color_red, **hfont)\n",
    "axes[1].barh(index, column1, align='center', color=color_blue, zorder=10)\n",
    "axes[1].set_title(title1, fontsize=18, pad=15, color=color_blue, **hfont)\n",
    "\n",
    "# If you have positive numbers and want to invert the x-axis of the left plot\n",
    "axes[0].invert_xaxis() \n",
    "\n",
    "# To show data from highest to lowest\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "axes[0].set(yticks=cow_id, yticklabels=cow_id)\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[0].tick_params(axis='y', colors='black') # tick color\n",
    "\n",
    "axes[0].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[0].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "for label in (axes[0].get_xticklabels() + axes[0].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "for label in (axes[1].get_xticklabels() + axes[1].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, top=0.85, bottom=0.1, left=0.18, right=0.95)\n",
    "filename = 'Problematic_Cows'\n",
    "plt.savefig(filename+'.png', facecolor=facecolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35c659-e272-4de7-9c88-68deee33fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# Total_timeDelta_Seconds__minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25d87e85-9998-4bf1-bbff-622b6174bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Plot decision boundary with uncertainty\u001b[39;00m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m---> 18\u001b[0m x_min, x_max \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m y_min, y_max \u001b[38;5;241m=\u001b[39m X[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39mlinspace(x_min, x_max, \u001b[38;5;241m100\u001b[39m),\n\u001b[1;32m     21\u001b[0m                      np\u001b[38;5;241m.\u001b[39mlinspace(y_min, y_max, \u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:5974\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5972\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5973\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5974\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = pd.DataFrame(ts_dataset['problematic'], columns=['problematic'])\n",
    "#X = pd.DataFrame(ts_dataset['Total_timeDelta_Seconds__minimum', 'Total_timeDelta_Seconds__root_mean_square'], columns=['Total_timeDelta_Seconds__minimum', 'Total_timeDelta_Seconds__root_mean_square'])\n",
    "\n",
    "X = pd.DataFrame(ts_dataset['Total_timeDelta_Seconds__minimum'], columns=['Total_timeDelta_Seconds__minimum'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the Gaussian Process model with an RBF kernel\n",
    "kernel = 1.0 * RBF(length_scale=1.0)\n",
    "gpc = GaussianProcessClassifier(kernel=kernel)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gpc.fit(X_train, y_train)\n",
    "\n",
    "# Plot decision boundary with uncertainty\n",
    "plt.figure(figsize=(10, 5))\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# Obtain predictions and uncertainties\n",
    "Z = gpc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "probs_mesh = gpc.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]  # Probability for class 1\n",
    "Z = Z.reshape(xx.shape)\n",
    "probs_mesh = probs_mesh.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundaries\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# Plot class probabilities as uncertainty\n",
    "plt.contourf(xx, yy, probs_mesh, cmap='RdYlBu', alpha=0.2)\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k')\n",
    "plt.title('Gaussian Process Classification with Uncertainty')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b89d5-1a20-4699-9c27-a83383e6918e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
