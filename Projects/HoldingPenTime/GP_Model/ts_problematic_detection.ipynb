{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5613    12729\n",
      "4478    11601\n",
      "3757    11428\n",
      "6197    11250\n",
      "2423    11192\n",
      "4504    10688\n",
      "3147    10658\n",
      "5147    10576\n",
      "5046    10204\n",
      "478     10028\n",
      "Name: Gigacow_Cow_Id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Gigacow-tools# - data collection for fast/slow learner.\n",
    "This scripts used for single cow data collection work.\n",
    "Data Tables: gigacow_filter.csv, lactation_filter.csv, traffic_raw_filter.csv\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "pd.options.mode.chained_assignment = None\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, MinimalFCParameters\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "#access data from local directory\n",
    "dataDir = Path.cwd().parent.parent/'Data/processed'\n",
    "gigacow_cols = ['Gigacow_Cow_Id', 'FarmName_Pseudo', 'BreedName', 'BirthDate']\n",
    "lactation_cols = ['Gigacow_Cow_Id', 'FarmName_Pseudo', 'LactationInfoDate', 'LactationNumber', 'DaysInMilk']\n",
    "gigacow = pd.read_csv(dataDir/'gigacow_filter.csv', encoding='utf-8', usecols=gigacow_cols)\n",
    "lactation = pd.read_csv(dataDir/'lactation_filter.csv', encoding='utf-8', usecols=lactation_cols)\n",
    "traffic = pd.read_csv(dataDir/'traffic_raw_filter.csv', encoding='utf-8', index_col=False)\n",
    "#check out cows with most milking events\n",
    "print(traffic.Gigacow_Cow_Id.value_counts().nlargest(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 [2560, 3075, 2569, 4109, 3603, 1555, 5147, 3613, 544, 550, 5160, 2090, 3638, 3657, 74, 1103, 4176, 2135, 4704, 6241, 4195, 622, 5235, 3705, 3707, 645, 2694, 5767, 3718, 2702, 151, 6300, 1181, 3744, 2724, 6316, 3762, 5301, 182, 4792, 708, 4295, 5322, 2251, 1738, 1744, 5846, 4311, 1244, 5852, 2278, 6380, 5873, 5372, 1277, 769, 1796, 2844, 6434, 4899, 3890, 1336, 2374, 6472, 4939, 5965, 855, 5465, 1905, 3446, 3447, 2423, 4988, 4990, 6018, 3979, 2956, 6039, 2460, 926, 3487, 2979, 4525, 943, 5555, 5046, 951, 4537, 961, 1985, 6086, 4038, 2510, 5076, 2517, 985, 478, 5088, 5092, 3563, 2031, 6127, 5616, 2039, 2047]\n"
     ]
    }
   ],
   "source": [
    "# Select cows with sufficient data points on single lactation periods\n",
    "# Try to collect cow's data that contain milking events on lactation periods 1\n",
    "# fetch all milking traffic events for merging\n",
    "traffic_milking = traffic.TrafficResult.str.contains('kg', regex=False)\n",
    "all_list = traffic_milking.index[traffic_milking.values == True].tolist()\n",
    "milking_total = traffic[traffic.index.isin(all_list)]\n",
    "milking_total.TrafficEventDateTime = pd.to_datetime(milking_total.TrafficEventDateTime)\n",
    "milking_total['milking_date'] = milking_total.TrafficEventDateTime.dt.date\n",
    "\n",
    "# convert data type\n",
    "milking_total.milking_date = pd.to_datetime(milking_total.milking_date)\n",
    "lactation.LactationInfoDate = pd.to_datetime(lactation.LactationInfoDate)\n",
    "# merge all milking events with lactation table for filtering\n",
    "milking_total = milking_total.merge(lactation, how='left', left_on=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'milking_date'], right_on=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'LactationInfoDate'])\n",
    "\n",
    "def lac_collect(NumLac, milking_total):\n",
    "    \"\"\"Generate cow list for multiple lactation periods.\n",
    "\n",
    "    Args:\n",
    "        NumLac: The number of lactaion period\n",
    "        milking_total: A dataframe contains all the milkings events\n",
    "\n",
    "    Returns:\n",
    "        A list contain all the cows events with sufficient data points within the lactation periods.\n",
    "    \"\"\"\n",
    "    cow_list = list()\n",
    "    for num in range(1, NumLac+1):\n",
    "        # select records that contains lactation period #num\n",
    "        milking_select1 = milking_total.loc[milking_total['LactationNumber'] == num]\n",
    "        milking_select1.drop_duplicates(subset=['Gigacow_Cow_Id', 'milking_date', 'LactationNumber', 'DaysInMilk'], inplace=True)\n",
    "        # drop the anomaly data point\n",
    "        milking_select1 = milking_select1.loc[milking_select1.DaysInMilk < 400]\n",
    "        # select sufficient data points on lactation\n",
    "        selected1 = milking_select1.Gigacow_Cow_Id.value_counts(ascending=True)\n",
    "        selected1 = selected1.loc[(selected1.values > 150) & (selected1.values < 365)]\n",
    "        selected_cow_list = selected1.index.to_list()\n",
    "        if num == 1:\n",
    "            cow_list = selected_cow_list\n",
    "        cow_list = list(set(cow_list) & set(selected_cow_list))\n",
    "        print(len(cow_list), cow_list)\n",
    "    return cow_list\n",
    "\n",
    "cow_list = lac_collect(1, milking_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countCowAge(birthDate, milkingDate):\n",
    "    '''\n",
    "    func: Calculate cows age based on birthDate and milkingDate\n",
    "    args: \n",
    "        birthDate: cow's birth datetime\n",
    "        milkingDate: milking events datetime\n",
    "    return: cow age in human years(float)\n",
    "    '''\n",
    "    birthDate = pd.to_datetime(birthDate)\n",
    "    milkingDate = pd.to_datetime(milkingDate)\n",
    "    days = np.float32(np.datetime64(milkingDate, 'D') - np.datetime64(birthDate, 'D'))\n",
    "    age = np.around(days/365, 2)\n",
    "    return age\n",
    "\n",
    "# select single cow from the traffic table\n",
    "\n",
    "def data_collector(traffic, gigacow, lactation, cow_id, lacNumList):\n",
    "    '''\n",
    "    func: collect features from for a single cow\n",
    "    args: \n",
    "        traffic: traffic data table\n",
    "        gigacow: gigacow data table\n",
    "        lactation: lactation data table\n",
    "        cow_id: gigacow_id of the cow\n",
    "        lacNumList: a list lactation period number\n",
    "    return: A dataframe contains all features for a single cow on specfic lactation period\n",
    "    '''\n",
    "\n",
    "    traffic_single_cow = traffic.loc[traffic['Gigacow_Cow_Id'] == cow_id]\n",
    "    traffic_single_cow.sort_values(by='TrafficEventDateTime', inplace=True)\n",
    "    traffic_single_cow.index = range(len(traffic_single_cow))\n",
    "\n",
    "    '''\n",
    "        Extract Milking Event and its most recent traffic event to calculate T2-T1\n",
    "        T1: Entry time into the Mjolkfalla\n",
    "        T2: Entry time into the milking robot\n",
    "        T2-T1: calculate time difference between T2&T1 (i.e., Time spend in Mjolkfalla/holding area)\n",
    "    '''\n",
    "    # locate mikling event by searching 'kg' keyword in traffic result\n",
    "    # the most recent traffic event to milking event should be pre_milking event\n",
    "    # need to filter out records with gate failure\n",
    "    track_milking = traffic_single_cow.TrafficResult.str.contains('kg', regex=False)\n",
    "    milking_index_list = track_milking.index[track_milking.values == True].tolist()\n",
    "    pre_milking_index_list = [x-1 for x in milking_index_list]\n",
    "    milking_traffic = traffic_single_cow[traffic_single_cow.index.isin(milking_index_list)]\n",
    "    pre_milking_traffic = traffic_single_cow[traffic_single_cow.index.isin(pre_milking_index_list)]\n",
    "\n",
    "    # drop rows that the gate failed to detect cows but have milking result\n",
    "    # previous area in milking_traffic table should only be Mjolkfalla\n",
    "    # previous area in pre_milking_traffic table should not be Mjolkfalla\n",
    "    failed_list_1_milk = milking_traffic.index[milking_traffic['PreviousArea'] == 'Koridor till Sorteringsgrind 2'].tolist()\n",
    "    failed_list_1_pre = [x-1 for x in failed_list_1_milk]\n",
    "    failed_list_2_pre = pre_milking_traffic.index[pre_milking_traffic['PreviousArea'] == 'Mjolkfalla'].tolist()\n",
    "    failed_list_2_milk = [x+1 for x in failed_list_2_pre]\n",
    "    # traffic result in pre_milking_traffic table should contain Mjolkfalla\n",
    "    track_pre_milking = pre_milking_traffic.TrafficResult.str.contains('Mjolkfalla', regex=False)\n",
    "    failed_list_3_pre = track_pre_milking.index[track_pre_milking.values == False].tolist()\n",
    "    failed_list_3_milk = [x+1 for x in failed_list_3_pre]\n",
    "\n",
    "    # remove failed records based on index list\n",
    "    milking_traffic_failed = failed_list_1_milk + failed_list_2_milk + failed_list_3_milk\n",
    "    pre_milking_traffic_failed = failed_list_1_pre + failed_list_2_pre + failed_list_3_pre\n",
    "    milking_traffic.drop(axis=0, index=milking_traffic_failed, inplace=True)\n",
    "    pre_milking_traffic.drop(axis=0, index=pre_milking_traffic_failed, inplace=True)\n",
    "    # concatenate two tables to track the traffic directly\n",
    "    all_milking_traffic = pd.concat([milking_traffic, pre_milking_traffic])\n",
    "    all_milking_traffic.sort_values(by=['TrafficEventDateTime'], inplace=True)\n",
    "    #rename table columns for merging\n",
    "    milking_traffic.rename(columns={\"TrafficEventDateTime\": \"MilkingEventDateTime\", \"TrafficResult\": \"MilkProduction\", \"TimeInArea_totalSeconds\": \"RoundedSecondsTimeInArea\"}, inplace=True)\n",
    "    pre_milking_traffic.rename(columns={\"TrafficEventDateTime\": \"Pre_MilkingEventDateTime\", \"TimeInArea_totalSeconds\": \"RoundedSecondsTimeInArea\"}, inplace=True)\n",
    "    # unify the index of two tables\n",
    "    milking_traffic.index = range(len(milking_traffic))\n",
    "    pre_milking_traffic.index = range(len(pre_milking_traffic))\n",
    "    # inert \"pre_traffic_milking\" to milking traffic table\n",
    "    milking_traffic.insert(5, 'Pre_MilkingEventDateTime', pre_milking_traffic['Pre_MilkingEventDateTime'])\n",
    "    # calculate T2-T1\n",
    "    milking_traffic.MilkingEventDateTime = pd.to_datetime(milking_traffic.MilkingEventDateTime)\n",
    "    milking_traffic.Pre_MilkingEventDateTime = pd.to_datetime(milking_traffic.Pre_MilkingEventDateTime)\n",
    "    milking_traffic['timeDelta_Seconds'] = (milking_traffic['MilkingEventDateTime'] - milking_traffic['Pre_MilkingEventDateTime']).dt.total_seconds()\n",
    "\n",
    "    # extract traffic result(milk production)\n",
    "    milking_traffic['MilkProduction'].replace(r\"[^0-9.,]+\",\" \", inplace=True, regex=True)\n",
    "    milking_traffic['MilkProduction'].replace(r\"\\s*\",\"\", inplace=True, regex=True)\n",
    "    milking_traffic['MilkProduction'].replace(r\"[,]+\",\".\", inplace=True, regex=True)\n",
    "    milking_traffic['MilkProduction'] = milking_traffic['MilkProduction'].astype('float64')\n",
    "\n",
    "    # merge all the other features into milking_traffic table\n",
    "    milking_traffic['MilkingDate'] = milking_traffic.MilkingEventDateTime.dt.date\n",
    "    milking_traffic.MilkingDate = pd.to_datetime(milking_traffic.MilkingDate)\n",
    "    lactation.LactationInfoDate = pd.to_datetime(lactation.LactationInfoDate)\n",
    "    single_cow_merge = milking_traffic.merge(lactation, how='left', left_on=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'MilkingDate'], right_on=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'LactationInfoDate'])\n",
    "    single_cow_merge = single_cow_merge.merge(gigacow, how='left', left_on=['FarmName_Pseudo', 'Gigacow_Cow_Id'], right_on=['FarmName_Pseudo', 'Gigacow_Cow_Id'])\n",
    "\n",
    "    # drop failed data points based on RoundedSecondsTimeInArea & timeDelta_Seconds\n",
    "    single_cow_merge.drop(single_cow_merge.loc[abs(single_cow_merge.timeDelta_Seconds - single_cow_merge.RoundedSecondsTimeInArea) > 300].index, inplace=True)\n",
    "    single_cow_merge['TrafficDeviceName'].replace(r\"[A-Za-z]+\\s*\",\"vms\", inplace=True, regex=True)\n",
    "    # calculate age of cows\n",
    "    single_cow_merge['Age'] = single_cow_merge.apply(lambda x: countCowAge(x['BirthDate'], x['MilkingEventDateTime']), axis=1)\n",
    "    single_cow_merge.drop(['BirthDate'], axis=1, inplace=True)\n",
    "    single_cow_merge.dropna(inplace=True)\n",
    "\n",
    "    # integrate multiple milking events for a single DIM\n",
    "    single_cow_merge = single_cow_merge[single_cow_merge.LactationNumber.isin(lacNumList)]\n",
    "    single_cow_merge.index = range(1,len(single_cow_merge)+1) \n",
    "    single_cow_merge.drop(['MilkingEventDateTime', 'Pre_MilkingEventDateTime', 'Traffic_Id', 'MilkingInterval_totalSeconds', 'RoundedSecondsTimeInArea', 'PreviousArea', 'GroupName', 'LactationInfoDate', 'TrafficDeviceName'], axis=1, inplace=True)\n",
    "\n",
    "    # uncomment following part to get combined milking events for each DIM\n",
    "    # comb_cows = single_cow_merge.groupby(by=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'MilkingDate', 'LactationNumber', 'DaysInMilk', 'BreedName', 'Age'], sort=False, as_index=False).sum(['MilkProduction', 'timeDelta_Seconds'])\n",
    "    # single_cow_merge_size = single_cow_merge.groupby(by=['FarmName_Pseudo', 'Gigacow_Cow_Id', 'MilkingDate', 'LactationNumber', 'DaysInMilk', 'BreedName', 'Age'], sort=False, as_index=False).size()\n",
    "    # comb_cows = pd.concat([comb_cows, single_cow_merge_size['size']], axis=1, ignore_index=False)\n",
    "    # comb_cows.rename(columns={\"MilkProduction\": \"Total_MilkProduction\", \"timeDelta_Seconds\": \"Total_timeDelta_Seconds\", \"size\": \"milking_times\"}, inplace=True)\n",
    "    # comb_cows.index = range(1, len(comb_cows)+1)\n",
    "    # return comb_cows\n",
    "\n",
    "    single_cow_merge.rename(columns={\"MilkProduction\": \"Total_MilkProduction\", \"timeDelta_Seconds\": \"Total_timeDelta_Seconds\", \"size\": \"milking_times\"}, inplace=True)\n",
    "    single_cow_merge.index = range(1, len(single_cow_merge)+1)\n",
    "    return single_cow_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "labeling cow with problematic/normal(1/0)\n",
    "\"\"\"\n",
    "threshold_ratio = 0.05\n",
    "Path(dataDir/'Problematic_targetCows').mkdir(parents=True, exist_ok=True)\n",
    "def labeling_problematic(threshold_ratio, cow_total): \n",
    "    '''\n",
    "    func: labeling problematic cows\n",
    "    args: \n",
    "        threshold_ratio: threshold ratio for the abnormal event milking events\n",
    "        cow_total: A dataframe contains all data points for a single cow\n",
    "    return: problematic cows dataset with label\n",
    "    '''\n",
    "    global learner\n",
    "    total_events = len(cow_total)\n",
    "    abnoramal_cows = cow_total.loc[cow_total.Total_timeDelta_Seconds > 7200]\n",
    "    abnoramal_ratio = len(abnoramal_cows)/total_events\n",
    "    print(abnoramal_ratio)\n",
    "    if abnoramal_ratio > threshold_ratio:\n",
    "        problematic = 1 # problematic cow\n",
    "    else:\n",
    "        problematic = 0 # normal cow\n",
    "    cow_total['problematic'] = problematic\n",
    "    return cow_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered:  100 [2560, 3075, 2569, 4109, 3603, 1555, 5147, 3613, 544, 550, 5160, 2090, 3638, 3657, 74, 1103, 4176, 2135, 4704, 6241, 4195, 5235, 3705, 3707, 645, 2694, 5767, 3718, 2702, 151, 6300, 1181, 3744, 2724, 6316, 5301, 4792, 708, 4295, 5322, 2251, 1738, 1744, 5846, 4311, 1244, 5852, 2278, 6380, 5873, 5372, 1277, 769, 1796, 2844, 6434, 4899, 3890, 1336, 2374, 6472, 4939, 5965, 855, 5465, 1905, 3446, 3447, 2423, 4988, 4990, 6018, 3979, 2956, 6039, 2460, 926, 2979, 4525, 943, 5555, 5046, 951, 961, 1985, 6086, 4038, 2510, 5076, 2517, 985, 478, 5088, 5092, 3563, 2031, 6127, 5616, 2039, 2047]\n"
     ]
    }
   ],
   "source": [
    "# filter out cows' record start at the middle of the lactation\n",
    "filter_list = []\n",
    "for id in cow_list:\n",
    "    single_cow = data_collector(traffic, gigacow, lactation, id, [1])\n",
    "    if single_cow.DaysInMilk.min() < 60:\n",
    "        filter_list.append(id)\n",
    "\n",
    "print(\"filtered: \", len(filter_list), filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cow_id: 2560\n",
      "0.004132231404958678\n",
      "cow_id: 3075\n",
      "0.06535947712418301\n",
      "cow_id: 2569\n",
      "0.0\n",
      "cow_id: 4109\n",
      "0.2611683848797251\n",
      "cow_id: 3603\n",
      "0.032362459546925564\n",
      "cow_id: 1555\n",
      "0.0017452006980802793\n",
      "cow_id: 5147\n",
      "0.0\n",
      "cow_id: 3613\n",
      "0.0\n",
      "cow_id: 544\n",
      "0.22893772893772893\n",
      "cow_id: 550\n",
      "0.0899581589958159\n",
      "cow_id: 5160\n",
      "0.004722550177095631\n",
      "cow_id: 2090\n",
      "0.005474452554744526\n",
      "cow_id: 3638\n",
      "0.0027397260273972603\n",
      "cow_id: 3657\n",
      "0.09400544959128065\n",
      "cow_id: 74\n",
      "0.0026490066225165563\n",
      "cow_id: 1103\n",
      "0.0020408163265306124\n",
      "cow_id: 4176\n",
      "0.032577903682719546\n",
      "cow_id: 2135\n",
      "0.06801736613603473\n",
      "cow_id: 4704\n",
      "0.03292181069958848\n",
      "cow_id: 6241\n",
      "0.014265335235378032\n",
      "cow_id: 4195\n",
      "0.011217948717948718\n",
      "cow_id: 5235\n",
      "0.017857142857142856\n",
      "cow_id: 3705\n",
      "0.004645760743321719\n",
      "cow_id: 3707\n",
      "0.007556675062972292\n",
      "cow_id: 645\n",
      "0.11026615969581749\n",
      "cow_id: 2694\n",
      "0.125\n",
      "cow_id: 5767\n",
      "0.016320474777448073\n",
      "cow_id: 3718\n",
      "0.0021668472372697724\n",
      "cow_id: 2702\n",
      "0.0\n",
      "cow_id: 151\n",
      "0.004464285714285714\n",
      "cow_id: 6300\n",
      "0.07692307692307693\n",
      "cow_id: 1181\n",
      "0.02621359223300971\n",
      "cow_id: 3744\n",
      "0.12152777777777778\n",
      "cow_id: 2724\n",
      "0.1095890410958904\n",
      "cow_id: 6316\n",
      "0.12165450121654502\n",
      "cow_id: 5301\n",
      "0.14165261382799327\n",
      "cow_id: 4792\n",
      "0.1022964509394572\n",
      "cow_id: 708\n",
      "0.0012953367875647669\n",
      "cow_id: 4295\n",
      "0.15113350125944586\n",
      "cow_id: 5322\n",
      "0.0047169811320754715\n",
      "cow_id: 2251\n",
      "0.030791788856304986\n",
      "cow_id: 1738\n",
      "0.0161892901618929\n",
      "cow_id: 1744\n",
      "0.15217391304347827\n",
      "cow_id: 5846\n",
      "0.015822784810126583\n",
      "cow_id: 4311\n",
      "0.24774774774774774\n",
      "cow_id: 1244\n",
      "0.01748971193415638\n",
      "cow_id: 5852\n",
      "0.004132231404958678\n",
      "cow_id: 2278\n",
      "0.004914004914004914\n",
      "cow_id: 6380\n",
      "0.005649717514124294\n",
      "cow_id: 5873\n",
      "0.1118421052631579\n",
      "cow_id: 5372\n",
      "0.3037249283667622\n",
      "cow_id: 1277\n",
      "0.31567328918322296\n",
      "cow_id: 769\n",
      "0.022354694485842028\n",
      "cow_id: 1796\n",
      "0.028528528528528527\n",
      "cow_id: 2844\n",
      "0.04136947218259629\n",
      "cow_id: 6434\n",
      "0.1154639175257732\n",
      "cow_id: 4899\n",
      "0.002331002331002331\n",
      "cow_id: 3890\n",
      "0.012024048096192385\n",
      "cow_id: 1336\n",
      "0.01478494623655914\n",
      "cow_id: 2374\n",
      "0.0\n",
      "cow_id: 6472\n",
      "0.004310344827586207\n",
      "cow_id: 4939\n",
      "0.005161290322580645\n",
      "cow_id: 5965\n",
      "0.09623430962343096\n",
      "cow_id: 855\n",
      "0.05654761904761905\n",
      "cow_id: 5465\n",
      "0.00410958904109589\n",
      "cow_id: 1905\n",
      "0.006880733944954129\n",
      "cow_id: 3446\n",
      "0.022508038585209004\n",
      "cow_id: 3447\n",
      "0.004484304932735426\n",
      "cow_id: 2423\n",
      "0.01445466491458607\n",
      "cow_id: 4988\n",
      "0.12968299711815562\n",
      "cow_id: 4990\n",
      "0.002331002331002331\n",
      "cow_id: 6018\n",
      "0.05771643663739021\n",
      "cow_id: 3979\n",
      "0.26153846153846155\n",
      "cow_id: 2956\n",
      "0.013646702047005308\n",
      "cow_id: 6039\n",
      "0.30392156862745096\n",
      "cow_id: 2460\n",
      "0.08737864077669903\n",
      "cow_id: 926\n",
      "0.007905138339920948\n",
      "cow_id: 2979\n",
      "0.06302521008403361\n",
      "cow_id: 4525\n",
      "0.0299625468164794\n",
      "cow_id: 943\n",
      "0.0035714285714285713\n",
      "cow_id: 5555\n",
      "0.005115089514066497\n",
      "cow_id: 5046\n",
      "0.004120879120879121\n",
      "cow_id: 951\n",
      "0.013008130081300813\n",
      "cow_id: 961\n",
      "0.12624584717607973\n",
      "cow_id: 1985\n",
      "0.006243496357960458\n",
      "cow_id: 6086\n",
      "0.015238095238095238\n",
      "cow_id: 4038\n",
      "0.024783147459727387\n",
      "cow_id: 2510\n",
      "0.0010775862068965517\n",
      "cow_id: 5076\n",
      "0.049281314168377825\n",
      "cow_id: 2517\n",
      "0.1897810218978102\n",
      "cow_id: 985\n",
      "0.0029354207436399216\n",
      "cow_id: 478\n",
      "0.012091898428053204\n",
      "cow_id: 5088\n",
      "0.009248554913294798\n",
      "cow_id: 5092\n",
      "0.0\n",
      "cow_id: 3563\n",
      "0.275974025974026\n",
      "cow_id: 2031\n",
      "0.006756756756756757\n",
      "cow_id: 6127\n",
      "0.014814814814814815\n",
      "cow_id: 5616\n",
      "0.03417721518987342\n",
      "cow_id: 2039\n",
      "0.014184397163120567\n",
      "cow_id: 2047\n",
      "0.004694835680751174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import warnings\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "\"\"\" plot the relations between timeDelta and Lactation/DIM(DaysInMilk)\n",
    "        @@@ Total_timeDelta @@@\n",
    "    \"\"\" \n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    with PdfPages(dataDir/'100cows_timecost_scatters_lac1_with_label_scale30000.pdf') as pdf:\n",
    "        for id in filter_list:\n",
    "            print(\"cow_id:\", id)\n",
    "            single_cow_merge = data_collector(traffic, gigacow, lactation, id, [1])\n",
    "            single_cow_merge = labeling_problematic(0.05, single_cow_merge)\n",
    "            prob = single_cow_merge.problematic.unique()[0]\n",
    "            fig1 = plt.figure()\n",
    "            # fig2 = plt.figure()\n",
    "            if prob == 1:\n",
    "                title = \"Problematic_Cow_cow_id_\"+ str(id)\n",
    "            else:\n",
    "                title = \"Normal_Cow_cow_id_\"+ str(id)\n",
    "            fig1 = single_cow_merge.loc[single_cow_merge.LactationNumber == 1].plot(x=\"DaysInMilk\", y=\"Total_timeDelta_Seconds\", kind='scatter', title=title+\"_Lac1\", xlim=[1, 360], ylim=[0, 30000], s=2, c='b')\n",
    "            # fig2 = single_cow_merge.loc[single_cow_merge.LactationNumber == 2].plot(x=\"DaysInMilk\", y=\"Total_timeDelta_Seconds\", kind='scatter', title=title+\"_Lac2\", xlim=[1, 360], ylim=[0, 10000], s=2, c='b')\n",
    "            pdf.savefig(fig1.get_figure())\n",
    "            # pdf.savefig(fig2.get_figure())\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004132231404958678\n",
      "0.06535947712418301\n",
      "This cow is problematic\n",
      "0.0\n",
      "0.2611683848797251\n",
      "This cow is problematic\n",
      "0.032362459546925564\n",
      "0.0017452006980802793\n",
      "0.0\n",
      "0.0\n",
      "0.22893772893772893\n",
      "This cow is problematic\n",
      "0.0899581589958159\n",
      "This cow is problematic\n",
      "0.004722550177095631\n",
      "0.005474452554744526\n",
      "0.0027397260273972603\n",
      "0.09400544959128065\n",
      "This cow is problematic\n",
      "0.0026490066225165563\n",
      "0.0020408163265306124\n",
      "0.032577903682719546\n",
      "0.06801736613603473\n",
      "This cow is problematic\n",
      "0.03292181069958848\n",
      "0.014265335235378032\n",
      "0.011217948717948718\n",
      "0.017857142857142856\n",
      "0.004645760743321719\n",
      "0.007556675062972292\n",
      "0.11026615969581749\n",
      "This cow is problematic\n",
      "0.125\n",
      "This cow is problematic\n",
      "0.016320474777448073\n",
      "0.0021668472372697724\n",
      "0.0\n",
      "0.004464285714285714\n",
      "0.07692307692307693\n",
      "This cow is problematic\n",
      "0.02621359223300971\n",
      "0.12152777777777778\n",
      "This cow is problematic\n",
      "0.1095890410958904\n",
      "This cow is problematic\n",
      "0.12165450121654502\n",
      "This cow is problematic\n",
      "0.14165261382799327\n",
      "This cow is problematic\n",
      "0.1022964509394572\n",
      "This cow is problematic\n",
      "0.0012953367875647669\n",
      "0.15113350125944586\n",
      "This cow is problematic\n",
      "0.0047169811320754715\n",
      "0.030791788856304986\n",
      "0.0161892901618929\n",
      "0.15217391304347827\n",
      "This cow is problematic\n",
      "0.015822784810126583\n",
      "0.24774774774774774\n",
      "This cow is problematic\n",
      "0.01748971193415638\n",
      "0.004132231404958678\n",
      "0.004914004914004914\n",
      "0.005649717514124294\n",
      "0.1118421052631579\n",
      "This cow is problematic\n",
      "0.3037249283667622\n",
      "This cow is problematic\n",
      "0.31567328918322296\n",
      "This cow is problematic\n",
      "0.022354694485842028\n",
      "0.028528528528528527\n",
      "0.04136947218259629\n",
      "0.1154639175257732\n",
      "This cow is problematic\n",
      "0.002331002331002331\n",
      "0.012024048096192385\n",
      "0.01478494623655914\n",
      "0.0\n",
      "0.004310344827586207\n",
      "0.005161290322580645\n",
      "0.09623430962343096\n",
      "This cow is problematic\n",
      "0.05654761904761905\n",
      "This cow is problematic\n",
      "0.00410958904109589\n",
      "0.006880733944954129\n",
      "0.022508038585209004\n",
      "0.004484304932735426\n",
      "0.01445466491458607\n",
      "0.12968299711815562\n",
      "This cow is problematic\n",
      "0.002331002331002331\n",
      "0.05771643663739021\n",
      "This cow is problematic\n",
      "0.26153846153846155\n",
      "This cow is problematic\n",
      "0.013646702047005308\n",
      "0.30392156862745096\n",
      "This cow is problematic\n",
      "0.08737864077669903\n",
      "This cow is problematic\n",
      "0.007905138339920948\n",
      "0.06302521008403361\n",
      "This cow is problematic\n",
      "0.0299625468164794\n",
      "0.0035714285714285713\n",
      "0.005115089514066497\n",
      "0.004120879120879121\n",
      "0.013008130081300813\n",
      "0.12624584717607973\n",
      "This cow is problematic\n",
      "0.006243496357960458\n",
      "0.015238095238095238\n",
      "0.024783147459727387\n",
      "0.0010775862068965517\n",
      "0.049281314168377825\n",
      "0.1897810218978102\n",
      "This cow is problematic\n",
      "0.0029354207436399216\n",
      "0.012091898428053204\n",
      "0.009248554913294798\n",
      "0.0\n",
      "0.275974025974026\n",
      "This cow is problematic\n",
      "0.006756756756756757\n",
      "0.014814814814814815\n",
      "0.03417721518987342\n",
      "0.014184397163120567\n",
      "0.004694835680751174\n",
      "num of cows:  105\n",
      "Mean of total time cost:  1826.0575045068983\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "mean_totalTimeCost = 0\n",
    "Path(dataDir/'Problematic_targetCows').mkdir(parents=True, exist_ok=True)\n",
    "lactationNum = [1]\n",
    "\n",
    "# save a list of cow data for abnormal cows detection problem\n",
    "for i, cow_id in enumerate(filter_list):\n",
    "    single_cow_merge = data_collector(traffic, gigacow, lactation, cow_id, lactationNum)\n",
    "    mean_totalTimeCost += single_cow_merge.Total_timeDelta_Seconds.mean()\n",
    "    single_cow_merge = labeling_problematic(threshold_ratio, single_cow_merge)\n",
    "    problematic = single_cow_merge.problematic.unique()[0]\n",
    "    if problematic == 1:\n",
    "        print(\"This cow is problematic\")\n",
    "    single_cow_merge[\"id\"] = i+1\n",
    "    single_cow_merge.dropna(inplace=True)\n",
    "    fileName = 'Problematic_targetCows/cow_' + str(i) + '.csv'\n",
    "    single_cow_merge.to_csv(dataDir/fileName)\n",
    "print(\"num of cows: \", len(cow_list))\n",
    "print(\"Mean of total time cost: \", mean_totalTimeCost/len(cow_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>9.38</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>8.46</td>\n",
       "      <td>352.0</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>6.68</td>\n",
       "      <td>997.0</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>7.34</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>8.15</td>\n",
       "      <td>407.0</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65499</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>10.51</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65500</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.49</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65501</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65502</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>6.77</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65503</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.81</td>\n",
       "      <td>635.0</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65504 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "0            a624fb9a            2560                  9.38   \n",
       "1            a624fb9a            2560                  8.46   \n",
       "2            a624fb9a            2560                  6.68   \n",
       "3            a624fb9a            2560                  7.34   \n",
       "4            a624fb9a            2560                  8.15   \n",
       "...               ...             ...                   ...   \n",
       "65499        a624fb9a            2047                 10.51   \n",
       "65500        a624fb9a            2047                  7.49   \n",
       "65501        a624fb9a            2047                  7.92   \n",
       "65502        a624fb9a            2047                  6.77   \n",
       "65503        a624fb9a            2047                  7.81   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "0                       3176.0  2022-02-14              1.0         2.0   \n",
       "1                        352.0  2022-02-14              1.0         2.0   \n",
       "2                        997.0  2022-02-15              1.0         3.0   \n",
       "3                       9274.0  2022-02-15              1.0         3.0   \n",
       "4                        407.0  2022-02-16              1.0         4.0   \n",
       "...                        ...         ...              ...         ...   \n",
       "65499                     25.0  2022-10-05              1.0       284.0   \n",
       "65500                      9.0  2022-10-05              1.0       284.0   \n",
       "65501                    181.0  2022-10-06              1.0       285.0   \n",
       "65502                     90.0  2022-10-06              1.0       285.0   \n",
       "65503                    635.0  2022-10-06              1.0       285.0   \n",
       "\n",
       "       BreedName   Age  problematic   id  \n",
       "0              1  2.15            0    1  \n",
       "1              1  2.15            0    1  \n",
       "2              1  2.15            0    1  \n",
       "3              1  2.15            0    1  \n",
       "4              1  2.15            0    1  \n",
       "...          ...   ...          ...  ...  \n",
       "65499          1  2.92            0  100  \n",
       "65500          1  2.92            0  100  \n",
       "65501          1  2.92            0  100  \n",
       "65502          1  2.92            0  100  \n",
       "65503          1  2.92            0  100  \n",
       "\n",
       "[65504 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Data Preparation \"\"\"\n",
    "\n",
    "usecols = ['id', 'FarmName_Pseudo', 'Gigacow_Cow_Id', 'Total_MilkProduction', 'Total_timeDelta_Seconds', 'LactationNumber', 'DaysInMilk', 'BreedName', 'Age', 'MilkingDate', 'problematic']\n",
    "dataDir = Path.cwd().parent.parent/'Data/processed/Problematic_targetCows/'\n",
    "\n",
    "# integrate all the cows data into one dataset\n",
    "filelist = list(Path(dataDir).glob('*.csv'))\n",
    "for i, _ in enumerate(filelist):\n",
    "    fileName = 'cow_' + str(i) + '.csv'\n",
    "    single_cow = pd.read_csv(dataDir/fileName, encoding='utf-8', usecols=usecols)\n",
    "    single_cow.sort_values(by=['MilkingDate'], inplace=True)\n",
    "    if i == 0:\n",
    "        cow_total = single_cow\n",
    "    else:\n",
    "        cow_total = pd.concat([cow_total, single_cow], axis=0, ignore_index=True)\n",
    "cow_total.to_csv(dataDir.parent/\"Cow_Prob_dataset_L1.csv\", index=False)\n",
    "cow_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    68\n",
      "1    32\n",
      "Name: problematic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#df_static_features = cow_total[['FarmName_Pseudo']]\n",
    "static_cols = ['FarmName_Pseudo', 'TrafficDeviceName', 'LactationNumber', 'BreedName']\n",
    "timeSeries_cols = ['Age', 'Total_MilkProduction', 'Total_timeDelta_Seconds', 'DaysInMilk']\n",
    "output_col = ['problematic']\n",
    "\n",
    "cow_label = cow_total[['id', 'problematic']].copy()\n",
    "cow_timeseries = cow_total[['id', 'MilkingDate']].copy()\n",
    "cow_timeseries.index = range(len(cow_timeseries))\n",
    "# fetch y for feature extraction\n",
    "y = cow_label.drop_duplicates(subset=['id'])\n",
    "y = y[\"problematic\"]\n",
    "y.index = range(1,len(y)+1) \n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>DaysInMilk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>2.15</td>\n",
       "      <td>9.38</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.46</td>\n",
       "      <td>352.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>6.68</td>\n",
       "      <td>997.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>7.34</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.15</td>\n",
       "      <td>407.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65499</th>\n",
       "      <td>100</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2.92</td>\n",
       "      <td>10.51</td>\n",
       "      <td>25.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65500</th>\n",
       "      <td>100</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2.92</td>\n",
       "      <td>7.49</td>\n",
       "      <td>9.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65501</th>\n",
       "      <td>100</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>2.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65502</th>\n",
       "      <td>100</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>2.92</td>\n",
       "      <td>6.77</td>\n",
       "      <td>90.0</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65503</th>\n",
       "      <td>100</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>2.92</td>\n",
       "      <td>7.81</td>\n",
       "      <td>635.0</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65504 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id MilkingDate   Age  Total_MilkProduction  Total_timeDelta_Seconds  \\\n",
       "0        1  2022-02-14  2.15                  9.38                   3176.0   \n",
       "1        1  2022-02-14  2.15                  8.46                    352.0   \n",
       "2        1  2022-02-15  2.15                  6.68                    997.0   \n",
       "3        1  2022-02-15  2.15                  7.34                   9274.0   \n",
       "4        1  2022-02-16  2.15                  8.15                    407.0   \n",
       "...    ...         ...   ...                   ...                      ...   \n",
       "65499  100  2022-10-05  2.92                 10.51                     25.0   \n",
       "65500  100  2022-10-05  2.92                  7.49                      9.0   \n",
       "65501  100  2022-10-06  2.92                  7.92                    181.0   \n",
       "65502  100  2022-10-06  2.92                  6.77                     90.0   \n",
       "65503  100  2022-10-06  2.92                  7.81                    635.0   \n",
       "\n",
       "       DaysInMilk  \n",
       "0             2.0  \n",
       "1             2.0  \n",
       "2             3.0  \n",
       "3             3.0  \n",
       "4             4.0  \n",
       "...           ...  \n",
       "65499       284.0  \n",
       "65500       284.0  \n",
       "65501       285.0  \n",
       "65502       285.0  \n",
       "65503       285.0  \n",
       "\n",
       "[65504 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare datasert for Tsfresh extraction\n",
    "ts_extracted_dataset = cow_total[['id']].copy()\n",
    "ts_extracted_dataset.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_dataset.index = range(1, len(ts_extracted_dataset)+1)\n",
    "ts_processed = pd.DataFrame(cow_total[timeSeries_cols].copy())\n",
    "ts_processed.index = range(0,len(ts_processed)) \n",
    "ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "ts_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id MilkingDate   Age\n",
      "0        1  2022-02-14  2.15\n",
      "1        1  2022-02-14  2.15\n",
      "2        1  2022-02-15  2.15\n",
      "3        1  2022-02-15  2.15\n",
      "4        1  2022-02-16  2.15\n",
      "...    ...         ...   ...\n",
      "65499  100  2022-10-05  2.92\n",
      "65500  100  2022-10-05  2.92\n",
      "65501  100  2022-10-06  2.92\n",
      "65502  100  2022-10-06  2.92\n",
      "65503  100  2022-10-06  2.92\n",
      "\n",
      "[65504 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 34/34 [00:06<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id MilkingDate  Total_MilkProduction\n",
      "0        1  2022-02-14                  9.38\n",
      "1        1  2022-02-14                  8.46\n",
      "2        1  2022-02-15                  6.68\n",
      "3        1  2022-02-15                  7.34\n",
      "4        1  2022-02-16                  8.15\n",
      "...    ...         ...                   ...\n",
      "65499  100  2022-10-05                 10.51\n",
      "65500  100  2022-10-05                  7.49\n",
      "65501  100  2022-10-06                  7.92\n",
      "65502  100  2022-10-06                  6.77\n",
      "65503  100  2022-10-06                  7.81\n",
      "\n",
      "[65504 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 34/34 [00:05<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id MilkingDate  Total_timeDelta_Seconds\n",
      "0        1  2022-02-14                   3176.0\n",
      "1        1  2022-02-14                    352.0\n",
      "2        1  2022-02-15                    997.0\n",
      "3        1  2022-02-15                   9274.0\n",
      "4        1  2022-02-16                    407.0\n",
      "...    ...         ...                      ...\n",
      "65499  100  2022-10-05                     25.0\n",
      "65500  100  2022-10-05                      9.0\n",
      "65501  100  2022-10-06                    181.0\n",
      "65502  100  2022-10-06                     90.0\n",
      "65503  100  2022-10-06                    635.0\n",
      "\n",
      "[65504 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 34/34 [00:05<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id MilkingDate  DaysInMilk\n",
      "0        1  2022-02-14         2.0\n",
      "1        1  2022-02-14         2.0\n",
      "2        1  2022-02-15         3.0\n",
      "3        1  2022-02-15         3.0\n",
      "4        1  2022-02-16         4.0\n",
      "...    ...         ...         ...\n",
      "65499  100  2022-10-05       284.0\n",
      "65500  100  2022-10-05       284.0\n",
      "65501  100  2022-10-06       285.0\n",
      "65502  100  2022-10-06       285.0\n",
      "65503  100  2022-10-06       285.0\n",
      "\n",
      "[65504 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 34/34 [00:05<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                 feature  \\\n",
      "feature                                                                                    \n",
      "DaysInMilk__minimum                                                  DaysInMilk__minimum   \n",
      "DaysInMilk__sum_values                                            DaysInMilk__sum_values   \n",
      "Total_MilkProduction__minimum                              Total_MilkProduction__minimum   \n",
      "Total_MilkProduction__maximum                              Total_MilkProduction__maximum   \n",
      "Total_MilkProduction__absolute_maximum            Total_MilkProduction__absolute_maximum   \n",
      "Age__sum_values                                                          Age__sum_values   \n",
      "Total_MilkProduction__standard_deviation        Total_MilkProduction__standard_deviation   \n",
      "Total_MilkProduction__variance                            Total_MilkProduction__variance   \n",
      "DaysInMilk__length                                                    DaysInMilk__length   \n",
      "Total_timeDelta_Seconds__length                          Total_timeDelta_Seconds__length   \n",
      "Age__length                                                                  Age__length   \n",
      "Total_MilkProduction__length                                Total_MilkProduction__length   \n",
      "Total_timeDelta_Seconds__minimum                        Total_timeDelta_Seconds__minimum   \n",
      "Total_MilkProduction__root_mean_square            Total_MilkProduction__root_mean_square   \n",
      "Total_MilkProduction__mean                                    Total_MilkProduction__mean   \n",
      "Total_MilkProduction__median                                Total_MilkProduction__median   \n",
      "Total_timeDelta_Seconds__sum_values                  Total_timeDelta_Seconds__sum_values   \n",
      "Total_timeDelta_Seconds__maximum                        Total_timeDelta_Seconds__maximum   \n",
      "Total_timeDelta_Seconds__absolute_maximum      Total_timeDelta_Seconds__absolute_maximum   \n",
      "Total_timeDelta_Seconds__median                          Total_timeDelta_Seconds__median   \n",
      "Total_timeDelta_Seconds__mean                              Total_timeDelta_Seconds__mean   \n",
      "Total_timeDelta_Seconds__standard_deviation  Total_timeDelta_Seconds__standard_deviation   \n",
      "Total_timeDelta_Seconds__root_mean_square      Total_timeDelta_Seconds__root_mean_square   \n",
      "Total_timeDelta_Seconds__variance                      Total_timeDelta_Seconds__variance   \n",
      "\n",
      "                                             type       p_value  relevant  \n",
      "feature                                                                    \n",
      "DaysInMilk__minimum                          real  1.389926e-03      True  \n",
      "DaysInMilk__sum_values                       real  6.671113e-04      True  \n",
      "Total_MilkProduction__minimum                real  3.149716e-04      True  \n",
      "Total_MilkProduction__maximum                real  6.808895e-05      True  \n",
      "Total_MilkProduction__absolute_maximum       real  6.808895e-05      True  \n",
      "Age__sum_values                              real  4.179242e-05      True  \n",
      "Total_MilkProduction__standard_deviation     real  2.257849e-05      True  \n",
      "Total_MilkProduction__variance               real  2.257849e-05      True  \n",
      "DaysInMilk__length                           real  7.536183e-06      True  \n",
      "Total_timeDelta_Seconds__length              real  7.536183e-06      True  \n",
      "Age__length                                  real  7.536183e-06      True  \n",
      "Total_MilkProduction__length                 real  7.536183e-06      True  \n",
      "Total_timeDelta_Seconds__minimum             real  6.318650e-09      True  \n",
      "Total_MilkProduction__root_mean_square       real  3.794103e-09      True  \n",
      "Total_MilkProduction__mean                   real  3.794103e-09      True  \n",
      "Total_MilkProduction__median                 real  2.206404e-09      True  \n",
      "Total_timeDelta_Seconds__sum_values          real  2.590275e-10      True  \n",
      "Total_timeDelta_Seconds__maximum             real  1.325773e-14      True  \n",
      "Total_timeDelta_Seconds__absolute_maximum    real  1.325773e-14      True  \n",
      "Total_timeDelta_Seconds__median              real  5.866205e-15      True  \n",
      "Total_timeDelta_Seconds__mean                real  1.048593e-15      True  \n",
      "Total_timeDelta_Seconds__standard_deviation  real  9.296135e-16      True  \n",
      "Total_timeDelta_Seconds__root_mean_square    real  9.296135e-16      True  \n",
      "Total_timeDelta_Seconds__variance            real  9.296135e-16      True  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DaysInMilk__minimum</th>\n",
       "      <th>DaysInMilk__sum_values</th>\n",
       "      <th>Total_MilkProduction__minimum</th>\n",
       "      <th>Total_MilkProduction__maximum</th>\n",
       "      <th>Total_MilkProduction__absolute_maximum</th>\n",
       "      <th>Age__sum_values</th>\n",
       "      <th>Total_MilkProduction__standard_deviation</th>\n",
       "      <th>Total_MilkProduction__variance</th>\n",
       "      <th>DaysInMilk__length</th>\n",
       "      <th>Total_timeDelta_Seconds__length</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_MilkProduction__mean</th>\n",
       "      <th>Total_MilkProduction__median</th>\n",
       "      <th>Total_timeDelta_Seconds__sum_values</th>\n",
       "      <th>Total_timeDelta_Seconds__maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__absolute_maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__median</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>76755.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>16.23</td>\n",
       "      <td>16.23</td>\n",
       "      <td>1763.74</td>\n",
       "      <td>2.082052</td>\n",
       "      <td>4.334941</td>\n",
       "      <td>726.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.920055</td>\n",
       "      <td>8.900</td>\n",
       "      <td>557837.0</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>768.370523</td>\n",
       "      <td>1146.471180</td>\n",
       "      <td>1380.141090</td>\n",
       "      <td>1.314396e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>93071.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>15.38</td>\n",
       "      <td>15.38</td>\n",
       "      <td>1391.84</td>\n",
       "      <td>2.117326</td>\n",
       "      <td>4.483070</td>\n",
       "      <td>612.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.213676</td>\n",
       "      <td>9.080</td>\n",
       "      <td>1420084.0</td>\n",
       "      <td>54718.0</td>\n",
       "      <td>54718.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2320.398693</td>\n",
       "      <td>4919.058491</td>\n",
       "      <td>5438.877323</td>\n",
       "      <td>2.419714e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>131892.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>16.44</td>\n",
       "      <td>16.44</td>\n",
       "      <td>1867.81</td>\n",
       "      <td>1.609935</td>\n",
       "      <td>2.591890</td>\n",
       "      <td>781.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.643534</td>\n",
       "      <td>9.440</td>\n",
       "      <td>251817.0</td>\n",
       "      <td>3621.0</td>\n",
       "      <td>3621.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>322.428937</td>\n",
       "      <td>421.207932</td>\n",
       "      <td>530.449377</td>\n",
       "      <td>1.774161e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>46592.0</td>\n",
       "      <td>3.01</td>\n",
       "      <td>20.60</td>\n",
       "      <td>20.60</td>\n",
       "      <td>692.09</td>\n",
       "      <td>2.544574</td>\n",
       "      <td>6.474859</td>\n",
       "      <td>291.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.029278</td>\n",
       "      <td>10.860</td>\n",
       "      <td>1659808.0</td>\n",
       "      <td>35048.0</td>\n",
       "      <td>35048.0</td>\n",
       "      <td>2841.0</td>\n",
       "      <td>5703.807560</td>\n",
       "      <td>7055.432846</td>\n",
       "      <td>9072.626595</td>\n",
       "      <td>4.977913e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>95895.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>20.68</td>\n",
       "      <td>20.68</td>\n",
       "      <td>956.95</td>\n",
       "      <td>2.757360</td>\n",
       "      <td>7.603035</td>\n",
       "      <td>309.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.673625</td>\n",
       "      <td>7.260</td>\n",
       "      <td>562325.0</td>\n",
       "      <td>13210.0</td>\n",
       "      <td>13210.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>1819.822006</td>\n",
       "      <td>2067.507172</td>\n",
       "      <td>2754.330779</td>\n",
       "      <td>4.274586e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>37.0</td>\n",
       "      <td>88335.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>17.32</td>\n",
       "      <td>17.32</td>\n",
       "      <td>883.48</td>\n",
       "      <td>2.289577</td>\n",
       "      <td>5.242164</td>\n",
       "      <td>296.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.022399</td>\n",
       "      <td>7.595</td>\n",
       "      <td>309840.0</td>\n",
       "      <td>9727.0</td>\n",
       "      <td>9727.0</td>\n",
       "      <td>603.5</td>\n",
       "      <td>1046.756757</td>\n",
       "      <td>1234.991862</td>\n",
       "      <td>1618.920816</td>\n",
       "      <td>1.525205e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3.0</td>\n",
       "      <td>45246.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>18.30</td>\n",
       "      <td>18.30</td>\n",
       "      <td>1192.13</td>\n",
       "      <td>2.198376</td>\n",
       "      <td>4.832859</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.076907</td>\n",
       "      <td>9.690</td>\n",
       "      <td>670619.0</td>\n",
       "      <td>12242.0</td>\n",
       "      <td>12242.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>1241.887037</td>\n",
       "      <td>1816.919779</td>\n",
       "      <td>2200.790970</td>\n",
       "      <td>3.301197e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0</td>\n",
       "      <td>109591.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>19.27</td>\n",
       "      <td>19.27</td>\n",
       "      <td>1899.73</td>\n",
       "      <td>2.382444</td>\n",
       "      <td>5.676040</td>\n",
       "      <td>790.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.056608</td>\n",
       "      <td>9.920</td>\n",
       "      <td>1271788.0</td>\n",
       "      <td>14305.0</td>\n",
       "      <td>14305.0</td>\n",
       "      <td>582.5</td>\n",
       "      <td>1609.858228</td>\n",
       "      <td>2183.442151</td>\n",
       "      <td>2712.759322</td>\n",
       "      <td>4.767420e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10.0</td>\n",
       "      <td>112748.0</td>\n",
       "      <td>5.98</td>\n",
       "      <td>22.38</td>\n",
       "      <td>22.38</td>\n",
       "      <td>1612.68</td>\n",
       "      <td>2.519919</td>\n",
       "      <td>6.349992</td>\n",
       "      <td>705.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.380128</td>\n",
       "      <td>10.880</td>\n",
       "      <td>926222.0</td>\n",
       "      <td>22967.0</td>\n",
       "      <td>22967.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>1313.790071</td>\n",
       "      <td>1903.702103</td>\n",
       "      <td>2313.033949</td>\n",
       "      <td>3.624082e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>109663.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>18.29</td>\n",
       "      <td>18.29</td>\n",
       "      <td>2125.74</td>\n",
       "      <td>2.210114</td>\n",
       "      <td>4.884605</td>\n",
       "      <td>852.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.839331</td>\n",
       "      <td>9.520</td>\n",
       "      <td>771325.0</td>\n",
       "      <td>11017.0</td>\n",
       "      <td>11017.0</td>\n",
       "      <td>405.5</td>\n",
       "      <td>905.311033</td>\n",
       "      <td>1328.953450</td>\n",
       "      <td>1608.012854</td>\n",
       "      <td>1.766117e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DaysInMilk__minimum  DaysInMilk__sum_values  \\\n",
       "1                    2.0                 76755.0   \n",
       "2                   14.0                 93071.0   \n",
       "3                   11.0                131892.0   \n",
       "4                    6.0                 46592.0   \n",
       "5                    5.0                 95895.0   \n",
       "..                   ...                     ...   \n",
       "96                  37.0                 88335.0   \n",
       "97                   3.0                 45246.0   \n",
       "98                   1.0                109591.0   \n",
       "99                  10.0                112748.0   \n",
       "100                  1.0                109663.0   \n",
       "\n",
       "     Total_MilkProduction__minimum  Total_MilkProduction__maximum  \\\n",
       "1                             0.54                          16.23   \n",
       "2                             1.14                          15.38   \n",
       "3                             1.09                          16.44   \n",
       "4                             3.01                          20.60   \n",
       "5                             0.89                          20.68   \n",
       "..                             ...                            ...   \n",
       "96                            0.73                          17.32   \n",
       "97                            0.68                          18.30   \n",
       "98                            0.35                          19.27   \n",
       "99                            5.98                          22.38   \n",
       "100                           1.09                          18.29   \n",
       "\n",
       "     Total_MilkProduction__absolute_maximum  Age__sum_values  \\\n",
       "1                                     16.23          1763.74   \n",
       "2                                     15.38          1391.84   \n",
       "3                                     16.44          1867.81   \n",
       "4                                     20.60           692.09   \n",
       "5                                     20.68           956.95   \n",
       "..                                      ...              ...   \n",
       "96                                    17.32           883.48   \n",
       "97                                    18.30          1192.13   \n",
       "98                                    19.27          1899.73   \n",
       "99                                    22.38          1612.68   \n",
       "100                                   18.29          2125.74   \n",
       "\n",
       "     Total_MilkProduction__standard_deviation  Total_MilkProduction__variance  \\\n",
       "1                                    2.082052                        4.334941   \n",
       "2                                    2.117326                        4.483070   \n",
       "3                                    1.609935                        2.591890   \n",
       "4                                    2.544574                        6.474859   \n",
       "5                                    2.757360                        7.603035   \n",
       "..                                        ...                             ...   \n",
       "96                                   2.289577                        5.242164   \n",
       "97                                   2.198376                        4.832859   \n",
       "98                                   2.382444                        5.676040   \n",
       "99                                   2.519919                        6.349992   \n",
       "100                                  2.210114                        4.884605   \n",
       "\n",
       "     DaysInMilk__length  Total_timeDelta_Seconds__length  ...  \\\n",
       "1                 726.0                            726.0  ...   \n",
       "2                 612.0                            612.0  ...   \n",
       "3                 781.0                            781.0  ...   \n",
       "4                 291.0                            291.0  ...   \n",
       "5                 309.0                            309.0  ...   \n",
       "..                  ...                              ...  ...   \n",
       "96                296.0                            296.0  ...   \n",
       "97                540.0                            540.0  ...   \n",
       "98                790.0                            790.0  ...   \n",
       "99                705.0                            705.0  ...   \n",
       "100               852.0                            852.0  ...   \n",
       "\n",
       "     Total_MilkProduction__mean  Total_MilkProduction__median  \\\n",
       "1                      8.920055                         8.900   \n",
       "2                      9.213676                         9.080   \n",
       "3                      9.643534                         9.440   \n",
       "4                     11.029278                        10.860   \n",
       "5                      7.673625                         7.260   \n",
       "..                          ...                           ...   \n",
       "96                     8.022399                         7.595   \n",
       "97                    10.076907                         9.690   \n",
       "98                    10.056608                         9.920   \n",
       "99                    11.380128                        10.880   \n",
       "100                    9.839331                         9.520   \n",
       "\n",
       "     Total_timeDelta_Seconds__sum_values  Total_timeDelta_Seconds__maximum  \\\n",
       "1                               557837.0                            9274.0   \n",
       "2                              1420084.0                           54718.0   \n",
       "3                               251817.0                            3621.0   \n",
       "4                              1659808.0                           35048.0   \n",
       "5                               562325.0                           13210.0   \n",
       "..                                   ...                               ...   \n",
       "96                              309840.0                            9727.0   \n",
       "97                              670619.0                           12242.0   \n",
       "98                             1271788.0                           14305.0   \n",
       "99                              926222.0                           22967.0   \n",
       "100                             771325.0                           11017.0   \n",
       "\n",
       "     Total_timeDelta_Seconds__absolute_maximum  \\\n",
       "1                                       9274.0   \n",
       "2                                      54718.0   \n",
       "3                                       3621.0   \n",
       "4                                      35048.0   \n",
       "5                                      13210.0   \n",
       "..                                         ...   \n",
       "96                                      9727.0   \n",
       "97                                     12242.0   \n",
       "98                                     14305.0   \n",
       "99                                     22967.0   \n",
       "100                                    11017.0   \n",
       "\n",
       "     Total_timeDelta_Seconds__median  Total_timeDelta_Seconds__mean  \\\n",
       "1                              330.0                     768.370523   \n",
       "2                              845.0                    2320.398693   \n",
       "3                              211.0                     322.428937   \n",
       "4                             2841.0                    5703.807560   \n",
       "5                              957.0                    1819.822006   \n",
       "..                               ...                            ...   \n",
       "96                             603.5                    1046.756757   \n",
       "97                             427.0                    1241.887037   \n",
       "98                             582.5                    1609.858228   \n",
       "99                             685.0                    1313.790071   \n",
       "100                            405.5                     905.311033   \n",
       "\n",
       "     Total_timeDelta_Seconds__standard_deviation  \\\n",
       "1                                    1146.471180   \n",
       "2                                    4919.058491   \n",
       "3                                     421.207932   \n",
       "4                                    7055.432846   \n",
       "5                                    2067.507172   \n",
       "..                                           ...   \n",
       "96                                   1234.991862   \n",
       "97                                   1816.919779   \n",
       "98                                   2183.442151   \n",
       "99                                   1903.702103   \n",
       "100                                  1328.953450   \n",
       "\n",
       "     Total_timeDelta_Seconds__root_mean_square  \\\n",
       "1                                  1380.141090   \n",
       "2                                  5438.877323   \n",
       "3                                   530.449377   \n",
       "4                                  9072.626595   \n",
       "5                                  2754.330779   \n",
       "..                                         ...   \n",
       "96                                 1618.920816   \n",
       "97                                 2200.790970   \n",
       "98                                 2712.759322   \n",
       "99                                 2313.033949   \n",
       "100                                1608.012854   \n",
       "\n",
       "     Total_timeDelta_Seconds__variance  \n",
       "1                         1.314396e+06  \n",
       "2                         2.419714e+07  \n",
       "3                         1.774161e+05  \n",
       "4                         4.977913e+07  \n",
       "5                         4.274586e+06  \n",
       "..                                 ...  \n",
       "96                        1.525205e+06  \n",
       "97                        3.301197e+06  \n",
       "98                        4.767420e+06  \n",
       "99                        3.624082e+06  \n",
       "100                       1.766117e+06  \n",
       "\n",
       "[100 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_1 = MinimalFCParameters() \n",
    "#settings_2 = ComprehensiveFCParameters\n",
    "\n",
    "for i, col in enumerate(timeSeries_cols):\n",
    "    ts_processed = pd.DataFrame(cow_total[col].copy())\n",
    "    ts_processed.index = range(0,len(ts_processed)) \n",
    "    ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "    print(ts_processed)\n",
    "    # extract time series features\n",
    "    extracted_features = extract_features(ts_processed, column_id=\"id\", column_sort=\"MilkingDate\", default_fc_parameters=settings_1)\n",
    "    #extracted_features.dropna(axis=1, inplace=True)\n",
    "    impute(extracted_features)\n",
    "    \n",
    "    # select most relevant features based on relevance table\n",
    "    if i == 0:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = temp\n",
    "    else:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = pd.concat([relevance_table, temp], axis=0)\n",
    "    features_filtered = select_features(extracted_features, y)\n",
    "    ts_extracted_dataset = pd.concat([ts_extracted_dataset, features_filtered], axis=1)\n",
    "\n",
    "# Select relevant features from the relevance table\n",
    "relevance_table = relevance_table[relevance_table.relevant]\n",
    "relevance_table.sort_values(\"p_value\", ascending=False, inplace=True)\n",
    "relevant_features_list = list(relevance_table.feature[:])\n",
    "print(relevance_table)\n",
    "\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset[relevant_features_list].copy()\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset_filtered.loc[:,~ts_extracted_dataset_filtered.columns.duplicated()]\n",
    "ts_extracted_dataset = ts_extracted_dataset_filtered\n",
    "ts_extracted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DaysInMilk__minimum</th>\n",
       "      <th>DaysInMilk__sum_values</th>\n",
       "      <th>Total_MilkProduction__minimum</th>\n",
       "      <th>Total_MilkProduction__maximum</th>\n",
       "      <th>Total_MilkProduction__absolute_maximum</th>\n",
       "      <th>Age__sum_values</th>\n",
       "      <th>Total_MilkProduction__standard_deviation</th>\n",
       "      <th>Total_MilkProduction__variance</th>\n",
       "      <th>DaysInMilk__length</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_timeDelta_Seconds__median</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.564442</td>\n",
       "      <td>-0.366224</td>\n",
       "      <td>-0.519649</td>\n",
       "      <td>-0.598940</td>\n",
       "      <td>-0.598940</td>\n",
       "      <td>0.179023</td>\n",
       "      <td>-0.744216</td>\n",
       "      <td>-0.719037</td>\n",
       "      <td>0.303051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.710248</td>\n",
       "      <td>-0.781338</td>\n",
       "      <td>-0.804922</td>\n",
       "      <td>-0.805043</td>\n",
       "      <td>-0.653336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.508982</td>\n",
       "      <td>-0.173549</td>\n",
       "      <td>-0.150318</td>\n",
       "      <td>-0.827626</td>\n",
       "      <td>-0.827626</td>\n",
       "      <td>-0.367402</td>\n",
       "      <td>-0.690739</td>\n",
       "      <td>-0.679881</td>\n",
       "      <td>-0.183812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175317</td>\n",
       "      <td>0.274075</td>\n",
       "      <td>1.356482</td>\n",
       "      <td>0.986734</td>\n",
       "      <td>1.160595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.240626</td>\n",
       "      <td>0.284888</td>\n",
       "      <td>-0.181095</td>\n",
       "      <td>-0.542442</td>\n",
       "      <td>-0.542442</td>\n",
       "      <td>0.331931</td>\n",
       "      <td>-1.459976</td>\n",
       "      <td>-1.179790</td>\n",
       "      <td>0.537940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833854</td>\n",
       "      <td>-1.084588</td>\n",
       "      <td>-1.220442</td>\n",
       "      <td>-1.180150</td>\n",
       "      <td>-0.743465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.206634</td>\n",
       "      <td>-0.722418</td>\n",
       "      <td>1.000764</td>\n",
       "      <td>0.576771</td>\n",
       "      <td>0.576771</td>\n",
       "      <td>-1.395532</td>\n",
       "      <td>-0.043003</td>\n",
       "      <td>-0.153377</td>\n",
       "      <td>-1.554714</td>\n",
       "      <td>...</td>\n",
       "      <td>1.897930</td>\n",
       "      <td>2.574865</td>\n",
       "      <td>2.580461</td>\n",
       "      <td>2.590896</td>\n",
       "      <td>3.188498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.296086</td>\n",
       "      <td>-0.140200</td>\n",
       "      <td>-0.304206</td>\n",
       "      <td>0.598295</td>\n",
       "      <td>0.598295</td>\n",
       "      <td>-1.006378</td>\n",
       "      <td>0.279594</td>\n",
       "      <td>0.144842</td>\n",
       "      <td>-1.477841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058983</td>\n",
       "      <td>-0.066328</td>\n",
       "      <td>-0.277239</td>\n",
       "      <td>-0.198391</td>\n",
       "      <td>-0.418680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>2.566380</td>\n",
       "      <td>-0.229476</td>\n",
       "      <td>-0.402694</td>\n",
       "      <td>-0.305685</td>\n",
       "      <td>-0.305685</td>\n",
       "      <td>-1.114326</td>\n",
       "      <td>-0.429595</td>\n",
       "      <td>-0.479224</td>\n",
       "      <td>-1.533361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426163</td>\n",
       "      <td>-0.592029</td>\n",
       "      <td>-0.754206</td>\n",
       "      <td>-0.699631</td>\n",
       "      <td>-0.636625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>-0.474990</td>\n",
       "      <td>-0.738313</td>\n",
       "      <td>-0.433471</td>\n",
       "      <td>-0.042024</td>\n",
       "      <td>-0.042024</td>\n",
       "      <td>-0.660833</td>\n",
       "      <td>-0.567861</td>\n",
       "      <td>-0.587419</td>\n",
       "      <td>-0.491304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.609494</td>\n",
       "      <td>-0.459336</td>\n",
       "      <td>-0.420806</td>\n",
       "      <td>-0.442758</td>\n",
       "      <td>-0.495841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>-0.653895</td>\n",
       "      <td>0.021536</td>\n",
       "      <td>-0.636603</td>\n",
       "      <td>0.218946</td>\n",
       "      <td>0.218946</td>\n",
       "      <td>0.378831</td>\n",
       "      <td>-0.288803</td>\n",
       "      <td>-0.364535</td>\n",
       "      <td>0.576377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447976</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.210817</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-0.379612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.151174</td>\n",
       "      <td>0.058817</td>\n",
       "      <td>2.828952</td>\n",
       "      <td>1.055666</td>\n",
       "      <td>1.055666</td>\n",
       "      <td>-0.042927</td>\n",
       "      <td>-0.080382</td>\n",
       "      <td>-0.186384</td>\n",
       "      <td>0.213365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341509</td>\n",
       "      <td>-0.410441</td>\n",
       "      <td>-0.371087</td>\n",
       "      <td>-0.393207</td>\n",
       "      <td>-0.470246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>-0.653895</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>-0.181095</td>\n",
       "      <td>-0.044715</td>\n",
       "      <td>-0.044715</td>\n",
       "      <td>0.710903</td>\n",
       "      <td>-0.550066</td>\n",
       "      <td>-0.573740</td>\n",
       "      <td>0.841162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.631826</td>\n",
       "      <td>-0.688215</td>\n",
       "      <td>-0.700374</td>\n",
       "      <td>-0.704447</td>\n",
       "      <td>-0.617528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  DaysInMilk__minimum  DaysInMilk__sum_values  \\\n",
       "1      1            -0.564442               -0.366224   \n",
       "2      2             0.508982               -0.173549   \n",
       "3      3             0.240626                0.284888   \n",
       "4      4            -0.206634               -0.722418   \n",
       "5      5            -0.296086               -0.140200   \n",
       "..   ...                  ...                     ...   \n",
       "96    96             2.566380               -0.229476   \n",
       "97    97            -0.474990               -0.738313   \n",
       "98    98            -0.653895                0.021536   \n",
       "99    99             0.151174                0.058817   \n",
       "100  100            -0.653895                0.022386   \n",
       "\n",
       "     Total_MilkProduction__minimum  Total_MilkProduction__maximum  \\\n",
       "1                        -0.519649                      -0.598940   \n",
       "2                        -0.150318                      -0.827626   \n",
       "3                        -0.181095                      -0.542442   \n",
       "4                         1.000764                       0.576771   \n",
       "5                        -0.304206                       0.598295   \n",
       "..                             ...                            ...   \n",
       "96                       -0.402694                      -0.305685   \n",
       "97                       -0.433471                      -0.042024   \n",
       "98                       -0.636603                       0.218946   \n",
       "99                        2.828952                       1.055666   \n",
       "100                      -0.181095                      -0.044715   \n",
       "\n",
       "     Total_MilkProduction__absolute_maximum  Age__sum_values  \\\n",
       "1                                 -0.598940         0.179023   \n",
       "2                                 -0.827626        -0.367402   \n",
       "3                                 -0.542442         0.331931   \n",
       "4                                  0.576771        -1.395532   \n",
       "5                                  0.598295        -1.006378   \n",
       "..                                      ...              ...   \n",
       "96                                -0.305685        -1.114326   \n",
       "97                                -0.042024        -0.660833   \n",
       "98                                 0.218946         0.378831   \n",
       "99                                 1.055666        -0.042927   \n",
       "100                               -0.044715         0.710903   \n",
       "\n",
       "     Total_MilkProduction__standard_deviation  Total_MilkProduction__variance  \\\n",
       "1                                   -0.744216                       -0.719037   \n",
       "2                                   -0.690739                       -0.679881   \n",
       "3                                   -1.459976                       -1.179790   \n",
       "4                                   -0.043003                       -0.153377   \n",
       "5                                    0.279594                        0.144842   \n",
       "..                                        ...                             ...   \n",
       "96                                  -0.429595                       -0.479224   \n",
       "97                                  -0.567861                       -0.587419   \n",
       "98                                  -0.288803                       -0.364535   \n",
       "99                                  -0.080382                       -0.186384   \n",
       "100                                 -0.550066                       -0.573740   \n",
       "\n",
       "     DaysInMilk__length  ...  Total_timeDelta_Seconds__median  \\\n",
       "1              0.303051  ...                        -0.710248   \n",
       "2             -0.183812  ...                        -0.175317   \n",
       "3              0.537940  ...                        -0.833854   \n",
       "4             -1.554714  ...                         1.897930   \n",
       "5             -1.477841  ...                        -0.058983   \n",
       "..                  ...  ...                              ...   \n",
       "96            -1.533361  ...                        -0.426163   \n",
       "97            -0.491304  ...                        -0.609494   \n",
       "98             0.576377  ...                        -0.447976   \n",
       "99             0.213365  ...                        -0.341509   \n",
       "100            0.841162  ...                        -0.631826   \n",
       "\n",
       "     Total_timeDelta_Seconds__mean  \\\n",
       "1                        -0.781338   \n",
       "2                         0.274075   \n",
       "3                        -1.084588   \n",
       "4                         2.574865   \n",
       "5                        -0.066328   \n",
       "..                             ...   \n",
       "96                       -0.592029   \n",
       "97                       -0.459336   \n",
       "98                       -0.209108   \n",
       "99                       -0.410441   \n",
       "100                      -0.688215   \n",
       "\n",
       "     Total_timeDelta_Seconds__standard_deviation  \\\n",
       "1                                      -0.804922   \n",
       "2                                       1.356482   \n",
       "3                                      -1.220442   \n",
       "4                                       2.580461   \n",
       "5                                      -0.277239   \n",
       "..                                           ...   \n",
       "96                                     -0.754206   \n",
       "97                                     -0.420806   \n",
       "98                                     -0.210817   \n",
       "99                                     -0.371087   \n",
       "100                                    -0.700374   \n",
       "\n",
       "     Total_timeDelta_Seconds__root_mean_square  \\\n",
       "1                                    -0.805043   \n",
       "2                                     0.986734   \n",
       "3                                    -1.180150   \n",
       "4                                     2.590896   \n",
       "5                                    -0.198391   \n",
       "..                                         ...   \n",
       "96                                   -0.699631   \n",
       "97                                   -0.442758   \n",
       "98                                   -0.216743   \n",
       "99                                   -0.393207   \n",
       "100                                  -0.704447   \n",
       "\n",
       "     Total_timeDelta_Seconds__variance  BreedName_1  BreedName_2  BreedName_4  \\\n",
       "1                            -0.653336          1.0          0.0          0.0   \n",
       "2                             1.160595          0.0          1.0          0.0   \n",
       "3                            -0.743465          1.0          0.0          0.0   \n",
       "4                             3.188498          0.0          0.0          1.0   \n",
       "5                            -0.418680          0.0          1.0          0.0   \n",
       "..                                 ...          ...          ...          ...   \n",
       "96                           -0.636625          0.0          1.0          0.0   \n",
       "97                           -0.495841          1.0          0.0          0.0   \n",
       "98                           -0.379612          0.0          1.0          0.0   \n",
       "99                           -0.470246          1.0          0.0          0.0   \n",
       "100                          -0.617528          1.0          0.0          0.0   \n",
       "\n",
       "     BreedName_99  problematic  \n",
       "1             0.0            0  \n",
       "2             0.0            1  \n",
       "3             0.0            0  \n",
       "4             0.0            1  \n",
       "5             0.0            0  \n",
       "..            ...          ...  \n",
       "96            0.0            0  \n",
       "97            0.0            0  \n",
       "98            0.0            0  \n",
       "99            0.0            0  \n",
       "100           0.0            0  \n",
       "\n",
       "[100 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct extracted training data\n",
    "ts_extracted_id = cow_total[['id']].copy()\n",
    "ts_extracted_id.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_id.index = range(1, len(ts_extracted_id)+1)\n",
    "ts_extracted_dataset = pd.concat([ts_extracted_id, ts_extracted_dataset], axis=1)\n",
    "\n",
    "ts_extracted_features = ts_extracted_dataset.iloc[:, 1:len(ts_extracted_dataset.columns)].copy()\n",
    "# normalize numerical features\n",
    "ts_extracted_cols = ts_extracted_features.columns\n",
    "scaler_std = StandardScaler()\n",
    "ts_std = scaler_std.fit_transform(ts_extracted_features)\n",
    "# transform standard data into dataframe\n",
    "ts_extracted_processed = pd.DataFrame(ts_std, columns=ts_extracted_cols)\n",
    "ts_extracted_processed.index = range(1,len(ts_extracted_processed)+1)\n",
    "# append id col to the dataframe\n",
    "ts_extracted_processed = pd.concat([ts_extracted_dataset['id'], ts_extracted_processed], axis=1)\n",
    "\n",
    "# One-Hot encoding categorical feature - BreedName\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "cow_breed = cow_total[['id', 'BreedName']].copy()\n",
    "cow_breed.drop_duplicates(subset=['id'], inplace=True)\n",
    "cat = ohe.fit_transform(np.array(cow_breed['BreedName']).reshape(-1, 1))\n",
    "col_names = ohe.get_feature_names_out(['BreedName'])\n",
    "cat_breed = pd.DataFrame(cat, columns=col_names)\n",
    "cat_breed.index = range(1,len(cow_breed)+1)\n",
    "\n",
    "# append features on extracted dataset\n",
    "ts_dataset = pd.concat([ts_extracted_processed, cat_breed], axis=1)\n",
    "ts_dataset = pd.concat([ts_dataset, y], axis=1)\n",
    "ts_dataset.to_csv(dataDir/\"problematic_100cows_7200s_5percent.csv\", index=False)\n",
    "ts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation on Gaussian Process Classifier\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, Matern, RationalQuadratic, WhiteKernel, ExpSineSquared\n",
    "grid = dict()\n",
    "grid['kernel'] = [1*RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)), \n",
    "                  1*DotProduct(), 1*Matern(),  1*RationalQuadratic(),\n",
    "                  1*Matern()+1*WhiteKernel(noise_level=0.5),\n",
    "                  1*ExpSineSquared(),\n",
    "                  1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0, length_scale_bounds=(0.1, 10.0), periodicity_bounds=(1.0, 10.0)),\n",
    "                  1*Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)+1*WhiteKernel(noise_level=0.5),\n",
    "                ]\n",
    "\n",
    "\n",
    "dataDir = Path.cwd().parent.parent/'Data/processed'\n",
    "ts_dataset = pd.read_csv(dataDir/\"problematic_100cows_7200s_5percent.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 62-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 58-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 67-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 54-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 64-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 59-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 61-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 65-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 60-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 55-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 53-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 57-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 46-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 42-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 47-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 34-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 45-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 43-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 41-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 40-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 50-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 38-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 44-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 49-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.974 0.972 0.974 0.974 0.974   nan   nan 0.978]\n",
      "  warnings.warn(\n",
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.978\n",
      "Best estimator parameters:  {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy 0.974 with: {'kernel': 1**2 * RBF(length_scale=1)}\n",
      "Accuracy 0.972 with: {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.974 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      "Accuracy 0.974 with: {'kernel': 1**2 * RationalQuadratic(alpha=1, length_scale=1)}\n",
      "Accuracy 0.974 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=1)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=3)}\n",
      "Accuracy 0.978 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ts_dataset.iloc[:, 0:len(ts_dataset.columns)-1].copy()\n",
    "y = pd.DataFrame(ts_dataset.iloc[:, -1])\n",
    "# split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=86)\n",
    "model = GaussianProcessClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=5)\n",
    "# exhausive search over different kernels\n",
    "search = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# fit model into the dataset\n",
    "result = search.fit(X, y)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", result.best_score_)\n",
    "print(\"Best estimator parameters: \", result.best_params_)\n",
    "\n",
    "means = result.cv_results_['mean_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"Accuracy %.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              53\n",
       "1              22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              15\n",
       "1              10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training data:  1.0\n",
      "Prediction on test data:  [1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "Prediction accuracy on test data:  1.0\n"
     ]
    }
   ],
   "source": [
    "# best_kernel = 1*DotProduct()\n",
    "# best_kernel = 1**2 * RationalQuadratic(alpha=1, length_scale=1)\n",
    "best_kernel = 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)\n",
    "# best_kernel = 1**2 * Matern(length_scale=1, nu=1.5)\n",
    "# best_kernel = 1**2 * RBF(length_scale=1)\n",
    "model = GaussianProcessClassifier(kernel=best_kernel, random_state=30, n_jobs=-1)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model.score(X_train, y_train))\n",
    "print(\"Prediction on test data: \", model.predict(X_test))\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"Prediction accuracy on test data: \", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1008989 , 0.8991011 ],\n",
       "       [0.07287753, 0.92712247],\n",
       "       [0.31705844, 0.68294156],\n",
       "       [0.88830167, 0.11169833],\n",
       "       [0.05632446, 0.94367554],\n",
       "       [0.96845917, 0.03154083],\n",
       "       [0.0700798 , 0.9299202 ],\n",
       "       [0.79918891, 0.20081109],\n",
       "       [0.0738107 , 0.9261893 ],\n",
       "       [0.08402116, 0.91597884],\n",
       "       [0.86272997, 0.13727003],\n",
       "       [0.88470098, 0.11529902],\n",
       "       [0.10429109, 0.89570891],\n",
       "       [0.13388823, 0.86611177],\n",
       "       [0.86975656, 0.13024344],\n",
       "       [0.87194862, 0.12805138],\n",
       "       [0.90707336, 0.09292664],\n",
       "       [0.82480743, 0.17519257],\n",
       "       [0.22735236, 0.77264764],\n",
       "       [0.89944822, 0.10055178],\n",
       "       [0.93381763, 0.06618237],\n",
       "       [0.83860234, 0.16139766],\n",
       "       [0.93713469, 0.06286531],\n",
       "       [0.93404599, 0.06595401],\n",
       "       [0.96655879, 0.03344121]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_list = model.predict_proba(X_test)\n",
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "cow_id = X_test.index.copy()\n",
    "cow_id = cow_id.astype(str)\n",
    "\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "facecolor = '#eaeaf2'\n",
    "color_red = '#f44336'\n",
    "color_blue = '#4496df'\n",
    "index = cow_id\n",
    "column0 = prob_list[:, 0]\n",
    "column1 = prob_list[:, 1]\n",
    "title0 = 'Problematic Cows, test set'\n",
    "title1 = 'Normal Cows, test set'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5), facecolor=facecolor, ncols=2, sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0].barh(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes[0].set_title(title0, fontsize=18, pad=15, color=color_red, **hfont)\n",
    "axes[1].barh(index, column1, align='center', color=color_blue, zorder=10)\n",
    "axes[1].set_title(title1, fontsize=18, pad=15, color=color_blue, **hfont)\n",
    "\n",
    "# If you have positive numbers and want to invert the x-axis of the left plot\n",
    "axes[0].invert_xaxis() \n",
    "\n",
    "# To show data from highest to lowest\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "axes[0].set(yticks=cow_id, yticklabels=cow_id)\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[0].tick_params(axis='y', colors='black') # tick color\n",
    "\n",
    "axes[0].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[0].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "for label in (axes[0].get_xticklabels() + axes[0].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "for label in (axes[1].get_xticklabels() + axes[1].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, top=0.85, bottom=0.1, left=0.18, right=0.95)\n",
    "filename = 'Problematic_Cows'\n",
    "plt.savefig(filename+'.png', facecolor=facecolor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7857ada9c2c05e5ee75d334d60fb77cca110ad03375c3b02029444557fa6212d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
