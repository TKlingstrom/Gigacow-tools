{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "396af3cf-0117-4f47-a509-3261e5d8cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "pd.options.mode.chained_assignment = None\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, MinimalFCParameters\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85bb1b24-e295-47ea-b4e1-fda41010b4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>9.38</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>8.46</td>\n",
       "      <td>352.0</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>6.68</td>\n",
       "      <td>997.0</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>7.34</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2560</td>\n",
       "      <td>8.15</td>\n",
       "      <td>407.0</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95849</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.96</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95850</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.53</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95851</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>3.24</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95852</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>9.23</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95853</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95854 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "0            a624fb9a            2560                  9.38   \n",
       "1            a624fb9a            2560                  8.46   \n",
       "2            a624fb9a            2560                  6.68   \n",
       "3            a624fb9a            2560                  7.34   \n",
       "4            a624fb9a            2560                  8.15   \n",
       "...               ...             ...                   ...   \n",
       "95849        a624fb9a            2047                  7.96   \n",
       "95850        a624fb9a            2047                  5.53   \n",
       "95851        a624fb9a            2047                  3.24   \n",
       "95852        a624fb9a            2047                  9.23   \n",
       "95853        a624fb9a            2047                  7.42   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "0                       3176.0  2022-02-14              1.0         2.0   \n",
       "1                        352.0  2022-02-14              1.0         2.0   \n",
       "2                        997.0  2022-02-15              1.0         3.0   \n",
       "3                       9274.0  2022-02-15              1.0         3.0   \n",
       "4                        407.0  2022-02-16              1.0         4.0   \n",
       "...                        ...         ...              ...         ...   \n",
       "95849                     59.0  2022-11-12              1.0       322.0   \n",
       "95850                    148.0  2022-11-13              1.0       323.0   \n",
       "95851                    287.0  2022-11-13              1.0       323.0   \n",
       "95852                    240.0  2022-11-13              1.0       323.0   \n",
       "95853                     10.0  2022-11-14              1.0       324.0   \n",
       "\n",
       "       BreedName   Age  problematic   id  \n",
       "0              1  2.15            0    1  \n",
       "1              1  2.15            0    1  \n",
       "2              1  2.15            0    1  \n",
       "3              1  2.15            0    1  \n",
       "4              1  2.15            0    1  \n",
       "...          ...   ...          ...  ...  \n",
       "95849          1  3.02            0  142  \n",
       "95850          1  3.03            0  142  \n",
       "95851          1  3.03            0  142  \n",
       "95852          1  3.03            0  142  \n",
       "95853          1  3.03            0  142  \n",
       "\n",
       "[95854 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cows = pd.DataFrame()\n",
    "\n",
    "dataDir = '../../Data/processed/'\n",
    "total_cows = pd.read_csv(dataDir+'Cow_Prob_dataset_L1.csv')\n",
    "total_cows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ce9495d-c5c2-4f84-a678-bd72f3ed549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cows_SRB1 = total_cows[total_cows['BreedName'] == 1]\n",
    "\n",
    "total_cows = total_cows_SRB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c42e8a3-5fce-4f84-9e68-f3297bf92301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 46, 20, 75, 63] 5\n"
     ]
    }
   ],
   "source": [
    "# Select IDs from the total_cows\n",
    "test_cow_list = []\n",
    "ids = total_cows['id']\n",
    "\n",
    "unique_cow_ids = ids.unique()\n",
    "\n",
    "# Select a few rows randomly\n",
    "num_of_selected_cows = 5\n",
    "\n",
    "#test_cow_list = [1]\n",
    "\n",
    "#test_cow_list = random.choices( unique_cow_ids, k=num_of_selected_cows)\n",
    "#test_cow_list.sort()\n",
    "\n",
    "test_cow_list_SRB1 =  [20, 46, 20, 75, 63]\n",
    "test_cow_list = test_cow_list_SRB1\n",
    "print(test_cow_list, len(test_cow_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "471088dc-15b0-4be2-a527-8967a8de7801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Gigacow_Cow_Id</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>Age</th>\n",
       "      <th>problematic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32845</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.96</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32846</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>5.53</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32847</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>3.24</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32848</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>9.23</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32849</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>2047</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FarmName_Pseudo  Gigacow_Cow_Id  Total_MilkProduction  \\\n",
       "32845        a624fb9a            2047                  7.96   \n",
       "32846        a624fb9a            2047                  5.53   \n",
       "32847        a624fb9a            2047                  3.24   \n",
       "32848        a624fb9a            2047                  9.23   \n",
       "32849        a624fb9a            2047                  7.42   \n",
       "\n",
       "       Total_timeDelta_Seconds MilkingDate  LactationNumber  DaysInMilk  \\\n",
       "32845                     59.0  2022-11-12              1.0       322.0   \n",
       "32846                    148.0  2022-11-13              1.0       323.0   \n",
       "32847                    287.0  2022-11-13              1.0       323.0   \n",
       "32848                    240.0  2022-11-13              1.0       323.0   \n",
       "32849                     10.0  2022-11-14              1.0       324.0   \n",
       "\n",
       "       BreedName   Age  problematic   id  \n",
       "32845          1  3.02            0  142  \n",
       "32846          1  3.03            0  142  \n",
       "32847          1  3.03            0  142  \n",
       "32848          1  3.03            0  142  \n",
       "32849          1  3.03            0  142  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_total_cows = total_cows\n",
    "ts_length_test_data = 105\n",
    "\n",
    "for l in test_cow_list:\n",
    "    # Choose a specific duration\n",
    "    condition = modified_total_cows['id'] == l\n",
    "    test_cow = modified_total_cows[condition].copy()\n",
    "    test_cow = test_cow.reset_index()        \n",
    "    # print(test_cow)\n",
    "    if 'index' in test_cow:\n",
    "        test_cow = test_cow.drop('index', axis=1)\n",
    "        \n",
    "    modified_total_cows = modified_total_cows[~condition]\n",
    "            \n",
    "    test_cow['MilkingDate'] = pd.to_datetime(test_cow['MilkingDate'])\n",
    "    test_cow['MilkingDate'] = test_cow['MilkingDate'].dt.date\n",
    "            \n",
    "    start_date = test_cow['MilkingDate'][0]\n",
    "    #print('start_date: ',start_date)\n",
    "    end_date = pd.to_datetime(start_date + pd.DateOffset(days=ts_length_test_data)).date()\n",
    "    #print('end_date: ', end_date)\n",
    "    filtered_df = test_cow[(test_cow['MilkingDate'] >= start_date) & (test_cow['MilkingDate'] <= end_date)]   \n",
    "    \n",
    "    modified_total_cows = pd.concat([modified_total_cows, filtered_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "#modified_total_cows = modified_total_cows.drop('index', axis=1)\n",
    "#modified_total_cows = modified_total_cows.sort_values('id')\n",
    "modified_total_cows = modified_total_cows.sort_values(by=['id', 'MilkingDate'])\n",
    "\n",
    "modified_total_cows.to_csv(dataDir+\"upp.csv\", index=False)\n",
    "\n",
    "#modified_total_cows = modified_total_cows.reset_index()\n",
    "\n",
    "modified_total_cows.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "25a586e8-e3cc-4b2d-b73c-a1e5d235b14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33909, 11)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cow_total =  modified_total_cows\n",
    "cow_total.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "009c6a05-7081-436c-8d5e-bf0f1a184716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    44\n",
      "1     4\n",
      "Name: problematic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#original\n",
    "#df_static_features = cow_total[['FarmName_Pseudo']]\n",
    "static_cols = ['FarmName_Pseudo', 'TrafficDeviceName', 'LactationNumber', 'BreedName']\n",
    "timeSeries_cols = ['Age', 'Total_MilkProduction', 'Total_timeDelta_Seconds', 'DaysInMilk']\n",
    "output_col = ['problematic']\n",
    "\n",
    "cow_label = cow_total[['id', 'problematic']].copy()\n",
    "cow_timeseries = cow_total[['id', 'MilkingDate']].copy()\n",
    "cow_timeseries.index = range(len(cow_timeseries))\n",
    "# fetch y for feature extraction\n",
    "y = cow_label.drop_duplicates(subset=['id'])\n",
    "y = y[\"problematic\"]\n",
    "y.index = range(1,len(y)+1) \n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "5ba0c709-0d26-4e73-a0fc-8d0681161b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_extracted_dataset shape:  (33909, 1)\n",
      "ts_extracted_dataset shape:  (48, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MilkingDate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_MilkProduction</th>\n",
       "      <th>Total_timeDelta_Seconds</th>\n",
       "      <th>DaysInMilk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>2.15</td>\n",
       "      <td>9.38</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.46</td>\n",
       "      <td>352.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>6.68</td>\n",
       "      <td>997.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>7.34</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.15</td>\n",
       "      <td>407.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33904</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>3.02</td>\n",
       "      <td>7.96</td>\n",
       "      <td>59.0</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33905</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>3.03</td>\n",
       "      <td>5.53</td>\n",
       "      <td>148.0</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33906</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>3.03</td>\n",
       "      <td>3.24</td>\n",
       "      <td>287.0</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33907</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>3.03</td>\n",
       "      <td>9.23</td>\n",
       "      <td>240.0</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33908</th>\n",
       "      <td>142</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>3.03</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33909 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id MilkingDate   Age  Total_MilkProduction  Total_timeDelta_Seconds  \\\n",
       "0        1  2022-02-14  2.15                  9.38                   3176.0   \n",
       "1        1  2022-02-14  2.15                  8.46                    352.0   \n",
       "2        1  2022-02-15  2.15                  6.68                    997.0   \n",
       "3        1  2022-02-15  2.15                  7.34                   9274.0   \n",
       "4        1  2022-02-16  2.15                  8.15                    407.0   \n",
       "...    ...         ...   ...                   ...                      ...   \n",
       "33904  142  2022-11-12  3.02                  7.96                     59.0   \n",
       "33905  142  2022-11-13  3.03                  5.53                    148.0   \n",
       "33906  142  2022-11-13  3.03                  3.24                    287.0   \n",
       "33907  142  2022-11-13  3.03                  9.23                    240.0   \n",
       "33908  142  2022-11-14  3.03                  7.42                     10.0   \n",
       "\n",
       "       DaysInMilk  \n",
       "0             2.0  \n",
       "1             2.0  \n",
       "2             3.0  \n",
       "3             3.0  \n",
       "4             4.0  \n",
       "...           ...  \n",
       "33904       322.0  \n",
       "33905       323.0  \n",
       "33906       323.0  \n",
       "33907       323.0  \n",
       "33908       324.0  \n",
       "\n",
       "[33909 rows x 6 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "# Prepare datasert for Tsfresh extraction\n",
    "ts_extracted_dataset = cow_total[['id']].copy()\n",
    "print('ts_extracted_dataset shape: ', ts_extracted_dataset.shape)\n",
    "ts_extracted_dataset.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_dataset.index = range(1, len(ts_extracted_dataset)+1)\n",
    "print('ts_extracted_dataset shape: ',ts_extracted_dataset.shape)\n",
    "\n",
    "ts_processed = pd.DataFrame(cow_total[timeSeries_cols].copy())\n",
    "ts_processed.index = range(0,len(ts_processed)) \n",
    "\n",
    "ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "ts_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "833d7cef-efd5-40ca-b8bb-489abb16659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33909, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 126.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33909, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 135.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33909, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 157.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33909, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 164.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                 feature  \\\n",
      "feature                                                                                    \n",
      "Total_timeDelta_Seconds__minimum                        Total_timeDelta_Seconds__minimum   \n",
      "Total_timeDelta_Seconds__sum_values                  Total_timeDelta_Seconds__sum_values   \n",
      "Total_timeDelta_Seconds__maximum                        Total_timeDelta_Seconds__maximum   \n",
      "Total_timeDelta_Seconds__absolute_maximum      Total_timeDelta_Seconds__absolute_maximum   \n",
      "Total_timeDelta_Seconds__median                          Total_timeDelta_Seconds__median   \n",
      "Total_timeDelta_Seconds__mean                              Total_timeDelta_Seconds__mean   \n",
      "Total_timeDelta_Seconds__standard_deviation  Total_timeDelta_Seconds__standard_deviation   \n",
      "Total_timeDelta_Seconds__variance                      Total_timeDelta_Seconds__variance   \n",
      "Total_timeDelta_Seconds__root_mean_square      Total_timeDelta_Seconds__root_mean_square   \n",
      "\n",
      "                                             type   p_value  relevant  \n",
      "feature                                                                \n",
      "Total_timeDelta_Seconds__minimum             real  0.003051      True  \n",
      "Total_timeDelta_Seconds__sum_values          real  0.000072      True  \n",
      "Total_timeDelta_Seconds__maximum             real  0.000041      True  \n",
      "Total_timeDelta_Seconds__absolute_maximum    real  0.000041      True  \n",
      "Total_timeDelta_Seconds__median              real  0.000010      True  \n",
      "Total_timeDelta_Seconds__mean                real  0.000010      True  \n",
      "Total_timeDelta_Seconds__standard_deviation  real  0.000010      True  \n",
      "Total_timeDelta_Seconds__variance            real  0.000010      True  \n",
      "Total_timeDelta_Seconds__root_mean_square    real  0.000010      True  \n"
     ]
    }
   ],
   "source": [
    "#Original\n",
    "settings_1 = MinimalFCParameters() \n",
    "#settings_2 = ComprehensiveFCParameters\n",
    "\n",
    "for i, col in enumerate(timeSeries_cols):\n",
    "    ts_processed = pd.DataFrame(cow_total[col].copy())\n",
    "    ts_processed.index = range(0,len(ts_processed)) \n",
    "    ts_processed = pd.concat([cow_timeseries, ts_processed], axis=1)\n",
    "    \n",
    "    print(ts_processed.shape)\n",
    "    \n",
    "    #print(ts_processed[ts_processed['id'] == 122])\n",
    "    # extract time series features\n",
    "    extracted_features = extract_features(ts_processed, column_id=\"id\", column_sort=\"MilkingDate\", default_fc_parameters=settings_1)\n",
    "    #extracted_features.dropna(axis=1, inplace=True)\n",
    "    impute(extracted_features)\n",
    "\n",
    "    # calculate_relevance_table method is sensitive to the index of the rows.\n",
    "    # The following two lines are to align the indices. \n",
    "    \n",
    "    #extracted_features.reset_index(drop=True, inplace=True)\n",
    "    #y.reset_index(drop=True, inplace=True)\n",
    "    extracted_features.index = range(1, len(extracted_features)+1)\n",
    "    y.index = range(1, len(y)+1)\n",
    "    #print(extracted_features)\n",
    "    #print(y)\n",
    "    \n",
    "    # select most relevant features based on relevance table\n",
    "    if i == 0:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = temp\n",
    "    else:\n",
    "        temp = calculate_relevance_table(extracted_features, y)\n",
    "        relevance_table = pd.concat([relevance_table, temp], axis=0)\n",
    "    features_filtered = select_features(extracted_features, y)\n",
    "    ts_extracted_dataset = pd.concat([ts_extracted_dataset, features_filtered], axis=1)\n",
    "\n",
    "# Select relevant features from the relevance table\n",
    "relevance_table = relevance_table[relevance_table.relevant]\n",
    "relevance_table.sort_values(\"p_value\", ascending=False, inplace=True)\n",
    "relevant_features_list = list(relevance_table.feature[:])\n",
    "print(relevance_table)\n",
    "\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset[relevant_features_list].copy()\n",
    "ts_extracted_dataset_filtered = ts_extracted_dataset_filtered.loc[:,~ts_extracted_dataset_filtered.columns.duplicated()]\n",
    "ts_extracted_dataset = ts_extracted_dataset_filtered\n",
    "ts_extracted_dataset\n",
    "ts_extracted_dataset.to_csv(dataDir+\"problematic_cows_7200s_5percent_extracted_features.csv\", index=False)\n",
    "relevance_table.to_csv(dataDir+\"problematic_cows_7200s_5percent_relevance_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f7621dc3-75b5-4db0-99ad-1a9a52619e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Total_timeDelta_Seconds__minimum</th>\n",
       "      <th>Total_timeDelta_Seconds__sum_values</th>\n",
       "      <th>Total_timeDelta_Seconds__maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__absolute_maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__median</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.779811</td>\n",
       "      <td>-0.425553</td>\n",
       "      <td>-0.614461</td>\n",
       "      <td>-0.614461</td>\n",
       "      <td>-0.263725</td>\n",
       "      <td>-0.334274</td>\n",
       "      <td>-0.402761</td>\n",
       "      <td>-0.233162</td>\n",
       "      <td>-0.369783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.779811</td>\n",
       "      <td>-1.167791</td>\n",
       "      <td>-1.176320</td>\n",
       "      <td>-1.176320</td>\n",
       "      <td>-0.305034</td>\n",
       "      <td>-0.487462</td>\n",
       "      <td>-0.686502</td>\n",
       "      <td>-0.260441</td>\n",
       "      <td>-0.590957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>-0.632537</td>\n",
       "      <td>-0.824276</td>\n",
       "      <td>-0.824276</td>\n",
       "      <td>-0.252709</td>\n",
       "      <td>-0.365394</td>\n",
       "      <td>-0.492175</td>\n",
       "      <td>-0.244405</td>\n",
       "      <td>-0.432170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>0.535284</td>\n",
       "      <td>-0.278320</td>\n",
       "      <td>-0.278320</td>\n",
       "      <td>-0.182680</td>\n",
       "      <td>-0.173757</td>\n",
       "      <td>-0.183905</td>\n",
       "      <td>-0.195366</td>\n",
       "      <td>-0.181076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>-0.672483</td>\n",
       "      <td>-0.393415</td>\n",
       "      <td>-0.393415</td>\n",
       "      <td>-0.306608</td>\n",
       "      <td>-0.384676</td>\n",
       "      <td>-0.385049</td>\n",
       "      <td>-0.230646</td>\n",
       "      <td>-0.378774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>-0.386281</td>\n",
       "      <td>-0.564169</td>\n",
       "      <td>-0.564169</td>\n",
       "      <td>-0.148845</td>\n",
       "      <td>-0.096632</td>\n",
       "      <td>-0.094039</td>\n",
       "      <td>-0.175620</td>\n",
       "      <td>-0.098512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>5.663221</td>\n",
       "      <td>0.840277</td>\n",
       "      <td>3.324214</td>\n",
       "      <td>3.324214</td>\n",
       "      <td>6.639679</td>\n",
       "      <td>6.316660</td>\n",
       "      <td>5.832649</td>\n",
       "      <td>6.558198</td>\n",
       "      <td>6.107518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>-0.679200</td>\n",
       "      <td>-0.694471</td>\n",
       "      <td>-0.694471</td>\n",
       "      <td>-0.262151</td>\n",
       "      <td>-0.359360</td>\n",
       "      <td>-0.435491</td>\n",
       "      <td>-0.237560</td>\n",
       "      <td>-0.398386</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>-0.895987</td>\n",
       "      <td>-0.469947</td>\n",
       "      <td>-0.469947</td>\n",
       "      <td>-0.258414</td>\n",
       "      <td>-0.289850</td>\n",
       "      <td>-0.219632</td>\n",
       "      <td>-0.202533</td>\n",
       "      <td>-0.247721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>0.447433</td>\n",
       "      <td>1.203168</td>\n",
       "      <td>0.515517</td>\n",
       "      <td>0.515517</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>0.091578</td>\n",
       "      <td>0.117194</td>\n",
       "      <td>-0.119519</td>\n",
       "      <td>0.099364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27</td>\n",
       "      <td>0.754244</td>\n",
       "      <td>0.681889</td>\n",
       "      <td>1.168915</td>\n",
       "      <td>1.168915</td>\n",
       "      <td>-0.040457</td>\n",
       "      <td>0.027210</td>\n",
       "      <td>0.070026</td>\n",
       "      <td>-0.133226</td>\n",
       "      <td>0.044877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>0.140382</td>\n",
       "      <td>-0.358628</td>\n",
       "      <td>-0.358628</td>\n",
       "      <td>-0.253889</td>\n",
       "      <td>-0.288585</td>\n",
       "      <td>-0.298517</td>\n",
       "      <td>-0.216979</td>\n",
       "      <td>-0.292676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>0.140622</td>\n",
       "      <td>2.511158</td>\n",
       "      <td>3.105951</td>\n",
       "      <td>3.105951</td>\n",
       "      <td>0.915366</td>\n",
       "      <td>1.841028</td>\n",
       "      <td>2.739376</td>\n",
       "      <td>1.708623</td>\n",
       "      <td>2.287393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>-0.451524</td>\n",
       "      <td>-0.325134</td>\n",
       "      <td>-0.325134</td>\n",
       "      <td>-0.268446</td>\n",
       "      <td>-0.294130</td>\n",
       "      <td>-0.271929</td>\n",
       "      <td>-0.212322</td>\n",
       "      <td>-0.279675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>-0.125115</td>\n",
       "      <td>0.517605</td>\n",
       "      <td>0.517605</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.220775</td>\n",
       "      <td>-0.146482</td>\n",
       "      <td>-0.187442</td>\n",
       "      <td>-0.179491</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>0.140622</td>\n",
       "      <td>-1.098639</td>\n",
       "      <td>-0.616151</td>\n",
       "      <td>-0.616151</td>\n",
       "      <td>-0.241300</td>\n",
       "      <td>-0.389331</td>\n",
       "      <td>-0.552847</td>\n",
       "      <td>-0.250647</td>\n",
       "      <td>-0.475321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36</td>\n",
       "      <td>0.447433</td>\n",
       "      <td>-0.509040</td>\n",
       "      <td>-0.112039</td>\n",
       "      <td>-0.112039</td>\n",
       "      <td>-0.235005</td>\n",
       "      <td>-0.085907</td>\n",
       "      <td>0.106246</td>\n",
       "      <td>-0.122761</td>\n",
       "      <td>0.017378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>-0.779811</td>\n",
       "      <td>-0.188390</td>\n",
       "      <td>-0.227730</td>\n",
       "      <td>-0.227730</td>\n",
       "      <td>-0.223989</td>\n",
       "      <td>-0.216726</td>\n",
       "      <td>-0.144730</td>\n",
       "      <td>-0.187061</td>\n",
       "      <td>-0.176919</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>41</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>-0.258492</td>\n",
       "      <td>-0.047931</td>\n",
       "      <td>-0.047931</td>\n",
       "      <td>-0.227530</td>\n",
       "      <td>-0.269964</td>\n",
       "      <td>-0.286831</td>\n",
       "      <td>-0.214959</td>\n",
       "      <td>-0.278562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>46</td>\n",
       "      <td>0.447433</td>\n",
       "      <td>-1.027046</td>\n",
       "      <td>-0.797838</td>\n",
       "      <td>-0.797838</td>\n",
       "      <td>-0.169697</td>\n",
       "      <td>-0.264895</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.228911</td>\n",
       "      <td>-0.323333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>51</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>0.047404</td>\n",
       "      <td>-0.257448</td>\n",
       "      <td>-0.257448</td>\n",
       "      <td>-0.232645</td>\n",
       "      <td>-0.171490</td>\n",
       "      <td>-0.072034</td>\n",
       "      <td>-0.170410</td>\n",
       "      <td>-0.117777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>57</td>\n",
       "      <td>1.061055</td>\n",
       "      <td>3.178030</td>\n",
       "      <td>1.115642</td>\n",
       "      <td>1.115642</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.697319</td>\n",
       "      <td>0.557472</td>\n",
       "      <td>0.041106</td>\n",
       "      <td>0.622862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>60</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>-0.098672</td>\n",
       "      <td>-0.030538</td>\n",
       "      <td>-0.030538</td>\n",
       "      <td>-0.247595</td>\n",
       "      <td>-0.225151</td>\n",
       "      <td>-0.170182</td>\n",
       "      <td>-0.192510</td>\n",
       "      <td>-0.194728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>63</td>\n",
       "      <td>-0.779811</td>\n",
       "      <td>-1.206550</td>\n",
       "      <td>-0.214213</td>\n",
       "      <td>-0.214213</td>\n",
       "      <td>-0.281822</td>\n",
       "      <td>-0.369637</td>\n",
       "      <td>-0.394317</td>\n",
       "      <td>-0.231974</td>\n",
       "      <td>-0.378840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>69</td>\n",
       "      <td>-0.779811</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>0.044999</td>\n",
       "      <td>0.044999</td>\n",
       "      <td>-0.226350</td>\n",
       "      <td>-0.193891</td>\n",
       "      <td>-0.128434</td>\n",
       "      <td>-0.183468</td>\n",
       "      <td>-0.158658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>71</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>0.252509</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.210219</td>\n",
       "      <td>-0.171301</td>\n",
       "      <td>-0.149931</td>\n",
       "      <td>-0.188190</td>\n",
       "      <td>-0.161400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>74</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>-0.570402</td>\n",
       "      <td>-0.569735</td>\n",
       "      <td>-0.569735</td>\n",
       "      <td>-0.295002</td>\n",
       "      <td>-0.351656</td>\n",
       "      <td>-0.352828</td>\n",
       "      <td>-0.225824</td>\n",
       "      <td>-0.348059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>75</td>\n",
       "      <td>0.754244</td>\n",
       "      <td>-0.796172</td>\n",
       "      <td>-0.389638</td>\n",
       "      <td>-0.389638</td>\n",
       "      <td>-0.010754</td>\n",
       "      <td>-0.016077</td>\n",
       "      <td>-0.011074</td>\n",
       "      <td>-0.155207</td>\n",
       "      <td>-0.017864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>76</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>-0.707777</td>\n",
       "      <td>-0.060753</td>\n",
       "      <td>-0.060753</td>\n",
       "      <td>-0.223202</td>\n",
       "      <td>-0.265452</td>\n",
       "      <td>-0.279794</td>\n",
       "      <td>-0.213722</td>\n",
       "      <td>-0.272775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>85</td>\n",
       "      <td>1.061055</td>\n",
       "      <td>1.394059</td>\n",
       "      <td>1.581389</td>\n",
       "      <td>1.581389</td>\n",
       "      <td>0.212318</td>\n",
       "      <td>0.226403</td>\n",
       "      <td>0.164339</td>\n",
       "      <td>-0.105143</td>\n",
       "      <td>0.188804</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>92</td>\n",
       "      <td>0.447433</td>\n",
       "      <td>-0.327228</td>\n",
       "      <td>-0.415878</td>\n",
       "      <td>-0.415878</td>\n",
       "      <td>-0.228317</td>\n",
       "      <td>-0.322013</td>\n",
       "      <td>-0.416241</td>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.371997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>95</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>0.252827</td>\n",
       "      <td>-0.160641</td>\n",
       "      <td>-0.160641</td>\n",
       "      <td>-0.197630</td>\n",
       "      <td>-0.172263</td>\n",
       "      <td>-0.170813</td>\n",
       "      <td>-0.192643</td>\n",
       "      <td>-0.173286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>97</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>0.074257</td>\n",
       "      <td>-0.322947</td>\n",
       "      <td>-0.322947</td>\n",
       "      <td>-0.121306</td>\n",
       "      <td>-0.140353</td>\n",
       "      <td>-0.195846</td>\n",
       "      <td>-0.197805</td>\n",
       "      <td>-0.172490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>98</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>-0.656623</td>\n",
       "      <td>-0.840576</td>\n",
       "      <td>-0.840576</td>\n",
       "      <td>-0.280642</td>\n",
       "      <td>-0.395994</td>\n",
       "      <td>-0.486213</td>\n",
       "      <td>-0.243731</td>\n",
       "      <td>-0.441734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>-0.089900</td>\n",
       "      <td>-0.660579</td>\n",
       "      <td>-0.660579</td>\n",
       "      <td>-0.266872</td>\n",
       "      <td>-0.312262</td>\n",
       "      <td>-0.354408</td>\n",
       "      <td>-0.226067</td>\n",
       "      <td>-0.333711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>103</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>-0.847034</td>\n",
       "      <td>-0.539520</td>\n",
       "      <td>-0.539520</td>\n",
       "      <td>-0.297756</td>\n",
       "      <td>-0.394955</td>\n",
       "      <td>-0.427149</td>\n",
       "      <td>-0.236470</td>\n",
       "      <td>-0.407242</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>108</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>1.129953</td>\n",
       "      <td>0.168940</td>\n",
       "      <td>0.168940</td>\n",
       "      <td>-0.021769</td>\n",
       "      <td>0.057591</td>\n",
       "      <td>0.048252</td>\n",
       "      <td>-0.139324</td>\n",
       "      <td>0.047512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>109</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>-0.346973</td>\n",
       "      <td>-0.744962</td>\n",
       "      <td>-0.744962</td>\n",
       "      <td>-0.248972</td>\n",
       "      <td>-0.314821</td>\n",
       "      <td>-0.394439</td>\n",
       "      <td>-0.231992</td>\n",
       "      <td>-0.356985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>115</td>\n",
       "      <td>1.674677</td>\n",
       "      <td>3.601316</td>\n",
       "      <td>3.298571</td>\n",
       "      <td>3.298571</td>\n",
       "      <td>0.630133</td>\n",
       "      <td>0.994160</td>\n",
       "      <td>1.364007</td>\n",
       "      <td>0.488529</td>\n",
       "      <td>1.172353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>124</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>-0.065524</td>\n",
       "      <td>-0.085203</td>\n",
       "      <td>-0.085203</td>\n",
       "      <td>-0.225169</td>\n",
       "      <td>-0.190952</td>\n",
       "      <td>-0.175277</td>\n",
       "      <td>-0.193577</td>\n",
       "      <td>-0.183688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>128</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>-0.304039</td>\n",
       "      <td>-0.442018</td>\n",
       "      <td>-0.442018</td>\n",
       "      <td>-0.092979</td>\n",
       "      <td>-0.114194</td>\n",
       "      <td>-0.207174</td>\n",
       "      <td>-0.200078</td>\n",
       "      <td>-0.166030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>129</td>\n",
       "      <td>-1.086623</td>\n",
       "      <td>-0.543277</td>\n",
       "      <td>-0.773686</td>\n",
       "      <td>-0.773686</td>\n",
       "      <td>-0.281036</td>\n",
       "      <td>-0.377598</td>\n",
       "      <td>-0.462811</td>\n",
       "      <td>-0.240981</td>\n",
       "      <td>-0.421140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>131</td>\n",
       "      <td>0.754244</td>\n",
       "      <td>0.032153</td>\n",
       "      <td>0.376668</td>\n",
       "      <td>0.376668</td>\n",
       "      <td>-0.070947</td>\n",
       "      <td>0.056495</td>\n",
       "      <td>0.195285</td>\n",
       "      <td>-0.095338</td>\n",
       "      <td>0.125460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>134</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>0.062470</td>\n",
       "      <td>-0.364393</td>\n",
       "      <td>-0.364393</td>\n",
       "      <td>-0.207072</td>\n",
       "      <td>-0.209021</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.198530</td>\n",
       "      <td>-0.204646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>136</td>\n",
       "      <td>0.447433</td>\n",
       "      <td>-0.977133</td>\n",
       "      <td>-0.951199</td>\n",
       "      <td>-0.951199</td>\n",
       "      <td>-0.308575</td>\n",
       "      <td>-0.436328</td>\n",
       "      <td>-0.561606</td>\n",
       "      <td>-0.251455</td>\n",
       "      <td>-0.500484</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>140</td>\n",
       "      <td>-0.779811</td>\n",
       "      <td>0.072957</td>\n",
       "      <td>-0.319468</td>\n",
       "      <td>-0.319468</td>\n",
       "      <td>-0.247201</td>\n",
       "      <td>-0.233636</td>\n",
       "      <td>-0.214519</td>\n",
       "      <td>-0.201531</td>\n",
       "      <td>-0.223197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>141</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>0.130686</td>\n",
       "      <td>0.746503</td>\n",
       "      <td>0.746503</td>\n",
       "      <td>-0.118552</td>\n",
       "      <td>-0.121710</td>\n",
       "      <td>-0.075106</td>\n",
       "      <td>-0.171147</td>\n",
       "      <td>-0.099140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>142</td>\n",
       "      <td>-0.166189</td>\n",
       "      <td>-0.083996</td>\n",
       "      <td>-0.441222</td>\n",
       "      <td>-0.441222</td>\n",
       "      <td>-0.236775</td>\n",
       "      <td>-0.285969</td>\n",
       "      <td>-0.321108</td>\n",
       "      <td>-0.220767</td>\n",
       "      <td>-0.304293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Total_timeDelta_Seconds__minimum  \\\n",
       "1     1                         -0.779811   \n",
       "2     4                         -0.779811   \n",
       "3     9                         -0.166189   \n",
       "4    11                         -0.473000   \n",
       "5    15                         -0.473000   \n",
       "6    18                         -0.166189   \n",
       "7    20                          5.663221   \n",
       "8    23                         -0.473000   \n",
       "9    24                         -0.166189   \n",
       "10   25                          0.447433   \n",
       "11   27                          0.754244   \n",
       "12   29                         -0.166189   \n",
       "13   30                          0.140622   \n",
       "14   31                         -0.473000   \n",
       "15   34                         -0.166189   \n",
       "16   35                          0.140622   \n",
       "17   36                          0.447433   \n",
       "18   38                         -0.779811   \n",
       "19   41                         -0.473000   \n",
       "20   46                          0.447433   \n",
       "21   51                         -0.166189   \n",
       "22   57                          1.061055   \n",
       "23   60                         -0.473000   \n",
       "24   63                         -0.779811   \n",
       "25   69                         -0.779811   \n",
       "26   71                         -0.166189   \n",
       "27   74                         -0.473000   \n",
       "28   75                          0.754244   \n",
       "29   76                         -0.166189   \n",
       "30   85                          1.061055   \n",
       "31   92                          0.447433   \n",
       "32   95                         -0.473000   \n",
       "33   97                         -0.166189   \n",
       "34   98                         -0.166189   \n",
       "35  100                         -0.166189   \n",
       "36  103                         -0.473000   \n",
       "37  108                         -0.166189   \n",
       "38  109                         -0.473000   \n",
       "39  115                          1.674677   \n",
       "40  124                         -0.473000   \n",
       "41  128                         -0.473000   \n",
       "42  129                         -1.086623   \n",
       "43  131                          0.754244   \n",
       "44  134                         -0.473000   \n",
       "45  136                          0.447433   \n",
       "46  140                         -0.779811   \n",
       "47  141                         -0.166189   \n",
       "48  142                         -0.166189   \n",
       "\n",
       "    Total_timeDelta_Seconds__sum_values  Total_timeDelta_Seconds__maximum  \\\n",
       "1                             -0.425553                         -0.614461   \n",
       "2                             -1.167791                         -1.176320   \n",
       "3                             -0.632537                         -0.824276   \n",
       "4                              0.535284                         -0.278320   \n",
       "5                             -0.672483                         -0.393415   \n",
       "6                             -0.386281                         -0.564169   \n",
       "7                              0.840277                          3.324214   \n",
       "8                             -0.679200                         -0.694471   \n",
       "9                             -0.895987                         -0.469947   \n",
       "10                             1.203168                          0.515517   \n",
       "11                             0.681889                          1.168915   \n",
       "12                             0.140382                         -0.358628   \n",
       "13                             2.511158                          3.105951   \n",
       "14                            -0.451524                         -0.325134   \n",
       "15                            -0.125115                          0.517605   \n",
       "16                            -1.098639                         -0.616151   \n",
       "17                            -0.509040                         -0.112039   \n",
       "18                            -0.188390                         -0.227730   \n",
       "19                            -0.258492                         -0.047931   \n",
       "20                            -1.027046                         -0.797838   \n",
       "21                             0.047404                         -0.257448   \n",
       "22                             3.178030                          1.115642   \n",
       "23                            -0.098672                         -0.030538   \n",
       "24                            -1.206550                         -0.214213   \n",
       "25                            -0.001402                          0.044999   \n",
       "26                             0.252509                          0.120537   \n",
       "27                            -0.570402                         -0.569735   \n",
       "28                            -0.796172                         -0.389638   \n",
       "29                            -0.707777                         -0.060753   \n",
       "30                             1.394059                          1.581389   \n",
       "31                            -0.327228                         -0.415878   \n",
       "32                             0.252827                         -0.160641   \n",
       "33                             0.074257                         -0.322947   \n",
       "34                            -0.656623                         -0.840576   \n",
       "35                            -0.089900                         -0.660579   \n",
       "36                            -0.847034                         -0.539520   \n",
       "37                             1.129953                          0.168940   \n",
       "38                            -0.346973                         -0.744962   \n",
       "39                             3.601316                          3.298571   \n",
       "40                            -0.065524                         -0.085203   \n",
       "41                            -0.304039                         -0.442018   \n",
       "42                            -0.543277                         -0.773686   \n",
       "43                             0.032153                          0.376668   \n",
       "44                             0.062470                         -0.364393   \n",
       "45                            -0.977133                         -0.951199   \n",
       "46                             0.072957                         -0.319468   \n",
       "47                             0.130686                          0.746503   \n",
       "48                            -0.083996                         -0.441222   \n",
       "\n",
       "    Total_timeDelta_Seconds__absolute_maximum  \\\n",
       "1                                   -0.614461   \n",
       "2                                   -1.176320   \n",
       "3                                   -0.824276   \n",
       "4                                   -0.278320   \n",
       "5                                   -0.393415   \n",
       "6                                   -0.564169   \n",
       "7                                    3.324214   \n",
       "8                                   -0.694471   \n",
       "9                                   -0.469947   \n",
       "10                                   0.515517   \n",
       "11                                   1.168915   \n",
       "12                                  -0.358628   \n",
       "13                                   3.105951   \n",
       "14                                  -0.325134   \n",
       "15                                   0.517605   \n",
       "16                                  -0.616151   \n",
       "17                                  -0.112039   \n",
       "18                                  -0.227730   \n",
       "19                                  -0.047931   \n",
       "20                                  -0.797838   \n",
       "21                                  -0.257448   \n",
       "22                                   1.115642   \n",
       "23                                  -0.030538   \n",
       "24                                  -0.214213   \n",
       "25                                   0.044999   \n",
       "26                                   0.120537   \n",
       "27                                  -0.569735   \n",
       "28                                  -0.389638   \n",
       "29                                  -0.060753   \n",
       "30                                   1.581389   \n",
       "31                                  -0.415878   \n",
       "32                                  -0.160641   \n",
       "33                                  -0.322947   \n",
       "34                                  -0.840576   \n",
       "35                                  -0.660579   \n",
       "36                                  -0.539520   \n",
       "37                                   0.168940   \n",
       "38                                  -0.744962   \n",
       "39                                   3.298571   \n",
       "40                                  -0.085203   \n",
       "41                                  -0.442018   \n",
       "42                                  -0.773686   \n",
       "43                                   0.376668   \n",
       "44                                  -0.364393   \n",
       "45                                  -0.951199   \n",
       "46                                  -0.319468   \n",
       "47                                   0.746503   \n",
       "48                                  -0.441222   \n",
       "\n",
       "    Total_timeDelta_Seconds__median  Total_timeDelta_Seconds__mean  \\\n",
       "1                         -0.263725                      -0.334274   \n",
       "2                         -0.305034                      -0.487462   \n",
       "3                         -0.252709                      -0.365394   \n",
       "4                         -0.182680                      -0.173757   \n",
       "5                         -0.306608                      -0.384676   \n",
       "6                         -0.148845                      -0.096632   \n",
       "7                          6.639679                       6.316660   \n",
       "8                         -0.262151                      -0.359360   \n",
       "9                         -0.258414                      -0.289850   \n",
       "10                        -0.000328                       0.091578   \n",
       "11                        -0.040457                       0.027210   \n",
       "12                        -0.253889                      -0.288585   \n",
       "13                         0.915366                       1.841028   \n",
       "14                        -0.268446                      -0.294130   \n",
       "15                        -0.238546                      -0.220775   \n",
       "16                        -0.241300                      -0.389331   \n",
       "17                        -0.235005                      -0.085907   \n",
       "18                        -0.223989                      -0.216726   \n",
       "19                        -0.227530                      -0.269964   \n",
       "20                        -0.169697                      -0.264895   \n",
       "21                        -0.232645                      -0.171490   \n",
       "22                         0.661017                       0.697319   \n",
       "23                        -0.247595                      -0.225151   \n",
       "24                        -0.281822                      -0.369637   \n",
       "25                        -0.226350                      -0.193891   \n",
       "26                        -0.210219                      -0.171301   \n",
       "27                        -0.295002                      -0.351656   \n",
       "28                        -0.010754                      -0.016077   \n",
       "29                        -0.223202                      -0.265452   \n",
       "30                         0.212318                       0.226403   \n",
       "31                        -0.228317                      -0.322013   \n",
       "32                        -0.197630                      -0.172263   \n",
       "33                        -0.121306                      -0.140353   \n",
       "34                        -0.280642                      -0.395994   \n",
       "35                        -0.266872                      -0.312262   \n",
       "36                        -0.297756                      -0.394955   \n",
       "37                        -0.021769                       0.057591   \n",
       "38                        -0.248972                      -0.314821   \n",
       "39                         0.630133                       0.994160   \n",
       "40                        -0.225169                      -0.190952   \n",
       "41                        -0.092979                      -0.114194   \n",
       "42                        -0.281036                      -0.377598   \n",
       "43                        -0.070947                       0.056495   \n",
       "44                        -0.207072                      -0.209021   \n",
       "45                        -0.308575                      -0.436328   \n",
       "46                        -0.247201                      -0.233636   \n",
       "47                        -0.118552                      -0.121710   \n",
       "48                        -0.236775                      -0.285969   \n",
       "\n",
       "    Total_timeDelta_Seconds__standard_deviation  \\\n",
       "1                                     -0.402761   \n",
       "2                                     -0.686502   \n",
       "3                                     -0.492175   \n",
       "4                                     -0.183905   \n",
       "5                                     -0.385049   \n",
       "6                                     -0.094039   \n",
       "7                                      5.832649   \n",
       "8                                     -0.435491   \n",
       "9                                     -0.219632   \n",
       "10                                     0.117194   \n",
       "11                                     0.070026   \n",
       "12                                    -0.298517   \n",
       "13                                     2.739376   \n",
       "14                                    -0.271929   \n",
       "15                                    -0.146482   \n",
       "16                                    -0.552847   \n",
       "17                                     0.106246   \n",
       "18                                    -0.144730   \n",
       "19                                    -0.286831   \n",
       "20                                    -0.373210   \n",
       "21                                    -0.072034   \n",
       "22                                     0.557472   \n",
       "23                                    -0.170182   \n",
       "24                                    -0.394317   \n",
       "25                                    -0.128434   \n",
       "26                                    -0.149931   \n",
       "27                                    -0.352828   \n",
       "28                                    -0.011074   \n",
       "29                                    -0.279794   \n",
       "30                                     0.164339   \n",
       "31                                    -0.416241   \n",
       "32                                    -0.170813   \n",
       "33                                    -0.195846   \n",
       "34                                    -0.486213   \n",
       "35                                    -0.354408   \n",
       "36                                    -0.427149   \n",
       "37                                     0.048252   \n",
       "38                                    -0.394439   \n",
       "39                                     1.364007   \n",
       "40                                    -0.175277   \n",
       "41                                    -0.207174   \n",
       "42                                    -0.462811   \n",
       "43                                     0.195285   \n",
       "44                                    -0.199441   \n",
       "45                                    -0.561606   \n",
       "46                                    -0.214519   \n",
       "47                                    -0.075106   \n",
       "48                                    -0.321108   \n",
       "\n",
       "    Total_timeDelta_Seconds__variance  \\\n",
       "1                           -0.233162   \n",
       "2                           -0.260441   \n",
       "3                           -0.244405   \n",
       "4                           -0.195366   \n",
       "5                           -0.230646   \n",
       "6                           -0.175620   \n",
       "7                            6.558198   \n",
       "8                           -0.237560   \n",
       "9                           -0.202533   \n",
       "10                          -0.119519   \n",
       "11                          -0.133226   \n",
       "12                          -0.216979   \n",
       "13                           1.708623   \n",
       "14                          -0.212322   \n",
       "15                          -0.187442   \n",
       "16                          -0.250647   \n",
       "17                          -0.122761   \n",
       "18                          -0.187061   \n",
       "19                          -0.214959   \n",
       "20                          -0.228911   \n",
       "21                          -0.170410   \n",
       "22                           0.041106   \n",
       "23                          -0.192510   \n",
       "24                          -0.231974   \n",
       "25                          -0.183468   \n",
       "26                          -0.188190   \n",
       "27                          -0.225824   \n",
       "28                          -0.155207   \n",
       "29                          -0.213722   \n",
       "30                          -0.105143   \n",
       "31                          -0.235013   \n",
       "32                          -0.192643   \n",
       "33                          -0.197805   \n",
       "34                          -0.243731   \n",
       "35                          -0.226067   \n",
       "36                          -0.236470   \n",
       "37                          -0.139324   \n",
       "38                          -0.231992   \n",
       "39                           0.488529   \n",
       "40                          -0.193577   \n",
       "41                          -0.200078   \n",
       "42                          -0.240981   \n",
       "43                          -0.095338   \n",
       "44                          -0.198530   \n",
       "45                          -0.251455   \n",
       "46                          -0.201531   \n",
       "47                          -0.171147   \n",
       "48                          -0.220767   \n",
       "\n",
       "    Total_timeDelta_Seconds__root_mean_square  BreedName_1  problematic  \n",
       "1                                   -0.369783          1.0            0  \n",
       "2                                   -0.590957          1.0            0  \n",
       "3                                   -0.432170          1.0            0  \n",
       "4                                   -0.181076          1.0            0  \n",
       "5                                   -0.378774          1.0            0  \n",
       "6                                   -0.098512          1.0            0  \n",
       "7                                    6.107518          1.0            1  \n",
       "8                                   -0.398386          1.0            0  \n",
       "9                                   -0.247721          1.0            0  \n",
       "10                                   0.099364          1.0            0  \n",
       "11                                   0.044877          1.0            0  \n",
       "12                                  -0.292676          1.0            0  \n",
       "13                                   2.287393          1.0            1  \n",
       "14                                  -0.279675          1.0            0  \n",
       "15                                  -0.179491          1.0            0  \n",
       "16                                  -0.475321          1.0            0  \n",
       "17                                   0.017378          1.0            0  \n",
       "18                                  -0.176919          1.0            0  \n",
       "19                                  -0.278562          1.0            0  \n",
       "20                                  -0.323333          1.0            0  \n",
       "21                                  -0.117777          1.0            0  \n",
       "22                                   0.622862          1.0            1  \n",
       "23                                  -0.194728          1.0            0  \n",
       "24                                  -0.378840          1.0            0  \n",
       "25                                  -0.158658          1.0            0  \n",
       "26                                  -0.161400          1.0            0  \n",
       "27                                  -0.348059          1.0            0  \n",
       "28                                  -0.017864          1.0            0  \n",
       "29                                  -0.272775          1.0            0  \n",
       "30                                   0.188804          1.0            0  \n",
       "31                                  -0.371997          1.0            0  \n",
       "32                                  -0.173286          1.0            0  \n",
       "33                                  -0.172490          1.0            0  \n",
       "34                                  -0.441734          1.0            0  \n",
       "35                                  -0.333711          1.0            0  \n",
       "36                                  -0.407242          1.0            0  \n",
       "37                                   0.047512          1.0            0  \n",
       "38                                  -0.356985          1.0            0  \n",
       "39                                   1.172353          1.0            1  \n",
       "40                                  -0.183688          1.0            0  \n",
       "41                                  -0.166030          1.0            0  \n",
       "42                                  -0.421140          1.0            0  \n",
       "43                                   0.125460          1.0            0  \n",
       "44                                  -0.204646          1.0            0  \n",
       "45                                  -0.500484          1.0            0  \n",
       "46                                  -0.223197          1.0            0  \n",
       "47                                  -0.099140          1.0            0  \n",
       "48                                  -0.304293          1.0            0  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original\n",
    "# Construct extracted training data\n",
    "ts_extracted_id = cow_total[['id']].copy()\n",
    "ts_extracted_id.drop_duplicates(subset=['id'], inplace=True)\n",
    "ts_extracted_id.index = range(1, len(ts_extracted_id)+1)\n",
    "ts_extracted_dataset = pd.concat([ts_extracted_id, ts_extracted_dataset], axis=1)\n",
    "#print(ts_extracted_dataset)\n",
    "ts_extracted_features = ts_extracted_dataset.iloc[:, 1:len(ts_extracted_dataset.columns)].copy()\n",
    "#print(ts_extracted_features)\n",
    "#ts_extracted_features\n",
    "\n",
    "# normalize numerical features\n",
    "ts_extracted_cols = ts_extracted_features.columns\n",
    "scaler_std = StandardScaler()\n",
    "ts_std = scaler_std.fit_transform(ts_extracted_features)\n",
    "# transform standard data into dataframe\n",
    "ts_extracted_processed = pd.DataFrame(ts_std, columns=ts_extracted_cols)\n",
    "ts_extracted_processed.index = range(1,len(ts_extracted_processed)+1)\n",
    "# append id col to the dataframe\n",
    "ts_extracted_processed = pd.concat([ts_extracted_dataset['id'], ts_extracted_processed], axis=1)\n",
    "\n",
    "# One-Hot encoding categorical feature - BreedName\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "\n",
    "cow_breed = cow_total[['id', 'BreedName']].copy()\n",
    "cow_breed.drop_duplicates(subset=['id'], inplace=True)\n",
    "cat = ohe.fit_transform(np.array(cow_breed['BreedName']).reshape(-1, 1))\n",
    "col_names = ohe.get_feature_names_out(['BreedName'])\n",
    "cat_breed = pd.DataFrame(cat, columns=col_names)\n",
    "cat_breed.index = range(1,len(cow_breed)+1)\n",
    "\n",
    "# append features on extracted dataset\n",
    "ts_dataset = pd.concat([ts_extracted_processed, cat_breed], axis=1)\n",
    "ts_dataset = pd.concat([ts_dataset, y], axis=1)\n",
    "ts_dataset.to_csv(dataDir+\"problematic_100cows_7200s_5percent_features.csv\", index=False)\n",
    "ts_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "65c049f4-c9d5-4cf5-8ecf-f65f5e7e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation on Gaussian Process Classifier\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, Matern, RationalQuadratic, WhiteKernel, ExpSineSquared\n",
    "grid = dict()\n",
    "grid['kernel'] = [1*RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)), \n",
    "                  1*DotProduct(), 1*Matern(),  1*RationalQuadratic(),\n",
    "                  1*Matern()+1*WhiteKernel(noise_level=0.5),\n",
    "                  1*ExpSineSquared(),\n",
    "                  1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0, length_scale_bounds=(0.1, 10.0), periodicity_bounds=(1.0, 10.0)),\n",
    "                  1*Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)+1*WhiteKernel(noise_level=0.5),\n",
    "                ]\n",
    "\n",
    "\n",
    "#dataDir = Path.cwd().parent.parent/'Data/processed'\n",
    "#id used as index\n",
    "#ts_dataset = pd.read_csv(dataDir/'Problematic_targetCows/problematic_100cows_7200s_5percent_features.csv', index_col='id')\n",
    "\n",
    "#use id as normal column\n",
    "#ts_dataset = pd.read_csv(dataDir+'Problematic_targetCows/problematic_100cows_7200s_5percent_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f6da5b4f-a365-4ccf-8202-4fca2114d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cow_dataset = pd.DataFrame()\n",
    "\n",
    "train_cow_dataset = ts_dataset[~ts_dataset['id'].isin(test_cow_list)]\n",
    "\n",
    "train_cow_list = train_cow_dataset['id'].unique()\n",
    "\n",
    "#print(len(train_cow_list))\n",
    "#print(train_cow_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "caf3ba49-8aeb-492b-a3c5-15526f6363aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.DataFrame(train_cow_dataset['problematic'], columns=['problematic'])\n",
    "train_data = train_cow_dataset.drop('problematic', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "eca48f91-10a1-4202-83b4-12856a3e1cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Total_timeDelta_Seconds__minimum</th>\n",
       "      <th>Total_timeDelta_Seconds__sum_values</th>\n",
       "      <th>Total_timeDelta_Seconds__maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__absolute_maximum</th>\n",
       "      <th>Total_timeDelta_Seconds__median</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>problematic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5.663221</td>\n",
       "      <td>0.840277</td>\n",
       "      <td>3.324214</td>\n",
       "      <td>3.324214</td>\n",
       "      <td>6.639679</td>\n",
       "      <td>6.316660</td>\n",
       "      <td>5.832649</td>\n",
       "      <td>6.558198</td>\n",
       "      <td>6.107518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.447433</td>\n",
       "      <td>-1.027046</td>\n",
       "      <td>-0.797838</td>\n",
       "      <td>-0.797838</td>\n",
       "      <td>-0.169697</td>\n",
       "      <td>-0.264895</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.228911</td>\n",
       "      <td>-0.323333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>5.663221</td>\n",
       "      <td>0.840277</td>\n",
       "      <td>3.324214</td>\n",
       "      <td>3.324214</td>\n",
       "      <td>6.639679</td>\n",
       "      <td>6.316660</td>\n",
       "      <td>5.832649</td>\n",
       "      <td>6.558198</td>\n",
       "      <td>6.107518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>0.754244</td>\n",
       "      <td>-0.796172</td>\n",
       "      <td>-0.389638</td>\n",
       "      <td>-0.389638</td>\n",
       "      <td>-0.010754</td>\n",
       "      <td>-0.016077</td>\n",
       "      <td>-0.011074</td>\n",
       "      <td>-0.155207</td>\n",
       "      <td>-0.017864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>-0.779811</td>\n",
       "      <td>-1.206550</td>\n",
       "      <td>-0.214213</td>\n",
       "      <td>-0.214213</td>\n",
       "      <td>-0.281822</td>\n",
       "      <td>-0.369637</td>\n",
       "      <td>-0.394317</td>\n",
       "      <td>-0.231974</td>\n",
       "      <td>-0.378840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Total_timeDelta_Seconds__minimum  Total_timeDelta_Seconds__sum_values  \\\n",
       "0  20                          5.663221                             0.840277   \n",
       "1  46                          0.447433                            -1.027046   \n",
       "2  20                          5.663221                             0.840277   \n",
       "3  75                          0.754244                            -0.796172   \n",
       "4  63                         -0.779811                            -1.206550   \n",
       "\n",
       "   Total_timeDelta_Seconds__maximum  \\\n",
       "0                          3.324214   \n",
       "1                         -0.797838   \n",
       "2                          3.324214   \n",
       "3                         -0.389638   \n",
       "4                         -0.214213   \n",
       "\n",
       "   Total_timeDelta_Seconds__absolute_maximum  Total_timeDelta_Seconds__median  \\\n",
       "0                                   3.324214                         6.639679   \n",
       "1                                  -0.797838                        -0.169697   \n",
       "2                                   3.324214                         6.639679   \n",
       "3                                  -0.389638                        -0.010754   \n",
       "4                                  -0.214213                        -0.281822   \n",
       "\n",
       "   Total_timeDelta_Seconds__mean  Total_timeDelta_Seconds__standard_deviation  \\\n",
       "0                       6.316660                                     5.832649   \n",
       "1                      -0.264895                                    -0.373210   \n",
       "2                       6.316660                                     5.832649   \n",
       "3                      -0.016077                                    -0.011074   \n",
       "4                      -0.369637                                    -0.394317   \n",
       "\n",
       "   Total_timeDelta_Seconds__variance  \\\n",
       "0                           6.558198   \n",
       "1                          -0.228911   \n",
       "2                           6.558198   \n",
       "3                          -0.155207   \n",
       "4                          -0.231974   \n",
       "\n",
       "   Total_timeDelta_Seconds__root_mean_square  BreedName_1  problematic  \n",
       "0                                   6.107518          1.0            1  \n",
       "1                                  -0.323333          1.0            0  \n",
       "2                                   6.107518          1.0            1  \n",
       "3                                  -0.017864          1.0            0  \n",
       "4                                  -0.378840          1.0            0  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cow_dataset = pd.DataFrame()\n",
    "\n",
    "for tc in test_cow_list:\n",
    "    test_data = ts_dataset[ts_dataset['id'] == tc]\n",
    "    frames = [test_cow_dataset, test_data]\n",
    "    test_cow_dataset = pd.concat(frames, ignore_index=True)\n",
    "    \n",
    "test_cow_dataset\n",
    "#test_cow_dataset.to_csv(dataDir+\"test_cow_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "44e23afb-169a-4b3a-949f-f590c68f8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.DataFrame(test_cow_dataset['problematic'], columns=['problematic'])\n",
    "test_data = test_cow_dataset.drop('problematic', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c528233d-dc85-4217-876a-fe7e70c285be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__periodicity is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py:472: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.9777777777777779\n",
      "Best estimator parameters:  {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.933 with: {'kernel': 1**2 * RBF(length_scale=1)}\n",
      "Accuracy 0.978 with: {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.933 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      "Accuracy 0.933 with: {'kernel': 1**2 * RationalQuadratic(alpha=1, length_scale=1)}\n",
      "Accuracy 0.933 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=1)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=3)}\n",
      "Accuracy 0.901 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "45 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 14-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 7-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 25-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 10-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 15-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 6-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 21-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 26-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 20-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 9-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 32-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 8-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 33-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 17-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 23-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 12-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 11-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 13-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 24-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 29-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 22-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 719, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 31-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.93333333 0.97777778 0.93333333 0.93333333 0.93333333        nan\n",
      "        nan 0.90055556]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#%%capture --no-stderr\n",
    "#%%capture --no-display\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_labels, test_labels\n",
    "\n",
    "model = GaussianProcessClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=5)\n",
    "# exhausive search over different kernels\n",
    "search = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# fit model into the dataset\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", result.best_score_)\n",
    "print(\"Best estimator parameters: \", result.best_params_)\n",
    "\n",
    "means = result.cv_results_['mean_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"Accuracy %.3f with: %r\" % (mean, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8b4a4de1-86d4-4489-be2f-6ccec8061d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 1**2 * DotProduct(sigma_0=1)}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "6de6e667-a6a3-4067-a2a8-8baaf1763601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              3\n",
       "1              2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "abddfa0d-f554-4c49-a721-704861548ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problematic\n",
       "0              41\n",
       "1               3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "78291d70-c611-4ff8-a397-e4afb82711be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training data:  1.0\n",
      "Prediction on test data:  [1 0 1 0 0]\n",
      "True values of test data:  [1, 0, 1, 0, 0]\n",
      "Prediction accuracy on test data:  1.0\n"
     ]
    }
   ],
   "source": [
    "best_kernel = 1**2 * DotProduct(sigma_0=1)\n",
    "#best_kernel = 1**2 * RationalQuadratic(alpha=1, length_scale=1)\n",
    "#best_kernel = 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)\n",
    "# best_kernel = 1**2 * Matern(length_scale=1, nu=1.5)\n",
    "#best_kernel = 1**2 * RBF(length_scale=1)\n",
    "model = GaussianProcessClassifier(kernel=best_kernel, random_state=30, n_jobs=-1)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model.score(X_train, y_train))\n",
    "\n",
    "# My guess is to look at what we have in X_test dataset and see if I can reduce the number of days.\n",
    "# The challenge is how do we ensure that the number of days we have found for correct prediction will always \n",
    "# be the correct one? \n",
    "\n",
    "print(\"Prediction on test data: \", model.predict(X_test))\n",
    "print(\"True values of test data: \", y_test['problematic'].tolist())\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"Prediction accuracy on test data: \", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "1ab5b6fe-3c2e-43fc-88af-5af744ba93ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34450248, 0.65549752],\n",
       "       [0.86213633, 0.13786367],\n",
       "       [0.34450248, 0.65549752],\n",
       "       [0.8106942 , 0.1893058 ],\n",
       "       [0.87550301, 0.12449699]])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_list = model.predict_proba(X_test)\n",
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ae0a5d15-268c-4a11-9d9f-faa6c891a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n",
      "findfont: Font family 'Calibri' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzQAAAHSCAYAAAA68I7BAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABdWUlEQVR4nO3dd3wc9YH+8WdmtkiyLNlyBeOKjXHFxo1eAgRCCWkkISEXkkvhLiEEuCQHITkgCRDSO8klvyQXQgq9h2qMwdjGGPcOtmVcJduy+paZ+f0x2rVkSbbKSvsd/Hm/XnkFa3d2H412d+bZ+c53rD17qn0BAAAAQAjZ+Q4AAAAAAF1FoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoTFY0ZXnq+jK82WvWZaX5d/NrIpd2fVjVezKdxwAQCdV1Ln6xAN79YkH9qqizs13HAB5FMl3gHyKPvBnRR/8S6uf+9Go/L6l8kaNk3vGeXJPOVuyrDwkRFdEH/izJCl99oXyBw3Nc5r22etXyXntJTnrVsraVynV10oFhfIHDJY7boLcU86WN2k6r71DWBW7FJn3jCQp9ZFP5zlNS5GnHpRVX6v0zNPljxqb7zgdZq9ZJmfNcnmDhso9+8J8x3lXe2B1vR5a2yBJijvSjy/qr/6FbX+3WFHn6rqnqyRJt5xVoomDo70V86izp87Vy1sSWr0npd11rmqTviK2VFpga3S/iE4+NqZZx8YUj/B5fKgHVtdLks4eFdegPk6e0xz0+vaktlalNbJfRLOGxfIdp8Mq6lzN25KQJH1kUlGe04THUV1omvNL+x/8R32d7H2VsvdVKrL0NbkvP6vEDbdK0fC8IY5mmZLqTjyp/ULjROQdOzz7372qap/iv7lbzool2R/5li0V9ZEaG2SXvy27/G1FX3hS3qixSlz3LflDh/VuRoNZFbuyf2PjCs3TD8mu3B0UgxAVGmfNckUf/IvcCVMpNL0o4UoPrqnX52YU5zvKUSvt+bpvRb2ee6tRrn/w50VRS67na3etp921SS18J6l+BZY+P6NY049hX6C5TEGfOChqVKF5Y0dSL29N6KyR8ZAVGi+7Tik0HUehadJwz/0H/+F5sraXK/aX38hZ+YacZYsV/ecflfrkF/MXEDnllw1U44/+2OvPa+3Zqfht18veVynfiSh97vvknn2hvDHjJNuRfF/Wnp1y3lykyNMPyt6ySfa2LXIpNMC70rwtCV1yQqGO6WvOjuDRIu35umt+tdZUpCVJJw2J6qJxBTpxYDR7JKY64WnV7pSef7tR6yrTWrk7RaEBDMQ5NG2xbfnDRynxX9+R17QjGXnhSclljC66IZVU/Me3BmWmsEiJm7+v1L9fJ2/siUGZkSTLkj/kWKUv+qAaf/xnpT78KcnmbQq82wwotDWi1JHrS/9YVZ/vOEelPy+ry5aZq6YW6RtnluikoS2HlZXEbZ02Iq5vn1Oqr55SrD4xhpwBJuIIzeHEYnLnnCX70b/JaqiXtaNc/vDRsip2qfArV0mSGn5+r+R5ij72d9krl8rav1d+vzI1/uKvBx+nvlaRpx9WZMmrsnbvkNJp+QMGyZ08XelLPyp/yLFHzlK1T9GH/yrnzUWyqvZKRcVyJ09X6oNXyR82osu/or1mmSLPPyl7wypZ1VVSJCrv2OFyZ5+l9HvfLxUUtl4tv7lbkZefVfqs9yr5H1+XM+8ZRV54QvY7WyXbkTd6rFIf+pS8CVODBVxXkeceU+TlZ2Xt2i5J8sZPVvKjn5E/elybuazNG+UsXShn1VJZlbtlHdgvRWNBtllnKP3ey1tly+TKKPjOf7W43Rs4JPt3OfRv2ObQNM+Ts+hlOQtelP3Welk11VJhkfyBg+VOOVnpM86XP3x0h9azJEVe+pfsrW9JkpKfuVbexJMOv4DjBEOqPK/1bcmkIs8/LmfhPNk7yqVkQn5pf3kTpip18Udan7/huSr8/Idk1dep8WvflXfyKS2f6tUXFf/lHZKk1CVXKHXVIUcj9+9V0X9+TJLU8NP/a/GatbaXK/rUA7LXLA/OBfJ9+X1L5ZcNkDdputJnXtCt12hzBdd+Unbl7uy/i648v8XtmddkC8mkIi8+KWfRfNnvbJEa6qXivnLHTVD6vEvlTZvd9pMlE4o8+6icxfNl79gmNTZIRcXyS0rljRkvd8apcuecJan1+Xjxe34g3fODFg9X/7fnO/6L1tYo+vSDcpYuDD4zkkmpuK/8kn5yT5gk95Sz5E0+uc1Frc0bFX3mEdlrV8iq2pctye7Jpyj1vg9LJaUH79vsfSBJztoVrdZp4pqvMQytB1iW9LHJRfrBqzVavD2pTftSGlvW+XNkPN/Xy1sSeqU8ofIDrhrTvvrGLI0bENV7jy9o97yb77x0QGsr0/rQhEJ9YEKhntnUqAXbEtpd66k+5WfP2fnKU/tVWe/pizP76JTj4np8fYMWvpNUZb2roqilyYOj+sikIg1uGmpUnfD05PoGvb4jqb31noqilqYfE9PHJheptKD1lzNpz9faipSW7kxpw96U9jd4qkn46hOzNLJfRGePjOvU4TFZOT6X8J3qtF58OzhP4ZxRcV18Qutt3aFmHxfXTN9v87bF2xOatzmht/anVZcM8h/fP6JzRsc1a1i81f1/8Eq13tyV0iXjCvTJk/q0uG1/g6cvPblfkjS6v6Pvndev1fI3/mu/dtZ6+sKMPjpndEH257VJT09vbNSbO5PaXesp6foqjlkqKbB1woCI5gyLa/KQ3JyLdc/rtXp5ayL77+++XN3i9oFFtn5+cf9DF9Pr25N6eWuj3tqXVk3CVzxiaUSpo9OGx3XO6Lgidtt/64XbEpq3JaHNVcE6jkcs9Y1bGtbX0dQhMZ0zOq6YY2nNnlSLLC9vTbTIKXXunDTX8/XSloQWlCe0rdpVQ8pXYdRS36bX6NQh0RZ/g+aqGj09vbFBy3elVFHnKe356ldoa9KgqC4+oUDHlbTcDc+83zI+8cDeFrefNTKua2YxRLUtFJoj8MsGZv/baqjXoR9l9obViv3+p7IaG+THCySn5bABa9sWxe+6Sfa+iuDxojEpEpG9a7vsXdsVmfeMkl+6Kbtj1BZrzy4V/uIOWVX75MfikhORdWC/Iq++KGfxK0rccGv7O2XtcV3F/vBTReY+ffB3LSiUEo1y3lov5631isz7lxL/fZf8QUPafZhMifAdR4rFZdXVyFn1puy1K5S44TZ5U05W/IffkrPiDfmRqOQ4shKNcpYtVsHaFWr89o/ljzmh1eMW3vwfB3NZtlRUJKuuVs6mdXI2rVPk5efU+K0fSs3OffKL+sgv7R+UH0l+n75S5OBL3G+2I3dE1QcU/8ltctataPH4qq+TvXmj7M0bZe3YpuSNt3f4ISPPPCpJ8oYOk3vG+Ue4dzOHHKGx9lUqftd/y962JcjlRKR4XHblHtnzn5fzyotK/dt/KH3RB5s9hiP3xKmKLH1Nzuo3Wxea1W+2+O/UIRGc1cuC7AMHtygz9oo3FP/hLbJSqYNZCgqC1/u+Cjmb1kmRSM7OdfFLSuU31Muqqwn+XdpyY+kXtdwxsHa+o/jd35TdVKR9y5IKi4L3z5IFiixZoNT5lyn179e1fKKGehXcdn22gPqWFZzjVF8ru+aA7O3lsteuyL5v/YLCIEv1AVm+J7+wSIq13onpCGtvheK3Xie7ck/TczedX1VzQPaB/bK3bZa9o1yJNgpN9P4/K/LwvbKadrr8eIHkutnzspyXnlHi6989+EWCbQe5GxtkJRqDv19x35YPGmN4TU+ZfkxMEwZGtLYyrb+vrNctZ3fiM0pSfcrTjxfUZI8y2JZUELFU1ehr8fakFm9P6pITCvTJqX3afYyU5+u786q1YW9aTtPybT+Xr/+Ze0DlB1xF7aCQVTX6eqU8qVV7Urrt3FJ5vnTH/GpV1HmKO5Iv6UAi2BlcV5nSd88rVVG05efZhsq07pxfk/131JaijlSd8LVyd0ord6f0+o6Yrp1TLDuHpea5txrlS7IkfXDCkctMxqEZ0p6vXy+u1cJ3klLT4xVFLdUkfL25K6U3d6V02vCkrplV3GJHfeLgqN7cldLqikM/bdXiZ1v2u6pLeuoTO7je9jd42lnrZR8nY2+9q9teqs7uEGezJH0dSLjadsDVjmpXk4d07nXWnsKopdK4pQOJ4POmT9RSpNmftyTecl01pn39YlGN3tx58PcrjFhqSPlaV5nWusq05m9N6Gtn9FVxrOXr5HdLavXSloOlpCCipnOcgvOclu5MafoxwTk8EVsqjVuqT/lKecFrqijaMkukgwMfPN/X3a/UaOWeg5mLopYSaV+1SV87m86vaqvQLN2R1C8X16gxeHvKsYLnrajz9FJd8CXE52YU66yRB7cVJXFLDSlLdalgnZYesg4LoxwhbA+F5gisioPfBvt9+ra6Pfb7n8o7bqRSV18r7/jxwTI73wlubKhX/Ie3yN5XIa9soJKfu17eSbMk25a19S3F/vBTORvXKvarO9U4dJj8kce3mSH2l9/IL+qjxE3flzflZMmyZG9ap9jvfiR722bFf/5dNf7gD/IHDOrw7xW997eKzH1afml/pT78KaVPPUcqLpHSadkbVin2l3tkb9mk+E9uVeN3f9XmsCfnjQVSKqXE574q98wLgkKzY5tiv7xTzuYNiv3pl3Knz5H99gYlrvuW3JmnB4Vm80bFf/5d2bt3KPZ/v1Li1p+1emx38slKn/4eeZOny+8/MCiKyYSc5a8r+vc/yN6+VbE//EzJG27NLpP69JeU+vSXst8wJ274H3kTp3V4nRx8clfxH39bzvrV8qNRpT5ytdLnXCiV9JM8V9beCtkrlshu9to4oqp9srdvDR5+5mldn7nMcxX7ya2yt22RX9RHyc98Re4pZ0mRqKzdOxT7v1/LWbpQsT//St7QYS2KrjfpJGnpa3JWL2tVWOw1yyVJfmGRrK1vS7XVweuhidM09feh6zP2x5/LSqXkTp2h5FXXHDxilUzK2r1dzqL58gcO7trv2obE934te82y7NG3Fue+HaquVvE7/1t2xS65k6Yr9ZF/C96j0Vhw1PSlfyl6/58Vff5x+ccOV/p9H8ouGnn6Idlb35Jf3FfJz98gd/qcYDnPk1W1T/bqN+WsW5m9f/rSjyp96UdVcO0nZVXuVvLTX+ryUY3og/8nu3KPvEFDlfzCDcGRPNtpeu1Vylm2WFZl66nGI089qOhDf5FfWKTk5VcqffaFUr+yYLktbyl23//KWf2m4j/8thp/9P+yM+o13HN/9giTd8JEJb794y7lRtdcOaVI354bnMexfFdSJw3teIH83ZJgyFTElj45tUjnjCpQPGKpqtHTP1fV66UtCT25oVFD+jg6//i2v0F+7q1GSdIXZ/bRqcODb7hrEl6rj6gH1zSoT9TSTWf21aSmnejVe1L65aJaVTX6+tvKelXUBUdkbju3ROMGRJX2fC3ZntRvl9RqV62nJ9Y36qOTW57kHHOk04bHdPqIuMb0j6gkbsmyLNUmPb2yNaH7Vzdo0TtJjR/QqIvGdbx4HMmqph3U0f2dbp3I/o+V9Vr4TlKWpA9MKNTF4wrUJ2arNunpyQ2NenRdgxZsS2pAUb2unHKwWE4aFKzDrVWuapNeix34NU3ZCiOWGtK+1lSkW5zUvrrp9oFFdvbImBT8jSrrPQ0qsvX5GcWaODgi27Lk+b721nvBUYL63A2d//S0Pvr0tD7ZowjXn9r3sEc9fr04KDNDim1dMbFI04+JqTBqKekG5fUvy+u0cV9av1tSqxtOO7j9WVeZ0ktbErIkfXxKkc4dHc+ur5qEp83701qwLZktjCcMjOo3l5VljyCdOrzrRzUWlCe1ck9KUVu6enrwHimIWPJ9X9UJXxv2pvRqebLVcpv2pfTThTVKe9J5Y+K6aGyhjulry7YsVda7enx9g557K6H/XVKr4/o6GlMW7I5/97x+LY4w/eaysi7lPhoxOP9w6uvkvPqCJMkv7iv/mONa3cUvLlHimz/IlhlJ2ftFnntM9p5d8p2IEv99p7zpc7LFwB95fFBQBg2VlUop9o//136OZDJYfuqM7I6wN/ZENX7zbvnFfWU11Cvy6N86/GtZ2zYr8szD8uMFarz5+0pf8P6DO6+RiLyJ09T47R/LKxske/NGOW+81vbj1NUGO3vnXZr9Nto/driS190i37JkV+xS9NlHlbjx9mDq60gkGP4y5gQlP3e9JMlZv1rW3opWj5345t1yz7lI/sAhB496xeJyZ52hxDd/ID8albPkVVmVnSgVHeS8/GxQZixLietvVfr9HwvKjCTZjvxBQ+Wed6lSH//3Dj+m/c6W7H973Zj9yln0cnDUQ1LiK7fIPeM8KRJsQPwhxypxw21yx54oSYrd97sWy7qTpkuSrPK3pZoD2Z9be/fI3r1DXtOwJMv35DQVnGz+piM4bvNCc2B/9shH4pqvtxx+F4vJHz5a6Y/8m9xzLury79sd0Uf+mi0ziZvuknfilIMzFRYVK33xR5T8z28E9334ry3OkXM2rpEUDL9zZ595cDnbll82UO6ZFyj5+Rt6JLe9YXXw3B/7bDCsLHN+le3IHzRE6QsuU+rKz7dcqPqAov/8Y/CaveFWpS+/MigzmeXGnKDETXfJHX2C7H0Virz4VI9kR+eNHRDVrGOD19ffV9XLb2dI06E27Utp8fZgR+rT0/rowrGF2XM/+hXY+sLMYs1u2gm+f3W9km7bj9uYlr40u6/OHlWgmBMs3zdut/qGPO35uumsEk0ZEpNtWbItS1OGxHTllKCgZIah3XxmUGYkKWJbOmX4weFcr21rOewn8/t/eU5fTT8mptICOzu0rDhm66JxhfrCzKAEPLOpsUPrpSNcz9eumuAoxsh+Xf9ed1+Dq3815bpsfKGumFSUPZJSHLP1sclFunhcUCSf2tCo/Q0HhxKN7OeoOGbJl7TmkKM0mSM072tatr3bJw5qWR427g0OBXxscpEmD4lmjybZlqVBTaW2eanqTW/uTGrJjpT6FVj61tklOm1EPHu0IeZYmnFsTN86u0RxR1qyI6UtVensspnfa/KQqC4bX9jitdk3bmvq0JiumVXc7vTn3bFhb7CuzxwZ17mjC7JHMC3LUmmBrVnD4vrqqa2/7P7Tm3VKe8HRv38/uVjDSpzs32NgkaPPTC/WhWML5PrSw+s4hy4XKDRtqauVvWqp4t/9muz9wTcPqYs+1OZRivSFrc/lyIi89pIkyZ1zZtvnWhQWKX3ZRyVJ9rLXg+uQtMGdc5b8YSNb31DaX+nzL2vxXB0Rmfu0LN+XO222/BFj2r5TYVFwJEGSveL1Nu/iDRws9/T3tPq5P+TY7LAk98QpwY7koctOnCo/GnwYW+Vvdzi7FAwD9EYcL8v3ZW9Y06llOyLy0r+CjNNmByU0B6yag+N52zrS11HOa/MkSe64icHRvlZ3cJT68L9JkuxtW1qsW3/EGPnFJbJ8v0VhsVctkyR5k6ZlS4/dNMRMCo5S2nt2Nd2n2Xk/hUXBcCgpOFfDJL6f/TumLvlIq6GgGe7M04OjUjUHZG/ecHDxpqFr+fi9/KLiTj935NUXZCUa5Y05od1za+Q4ck87N/jPZlOGI/8+OrlIthV8W79gW+tve9vyWtP9ygptnTu67eGNV0wKtk01yeAb8LYcV+JoxrFHPio0e1hMQ4tbv4+mDj24U/2eMQXqG2+9nZzadM7G7jpPjemOFbaMzIxiu+u8FoWgO2qTfnb4eHE3TvJf/E5Srh8MaXr/iW0fAfvAhEJFbcn1g/NsMizL0oSBB490ZVTUuaqo8zS02NaZTUORmt8uHTyCc+jRkMywqv2NuVlPuTR3c1D8zhgRV1lh25/HA4qc7O+0YlfLIV5ScDTG62Dhz5XMEMkDnVinW6vSenu/K8eSLjmh7deFpOzfd9XuVK//Xu9GDDlrcuiJsM2lzzhf6Q9+os3bvBMmt7NQKrsz6ba3gyHJnTJDkmT5nuzNm+RNmtb6Pm38rPlt0Ufuk1VbLWvPTvmDj2n3vhn2+lWSJGf56yq85or279gYzIOeGct/KG/MCe0OnfJL+0m7tssbM77N22U78vuWytpXKauujSLneXJemytnwUuyt26SVX1AVqr1ht7a1/roTre4ruy31gf/efKpOXzgZh9W3RgHbr8dZPOmtP+a8iZOk2/bsjxP9tsb5GZKq2XJnXiSIovny171Zvb8j8z5M+6k6dkjjc3Po8kcnfEGHxMcMcuIxeVNni5n5RsquOsmpc+/VO70OcERqEh+LwBovbNVVm0wLj9+zw8Ov84bgw2tVbFbGjtBkuSefIoiC+Yq8uyjsqoPyD31HLnjJ7c4ob6nuCefImfjGkX/9nvZO8qVnnWGvBMmBefRtCPznra3bTn8ezoZ7FD1xJFNdN2wEkdnj4pr7uaE7l9drznHxdo9MTpj8/7gW+uJgyLtnlsyrCSiskJb+xqCYTltFZcTBnRsN+D4srbvV9qswIzp3859mk0GUJ/yVBBpuUPbkPL1/NvBiew7alzVJX21dUBpf4OX82/hu3NGwttNf4PjyyKtzg3KKI7ZGt0/og17g53c5iYOjuj1HUmt2XPwaETm6MukwVENKXY0sMjWO9WuDjR6Ki2wg8LTdI7MpEEt1/f0Y6LauC84H2tHjavZw2IaN6D9bL1pfWXwO764OaH5W1sfqcuobzp3pLLZ0LjJg6OK2tKWKle3za3WOaPjmjQ42mK4XU+ZdkxUj69v0Bs7U/r+/GqdOTKuCYOih30dZn5XX9KN/6pq935e02s84Uo1CV+lBZwf0x0UmibNTy72o1Gpb6m8UWOVPv28NkvGweX6tX1DbY2sptmpmk8s0Gr5soPnvVjV+9u5z2GW799s0oLqqg4VGqvpqJPV2JAtLYeVaOdQf8FhLviUGSZTeJgxz5n7uOmWP080Kn73LdnzNiTJj0TlF/c9eBHM2hpZbjq7M5ozNdXB4yo4ApUrft9mM0vVVh/mnodnVVcFj9e//deEYjGpb6l0YH/2/hnepGnS4vly1hw8j8ZuWs/uxGlSv/7yBg2Vvb1cqton9Ss7eP5MG++D5BduUPyH35a99S1FH7pX0YfulR+Jyjv+BLkzTlP63Pe1OBent2Re45JarYN2JQ9uZN3Tz1Nq03pFnnlEkdfmKvLaXElNEzpMmaH0ORe1OZlFLqQv/ajsrW8psnCeIi8+pciLT8m3LPnHjZR70iyl33NJq+Gv2fd0MtHi92hXogP3Qa/68MRCvVqe0J46Ty+83agLxx7+fJEDiWD7UnaEHfxMocnc/1AlbRxRaUt7kwU4zYpXYXv3afZj95AYO2tcfe/lau1rdvQl7kh9Ila2bGROOk+0M2yus4pjwWP7Co5edVV1U64jlazM36j6kG/5M+fRbK9xVdXoqV+BnT36krlt4qCoXt6a0OqKlE4bHs8erRnSx9aAopY79JeOL1T5AVcL30lq7uaE5m4Ozjs5rsTR1KFRvWd0QV6ud5T2/Ox6zhSWI0k2635Dih19fmax/t/SWm3cl9bGfcE2uiRuaeKgqE4bEdeMY6I5nwlPkk4cGNXHpxTp/tX1Wr47peVNRzrLCm1NHhzVmSPj2XPKMjJHyDz/4Gv3SNobEoqOo9A0OezJxYfTkWuEHO5NZrX7j44t3wWZopW88nNKv//jOX3sXIg+cp+cNcvkx+JKfeyzcmefIX/A4BbrIX7rV+WsXyWr1bxzOZTD9e4dNyr73/aWTXJPP69bj+d3OFrLO2bOgbF3bAumWE4mZO+tCPL1C0q9N/Ek2fN2yVn9ptzTz5O9Ohie1taRQn/gEDXe8RvZTRegtdevll3+lpz1q+WsX63oo39X4qvfljd5etd+0a7yDm4N639zf/Z364zUp/9T6Qsvl7Nwnpz1q2RvXJOdnTD63GNKXfQhpT79n7lMHYhElLzuW0p94BOKLH5F9vpVsjetlb1ti+xtWxR56kGlrvy80pc2OxLT9Pumzr9UqX//au4zoceVFTq68PgCPb6hUQ+vbdDZo9ofqtJSxz4M2rvXEQ4E9bjfLqnVvobgRPZPTC3SpMHRFudIeL6vqx4Mhl/malSOY1sa2tfWzhpPW6vSR17gCLr4cazjSiPZWcJW70np9BFxralIy9LB4WQTBzcVmj1Nhaai7eFmUnDO0ldO6avLq9J6fXtS6ytT2rQvrW3VrrZVu3p6Y6OunFKkSzowRXUuec3+btfOKdapwzs/A+QZI+KaNjSqRe8ktXpPShv3prW3wdPCd4JZxk4cGNF/nd63R45GXTa+UGeMiGvhOwmtrUhpw9609jV42emgZw+L6ctzDs5ilxk+dmxfRz+8sF/O86BtFJqeUtw3O+ynrZPeM5rf5mdOPD/MfVrdtr/yiMsfyu9XJuvAftnlmzt0/97mLAi+DU996CqlL/5wm/fJTM2cc31L5DsRWW5adsVu5Wwkcr8yecNGyt6+Vc6SBUp94gtdKkx+Sb9glrW9FWp3rppkMpilTK2nqvaPGxn8/av2BefJJIMjXM3LijtpmiLznpGzepm8MeOzU457E9q5bo5tyztp1sFzehrq5Sx9LZiNrnKP4r+8Qw2/vK9Xh6H5mRPiJdnb3pbXb0bXHmfoMKU/8AmlJcnzZL+1TpHH/qHIklcV/ddDwXlHTeea5Zo/8nilMjMfuq7stcsVffBeOetWKHrf7+ROOTk7M2Lm97W3mfmeRse8/8RCvbg5oeqEryc3NLSYzvVQpfFgh3xfw+Fnrcoc+ejokZjetLfe1YamE76/PKc4O5lAc1U9dD7I5MFR7axJaEuVq4o6t0sznWWmJd5bf/iMh/sbTBgU1cKmnfQx/SPa1+BpeKmTvW9mWFnmyM2hR3DaMrJfJDvZgev5WluR1kNr67WuMq37VtRr8uBotyZD6KyYY6koGkyjvO2Aq1OHd+1ximO2zhtToPPGBGV/d62ruZsb9fj6Rq2rTOvBNQ361Ek9M+lB/0Jb7xtXqPc1zbRXfiCtZzY1au7mhBZvT+r5tw7OwtevaYjlnrrgulDtHd1Ebpn3CfduEYlmT7h3Vi1t927OyuA237LljW579qtDZ5xqcVvTydt+cd8ODTeTJPeEScGyyxZ1bMhZL8sUuPZmA7MqdmVn12qLnykKXfk2z3HkjW06j2Rp27O7dVX6ve+XJNm7tst5pRMXWWx2Yc3MOUn2qjfbu7fsNctkNc3Y1Xz2vQy3qZg4q9+U03T0xZt08AiKl50Y4M2D1585dvhhhz62UFgk9/TzlPzCjZKC8mnlsjxbzT622vnK1h8+OrgWjDo3YcZh2ba8cROVvP7b2eGI9so3DrlP5rWX4yOHjiNv8slKfON78qPRYGKHlQc/V7ym97S9cW2LqeY7KjO5Q08e8MSR9YnZev+JwU7RUxsa2x0mJkmjm85XWVORbveE4u3VbnZnur3zW/KpeREY1c4O9qp2JjPorgvGFMhScPTg4bUd3w42X9eZdfr2/rTqU23/reqSXvZ8pzH9W5em7BTYFansbGbNy8qAIkdDim3trvO0cndS+xuD559wmELTnGNbmjwkqq+fUaKoHbzFV+3J7TrN7K4f7uMjc67WoncSOTsBfkixo49P6aPTRgTnhh36WunOrsCRjCiN6PMzirO/V/Pr1JzQVMzTnrRke8cm+Wiu+XedHZ31EBSaHpU+tWlGoUXzZbX1zWljgyJP/EOS5E2fLRW1PU+6s2ierB3bWt9QfUCRF54MnuuUczqe6z0Xy7csWXW1iv71t0e4c7r3S0/Tyc/21rZnP4v+7feHX75pR9ZqZ9a4I0mf877g+Zctlv3moi49RpuPe+775DXNdhf74y9kr11x+AU8V5EH/yKnWQb31HMkBdMK223NVOW6ij50b7D48FFtzq6XORpjr14mZ+1y+ZYtd8LU7O1+2UB5Q4fJ3rNLzrxgpjB3YhtHZ9JH2Cg2v7BkR4ZmdlCmqEiS2ppQQpIcR+mm6aKdl5+V3eyaMW069LymNiagyLKdg0eb7EN2UAqbZkfr4mvviM8diTabxvngOk2feYH8WFyW5yn2x5+3GHLXiue1Xm/dfM8gdy4cW6CyQlsNaV+PHGZH+9ThwU7cvgZPcze3fU7UA2uC6WD7xqycXR0+l5pf7HDrgdZDvxpSvh5e1zPbn+NKI9nZ4V7aktDTG4/8PK9vT7b4m8w+LibHklKe9Ni6ts/nfHRdg1JecB7R7GGtj7hlpl6uqPM0r+nCkYeek5G5z/2rg+c+tq/T5nk7qcOchxGxD37fkuthhpnpl9srdVIwA54k7Wy6HtHhNKZ9pZuNUzvc7yUpO934ob9X5pyu+mTXj/J15bnH9Hc0ql/wOf3P1fWqPswXE5JUe0i+5hfPrOvgOUeg0PSo9AWXyRs8VJabVvyum2UvW5z9tt0qfzu46N+eXfIjUSU/+pn2HygaU/yum4Jvg5vauv3WOhXc8XVZNQfkFxYpfXnHz4XxR43NXkQw+vwTiv30dllbNh38VtlzZW19S5GH7lXBVz8le8umrq2ALnKbhi5FH/mrnMXzs9cHsfbsVOwX35OzcN5hpz72ho+SJDmvvND+hAaHe/4zL5A7frIs31f8J7cp8vg/pOqm67Z4rqyKXYo89YCi9/1v5x44GlPixtvk9Rsgq6Fe8e99XdH/93PZb61rsQNqVexS5NlHVXDjZxV74M8tjtC4c87MXmcm/rPvBNdJSgc7AtaenYr95NbsNVSSn/hCmzEyJ/fblbtlVe0LjoQdcnX4zPTNmWvetHWBUnvDahV8/fOKPPWArO1bD+b0fdkbViv2h+CCqV7ZIPkjWhar2G/uVtGV5x92dsH2+MccJ7+pUETmPtXu0ZDUh66SN+RYWa6r+F03KfLkA1LzCQLqa2UvW6zYr7+vgluvb7FswbeuVfRPvwwmTGhW6K19lYr+8RfZI4Tu9NktlsucK+Usmi/V1qgrCq/9ZDDD2cY1LcqNtWu7Yr+8Q1aiMSihJ808uFC/MqWu/Fzw3G8uUvx73whmPsu8rnxf1vZyRZ58QAVf/5ycpQtb5m56z1jvbMleBwf5EXMsfXhicJRm6c72vzQYWxbNXmfmz8vq9MymBiWapkSuavT0v2/UalHT1euvmFSU3fEyybCSYBYvKbhIaGbWMCm4/sd35h1QXTdO2j+ST0/roxMHBt+w/2V5vb7/SrWW70q2OEG7Nulp4TsJfXfeAf3ktRrVNstTVujoorHBjvrj6xv0wOp61TXtnNYlg4ubPrEh2AZdfEJBmyXkmL5OdtKATfvSsi1pwiGzl2UKzqZ9B2e2a8tXntqvv6+s08a9qRY74rtqXf1qca0SbnA0Zeoh5XbelkZ94oG9+sQDe7ND2jrjuJJg5/3V8mT2NXiomcfGWlxv6Q9La7Wz5uB2L+352rQ3pb+tqNNXntrfYprkPy2r088W1mjxO4kWP29M+3r+rcbsrGmHXpR2eGmQa11lWturu3ZB0R8vqNFvl9Rq2c5k9m8rBa+Lh9fWZydpmNbsuS3L0mdP7qOoLVXWe/rWiwe06J1Ei3Wzr8HVK1sTuuPlav1tZcvr0BxT7CjS9FKZuznBUZoOMu8Y9LtJYZES//WdoIzsq1DB92+WH41JkYishuAF7EejSn7ppuxY+LYkr7pGsX/+UQV3fEN+vECyrGCGsqblE1++ueV0uh2Q+uQXJN9X9OmHFFn0siKLXg6yxQukhrrskCVJOZ+U4IjZPvoZOSvfkHVgv+I/uU2+40jxAln1dZKk5Mc+K2fFEjntHOFIn3eZnPWrFVk8X84brwUz0dmO/AEDlbj1Z0cO4DhK3HCb4j+5Vc66lYrd97/BUaGiPlJjY3YWtHQXzp3whxyrxPd+pdhvvi9n1ZuKPveYos89Fgz56dP0+M2OfLhjT5TXvAzYjpLX3xqU4Xe2KP7LO+Xf80MpHs9Of+1btlL/9h/yps0+9OmD24cOkzdgkOzM0L42Tvb3Jp0kvfDEwRxtHaFRcM5G7C/3SH+5R74TCb7pb/b68QuLlLz25tZHMrojXiD3zPMVmft08Ld58C/y+5ZIsuTOOUupq74Y3K+4RImbv6/4j2+VvfUtxe69R7F775Hfp1jyvOx7UApmL2uhrlbRZx5R9JlHgiGMRX2kdFpWs4KcuvjD8qbObLFY+rxL5Cx4Uc6G1Sr84ofll/QPLigrqfEXf+3Qr2cd2K/oY39X9LG/B6+Loj5SMpGdtty3LKWu+mKra1OlL/qglEoq+vc/yFmzTM6tXw2KX0Gh1FCffd0GT9LyPe1NnCbv2OGyd2xTwf9cJ79P3+yRsNRVX8xO8Y3ecfaouJ7c0KgdNYffCfvCzD6qSXhaW5nWn5fV697l9SqIBOcqZHaBLjmhQOcf39EJBnqXZVm6elof/eS1Gr1T7eqWFw4o3vRRkXCD2c5uPK1Ed8zv+syQhxN1LN18Von+srxOL76d0PJdKS1vuv5JUdSS6/lKNPsTlBXaOmloyzLwsSlF2ZPTH1rboIfXNmTPF8n8DU4bHtMVk9qfFXTioIheabra/Kh+TqsT2w89X6atCQGkYEatx9Y36rH1jbKafoek6ytz4MSSdNVJRRpWkttdv/PHFGjD3lot3p7UGzv2qbTAlm0F6+vWcw+ex/mfs4v1uzdq9dq2pF54O6EX3k4o7gSTGTRfX1LLjyjXkxa9k8wW9IJIcLHQ5jOmjR8Q0QcmtJzsYNawmP6xql7VCV9fe7ZKfWNW9uKz17Zzztahkq6veVsS2aNnmaM+Dc3KyexhsVbXghpbFtV/nd5Xv1hUq4o6Tz9bWCvbCv4mKbfl6+rQZeMRS2eMiOulLQn9bWW9HlpTn72+05xhMX2yh84TCjsKTQ/zh49W4w9+r8hTDymy5FVZu3dI6VRwVfYpJyt96UezF6Fs9zGGHKOGO+9R9OG/ylm6UFbVPvkl/eROnq7Uh65q+6KbR2I7Sv3bfyp95gWKvPCEnLUrgnNXGuqkPn3lHjNM7uQZcmedftiy1RP8QUPU+L1fK/rg/8letjiYdjcak3vyFKUu/IC8qTMPe2FA98zzlZAUeeEJ2ds2y9q/T5bvde4E/5JSJb71IzkL5iry6guy394QDNPpUyx3wGB5U05W+swLuvb7lQ1U4ps/kL1upZzXXpKzbmVwPZ2GeileIG/YCLnjJsg99Vx5bRQJv2ygGr/3a0Wef0zOwnnBFMuJhLwBg+RNPEmpiz8iv53zjzK8idNkz39OUtuzl7kTpwXDEn0/OOrQbFrz7GOMGa/Edd+SvXqZ7LfWy9q/V1ZNlRSNyTvuWLlTZyp90QfbPPfG2hdMZpE52tRZyc9cK69skCKLX5a1Z1f2WklezYEW9/MHH6PG7/1azoIXFVk4T9bbG2XVHAjOhxk8VN7IsXJPPqXVNYeSX/mm7BVvyFm3QtaeXcEkFK4rb+AQeeMmKP2eS9qcuc2bMFWJr39P0ScfkL1lY3D+kN+54Q6NN31fzpplstevklW5JzsBhjd0mLzxk5V67+XtThmdvuxjcmedochzj8lZ9aasil3BBXsL+8gdeqy8idPkzjxd3rgJLRd0HCW++QNFH/iz7FVvytq/V3Zd0xEmA8+ze7ezLUsfm1yon7x2+CGARVFb3zy7RC9vSeiV8oS2VgUnIZcWWDphQFTvPb6g3Z1fU5x8bEzfOqdEj65t0Pq9aSVdX/0KbJ0yOLgq/LE9PM1wxLb0menFunhcoeZtSWhNRUq7a13VJn1FbGlIsa0x/SOaeWxMM4+NKXrIka7MzGKnbA+mSd68P626pK++cUuj+0f0ntFxzWpjqFlzEwdHs4Xm0OFmUnAdn2EljrZXu8EMaO2cP3PTmX21ek9aG/amVFnvZY9mDCm2deLAqC44vqDNc6kyFywtiEjHlXZ+fZ/RNHnFC283alu1q/0NXpvnrcQjlq6d01fnjU7ppS2N2rA3rapGL/uaHdbX0dShMc0aFmtx8c0PTijU6P6O1uxJZ6e4TqR9lcQtjSyN6NQRMZ01Mt7qekzFMVvfOrtUD62t1/rKtA40etnpo1MdPGDz6el9tHxXSmsrUtpV6+pAo6+k66t/gaUx/SM6c1S8zaGEkjRlSEw/uaifXng7oTd3JrW9xlV9ylfMCY5OjiuLaMaxMU1pYzjoZ6b30YAiW4vfSWpPnavKpvPNujPN+LudtWdPNWsHQO9Jp1T4uQ/KSjSq8Zt3t39lewBAj/vey9VavSelD5xYqI9OPsz15QCDcQ4NgF5lb1wrK9Eod9J0ygwA5FHK9bVxb0rFMUuXjjdzaCLQERQaAL3KbpoKOvXxz+Y3CAAc5TbtSyvpSpeeUNgjF6UEegtDzgAAAACEFnUcAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEViTfATIGDCiWZUme5+c7CgCgl9m2JYltAAAcjWzbku9Le/fWdm35HOfpMsvKd4L2ZTa0JjI1m6m5JHOzmZpLMjebqbkkc7OZmstkJq8zU7OZmksyN5upuSRzs5maSzI3m6m5pO51AWOO0HieL8exVV1dr3Tay3ecrEjEVv/+fYzLJZmbzdRckrnZTM0lmZvN1FySudlMzSVJAwcWy7Is47KZvM5MzWZqLsncbKbmkszNZmouydxspuaSpLKyPt1a3pgjNAAAAADQWRQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKEVyXcAAEcn27Zk21aXl3ccu8X/m8TUbKbmas60bCavM1OzmZpLMjebqbmknsvmeb48z8/pY+LoRaEB0Ots21JZv0JZjtPtxyopKcxBop5hajZTc7meb2w2U3NJ5mYzNZdkbjZTc0m5z+Z6vqr211FqkBMUGgC9zrYtWY6jxju+Lb98S77jwADxO38qp3+Z7ny+QuX7U/mOA6AHjegf1U3nD5JtWxQa5ASFBkDe+OVb5G1an+8YMEE6LUkq35/SpspknsMAAMLEvMGaAAAAANBBFBoAAAAAoUWhAQAAABBaFBoAAAAAoUWhAQAAABBaFBoAAAAAoUWhAQAAABBaFBoAAAAAoUWhAQAAABBaFBoAAAAAoUWhAQAAABBaFBoAAAAAoUWhAQAAABBaFBoAAAAAoUWhAQAAABBaFBoAAAAAoUWhAQAAABBaFBoAAAAAoUWhAQAAABBaka4s9PrrC/Xcc09r584disXimjBhkj74wSs0YMDAXOcDAAAAgHZ1+gjN3LnP6w9/uEfRaExXXHGlzjvvvVq7drXuvvu7qqra3xMZAQAAAKBNnTpCU1tbq0ceeUAjRozUDTf8txzHkSRNmjRFd911ux5//GF96lOf7ZGgAAAAAHCoTh2hWb58qRKJRp177gXZMiNJI0eO1tixJ+iNNxYrnU7nPCQAAAAAtKVThWbLlrclSWPGjG112/HHj1NjY6N27dqZm2QAAAAAcASdGnKWOUemf/+yVrf169dfkrR//z4dd9zwNpefOXNqu489f/48jRgxQo5j1sRrmTym5ZLMzWZqLsncbKbmknomm4m/JwCgd3VnW3C0bTdzwdRckmRZku93fflOFZpkMhksFGm9WDQabXGfriopKezW8j3F1FySudlMzSWZm83UXJLZ2QAA4ZOL7YrJ2yZTs5may3W9Li/bqUITi8UkSel0OvvfGalUssV92rJkyYp2bysr6yNJqq5u6NYvlGuOY6ukpNC4XJK52UzNJZmbzdRcUs9kyzwmAODo1Z3tytG23cwFU3NJUmlp9/YJOlVomg8rGzJkaIvbqqqqJLU9HK0zXNdTOm3WSpbMzSWZm83UXJK52UzNJZmdDQAQPrnYrpi8bTI1m4m5ujPcTOrkpACjRo2WJL399qZWt7311kbF4wUaOvSY7iUCAAAAgA7qVKE56aSTFYvFNHfuc3JdN/vzrVs3a9OmDZoxY1ab59cAAAAAQE/oVPsoLu6ryy//iO6//z79+Md3ac6c01RbW6MXXnhWffuW6LLLPtRTOQEAAACglU4fTjnvvPequLhYzz//jO6//z7FYjFNmDBJH/jAFerfv39PZAQAAACANnVpfNicOadpzpzTcp0FAAAAADrFvCvrAAAAAEAHUWgAAAAAhBaFBgAAAEBoUWgAAAAAhBaFBgAAAEBoUWgAAAAAhBaFBgAAAEBoUWgAAAAAhBaFBgAAAEBoUWgAAAAAhBaFBgAAAEBoUWgAAAAAhBaFBgAAAEBoUWgAAAAAhBaFBgAAAEBoUWgAAAAAhBaFBgAAAEBoUWgAAAAAhBaFBgAAAEBoUWgAAAAAhFYk3wEAHL2sEaP4VgWBSLA5GtE/mucgAHoa73PkGoUGQK/zPF++66rg5tvzHQUGcT1fN50/KN8xAPQC1/PleX6+Y+BdgkIDoNd5nq99VQ2ybavLj+E4tkpKClVd3SDX9XKYrvtMzWZqLknq169Ijm0Zl83kdWZqNlNzSeZmMzWX1HPZPAoNcohCAyAvcrUxc11P6bRZOwAZpmYzNZdkbjZTc0nmZjM1l2RuNlNzSWZnAxi+DgAAACC0KDQAAAAAQotCAwAAACC0KDQAAAAAQotCAwAAACC0KDQAAAAAQotCAwAAACC0KDQAAAAAQotCAwAAACC0KDQAAAAAQiuS7wDvdrZtybatHnlsx7Fb/L8pTM0lmZvN1FySudlMzSWZm83UXM2Zlq2768zzfHmen8tIAIBDUGh6kG1bKutXKMtxevR5SkoKe/Txu8rUXJK52UzNJZmbzdRckrnZTM3ler6x2bqay/V8Ve2vo9QAQA+i0PQg27ZkOY4a7/i2/PIt+Y4DAMaK3/lTOf3LdOfzFSrfn8p3nJwY0T+qm84fJNu2KDQA0IMoNL3AL98ib9P6fMcAAHOl05Kk8v0pbapM5jkMACBMzBqsDAAAAACdQKEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChFensAv/61xMqL9+i8vKtqqysUFnZAN1xx496IhsAAAAAHFanC80jjzygPn36aPjwUaqvr++JTAAAAADQIZ0uNN/5zt0aNGiwJOn227+pxsbGnIcCAAAAgI7o9Dk0mTIDAAAAAPnGpAAAAAAAQqvTQ866Y+bMqe3eNn/+PI0YMUKOY1bHyuTpSi7TfhcAQO/rqW1Bd7ZPPcnUXJK52UzNJZmbzdRckrnZTM0lSZYl+X7Xl+/VQtMRJSWF+Y7QJlNzAQDM1tPbD1O3T6bmkszNZmouydxspuaSzM1mai7X9bq8bK8WmiVLVrR7W1lZH0lSdXVDt36hXHMcWyUlhV3KlVkWAHD06qntWne2Tz3J1FySudlMzSWZm83UXJK52UzNJUmlpd3bXzbuCI3rekqnzVrJkrm5AABm6+nth6nbJ1NzSeZmMzWXZG42U3NJ5mYzMVd3hptJTAoAAAAAIMQoNAAAAABCq9NDzhYufFX79u2VJNXU1Mh103rqqcckSYWFRTr33PNzmxAAAAAA2tHpQvPqqy9r48b1LX722GMPSZLKygZQaAAAAAD0mk4XmhtvvKkncgAAAABAp3EODQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACK1IvgMcDawRo2iOAHA4kWBzNKJ/NM9Bcufd9LsAgMkoND3I83z5rquCm2/PdxQAMJ7r+brp/EH5jpFTrufL8/x8xwCAdzUKTQ/yPF/7qhpk21aPPL7j2CopKVR1dYNc1+uR5+gKU3NJ5mYzNZdkbjZTc0nmZjM1lyT161ckx7aMy9bddeZRaACgx1FoelhvbMxc11M6bc4OQIapuSRzs5maSzI3m6m5JHOzmZpLMjebqbkAAEwKAAAAACDEKDQAAAAAQotCAwAAACC0KDQAAAAAQotCAwAAACC0KDQAAAAAQotCAwAAACC0KDQAAAAAQotCAwAAACC0KDQAAAAAQiuS7wAAjk62bcm2rS4v7zh2i/83ianZTM3VnGnZTF5npmYzNZdkbjZTc0k9l83zfHmen9PHxNGLQgOg19m2pbJ+hbIcp9uPVVJSmINEPcPUbKbmcj3f2Gym5pLMzWZqLsncbKbmknKfzfV8Ve2vo9QgJyg0AHqdbVuyHEeNd3xbfvmWfMeBAeJ3/lRO/zLd+XyFyven8h0HQA8a0T+qm84fJNu2KDTICQoNgLzxy7fI27Q+3zFggnRaklS+P6VNlck8hwEAhIl5gzUBAAAAoIMoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQinbnz7t27tGjRAq1du0oVFRVKpVIaNGiQTj55ls4770LF4/GeygkAAAAArXSq0CxY8LJeeukFTZkyTbNmnapIxNH69ev02GMP6Y03Xtc3vvEtxWKxnsoKAAAAAC10qtCcfPIsXXjhJSoq6pP92VlnvUeDBw/R008/rgULXtY555yf85AAAAAA0JZOnUMzcuToFmUmY8aM2ZKk7dvfyU0qAAAAAOiAnEwKUFW1X5LUt29JLh4OAAAAADqkU0PO2uJ5np588lHZtqPZs0897H1nzpza7m3z58/TiBEj5DhmTbyWyWNaLsncbKbmkszNZmouqWeymfh7AgB6V3e2BUfbdjMXTM0lSZYl+X7Xl+92ofnHP+7V5s1v6f3v/5CGDj2muw+nkpLCbj9GTzA1l2RuNlNzSeZmMzWXZHY2AED45GK7YvK2ydRspuZyXa/Ly3ar0Dz66IOaN+9FnX76WXrf+y474v2XLFnR7m1lZcG5OdXVDd36hXLNcWyVlBQal0syN5upuSRzs5maS+qZbJnHBAAcvbqzXTnatpu5YGouSSot7d4+QZcLzeOPP6ynn35cp5xyuj75yatlWVa3gmS4rqd02qyVLJmbSzI3m6m5JHOzmZpLMjsbACB8crFdMXnbZGo2E3N1Z7iZ1MVJAZ544hE9+eSjmjPnVP3bv/27bNu8sXgAAAAA3v063USefPJRPfHEI5o9+1R9+tOfp8wAAAAAyJtODTl76aXn9fjjD6usbIAmTJik119f2OL2vn1LNHHi5JwGBAAAAID2dKrQbNmyWZK0b99e/fnPv291+7hx4yk0AAAAAHpNpwrN1Vd/Xldf/fmeygIAAAAAncIJMAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQoNAAAAABCi0IDAAAAILQi+Q4A4OhljRjFtyoIRILN0Yj+0TwHAdDTeJ8j1yg0AHqd5/nyXVcFN9+e7ygwiOv5uun8QfmOAaAXuJ4vz/PzHQPvEhQaAL3O83ztq2qQbVtdfgzHsVVSUqjq6ga5rpfDdN1najZTc0lSv35FcmzLuGwmrzNTs5maSzI3m6m5pJ7L5lFokEMUGgB5kauNmet6SqfN2gHIMDWbqbkkc7OZmksyN5upuSRzs5maSzI7G8DwdQAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFoUGgAAAAChRaEBAAAAEFqRfAdA19i2JccJ+mjm/01hai7J3Gym5pLMzWZqLsncbKbmas60bKauM8/z8x0BAIxBoQkh27ZU1q9QluNIkkpKCvOcqG2m5pLMzWZqLsncbKbmkszNZmou1/ONzWZaLtfzVVPdkO8YAGAECk0I2bYly3HUeMe35ZdvyXccAOi2+J0/ldO/THc+X6Hy/al8xzHaiP5R3XT+INm2le8oAGAECk2I+eVb5G1an+8YANB96bQkqXx/Spsqk3kOAwAIE7MGBQMAAABAJ1BoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaEU6c+ddu3bqyScf1bZtW1VVVSXPc1VWNkCTJ0/VBRe8T6Wl/XooJgAAAAC01qlCU1W1X9XVBzRt2gz169dfjuNo+/Ztmj//Jb3++iJ985u3qaSktGeSAgAAAMAhOlVoTjxxok48cWKrn48dO16///2v9eqrL+t977ssZ+EAAAAA4HBycg7NwIEDJUn19XW5eDgAAAAA6JBOHaHJSKWSSiQSSqVS2rVrpx5++H5J0uTJJ+U0HAAAAAAcTpcKzSuvvKx//OPe7L/79y/T1Vd/XuPHTzjscjNnTm33tvnz52nEiBFyHLMmXsvkMSmXSVkAAPlh25Yk87YJJm43M0zNZmouydxspuaSzM1mai5JsizJ97u+fJcKzbRpJ2vo0GOUSDRq27ZyrVixTHV1uRluVlJSmJPHyTVTcwEAjk7FxQWSzN0+mZpLMjebqbkkc7OZmksyN5upuVzX6/KyXSo0/fuXqX//MknStGkzNH36TN11121KpZK66KJL211uyZIV7d5WVtZHklRd3dCtXyjXHMdWSUmhUbkymQAAR6/a2kYVFxcYtX2SzNxuZpiazdRckrnZTM0lmZvN1FySVFravf3aLhWaQx133HANHz5C8+a9eNhC0xGu6ymdNmslS+bmAgAcnTwvGJ9h6vbJ1FySudlMzSWZm83UXJK52UzM1Z3hZlKOZjmTpGQypbq62lw9HAAAAAAcUacKzYEDVW3+fP36tdqx4x2NHn18LjIBAAAAQId0asjZfff9n6qrqzR+/ESVlQ1QKpVSefkWLVmySAUFBfrIRz7eUzkBAAAAoJVOFZpZs07RwoWvaNGiBaqpqZZlWSorG6AzzzxH733vxSorG9BTOQEAAACglU4VmpkzZ2vmzNk9lQUAAAAAOsW8K+sAAAAAQAdRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEViTfAdB11ohRNFIA7w6RYHM0on80z0HMxzoCgJYoNCHkeb5811XBzbfnOwoA5Izr+brp/EH5jhEKrufL8/x8xwAAI1BoQsjzfO2ralA06qikpFDV1Q1yXS/fsbIcxzYyl2RuNlNzSeZmMzWXZG42U3NJUr9+RXJsy7hspq4zz/Nl21a+YwCAESg0IeV5fnbj6rqe0mlzNrQZpuaSzM1mai7J3Gym5pLMzWZqLsncbCbmotAAQIBTMAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhRaAAAAACEFoUGAAAAQGhF8h0g7Gzbkm1beXlux7Fb/L8pTM0lmZvN1FySudlMzSWZm83UXM2Zlu1I68zzfHme35uRAACHoNB0g21bKutXKMtx8pqjpKQwr8/fHlNzSeZmMzWXZG42U3NJ5mYzNZfr+cZmay+X6/mq2l9HqQGAPKLQdINtW7IcR413fFt++ZZ8xwGA0Irf+VM5/ct05/MVKt+fynecDhnRP6qbzh8k27YoNACQRxSaHPDLt8jbtD7fMQAgvNJpSVL5/pQ2VSbzHAYAECZmDVYGAAAAgE6g0AAAAAAILQoNAAAAgNCi0AAAAAAILQoNAAAAgNCi0AAAAAAILQoNAAAAgNCi0AAAAAAILQoNAAAAgNCi0AAAAAAILQoNAAAAgNCi0AAAAAAILQoNAAAAgNCi0AAAAAAILQoNAAAAgNCi0AAAAAAILQoNAAAAgNCi0AAAAAAILQoNAAAAgNCKdPcBksmEbr/9FlVWVujMM8/RJz95dQ5iAQAAAMCRdfsIzWOPPayamppcZAEAAACATulWoSkv36oXX3xWl156ea7yAAAAAECHdbnQeJ6ne+/9oyZOnKzp02fmMhMAAAAAdEiXC80LLzyjnTt36OMf/1Qu8wAAAABAh3VpUoC9eyv1xBOP6JJL3q+BAwepsrKiQ8vNnDm13dvmz5+nESNGyHHMmngtk6etXKZlBQD0vnxtCw63fconU3NJ5mYzNZdkbjZTc0nmZjM1lyRZluT7XV++S4Xmvvv+T2VlA3TBBRd1/ZnbUVJSmPPHzAVTcwEA8ivf24d8P397TM0lmZvN1FySudlMzSWZm83UXK7rdXnZTheaxYtf0+rVK3TjjTfJcTq3+JIlK9q9raysjySpurqhW79QrjmOrZKSwjZzZW4DABy98rXdOtz2KZ9MzSWZm83UXJK52UzNJZmbzdRcklRa2r396U41knQ6rfvv/5umTDlJ/fuXZYeaVVXtlyQ1NjaqsrJCffr0UWFhUZcCua6ndNqslSyZmwsAkF/53j7k+/nbY2ouydxspuaSzM1mai7J3Gwm5urOcDOpk4UmmUyopqZaK1cu18qVy1vd/vrrC/X66wv1gQ98RBdddGn3kgEAAADAEXSq0MTjcV1zzbWtfl5TU6O//vVPmjhxss4661wdc8ywnAUEAAAAgPZ0qtA4TkTTps1o9fPM0LMBAwa2eTsAAAAA9ATz5m0DAAAAgA7q0rTNhxo4cJDuuedPuXgoAAAAAOgwjtAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQotAAAAAACC0KDQAAAIDQiuQ7wLuBNWIUzRAAuiMSbI5G9I/mOUjHhSkrALybUWi6wfN8+a6rgptvz3cUAAg91/N10/mD8h2jU1zPl+f5+Y4BAEc1Ck03eJ6vfVUNsm0rL8/vOLZKSgpVXd0g1/XykqEtpuaSzM1mai7J3Gym5pLMzWZqLknq169Ijm0Zl+1I68yj0ABA3lFousmEjZnrekqnzdkByDA1l2RuNlNzSeZmMzWXZG42U3NJ5mYzNRcAgEkBAAAAAIQYhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAIQWhQYAAABAaFFoAAAAAISWtWdPtZ/vEJI0cGCxLMuS63r5jtKK49hG5pLMzWZqLsncbKbmkszNZmouydxspuaybYttQBeYms3UXJK52UzNJZmbzdRckrnZTM1l25YkqbKytkvLR3IZpjt8X5KM6FatmPiHzzA1m6m5JHOzmZpLMjebqbkkc7OZmkuSfJ9tQGeZms3UXJK52UzNJZmbzdRckrnZTM0lZbpA1xhTaPbu7VojAwAAAHD04hwaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWhQaAAAAAKFFoQEAAAAQWpF8Pvm//vWEysu3qLx8qyorK1RWNkB33PGjXnnu119fqOeee1o7d+5QLBbXhAmT9MEPXqEBAwYecVnXTevZZ5/WokULVFlZoXg8rhNOOFGXX/5hDR16bF6z+b6vRYsWaN68F7Vnzy65rquysoGaNWuOzj33AhUUFPR6rvXr1+onP/n+Ye/zX//1TY0dO67Xs2V4nqdXXnlJCxa8op07d0jyNWDAIM2YMUuXXHJ5XnL96Ed3auPG9W3eds0112ratBldztXdbIf63e9+paVLX9eQIUN122135SWX66b197/fq61bN2vv3r1KJBpVWtpPo0aN0UUXXaLhw0d2K1d3stXV1Wnhwle1atVy7dq1U7W1NSorG6Bx48br4ovfr7KyAXnJJUlLlizW6tUrVF6+RTt37pDnefrud3+ggQMHdStTR/3973/Rq6/OVyqVlCSVlQ3QZz/7RY0de0KPPq/J6+zd9joz+b3ZFhM+zyTztwGmbTdN39cwcf9M6vl92sPJZQ+w9uyp9nOcr8OuueZq9enTR8OHj1J5+RYVFBT0SqGZO/d5/eMf9+r448dpzpxTVVtbqxdeeFaRSEQ33fQ/6tevf7vL+r6vX/3qJ1q1aoVOOmm6JkyYrNraGs2b96LS6ZS+9rVbdOyxw/KSTZIefvh+PfPMkxo/foKmTZsh27a1du1qLVv2hsaNG68bb7yp13NVVx/Q2rWrW/08nU7p3nv/pOLivrrrrh/LcbrWr7u7zlw3rXvu+YVWr16lWbNm6/jjx8mybO3dW6mammp96lOfzUuuH/3oTu3cuUNXXHFlq9tOOOFE9e9f1qVcucjW3MqVy/TrX/9MkUhUZWVl3doB6E6uRCKhH/3oTh1//DgNHDhQBQUF2rdvnxYsmK/q6gO69tobdeKJE/OSbfXqFfrlL3+i8eMn6sQTJ6i4uK927Niu+fNfUiTidOtzIxevsy1b3tZxxw1XfX29du/e1WuFJrPjWFBQoClTTlJNTY3WrVsjy7J0003/oxEjRvXI85q8zt6NrzOT35uHMuXzTDJ7G2DidtP0fQ0T9896ep/2SHLZA/J6hOY737lbgwYNliTdfvs31djY2OPPWVtbq0ceeUAjRozUDTf8txzHkSRNmjRFd911ux5//OHDvhGXL39Tq1at0JlnnqNPfvLq7M/nzDlNt99+i/75z7/qq1/9el6yua6ruXOf04gRI3XddV+TbQcjCs8++z36zW9+puXL39SuXTs63bi7m6ukpFRz5pzW6uevv75Qvu/rlFNO6/IHTHezSdJTTz2uVatW6MtfvkGTJk3pUo6eyCVJsViszXVnQjZJamxs1N/+9hedffZ7tGLFsrzmisfjuvnmW1v9/Mwzz9HNN9+oZ555sss7Td3NNmTIMbrttrs0ePCQFj+fMuUk/exnP9ATTzysL3zhy72eS5I+85kvqLS0nxzH0d/+9hft3r2r0zm6YvfuXVq69HVFozHdfffPFYvFJEkLF76qP/3pf/X739+j22/v3rfjbTF5nb1bX2cmvzebM+nzLMPUbYCJ202T9zVM3T/ryX3ajshlD8jrOTSZX6I3LV++VIlEo84994LsH16SRo4crbFjT9AbbyxWOp1ud/kNG9ZKkk499YwWPx80aLDGjTtB69at0b59e/OSzXVdpVIplZSUZt8sGaWlQUOPxeK9nqs9r7wyT5J0+ulnd3rZXGVLJBJ64YVnNXXqNE2aNEW+76uxsaHLeXKVqznP89TQ0CDP87qdK9fZHnvsQbmuq8sv/4hRuZorKSlVLBZTfX193rINHDio1U6mJE2YMEl9+vTR9u3v5CWXFAzxar5sb/nXv56QJM2efUq2zEjSKaecrsLCQu3Zs6tHvuQyeZ29m19nbTHhvdmcqZ9npm0DwrDdbM6EfQ1T9896cp+2I3LZA466SQG2bHlbkjRmzNhWtx1//Dg1NjZq166d7S6fSqUktf3Ci0aDjfLmzW/nJVssFtOYMWO1evVKPfPMU9qzZ7cqKys0f/5Leu21+Tr99LO6NIa6u7naUllZoQ0b1mns2BM0dOgxnc6Uq2ybNm1QY2ODRo0aowce+Luuv/4/9dWv/oduuOFL+vvf/6JkMpGXXBlVVVW67rprdP31/6HrrvuifvGLH2vr1s1dypTrbFu2vK25c5/XFVdcqcLCwm5lymUuz/NUW1uj6uoD2rp1s/74x9+psbFRkydPzXu2QzU01KuxsVF9+5YYlas3bN78liRpxozZrW475phgiMPq1Stz/rwmr7N3++vM5PemqZ9nJm4DTN9uNmfKvoap+2c9uU/b2/I65Cwfqqr2S1KbY08z4wz379+n444b3ubymQ3t+vVrWtwnmUxkX1j793etzXY3myT9+79foz/96X/18MP/1MMP/1OSZFmWLr30A10+SS8XuQ61YMHL8n1fp59+Vpcy5Spb5o3+4ovPyrJsXX75h1Ra2k/Lly/VSy+9oF27duq6674my7J6NZckDRgwUMcfP07Dhh2nSCSibdu26sUXn9cPfvA9ffnLN3R5iEYusrmuq3vv/aMmTJikmTPndClHT+SSpJ07d+g737kl+++CggK9970X6+KLL8t7tkM99dRjcl1Xp556ulG5ekNdXZ0ktXmeTOb32bFju2bMmJXT5zV5nb3bX2emvjdN/TwzdRtg8nbzUKbsa0hm7p/15D5tbzvqCk0yGcykE4m0/tWj0WiL+7RlzpxT9fTTj+nxxx/OziRRW1ujxx9/RLW1NUdcviezScG3AEOGDFVZ2QBNmjRFlmVp2bKlevzxh+V5ni677IN5ydWc53l67bVXVVBQ2O2dle5mSySCIS11dXW65ZbvZE9+O/nkINeiRa9pzZpVnR4jnIt1dvXVn2/x7+nTZ2r27NN0xx3/o/vu+7Nuv/3ws7n0ZLbnn/+Xdu/epS9+8douZeipXFIw7Oa6676mdDqtioo9ev3115RIJJROu10eP53r94AUzJT1/PPPaMKESTr11DONydVbXDcYBtHWzD6ZIWi5GMZyKJPX2bv9dWbqe9PUzzNTtwEmbzebM2lfQzJz/6wn92l721E35CyzoWxrTGFm2tDm47kP1adPsa677msaMGCQ/vrXP+mWW76mu+66XY2NDbrwwoslSQUFXTtc3d1syWRCd9/9XTU0NOjqqz+vWbNO0cyZc/S5z/2HTjvtTD311GPatm1rr+c61OrVK7V//z7NmjWnS2NGc5kt84YfNWpMq5k8Tjst+EYnM8a0N3O1Z+jQYzRjxmzt2bO7yycidzdbRcUePfHEo7rooktzOv41V+ssHg8+lKdMOUnvec8Fuu66r2vt2lX67W9/kfdsGStXLtef/vQ7DR8+Ql/4wpdajanOV67elNmBbes8mcyQla5+lh6Oyevs3f46M/G9afrn2aFM2AaEZbtp0r6GqftnPblP29uOukLT/BDcoaqqqiS1feiuueOOG6Fvfes7uu22u3TjjTfpttvu0te+9k2lUsELqqvjNLubbenSJdqzZ3eb30TMmDFbvu9rw4a257TvyVyHWrDgZUnSGWd0/QS9XGXL3FZa2q/VbaWlpZIODo3pzVyHk5lXPvPtSW9ne+CBv6moqEgzZ85RZWVF9n+e58l1XVVWVqi6+kCv52pPQUGBpk+foTVrVqmiYk+nl891ttWrV+i3v/2Fhgw5Rl/5ytdUWFjUpUy5ztXb+vTpI0kqL9/S6rb9+4NhFD0xXajJ6+xoe52Z8N4M2+eZlP9tQFi2mybta5i8f9ZT+7S97agrNKNGjZYkvf32pla3vfXWRsXjBR3+4w0ZMlTjxo3XkCFDJQXfBhQUFOr447t20abuZsuMpXRdt9VtmZ95XuvbejpXc9XV1VqxYpmGDRuukSNHdzpLrrONGjVGUtsfBvv2BT8rKen8ibS5XGeH2rNnd1Ou0i4t391se/dW6sCBKv3P//y3brnla9n/VVXtV2VlhW655Wv605/+t9dzHU4yGZz4WFdX26Xlc5Vt9eqVuueeX2jIkKG6/vqvq7i4uEt5cp0rHzLvvTfeWNzqtp07t0tSzqaDbfm85q6zo/F1lu/3Zhg/z/K9DQjDdtO0fY0w7J/lep+2tx11heakk05WLBbT3LnPtXhhbd26WZs2bdCMGbOyYxEPHKjSrl07OjRjx9y5z2nHjnd03nnvVTzetUOb3c2Wmb/8tddebfXYCxbMl3Twg6g3czW3cOGrcl1XZ5zRvRP0cpVt4MBBGjduvLZu3dziA8H3fb300guSpMmTT+r1XHV1dW0eQt66dbPeeGOxjj12WJeHR3Q32xVXfELXXHNtq//17dtX/fr11zXXXKtLL/1Ar+eqqaluc1rTAweqtHTp64rHC7r8jX8u3gNr1qzSPff8XIMHD9H1139DxcV9u5Ql17ny5X3vu1SStHjxwhZjtBcufFUNDQ0aPHhIt66c3R6T19m79XVm8nvT1M8zk7cBpm43mzNtXyMM+2fN5WKftrfldVKAhQtfzc5vXVNTI9dN66mnHpMkFRYW6dxzz8/5cxYX99Xll39E999/n37847s0Z85pqq2t0QsvPKu+fUt02WUfyt734Yfv18KFr+r667+h8eMnZH/+i1/8WAMHDtIxxxwry7K0Zs0qLV++VFOmnNSt2Vq6m23q1GkaNWqMVq9eoR/+8A5Nnz5DkqXly5dqw4Z1mjLlJI0bNz4v6yxjwYL5ikajmj07NxcKy0W2j33sKv3wh9/Tz3/+I5177vkqLS3VihXLtGbNKp122pltTofY07k2blynv/71zzr55FkaPHiwIpGo3nmnXK+99oocx9FVV30mb+usrb+rJP3zn/cpGo1q2rQZecm1ePFreuGFZzVt2gwNHDhIkYij3bt3a+HCV1RfX6+rrvpMl8dRdzfb1q2b9Zvf/Ey+7+u0085sczrirlw8Lxev/40b12vjxmCoQ3l5MB3sSy+9oKKiYIjSueee363hSu0ZMuQYTZt2spYtW6qvf/0rmjJlmmpqqrVu3RpZlqXPfvaanD+nZPY6e7e+zkx+b5r6eWbyNkAyc7vZnGn7Gibvn/XUPm1H5LIH5LXQvPrqy9mNQsZjjz0kKbhwWU8UGkk677z3qri4WM8//4zuv/8+xWIxTZgwSR/4wBXq37//EZcfM+Z4vfHGYi1c+IqkoHl//OOf0llnndvlky5zkc22bd1wwzc0d+4LWrJkoZ544hGlUikNHjxEl1/+YV1wwfvykivjrbc2ateuHZo165Ts+Plc6G62444brq9//Vt67LGHNG/ei0omExo0aLCuuOJKnXvuBXnJNWTIMRo3brzWrFmphQurlU6nVFraT7Nnn6oLL7wke0g4H9l6UndyjR07Xlu2bNbKlctUXX1A6XRaJSWlOvHESXrPey7o9mHz7mTbvv2d7Hz/99//tzbv09WrgXf3b7lu3Ro9+eSjLX72/PP/yv737Nmn9kihkaRrrvmK7rvvz3rttVf1+usLJQXjvT/zmS9mh1L0BJPX2bvxdWbye7MnvZu3ASZuNzNM3Ncwef+sJ/dpjySXPcDas6faz2k6AAAAAOglR905NAAAAADePSg0AAAAAEKLQgMAAAAgtCg0AAAAAEKLQgMAAAAgtCg0AAAAAEKLQgMAAAAgtCg0AAAAAEKLQgMAAAAgtCg0AAAAAEKLQgMAAAAgtCg0AAAAAEKLQgMAAAAgtP4/PT8ScCBpJ/kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "cow_id = X_test.index.copy()\n",
    "cow_id = cow_id.astype(str)\n",
    "\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "facecolor = '#eaeaf2'\n",
    "color_red = '#f44336'\n",
    "color_blue = '#4496df'\n",
    "index = cow_id\n",
    "column0 = prob_list[:, 0]\n",
    "column1 = prob_list[:, 1]\n",
    "title0 = 'Problematic Cows, test set'\n",
    "title1 = 'Normal Cows, test set'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5), facecolor=facecolor, ncols=2, sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0].barh(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes[0].set_title(title0, fontsize=18, pad=15, color=color_red, **hfont)\n",
    "axes[1].barh(index, column1, align='center', color=color_blue, zorder=10)\n",
    "axes[1].set_title(title1, fontsize=18, pad=15, color=color_blue, **hfont)\n",
    "\n",
    "# If you have positive numbers and want to invert the x-axis of the left plot\n",
    "axes[0].invert_xaxis() \n",
    "\n",
    "# To show data from highest to lowest\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "axes[0].set(yticks=cow_id, yticklabels=cow_id)\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[0].tick_params(axis='y', colors='black') # tick color\n",
    "\n",
    "axes[0].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[0].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "for label in (axes[0].get_xticklabels() + axes[0].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "for label in (axes[1].get_xticklabels() + axes[1].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, top=0.85, bottom=0.1, left=0.18, right=0.95)\n",
    "filename = 'Problematic_Cows'\n",
    "plt.savefig(filename+'.png', facecolor=facecolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5b35c659-e272-4de7-9c88-68deee33fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# Total_timeDelta_Seconds__minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "25d87e85-9998-4bf1-bbff-622b6174bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [274], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Plot decision boundary with uncertainty\u001b[39;00m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m---> 18\u001b[0m x_min, x_max \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m y_min, y_max \u001b[38;5;241m=\u001b[39m X[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39mlinspace(x_min, x_max, \u001b[38;5;241m100\u001b[39m),\n\u001b[1;32m     21\u001b[0m                      np\u001b[38;5;241m.\u001b[39mlinspace(y_min, y_max, \u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3810\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3810\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:5966\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5964\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5965\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5966\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = pd.DataFrame(ts_dataset['problematic'], columns=['problematic'])\n",
    "#X = pd.DataFrame(ts_dataset['Total_timeDelta_Seconds__minimum', 'Total_timeDelta_Seconds__root_mean_square'], columns=['Total_timeDelta_Seconds__minimum', 'Total_timeDelta_Seconds__root_mean_square'])\n",
    "\n",
    "X = pd.DataFrame(ts_dataset['Total_timeDelta_Seconds__minimum'], columns=['Total_timeDelta_Seconds__minimum'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the Gaussian Process model with an RBF kernel\n",
    "kernel = 1.0 * RBF(length_scale=1.0)\n",
    "gpc = GaussianProcessClassifier(kernel=kernel)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gpc.fit(X_train, y_train)\n",
    "\n",
    "# Plot decision boundary with uncertainty\n",
    "plt.figure(figsize=(10, 5))\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# Obtain predictions and uncertainties\n",
    "Z = gpc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "probs_mesh = gpc.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]  # Probability for class 1\n",
    "Z = Z.reshape(xx.shape)\n",
    "probs_mesh = probs_mesh.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundaries\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# Plot class probabilities as uncertainty\n",
    "plt.contourf(xx, yy, probs_mesh, cmap='RdYlBu', alpha=0.2)\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k')\n",
    "plt.title('Gaussian Process Classification with Uncertainty')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b89d5-1a20-4699-9c27-a83383e6918e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b17f1-6d3e-4567-b626-f2e78548914e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b08fc-5890-4205-9910-2501ef77cb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
